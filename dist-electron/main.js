var __defProp = Object.defineProperty;
var __typeError = (msg) => {
  throw TypeError(msg);
};
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField = (obj, key, value) => __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
var __accessCheck = (obj, member, msg) => member.has(obj) || __typeError("Cannot " + msg);
var __privateGet = (obj, member, getter) => (__accessCheck(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd = (obj, member, value) => member.has(obj) ? __typeError("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet = (obj, member, value, setter) => (__accessCheck(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var __privateMethod = (obj, member, method) => (__accessCheck(obj, member, "access private method"), method);
var _validator, _encryptionKey, _encryptionAlgorithm, _options, _defaultValues, _isInMigration, _watcher, _watchFile, _debouncedChangeHandler, _Conf_instances, prepareOptions_fn, setupValidator_fn, captureSchemaDefaults_fn, applyDefaultValues_fn, configureSerialization_fn, resolvePath_fn, initializeStore_fn, runMigrations_fn, _a;
import electron, { app as app$1, BrowserWindow, ipcMain as ipcMain$1, dialog, shell as shell$1 } from "electron";
import path$4 from "path";
import url, { fileURLToPath } from "url";
import process$1 from "node:process";
import path$3 from "node:path";
import { promisify, isDeepStrictEqual } from "node:util";
import fs$3 from "node:fs";
import crypto$1 from "node:crypto";
import assert from "node:assert";
import os$1 from "node:os";
import "node:events";
import "node:stream";
import { chromium } from "playwright";
import fs$4 from "fs";
import { ChromaClient, IncludeEnum } from "chromadb";
import require$$1$1 from "os";
import require$$3$2 from "perf_hooks";
import require$$4$1 from "util";
import require$$5$1 from "worker_threads";
import require$$7$2 from "crypto";
import require$$1$2 from "stream";
import require$$0$1 from "child_process";
import require$$2$1 from "events";
function _mergeNamespaces(n, m) {
  for (var i2 = 0; i2 < m.length; i2++) {
    const e = m[i2];
    if (typeof e !== "string" && !Array.isArray(e)) {
      for (const k in e) {
        if (k !== "default" && !(k in n)) {
          const d = Object.getOwnPropertyDescriptor(e, k);
          if (d) {
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: () => e[k]
            });
          }
        }
      }
    }
  }
  return Object.freeze(Object.defineProperty(n, Symbol.toStringTag, { value: "Module" }));
}
const isObject = (value) => {
  const type2 = typeof value;
  return value !== null && (type2 === "object" || type2 === "function");
};
const disallowedKeys = /* @__PURE__ */ new Set([
  "__proto__",
  "prototype",
  "constructor"
]);
const MAX_ARRAY_INDEX = 1e6;
const isDigit = (character) => character >= "0" && character <= "9";
function shouldCoerceToNumber(segment) {
  if (segment === "0") {
    return true;
  }
  if (/^[1-9]\d*$/.test(segment)) {
    const parsedNumber = Number.parseInt(segment, 10);
    return parsedNumber <= Number.MAX_SAFE_INTEGER && parsedNumber <= MAX_ARRAY_INDEX;
  }
  return false;
}
function processSegment(segment, parts) {
  if (disallowedKeys.has(segment)) {
    return false;
  }
  if (segment && shouldCoerceToNumber(segment)) {
    parts.push(Number.parseInt(segment, 10));
  } else {
    parts.push(segment);
  }
  return true;
}
function parsePath(path2) {
  if (typeof path2 !== "string") {
    throw new TypeError(`Expected a string, got ${typeof path2}`);
  }
  const parts = [];
  let currentSegment = "";
  let currentPart = "start";
  let isEscaping = false;
  let position2 = 0;
  for (const character of path2) {
    position2++;
    if (isEscaping) {
      currentSegment += character;
      isEscaping = false;
      continue;
    }
    if (character === "\\") {
      if (currentPart === "index") {
        throw new Error(`Invalid character '${character}' in an index at position ${position2}`);
      }
      if (currentPart === "indexEnd") {
        throw new Error(`Invalid character '${character}' after an index at position ${position2}`);
      }
      isEscaping = true;
      currentPart = currentPart === "start" ? "property" : currentPart;
      continue;
    }
    switch (character) {
      case ".": {
        if (currentPart === "index") {
          throw new Error(`Invalid character '${character}' in an index at position ${position2}`);
        }
        if (currentPart === "indexEnd") {
          currentPart = "property";
          break;
        }
        if (!processSegment(currentSegment, parts)) {
          return [];
        }
        currentSegment = "";
        currentPart = "property";
        break;
      }
      case "[": {
        if (currentPart === "index") {
          throw new Error(`Invalid character '${character}' in an index at position ${position2}`);
        }
        if (currentPart === "indexEnd") {
          currentPart = "index";
          break;
        }
        if (currentPart === "property" || currentPart === "start") {
          if ((currentSegment || currentPart === "property") && !processSegment(currentSegment, parts)) {
            return [];
          }
          currentSegment = "";
        }
        currentPart = "index";
        break;
      }
      case "]": {
        if (currentPart === "index") {
          if (currentSegment === "") {
            const lastSegment = parts.pop() || "";
            currentSegment = lastSegment + "[]";
            currentPart = "property";
          } else {
            const parsedNumber = Number.parseInt(currentSegment, 10);
            const isValidInteger = !Number.isNaN(parsedNumber) && Number.isFinite(parsedNumber) && parsedNumber >= 0 && parsedNumber <= Number.MAX_SAFE_INTEGER && parsedNumber <= MAX_ARRAY_INDEX && currentSegment === String(parsedNumber);
            if (isValidInteger) {
              parts.push(parsedNumber);
            } else {
              parts.push(currentSegment);
            }
            currentSegment = "";
            currentPart = "indexEnd";
          }
          break;
        }
        if (currentPart === "indexEnd") {
          throw new Error(`Invalid character '${character}' after an index at position ${position2}`);
        }
        currentSegment += character;
        break;
      }
      default: {
        if (currentPart === "index" && !isDigit(character)) {
          throw new Error(`Invalid character '${character}' in an index at position ${position2}`);
        }
        if (currentPart === "indexEnd") {
          throw new Error(`Invalid character '${character}' after an index at position ${position2}`);
        }
        if (currentPart === "start") {
          currentPart = "property";
        }
        currentSegment += character;
      }
    }
  }
  if (isEscaping) {
    currentSegment += "\\";
  }
  switch (currentPart) {
    case "property": {
      if (!processSegment(currentSegment, parts)) {
        return [];
      }
      break;
    }
    case "index": {
      throw new Error("Index was not closed");
    }
    case "start": {
      parts.push("");
      break;
    }
  }
  return parts;
}
function normalizePath(path2) {
  if (typeof path2 === "string") {
    return parsePath(path2);
  }
  if (Array.isArray(path2)) {
    const normalized = [];
    for (const [index2, segment] of path2.entries()) {
      if (typeof segment !== "string" && typeof segment !== "number") {
        throw new TypeError(`Expected a string or number for path segment at index ${index2}, got ${typeof segment}`);
      }
      if (typeof segment === "number" && !Number.isFinite(segment)) {
        throw new TypeError(`Path segment at index ${index2} must be a finite number, got ${segment}`);
      }
      if (disallowedKeys.has(segment)) {
        return [];
      }
      if (typeof segment === "string" && shouldCoerceToNumber(segment)) {
        normalized.push(Number.parseInt(segment, 10));
      } else {
        normalized.push(segment);
      }
    }
    return normalized;
  }
  return [];
}
function getProperty(object2, path2, value) {
  if (!isObject(object2) || typeof path2 !== "string" && !Array.isArray(path2)) {
    return value === void 0 ? object2 : value;
  }
  const pathArray = normalizePath(path2);
  if (pathArray.length === 0) {
    return value;
  }
  for (let index2 = 0; index2 < pathArray.length; index2++) {
    const key = pathArray[index2];
    object2 = object2[key];
    if (object2 === void 0 || object2 === null) {
      if (index2 !== pathArray.length - 1) {
        return value;
      }
      break;
    }
  }
  return object2 === void 0 ? value : object2;
}
function setProperty(object2, path2, value) {
  if (!isObject(object2) || typeof path2 !== "string" && !Array.isArray(path2)) {
    return object2;
  }
  const root = object2;
  const pathArray = normalizePath(path2);
  if (pathArray.length === 0) {
    return object2;
  }
  for (let index2 = 0; index2 < pathArray.length; index2++) {
    const key = pathArray[index2];
    if (index2 === pathArray.length - 1) {
      object2[key] = value;
    } else if (!isObject(object2[key])) {
      const nextKey = pathArray[index2 + 1];
      const shouldCreateArray = typeof nextKey === "number";
      object2[key] = shouldCreateArray ? [] : {};
    }
    object2 = object2[key];
  }
  return root;
}
function deleteProperty(object2, path2) {
  if (!isObject(object2) || typeof path2 !== "string" && !Array.isArray(path2)) {
    return false;
  }
  const pathArray = normalizePath(path2);
  if (pathArray.length === 0) {
    return false;
  }
  for (let index2 = 0; index2 < pathArray.length; index2++) {
    const key = pathArray[index2];
    if (index2 === pathArray.length - 1) {
      const existed = Object.hasOwn(object2, key);
      if (!existed) {
        return false;
      }
      delete object2[key];
      return true;
    }
    object2 = object2[key];
    if (!isObject(object2)) {
      return false;
    }
  }
}
function hasProperty(object2, path2) {
  if (!isObject(object2) || typeof path2 !== "string" && !Array.isArray(path2)) {
    return false;
  }
  const pathArray = normalizePath(path2);
  if (pathArray.length === 0) {
    return false;
  }
  for (const key of pathArray) {
    if (!isObject(object2) || !(key in object2)) {
      return false;
    }
    object2 = object2[key];
  }
  return true;
}
const homedir = os$1.homedir();
const tmpdir = os$1.tmpdir();
const { env: env$5 } = process$1;
const macos = (name2) => {
  const library = path$3.join(homedir, "Library");
  return {
    data: path$3.join(library, "Application Support", name2),
    config: path$3.join(library, "Preferences", name2),
    cache: path$3.join(library, "Caches", name2),
    log: path$3.join(library, "Logs", name2),
    temp: path$3.join(tmpdir, name2)
  };
};
const windows = (name2) => {
  const appData = env$5.APPDATA || path$3.join(homedir, "AppData", "Roaming");
  const localAppData = env$5.LOCALAPPDATA || path$3.join(homedir, "AppData", "Local");
  return {
    // Data/config/cache/log are invented by me as Windows isn't opinionated about this
    data: path$3.join(localAppData, name2, "Data"),
    config: path$3.join(appData, name2, "Config"),
    cache: path$3.join(localAppData, name2, "Cache"),
    log: path$3.join(localAppData, name2, "Log"),
    temp: path$3.join(tmpdir, name2)
  };
};
const linux = (name2) => {
  const username = path$3.basename(homedir);
  return {
    data: path$3.join(env$5.XDG_DATA_HOME || path$3.join(homedir, ".local", "share"), name2),
    config: path$3.join(env$5.XDG_CONFIG_HOME || path$3.join(homedir, ".config"), name2),
    cache: path$3.join(env$5.XDG_CACHE_HOME || path$3.join(homedir, ".cache"), name2),
    // https://wiki.debian.org/XDGBaseDirectorySpecification#state
    log: path$3.join(env$5.XDG_STATE_HOME || path$3.join(homedir, ".local", "state"), name2),
    temp: path$3.join(tmpdir, username, name2)
  };
};
function envPaths(name2, { suffix = "nodejs" } = {}) {
  if (typeof name2 !== "string") {
    throw new TypeError(`Expected a string, got ${typeof name2}`);
  }
  if (suffix) {
    name2 += `-${suffix}`;
  }
  if (process$1.platform === "darwin") {
    return macos(name2);
  }
  if (process$1.platform === "win32") {
    return windows(name2);
  }
  return linux(name2);
}
const attemptifyAsync = (fn2, options) => {
  const { onError } = options;
  return function attemptified(...args) {
    return fn2.apply(void 0, args).catch(onError);
  };
};
const attemptifySync = (fn2, options) => {
  const { onError } = options;
  return function attemptified(...args) {
    try {
      return fn2.apply(void 0, args);
    } catch (error2) {
      return onError(error2);
    }
  };
};
const RETRY_INTERVAL = 250;
const retryifyAsync = (fn2, options) => {
  const { isRetriable } = options;
  return function retryified(options2) {
    const { timeout: timeout2 } = options2;
    const interval = options2.interval ?? RETRY_INTERVAL;
    const timestamp = Date.now() + timeout2;
    return function attempt(...args) {
      return fn2.apply(void 0, args).catch((error2) => {
        if (!isRetriable(error2))
          throw error2;
        if (Date.now() >= timestamp)
          throw error2;
        const delay = Math.round(interval * Math.random());
        if (delay > 0) {
          const delayPromise = new Promise((resolve2) => setTimeout(resolve2, delay));
          return delayPromise.then(() => attempt.apply(void 0, args));
        } else {
          return attempt.apply(void 0, args);
        }
      });
    };
  };
};
const retryifySync = (fn2, options) => {
  const { isRetriable } = options;
  return function retryified(options2) {
    const { timeout: timeout2 } = options2;
    const timestamp = Date.now() + timeout2;
    return function attempt(...args) {
      while (true) {
        try {
          return fn2.apply(void 0, args);
        } catch (error2) {
          if (!isRetriable(error2))
            throw error2;
          if (Date.now() >= timestamp)
            throw error2;
          continue;
        }
      }
    };
  };
};
const Handlers = {
  /* API */
  isChangeErrorOk: (error2) => {
    if (!Handlers.isNodeError(error2))
      return false;
    const { code: code2 } = error2;
    if (code2 === "ENOSYS")
      return true;
    if (!IS_USER_ROOT && (code2 === "EINVAL" || code2 === "EPERM"))
      return true;
    return false;
  },
  isNodeError: (error2) => {
    return error2 instanceof Error;
  },
  isRetriableError: (error2) => {
    if (!Handlers.isNodeError(error2))
      return false;
    const { code: code2 } = error2;
    if (code2 === "EMFILE" || code2 === "ENFILE" || code2 === "EAGAIN" || code2 === "EBUSY" || code2 === "EACCESS" || code2 === "EACCES" || code2 === "EACCS" || code2 === "EPERM")
      return true;
    return false;
  },
  onChangeError: (error2) => {
    if (!Handlers.isNodeError(error2))
      throw error2;
    if (Handlers.isChangeErrorOk(error2))
      return;
    throw error2;
  }
};
const ATTEMPTIFY_CHANGE_ERROR_OPTIONS = {
  onError: Handlers.onChangeError
};
const ATTEMPTIFY_NOOP_OPTIONS = {
  onError: () => void 0
};
const IS_USER_ROOT = process$1.getuid ? !process$1.getuid() : false;
const RETRYIFY_OPTIONS = {
  isRetriable: Handlers.isRetriableError
};
const FS = {
  attempt: {
    /* ASYNC */
    chmod: attemptifyAsync(promisify(fs$3.chmod), ATTEMPTIFY_CHANGE_ERROR_OPTIONS),
    chown: attemptifyAsync(promisify(fs$3.chown), ATTEMPTIFY_CHANGE_ERROR_OPTIONS),
    close: attemptifyAsync(promisify(fs$3.close), ATTEMPTIFY_NOOP_OPTIONS),
    fsync: attemptifyAsync(promisify(fs$3.fsync), ATTEMPTIFY_NOOP_OPTIONS),
    mkdir: attemptifyAsync(promisify(fs$3.mkdir), ATTEMPTIFY_NOOP_OPTIONS),
    realpath: attemptifyAsync(promisify(fs$3.realpath), ATTEMPTIFY_NOOP_OPTIONS),
    stat: attemptifyAsync(promisify(fs$3.stat), ATTEMPTIFY_NOOP_OPTIONS),
    unlink: attemptifyAsync(promisify(fs$3.unlink), ATTEMPTIFY_NOOP_OPTIONS),
    /* SYNC */
    chmodSync: attemptifySync(fs$3.chmodSync, ATTEMPTIFY_CHANGE_ERROR_OPTIONS),
    chownSync: attemptifySync(fs$3.chownSync, ATTEMPTIFY_CHANGE_ERROR_OPTIONS),
    closeSync: attemptifySync(fs$3.closeSync, ATTEMPTIFY_NOOP_OPTIONS),
    existsSync: attemptifySync(fs$3.existsSync, ATTEMPTIFY_NOOP_OPTIONS),
    fsyncSync: attemptifySync(fs$3.fsync, ATTEMPTIFY_NOOP_OPTIONS),
    mkdirSync: attemptifySync(fs$3.mkdirSync, ATTEMPTIFY_NOOP_OPTIONS),
    realpathSync: attemptifySync(fs$3.realpathSync, ATTEMPTIFY_NOOP_OPTIONS),
    statSync: attemptifySync(fs$3.statSync, ATTEMPTIFY_NOOP_OPTIONS),
    unlinkSync: attemptifySync(fs$3.unlinkSync, ATTEMPTIFY_NOOP_OPTIONS)
  },
  retry: {
    /* ASYNC */
    close: retryifyAsync(promisify(fs$3.close), RETRYIFY_OPTIONS),
    fsync: retryifyAsync(promisify(fs$3.fsync), RETRYIFY_OPTIONS),
    open: retryifyAsync(promisify(fs$3.open), RETRYIFY_OPTIONS),
    readFile: retryifyAsync(promisify(fs$3.readFile), RETRYIFY_OPTIONS),
    rename: retryifyAsync(promisify(fs$3.rename), RETRYIFY_OPTIONS),
    stat: retryifyAsync(promisify(fs$3.stat), RETRYIFY_OPTIONS),
    write: retryifyAsync(promisify(fs$3.write), RETRYIFY_OPTIONS),
    writeFile: retryifyAsync(promisify(fs$3.writeFile), RETRYIFY_OPTIONS),
    /* SYNC */
    closeSync: retryifySync(fs$3.closeSync, RETRYIFY_OPTIONS),
    fsyncSync: retryifySync(fs$3.fsyncSync, RETRYIFY_OPTIONS),
    openSync: retryifySync(fs$3.openSync, RETRYIFY_OPTIONS),
    readFileSync: retryifySync(fs$3.readFileSync, RETRYIFY_OPTIONS),
    renameSync: retryifySync(fs$3.renameSync, RETRYIFY_OPTIONS),
    statSync: retryifySync(fs$3.statSync, RETRYIFY_OPTIONS),
    writeSync: retryifySync(fs$3.writeSync, RETRYIFY_OPTIONS),
    writeFileSync: retryifySync(fs$3.writeFileSync, RETRYIFY_OPTIONS)
  }
};
const DEFAULT_ENCODING = "utf8";
const DEFAULT_FILE_MODE = 438;
const DEFAULT_FOLDER_MODE = 511;
const DEFAULT_WRITE_OPTIONS = {};
const DEFAULT_USER_UID = process$1.geteuid ? process$1.geteuid() : -1;
const DEFAULT_USER_GID = process$1.getegid ? process$1.getegid() : -1;
const DEFAULT_TIMEOUT_SYNC = 1e3;
const IS_POSIX = !!process$1.getuid;
process$1.getuid ? !process$1.getuid() : false;
const LIMIT_BASENAME_LENGTH = 128;
const isException = (value) => {
  return value instanceof Error && "code" in value;
};
const isString = (value) => {
  return typeof value === "string";
};
const isUndefined = (value) => {
  return value === void 0;
};
const IS_LINUX = process$1.platform === "linux";
const IS_WINDOWS = process$1.platform === "win32";
const Signals = ["SIGHUP", "SIGINT", "SIGTERM"];
if (!IS_WINDOWS) {
  Signals.push("SIGALRM", "SIGABRT", "SIGVTALRM", "SIGXCPU", "SIGXFSZ", "SIGUSR2", "SIGTRAP", "SIGSYS", "SIGQUIT", "SIGIOT");
}
if (IS_LINUX) {
  Signals.push("SIGIO", "SIGPOLL", "SIGPWR", "SIGSTKFLT");
}
class Interceptor {
  /* CONSTRUCTOR */
  constructor() {
    this.callbacks = /* @__PURE__ */ new Set();
    this.exited = false;
    this.exit = (signal) => {
      if (this.exited)
        return;
      this.exited = true;
      for (const callback of this.callbacks) {
        callback();
      }
      if (signal) {
        if (IS_WINDOWS && (signal !== "SIGINT" && signal !== "SIGTERM" && signal !== "SIGKILL")) {
          process$1.kill(process$1.pid, "SIGTERM");
        } else {
          process$1.kill(process$1.pid, signal);
        }
      }
    };
    this.hook = () => {
      process$1.once("exit", () => this.exit());
      for (const signal of Signals) {
        try {
          process$1.once(signal, () => this.exit(signal));
        } catch {
        }
      }
    };
    this.register = (callback) => {
      this.callbacks.add(callback);
      return () => {
        this.callbacks.delete(callback);
      };
    };
    this.hook();
  }
}
const Interceptor$1 = new Interceptor();
const whenExit = Interceptor$1.register;
const Temp = {
  /* VARIABLES */
  store: {},
  // filePath => purge
  /* API */
  create: (filePath) => {
    const randomness = `000000${Math.floor(Math.random() * 16777215).toString(16)}`.slice(-6);
    const timestamp = Date.now().toString().slice(-10);
    const prefix = "tmp-";
    const suffix = `.${prefix}${timestamp}${randomness}`;
    const tempPath = `${filePath}${suffix}`;
    return tempPath;
  },
  get: (filePath, creator, purge = true) => {
    const tempPath = Temp.truncate(creator(filePath));
    if (tempPath in Temp.store)
      return Temp.get(filePath, creator, purge);
    Temp.store[tempPath] = purge;
    const disposer = () => delete Temp.store[tempPath];
    return [tempPath, disposer];
  },
  purge: (filePath) => {
    if (!Temp.store[filePath])
      return;
    delete Temp.store[filePath];
    FS.attempt.unlink(filePath);
  },
  purgeSync: (filePath) => {
    if (!Temp.store[filePath])
      return;
    delete Temp.store[filePath];
    FS.attempt.unlinkSync(filePath);
  },
  purgeSyncAll: () => {
    for (const filePath in Temp.store) {
      Temp.purgeSync(filePath);
    }
  },
  truncate: (filePath) => {
    const basename = path$3.basename(filePath);
    if (basename.length <= LIMIT_BASENAME_LENGTH)
      return filePath;
    const truncable = /^(\.?)(.*?)((?:\.[^.]+)?(?:\.tmp-\d{10}[a-f0-9]{6})?)$/.exec(basename);
    if (!truncable)
      return filePath;
    const truncationLength = basename.length - LIMIT_BASENAME_LENGTH;
    return `${filePath.slice(0, -basename.length)}${truncable[1]}${truncable[2].slice(0, -truncationLength)}${truncable[3]}`;
  }
};
whenExit(Temp.purgeSyncAll);
function writeFileSync(filePath, data, options = DEFAULT_WRITE_OPTIONS) {
  if (isString(options))
    return writeFileSync(filePath, data, { encoding: options });
  const timeout2 = options.timeout ?? DEFAULT_TIMEOUT_SYNC;
  const retryOptions = { timeout: timeout2 };
  let tempDisposer = null;
  let tempPath = null;
  let fd = null;
  try {
    const filePathReal = FS.attempt.realpathSync(filePath);
    const filePathExists = !!filePathReal;
    filePath = filePathReal || filePath;
    [tempPath, tempDisposer] = Temp.get(filePath, options.tmpCreate || Temp.create, !(options.tmpPurge === false));
    const useStatChown = IS_POSIX && isUndefined(options.chown);
    const useStatMode = isUndefined(options.mode);
    if (filePathExists && (useStatChown || useStatMode)) {
      const stats2 = FS.attempt.statSync(filePath);
      if (stats2) {
        options = { ...options };
        if (useStatChown) {
          options.chown = { uid: stats2.uid, gid: stats2.gid };
        }
        if (useStatMode) {
          options.mode = stats2.mode;
        }
      }
    }
    if (!filePathExists) {
      const parentPath = path$3.dirname(filePath);
      FS.attempt.mkdirSync(parentPath, {
        mode: DEFAULT_FOLDER_MODE,
        recursive: true
      });
    }
    fd = FS.retry.openSync(retryOptions)(tempPath, "w", options.mode || DEFAULT_FILE_MODE);
    if (options.tmpCreated) {
      options.tmpCreated(tempPath);
    }
    if (isString(data)) {
      FS.retry.writeSync(retryOptions)(fd, data, 0, options.encoding || DEFAULT_ENCODING);
    } else if (!isUndefined(data)) {
      FS.retry.writeSync(retryOptions)(fd, data, 0, data.length, 0);
    }
    if (options.fsync !== false) {
      if (options.fsyncWait !== false) {
        FS.retry.fsyncSync(retryOptions)(fd);
      } else {
        FS.attempt.fsync(fd);
      }
    }
    FS.retry.closeSync(retryOptions)(fd);
    fd = null;
    if (options.chown && (options.chown.uid !== DEFAULT_USER_UID || options.chown.gid !== DEFAULT_USER_GID)) {
      FS.attempt.chownSync(tempPath, options.chown.uid, options.chown.gid);
    }
    if (options.mode && options.mode !== DEFAULT_FILE_MODE) {
      FS.attempt.chmodSync(tempPath, options.mode);
    }
    try {
      FS.retry.renameSync(retryOptions)(tempPath, filePath);
    } catch (error2) {
      if (!isException(error2))
        throw error2;
      if (error2.code !== "ENAMETOOLONG")
        throw error2;
      FS.retry.renameSync(retryOptions)(tempPath, Temp.truncate(filePath));
    }
    tempDisposer();
    tempPath = null;
  } finally {
    if (fd)
      FS.attempt.closeSync(fd);
    if (tempPath)
      Temp.purge(tempPath);
  }
}
var commonjsGlobal = typeof globalThis !== "undefined" ? globalThis : typeof window !== "undefined" ? window : typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : {};
function getDefaultExportFromCjs(x) {
  return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, "default") ? x["default"] : x;
}
function getAugmentedNamespace(n) {
  if (n.__esModule) return n;
  var f = n.default;
  if (typeof f == "function") {
    var a = function a2() {
      if (this instanceof a2) {
        return Reflect.construct(f, arguments, this.constructor);
      }
      return f.apply(this, arguments);
    };
    a.prototype = f.prototype;
  } else a = {};
  Object.defineProperty(a, "__esModule", { value: true });
  Object.keys(n).forEach(function(k) {
    var d = Object.getOwnPropertyDescriptor(n, k);
    Object.defineProperty(a, k, d.get ? d : {
      enumerable: true,
      get: function() {
        return n[k];
      }
    });
  });
  return a;
}
var _2020 = { exports: {} };
var core$6 = {};
var validate$1 = {};
var boolSchema$1 = {};
var errors$1 = {};
var codegen$1 = {};
var code$3 = {};
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.regexpCode = exports$12.getEsmExportName = exports$12.getProperty = exports$12.safeStringify = exports$12.stringify = exports$12.strConcat = exports$12.addCodeArg = exports$12.str = exports$12._ = exports$12.nil = exports$12._Code = exports$12.Name = exports$12.IDENTIFIER = exports$12._CodeOrName = void 0;
  class _CodeOrName {
  }
  exports$12._CodeOrName = _CodeOrName;
  exports$12.IDENTIFIER = /^[a-z$_][a-z$_0-9]*$/i;
  class Name extends _CodeOrName {
    constructor(s) {
      super();
      if (!exports$12.IDENTIFIER.test(s))
        throw new Error("CodeGen: name must be a valid identifier");
      this.str = s;
    }
    toString() {
      return this.str;
    }
    emptyStr() {
      return false;
    }
    get names() {
      return { [this.str]: 1 };
    }
  }
  exports$12.Name = Name;
  class _Code extends _CodeOrName {
    constructor(code2) {
      super();
      this._items = typeof code2 === "string" ? [code2] : code2;
    }
    toString() {
      return this.str;
    }
    emptyStr() {
      if (this._items.length > 1)
        return false;
      const item = this._items[0];
      return item === "" || item === '""';
    }
    get str() {
      var _a2;
      return (_a2 = this._str) !== null && _a2 !== void 0 ? _a2 : this._str = this._items.reduce((s, c) => `${s}${c}`, "");
    }
    get names() {
      var _a2;
      return (_a2 = this._names) !== null && _a2 !== void 0 ? _a2 : this._names = this._items.reduce((names2, c) => {
        if (c instanceof Name)
          names2[c.str] = (names2[c.str] || 0) + 1;
        return names2;
      }, {});
    }
  }
  exports$12._Code = _Code;
  exports$12.nil = new _Code("");
  function _(strs, ...args) {
    const code2 = [strs[0]];
    let i2 = 0;
    while (i2 < args.length) {
      addCodeArg(code2, args[i2]);
      code2.push(strs[++i2]);
    }
    return new _Code(code2);
  }
  exports$12._ = _;
  const plus = new _Code("+");
  function str(strs, ...args) {
    const expr = [safeStringify(strs[0])];
    let i2 = 0;
    while (i2 < args.length) {
      expr.push(plus);
      addCodeArg(expr, args[i2]);
      expr.push(plus, safeStringify(strs[++i2]));
    }
    optimize(expr);
    return new _Code(expr);
  }
  exports$12.str = str;
  function addCodeArg(code2, arg) {
    if (arg instanceof _Code)
      code2.push(...arg._items);
    else if (arg instanceof Name)
      code2.push(arg);
    else
      code2.push(interpolate2(arg));
  }
  exports$12.addCodeArg = addCodeArg;
  function optimize(expr) {
    let i2 = 1;
    while (i2 < expr.length - 1) {
      if (expr[i2] === plus) {
        const res = mergeExprItems(expr[i2 - 1], expr[i2 + 1]);
        if (res !== void 0) {
          expr.splice(i2 - 1, 3, res);
          continue;
        }
        expr[i2++] = "+";
      }
      i2++;
    }
  }
  function mergeExprItems(a, b) {
    if (b === '""')
      return a;
    if (a === '""')
      return b;
    if (typeof a == "string") {
      if (b instanceof Name || a[a.length - 1] !== '"')
        return;
      if (typeof b != "string")
        return `${a.slice(0, -1)}${b}"`;
      if (b[0] === '"')
        return a.slice(0, -1) + b.slice(1);
      return;
    }
    if (typeof b == "string" && b[0] === '"' && !(a instanceof Name))
      return `"${a}${b.slice(1)}`;
    return;
  }
  function strConcat(c1, c2) {
    return c2.emptyStr() ? c1 : c1.emptyStr() ? c2 : str`${c1}${c2}`;
  }
  exports$12.strConcat = strConcat;
  function interpolate2(x) {
    return typeof x == "number" || typeof x == "boolean" || x === null ? x : safeStringify(Array.isArray(x) ? x.join(",") : x);
  }
  function stringify(x) {
    return new _Code(safeStringify(x));
  }
  exports$12.stringify = stringify;
  function safeStringify(x) {
    return JSON.stringify(x).replace(/\u2028/g, "\\u2028").replace(/\u2029/g, "\\u2029");
  }
  exports$12.safeStringify = safeStringify;
  function getProperty2(key) {
    return typeof key == "string" && exports$12.IDENTIFIER.test(key) ? new _Code(`.${key}`) : _`[${key}]`;
  }
  exports$12.getProperty = getProperty2;
  function getEsmExportName(key) {
    if (typeof key == "string" && exports$12.IDENTIFIER.test(key)) {
      return new _Code(`${key}`);
    }
    throw new Error(`CodeGen: invalid export name: ${key}, use explicit $id name mapping`);
  }
  exports$12.getEsmExportName = getEsmExportName;
  function regexpCode(rx) {
    return new _Code(rx.toString());
  }
  exports$12.regexpCode = regexpCode;
})(code$3);
var scope$1 = {};
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.ValueScope = exports$12.ValueScopeName = exports$12.Scope = exports$12.varKinds = exports$12.UsedValueState = void 0;
  const code_12 = code$3;
  class ValueError extends Error {
    constructor(name2) {
      super(`CodeGen: "code" for ${name2} not defined`);
      this.value = name2.value;
    }
  }
  var UsedValueState;
  (function(UsedValueState2) {
    UsedValueState2[UsedValueState2["Started"] = 0] = "Started";
    UsedValueState2[UsedValueState2["Completed"] = 1] = "Completed";
  })(UsedValueState || (exports$12.UsedValueState = UsedValueState = {}));
  exports$12.varKinds = {
    const: new code_12.Name("const"),
    let: new code_12.Name("let"),
    var: new code_12.Name("var")
  };
  class Scope {
    constructor({ prefixes, parent } = {}) {
      this._names = {};
      this._prefixes = prefixes;
      this._parent = parent;
    }
    toName(nameOrPrefix) {
      return nameOrPrefix instanceof code_12.Name ? nameOrPrefix : this.name(nameOrPrefix);
    }
    name(prefix) {
      return new code_12.Name(this._newName(prefix));
    }
    _newName(prefix) {
      const ng = this._names[prefix] || this._nameGroup(prefix);
      return `${prefix}${ng.index++}`;
    }
    _nameGroup(prefix) {
      var _a2, _b;
      if (((_b = (_a2 = this._parent) === null || _a2 === void 0 ? void 0 : _a2._prefixes) === null || _b === void 0 ? void 0 : _b.has(prefix)) || this._prefixes && !this._prefixes.has(prefix)) {
        throw new Error(`CodeGen: prefix "${prefix}" is not allowed in this scope`);
      }
      return this._names[prefix] = { prefix, index: 0 };
    }
  }
  exports$12.Scope = Scope;
  class ValueScopeName extends code_12.Name {
    constructor(prefix, nameStr) {
      super(nameStr);
      this.prefix = prefix;
    }
    setValue(value, { property, itemIndex }) {
      this.value = value;
      this.scopePath = (0, code_12._)`.${new code_12.Name(property)}[${itemIndex}]`;
    }
  }
  exports$12.ValueScopeName = ValueScopeName;
  const line = (0, code_12._)`\n`;
  class ValueScope extends Scope {
    constructor(opts) {
      super(opts);
      this._values = {};
      this._scope = opts.scope;
      this.opts = { ...opts, _n: opts.lines ? line : code_12.nil };
    }
    get() {
      return this._scope;
    }
    name(prefix) {
      return new ValueScopeName(prefix, this._newName(prefix));
    }
    value(nameOrPrefix, value) {
      var _a2;
      if (value.ref === void 0)
        throw new Error("CodeGen: ref must be passed in value");
      const name2 = this.toName(nameOrPrefix);
      const { prefix } = name2;
      const valueKey = (_a2 = value.key) !== null && _a2 !== void 0 ? _a2 : value.ref;
      let vs = this._values[prefix];
      if (vs) {
        const _name = vs.get(valueKey);
        if (_name)
          return _name;
      } else {
        vs = this._values[prefix] = /* @__PURE__ */ new Map();
      }
      vs.set(valueKey, name2);
      const s = this._scope[prefix] || (this._scope[prefix] = []);
      const itemIndex = s.length;
      s[itemIndex] = value.ref;
      name2.setValue(value, { property: prefix, itemIndex });
      return name2;
    }
    getValue(prefix, keyOrRef) {
      const vs = this._values[prefix];
      if (!vs)
        return;
      return vs.get(keyOrRef);
    }
    scopeRefs(scopeName, values = this._values) {
      return this._reduceValues(values, (name2) => {
        if (name2.scopePath === void 0)
          throw new Error(`CodeGen: name "${name2}" has no value`);
        return (0, code_12._)`${scopeName}${name2.scopePath}`;
      });
    }
    scopeCode(values = this._values, usedValues, getCode) {
      return this._reduceValues(values, (name2) => {
        if (name2.value === void 0)
          throw new Error(`CodeGen: name "${name2}" has no value`);
        return name2.value.code;
      }, usedValues, getCode);
    }
    _reduceValues(values, valueCode, usedValues = {}, getCode) {
      let code2 = code_12.nil;
      for (const prefix in values) {
        const vs = values[prefix];
        if (!vs)
          continue;
        const nameSet = usedValues[prefix] = usedValues[prefix] || /* @__PURE__ */ new Map();
        vs.forEach((name2) => {
          if (nameSet.has(name2))
            return;
          nameSet.set(name2, UsedValueState.Started);
          let c = valueCode(name2);
          if (c) {
            const def2 = this.opts.es5 ? exports$12.varKinds.var : exports$12.varKinds.const;
            code2 = (0, code_12._)`${code2}${def2} ${name2} = ${c};${this.opts._n}`;
          } else if (c = getCode === null || getCode === void 0 ? void 0 : getCode(name2)) {
            code2 = (0, code_12._)`${code2}${c}${this.opts._n}`;
          } else {
            throw new ValueError(name2);
          }
          nameSet.set(name2, UsedValueState.Completed);
        });
      }
      return code2;
    }
  }
  exports$12.ValueScope = ValueScope;
})(scope$1);
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.or = exports$12.and = exports$12.not = exports$12.CodeGen = exports$12.operators = exports$12.varKinds = exports$12.ValueScopeName = exports$12.ValueScope = exports$12.Scope = exports$12.Name = exports$12.regexpCode = exports$12.stringify = exports$12.getProperty = exports$12.nil = exports$12.strConcat = exports$12.str = exports$12._ = void 0;
  const code_12 = code$3;
  const scope_1 = scope$1;
  var code_2 = code$3;
  Object.defineProperty(exports$12, "_", { enumerable: true, get: function() {
    return code_2._;
  } });
  Object.defineProperty(exports$12, "str", { enumerable: true, get: function() {
    return code_2.str;
  } });
  Object.defineProperty(exports$12, "strConcat", { enumerable: true, get: function() {
    return code_2.strConcat;
  } });
  Object.defineProperty(exports$12, "nil", { enumerable: true, get: function() {
    return code_2.nil;
  } });
  Object.defineProperty(exports$12, "getProperty", { enumerable: true, get: function() {
    return code_2.getProperty;
  } });
  Object.defineProperty(exports$12, "stringify", { enumerable: true, get: function() {
    return code_2.stringify;
  } });
  Object.defineProperty(exports$12, "regexpCode", { enumerable: true, get: function() {
    return code_2.regexpCode;
  } });
  Object.defineProperty(exports$12, "Name", { enumerable: true, get: function() {
    return code_2.Name;
  } });
  var scope_2 = scope$1;
  Object.defineProperty(exports$12, "Scope", { enumerable: true, get: function() {
    return scope_2.Scope;
  } });
  Object.defineProperty(exports$12, "ValueScope", { enumerable: true, get: function() {
    return scope_2.ValueScope;
  } });
  Object.defineProperty(exports$12, "ValueScopeName", { enumerable: true, get: function() {
    return scope_2.ValueScopeName;
  } });
  Object.defineProperty(exports$12, "varKinds", { enumerable: true, get: function() {
    return scope_2.varKinds;
  } });
  exports$12.operators = {
    GT: new code_12._Code(">"),
    GTE: new code_12._Code(">="),
    LT: new code_12._Code("<"),
    LTE: new code_12._Code("<="),
    EQ: new code_12._Code("==="),
    NEQ: new code_12._Code("!=="),
    NOT: new code_12._Code("!"),
    OR: new code_12._Code("||"),
    AND: new code_12._Code("&&"),
    ADD: new code_12._Code("+")
  };
  class Node {
    optimizeNodes() {
      return this;
    }
    optimizeNames(_names, _constants) {
      return this;
    }
  }
  class Def extends Node {
    constructor(varKind, name2, rhs) {
      super();
      this.varKind = varKind;
      this.name = name2;
      this.rhs = rhs;
    }
    render({ es5, _n }) {
      const varKind = es5 ? scope_1.varKinds.var : this.varKind;
      const rhs = this.rhs === void 0 ? "" : ` = ${this.rhs}`;
      return `${varKind} ${this.name}${rhs};` + _n;
    }
    optimizeNames(names2, constants2) {
      if (!names2[this.name.str])
        return;
      if (this.rhs)
        this.rhs = optimizeExpr(this.rhs, names2, constants2);
      return this;
    }
    get names() {
      return this.rhs instanceof code_12._CodeOrName ? this.rhs.names : {};
    }
  }
  class Assign extends Node {
    constructor(lhs, rhs, sideEffects) {
      super();
      this.lhs = lhs;
      this.rhs = rhs;
      this.sideEffects = sideEffects;
    }
    render({ _n }) {
      return `${this.lhs} = ${this.rhs};` + _n;
    }
    optimizeNames(names2, constants2) {
      if (this.lhs instanceof code_12.Name && !names2[this.lhs.str] && !this.sideEffects)
        return;
      this.rhs = optimizeExpr(this.rhs, names2, constants2);
      return this;
    }
    get names() {
      const names2 = this.lhs instanceof code_12.Name ? {} : { ...this.lhs.names };
      return addExprNames(names2, this.rhs);
    }
  }
  class AssignOp extends Assign {
    constructor(lhs, op, rhs, sideEffects) {
      super(lhs, rhs, sideEffects);
      this.op = op;
    }
    render({ _n }) {
      return `${this.lhs} ${this.op}= ${this.rhs};` + _n;
    }
  }
  class Label extends Node {
    constructor(label) {
      super();
      this.label = label;
      this.names = {};
    }
    render({ _n }) {
      return `${this.label}:` + _n;
    }
  }
  class Break extends Node {
    constructor(label) {
      super();
      this.label = label;
      this.names = {};
    }
    render({ _n }) {
      const label = this.label ? ` ${this.label}` : "";
      return `break${label};` + _n;
    }
  }
  class Throw extends Node {
    constructor(error2) {
      super();
      this.error = error2;
    }
    render({ _n }) {
      return `throw ${this.error};` + _n;
    }
    get names() {
      return this.error.names;
    }
  }
  class AnyCode extends Node {
    constructor(code2) {
      super();
      this.code = code2;
    }
    render({ _n }) {
      return `${this.code};` + _n;
    }
    optimizeNodes() {
      return `${this.code}` ? this : void 0;
    }
    optimizeNames(names2, constants2) {
      this.code = optimizeExpr(this.code, names2, constants2);
      return this;
    }
    get names() {
      return this.code instanceof code_12._CodeOrName ? this.code.names : {};
    }
  }
  class ParentNode extends Node {
    constructor(nodes = []) {
      super();
      this.nodes = nodes;
    }
    render(opts) {
      return this.nodes.reduce((code2, n) => code2 + n.render(opts), "");
    }
    optimizeNodes() {
      const { nodes } = this;
      let i2 = nodes.length;
      while (i2--) {
        const n = nodes[i2].optimizeNodes();
        if (Array.isArray(n))
          nodes.splice(i2, 1, ...n);
        else if (n)
          nodes[i2] = n;
        else
          nodes.splice(i2, 1);
      }
      return nodes.length > 0 ? this : void 0;
    }
    optimizeNames(names2, constants2) {
      const { nodes } = this;
      let i2 = nodes.length;
      while (i2--) {
        const n = nodes[i2];
        if (n.optimizeNames(names2, constants2))
          continue;
        subtractNames(names2, n.names);
        nodes.splice(i2, 1);
      }
      return nodes.length > 0 ? this : void 0;
    }
    get names() {
      return this.nodes.reduce((names2, n) => addNames(names2, n.names), {});
    }
  }
  class BlockNode extends ParentNode {
    render(opts) {
      return "{" + opts._n + super.render(opts) + "}" + opts._n;
    }
  }
  class Root extends ParentNode {
  }
  class Else extends BlockNode {
  }
  Else.kind = "else";
  class If2 extends BlockNode {
    constructor(condition, nodes) {
      super(nodes);
      this.condition = condition;
    }
    render(opts) {
      let code2 = `if(${this.condition})` + super.render(opts);
      if (this.else)
        code2 += "else " + this.else.render(opts);
      return code2;
    }
    optimizeNodes() {
      super.optimizeNodes();
      const cond = this.condition;
      if (cond === true)
        return this.nodes;
      let e = this.else;
      if (e) {
        const ns = e.optimizeNodes();
        e = this.else = Array.isArray(ns) ? new Else(ns) : ns;
      }
      if (e) {
        if (cond === false)
          return e instanceof If2 ? e : e.nodes;
        if (this.nodes.length)
          return this;
        return new If2(not2(cond), e instanceof If2 ? [e] : e.nodes);
      }
      if (cond === false || !this.nodes.length)
        return void 0;
      return this;
    }
    optimizeNames(names2, constants2) {
      var _a2;
      this.else = (_a2 = this.else) === null || _a2 === void 0 ? void 0 : _a2.optimizeNames(names2, constants2);
      if (!(super.optimizeNames(names2, constants2) || this.else))
        return;
      this.condition = optimizeExpr(this.condition, names2, constants2);
      return this;
    }
    get names() {
      const names2 = super.names;
      addExprNames(names2, this.condition);
      if (this.else)
        addNames(names2, this.else.names);
      return names2;
    }
  }
  If2.kind = "if";
  class For2 extends BlockNode {
  }
  For2.kind = "for";
  class ForLoop extends For2 {
    constructor(iteration) {
      super();
      this.iteration = iteration;
    }
    render(opts) {
      return `for(${this.iteration})` + super.render(opts);
    }
    optimizeNames(names2, constants2) {
      if (!super.optimizeNames(names2, constants2))
        return;
      this.iteration = optimizeExpr(this.iteration, names2, constants2);
      return this;
    }
    get names() {
      return addNames(super.names, this.iteration.names);
    }
  }
  class ForRange extends For2 {
    constructor(varKind, name2, from, to) {
      super();
      this.varKind = varKind;
      this.name = name2;
      this.from = from;
      this.to = to;
    }
    render(opts) {
      const varKind = opts.es5 ? scope_1.varKinds.var : this.varKind;
      const { name: name2, from, to } = this;
      return `for(${varKind} ${name2}=${from}; ${name2}<${to}; ${name2}++)` + super.render(opts);
    }
    get names() {
      const names2 = addExprNames(super.names, this.from);
      return addExprNames(names2, this.to);
    }
  }
  class ForIter extends For2 {
    constructor(loop, varKind, name2, iterable) {
      super();
      this.loop = loop;
      this.varKind = varKind;
      this.name = name2;
      this.iterable = iterable;
    }
    render(opts) {
      return `for(${this.varKind} ${this.name} ${this.loop} ${this.iterable})` + super.render(opts);
    }
    optimizeNames(names2, constants2) {
      if (!super.optimizeNames(names2, constants2))
        return;
      this.iterable = optimizeExpr(this.iterable, names2, constants2);
      return this;
    }
    get names() {
      return addNames(super.names, this.iterable.names);
    }
  }
  class Func extends BlockNode {
    constructor(name2, args, async) {
      super();
      this.name = name2;
      this.args = args;
      this.async = async;
    }
    render(opts) {
      const _async = this.async ? "async " : "";
      return `${_async}function ${this.name}(${this.args})` + super.render(opts);
    }
  }
  Func.kind = "func";
  class Return extends ParentNode {
    render(opts) {
      return "return " + super.render(opts);
    }
  }
  Return.kind = "return";
  class Try extends BlockNode {
    render(opts) {
      let code2 = "try" + super.render(opts);
      if (this.catch)
        code2 += this.catch.render(opts);
      if (this.finally)
        code2 += this.finally.render(opts);
      return code2;
    }
    optimizeNodes() {
      var _a2, _b;
      super.optimizeNodes();
      (_a2 = this.catch) === null || _a2 === void 0 ? void 0 : _a2.optimizeNodes();
      (_b = this.finally) === null || _b === void 0 ? void 0 : _b.optimizeNodes();
      return this;
    }
    optimizeNames(names2, constants2) {
      var _a2, _b;
      super.optimizeNames(names2, constants2);
      (_a2 = this.catch) === null || _a2 === void 0 ? void 0 : _a2.optimizeNames(names2, constants2);
      (_b = this.finally) === null || _b === void 0 ? void 0 : _b.optimizeNames(names2, constants2);
      return this;
    }
    get names() {
      const names2 = super.names;
      if (this.catch)
        addNames(names2, this.catch.names);
      if (this.finally)
        addNames(names2, this.finally.names);
      return names2;
    }
  }
  class Catch extends BlockNode {
    constructor(error2) {
      super();
      this.error = error2;
    }
    render(opts) {
      return `catch(${this.error})` + super.render(opts);
    }
  }
  Catch.kind = "catch";
  class Finally extends BlockNode {
    render(opts) {
      return "finally" + super.render(opts);
    }
  }
  Finally.kind = "finally";
  class CodeGen {
    constructor(extScope, opts = {}) {
      this._values = {};
      this._blockStarts = [];
      this._constants = {};
      this.opts = { ...opts, _n: opts.lines ? "\n" : "" };
      this._extScope = extScope;
      this._scope = new scope_1.Scope({ parent: extScope });
      this._nodes = [new Root()];
    }
    toString() {
      return this._root.render(this.opts);
    }
    // returns unique name in the internal scope
    name(prefix) {
      return this._scope.name(prefix);
    }
    // reserves unique name in the external scope
    scopeName(prefix) {
      return this._extScope.name(prefix);
    }
    // reserves unique name in the external scope and assigns value to it
    scopeValue(prefixOrName, value) {
      const name2 = this._extScope.value(prefixOrName, value);
      const vs = this._values[name2.prefix] || (this._values[name2.prefix] = /* @__PURE__ */ new Set());
      vs.add(name2);
      return name2;
    }
    getScopeValue(prefix, keyOrRef) {
      return this._extScope.getValue(prefix, keyOrRef);
    }
    // return code that assigns values in the external scope to the names that are used internally
    // (same names that were returned by gen.scopeName or gen.scopeValue)
    scopeRefs(scopeName) {
      return this._extScope.scopeRefs(scopeName, this._values);
    }
    scopeCode() {
      return this._extScope.scopeCode(this._values);
    }
    _def(varKind, nameOrPrefix, rhs, constant) {
      const name2 = this._scope.toName(nameOrPrefix);
      if (rhs !== void 0 && constant)
        this._constants[name2.str] = rhs;
      this._leafNode(new Def(varKind, name2, rhs));
      return name2;
    }
    // `const` declaration (`var` in es5 mode)
    const(nameOrPrefix, rhs, _constant) {
      return this._def(scope_1.varKinds.const, nameOrPrefix, rhs, _constant);
    }
    // `let` declaration with optional assignment (`var` in es5 mode)
    let(nameOrPrefix, rhs, _constant) {
      return this._def(scope_1.varKinds.let, nameOrPrefix, rhs, _constant);
    }
    // `var` declaration with optional assignment
    var(nameOrPrefix, rhs, _constant) {
      return this._def(scope_1.varKinds.var, nameOrPrefix, rhs, _constant);
    }
    // assignment code
    assign(lhs, rhs, sideEffects) {
      return this._leafNode(new Assign(lhs, rhs, sideEffects));
    }
    // `+=` code
    add(lhs, rhs) {
      return this._leafNode(new AssignOp(lhs, exports$12.operators.ADD, rhs));
    }
    // appends passed SafeExpr to code or executes Block
    code(c) {
      if (typeof c == "function")
        c();
      else if (c !== code_12.nil)
        this._leafNode(new AnyCode(c));
      return this;
    }
    // returns code for object literal for the passed argument list of key-value pairs
    object(...keyValues) {
      const code2 = ["{"];
      for (const [key, value] of keyValues) {
        if (code2.length > 1)
          code2.push(",");
        code2.push(key);
        if (key !== value || this.opts.es5) {
          code2.push(":");
          (0, code_12.addCodeArg)(code2, value);
        }
      }
      code2.push("}");
      return new code_12._Code(code2);
    }
    // `if` clause (or statement if `thenBody` and, optionally, `elseBody` are passed)
    if(condition, thenBody, elseBody) {
      this._blockNode(new If2(condition));
      if (thenBody && elseBody) {
        this.code(thenBody).else().code(elseBody).endIf();
      } else if (thenBody) {
        this.code(thenBody).endIf();
      } else if (elseBody) {
        throw new Error('CodeGen: "else" body without "then" body');
      }
      return this;
    }
    // `else if` clause - invalid without `if` or after `else` clauses
    elseIf(condition) {
      return this._elseNode(new If2(condition));
    }
    // `else` clause - only valid after `if` or `else if` clauses
    else() {
      return this._elseNode(new Else());
    }
    // end `if` statement (needed if gen.if was used only with condition)
    endIf() {
      return this._endBlockNode(If2, Else);
    }
    _for(node, forBody) {
      this._blockNode(node);
      if (forBody)
        this.code(forBody).endFor();
      return this;
    }
    // a generic `for` clause (or statement if `forBody` is passed)
    for(iteration, forBody) {
      return this._for(new ForLoop(iteration), forBody);
    }
    // `for` statement for a range of values
    forRange(nameOrPrefix, from, to, forBody, varKind = this.opts.es5 ? scope_1.varKinds.var : scope_1.varKinds.let) {
      const name2 = this._scope.toName(nameOrPrefix);
      return this._for(new ForRange(varKind, name2, from, to), () => forBody(name2));
    }
    // `for-of` statement (in es5 mode replace with a normal for loop)
    forOf(nameOrPrefix, iterable, forBody, varKind = scope_1.varKinds.const) {
      const name2 = this._scope.toName(nameOrPrefix);
      if (this.opts.es5) {
        const arr = iterable instanceof code_12.Name ? iterable : this.var("_arr", iterable);
        return this.forRange("_i", 0, (0, code_12._)`${arr}.length`, (i2) => {
          this.var(name2, (0, code_12._)`${arr}[${i2}]`);
          forBody(name2);
        });
      }
      return this._for(new ForIter("of", varKind, name2, iterable), () => forBody(name2));
    }
    // `for-in` statement.
    // With option `ownProperties` replaced with a `for-of` loop for object keys
    forIn(nameOrPrefix, obj, forBody, varKind = this.opts.es5 ? scope_1.varKinds.var : scope_1.varKinds.const) {
      if (this.opts.ownProperties) {
        return this.forOf(nameOrPrefix, (0, code_12._)`Object.keys(${obj})`, forBody);
      }
      const name2 = this._scope.toName(nameOrPrefix);
      return this._for(new ForIter("in", varKind, name2, obj), () => forBody(name2));
    }
    // end `for` loop
    endFor() {
      return this._endBlockNode(For2);
    }
    // `label` statement
    label(label) {
      return this._leafNode(new Label(label));
    }
    // `break` statement
    break(label) {
      return this._leafNode(new Break(label));
    }
    // `return` statement
    return(value) {
      const node = new Return();
      this._blockNode(node);
      this.code(value);
      if (node.nodes.length !== 1)
        throw new Error('CodeGen: "return" should have one node');
      return this._endBlockNode(Return);
    }
    // `try` statement
    try(tryBody, catchCode, finallyCode) {
      if (!catchCode && !finallyCode)
        throw new Error('CodeGen: "try" without "catch" and "finally"');
      const node = new Try();
      this._blockNode(node);
      this.code(tryBody);
      if (catchCode) {
        const error2 = this.name("e");
        this._currNode = node.catch = new Catch(error2);
        catchCode(error2);
      }
      if (finallyCode) {
        this._currNode = node.finally = new Finally();
        this.code(finallyCode);
      }
      return this._endBlockNode(Catch, Finally);
    }
    // `throw` statement
    throw(error2) {
      return this._leafNode(new Throw(error2));
    }
    // start self-balancing block
    block(body, nodeCount) {
      this._blockStarts.push(this._nodes.length);
      if (body)
        this.code(body).endBlock(nodeCount);
      return this;
    }
    // end the current self-balancing block
    endBlock(nodeCount) {
      const len = this._blockStarts.pop();
      if (len === void 0)
        throw new Error("CodeGen: not in self-balancing block");
      const toClose = this._nodes.length - len;
      if (toClose < 0 || nodeCount !== void 0 && toClose !== nodeCount) {
        throw new Error(`CodeGen: wrong number of nodes: ${toClose} vs ${nodeCount} expected`);
      }
      this._nodes.length = len;
      return this;
    }
    // `function` heading (or definition if funcBody is passed)
    func(name2, args = code_12.nil, async, funcBody) {
      this._blockNode(new Func(name2, args, async));
      if (funcBody)
        this.code(funcBody).endFunc();
      return this;
    }
    // end function definition
    endFunc() {
      return this._endBlockNode(Func);
    }
    optimize(n = 1) {
      while (n-- > 0) {
        this._root.optimizeNodes();
        this._root.optimizeNames(this._root.names, this._constants);
      }
    }
    _leafNode(node) {
      this._currNode.nodes.push(node);
      return this;
    }
    _blockNode(node) {
      this._currNode.nodes.push(node);
      this._nodes.push(node);
    }
    _endBlockNode(N1, N2) {
      const n = this._currNode;
      if (n instanceof N1 || N2 && n instanceof N2) {
        this._nodes.pop();
        return this;
      }
      throw new Error(`CodeGen: not in block "${N2 ? `${N1.kind}/${N2.kind}` : N1.kind}"`);
    }
    _elseNode(node) {
      const n = this._currNode;
      if (!(n instanceof If2)) {
        throw new Error('CodeGen: "else" without "if"');
      }
      this._currNode = n.else = node;
      return this;
    }
    get _root() {
      return this._nodes[0];
    }
    get _currNode() {
      const ns = this._nodes;
      return ns[ns.length - 1];
    }
    set _currNode(node) {
      const ns = this._nodes;
      ns[ns.length - 1] = node;
    }
  }
  exports$12.CodeGen = CodeGen;
  function addNames(names2, from) {
    for (const n in from)
      names2[n] = (names2[n] || 0) + (from[n] || 0);
    return names2;
  }
  function addExprNames(names2, from) {
    return from instanceof code_12._CodeOrName ? addNames(names2, from.names) : names2;
  }
  function optimizeExpr(expr, names2, constants2) {
    if (expr instanceof code_12.Name)
      return replaceName(expr);
    if (!canOptimize(expr))
      return expr;
    return new code_12._Code(expr._items.reduce((items2, c) => {
      if (c instanceof code_12.Name)
        c = replaceName(c);
      if (c instanceof code_12._Code)
        items2.push(...c._items);
      else
        items2.push(c);
      return items2;
    }, []));
    function replaceName(n) {
      const c = constants2[n.str];
      if (c === void 0 || names2[n.str] !== 1)
        return n;
      delete names2[n.str];
      return c;
    }
    function canOptimize(e) {
      return e instanceof code_12._Code && e._items.some((c) => c instanceof code_12.Name && names2[c.str] === 1 && constants2[c.str] !== void 0);
    }
  }
  function subtractNames(names2, from) {
    for (const n in from)
      names2[n] = (names2[n] || 0) - (from[n] || 0);
  }
  function not2(x) {
    return typeof x == "boolean" || typeof x == "number" || x === null ? !x : (0, code_12._)`!${par(x)}`;
  }
  exports$12.not = not2;
  const andCode = mappend(exports$12.operators.AND);
  function and(...args) {
    return args.reduce(andCode);
  }
  exports$12.and = and;
  const orCode = mappend(exports$12.operators.OR);
  function or(...args) {
    return args.reduce(orCode);
  }
  exports$12.or = or;
  function mappend(op) {
    return (x, y) => x === code_12.nil ? y : y === code_12.nil ? x : (0, code_12._)`${par(x)} ${op} ${par(y)}`;
  }
  function par(x) {
    return x instanceof code_12.Name ? x : (0, code_12._)`(${x})`;
  }
})(codegen$1);
var util$2 = {};
Object.defineProperty(util$2, "__esModule", { value: true });
util$2.checkStrictMode = util$2.getErrorPath = util$2.Type = util$2.useFunc = util$2.setEvaluated = util$2.evaluatedPropsToName = util$2.mergeEvaluated = util$2.eachItem = util$2.unescapeJsonPointer = util$2.escapeJsonPointer = util$2.escapeFragment = util$2.unescapeFragment = util$2.schemaRefOrVal = util$2.schemaHasRulesButRef = util$2.schemaHasRules = util$2.checkUnknownRules = util$2.alwaysValidSchema = util$2.toHash = void 0;
const codegen_1$13 = codegen$1;
const code_1$l = code$3;
function toHash$1(arr) {
  const hash = {};
  for (const item of arr)
    hash[item] = true;
  return hash;
}
util$2.toHash = toHash$1;
function alwaysValidSchema$1(it, schema) {
  if (typeof schema == "boolean")
    return schema;
  if (Object.keys(schema).length === 0)
    return true;
  checkUnknownRules$1(it, schema);
  return !schemaHasRules$1(schema, it.self.RULES.all);
}
util$2.alwaysValidSchema = alwaysValidSchema$1;
function checkUnknownRules$1(it, schema = it.schema) {
  const { opts, self: self2 } = it;
  if (!opts.strictSchema)
    return;
  if (typeof schema === "boolean")
    return;
  const rules2 = self2.RULES.keywords;
  for (const key in schema) {
    if (!rules2[key])
      checkStrictMode$1(it, `unknown keyword: "${key}"`);
  }
}
util$2.checkUnknownRules = checkUnknownRules$1;
function schemaHasRules$1(schema, rules2) {
  if (typeof schema == "boolean")
    return !schema;
  for (const key in schema)
    if (rules2[key])
      return true;
  return false;
}
util$2.schemaHasRules = schemaHasRules$1;
function schemaHasRulesButRef$1(schema, RULES) {
  if (typeof schema == "boolean")
    return !schema;
  for (const key in schema)
    if (key !== "$ref" && RULES.all[key])
      return true;
  return false;
}
util$2.schemaHasRulesButRef = schemaHasRulesButRef$1;
function schemaRefOrVal$1({ topSchemaRef, schemaPath }, schema, keyword2, $data) {
  if (!$data) {
    if (typeof schema == "number" || typeof schema == "boolean")
      return schema;
    if (typeof schema == "string")
      return (0, codegen_1$13._)`${schema}`;
  }
  return (0, codegen_1$13._)`${topSchemaRef}${schemaPath}${(0, codegen_1$13.getProperty)(keyword2)}`;
}
util$2.schemaRefOrVal = schemaRefOrVal$1;
function unescapeFragment$1(str) {
  return unescapeJsonPointer$1(decodeURIComponent(str));
}
util$2.unescapeFragment = unescapeFragment$1;
function escapeFragment$1(str) {
  return encodeURIComponent(escapeJsonPointer$1(str));
}
util$2.escapeFragment = escapeFragment$1;
function escapeJsonPointer$1(str) {
  if (typeof str == "number")
    return `${str}`;
  return str.replace(/~/g, "~0").replace(/\//g, "~1");
}
util$2.escapeJsonPointer = escapeJsonPointer$1;
function unescapeJsonPointer$1(str) {
  return str.replace(/~1/g, "/").replace(/~0/g, "~");
}
util$2.unescapeJsonPointer = unescapeJsonPointer$1;
function eachItem$1(xs, f) {
  if (Array.isArray(xs)) {
    for (const x of xs)
      f(x);
  } else {
    f(xs);
  }
}
util$2.eachItem = eachItem$1;
function makeMergeEvaluated$1({ mergeNames, mergeToName, mergeValues, resultToName }) {
  return (gen, from, to, toName) => {
    const res = to === void 0 ? from : to instanceof codegen_1$13.Name ? (from instanceof codegen_1$13.Name ? mergeNames(gen, from, to) : mergeToName(gen, from, to), to) : from instanceof codegen_1$13.Name ? (mergeToName(gen, to, from), from) : mergeValues(from, to);
    return toName === codegen_1$13.Name && !(res instanceof codegen_1$13.Name) ? resultToName(gen, res) : res;
  };
}
util$2.mergeEvaluated = {
  props: makeMergeEvaluated$1({
    mergeNames: (gen, from, to) => gen.if((0, codegen_1$13._)`${to} !== true && ${from} !== undefined`, () => {
      gen.if((0, codegen_1$13._)`${from} === true`, () => gen.assign(to, true), () => gen.assign(to, (0, codegen_1$13._)`${to} || {}`).code((0, codegen_1$13._)`Object.assign(${to}, ${from})`));
    }),
    mergeToName: (gen, from, to) => gen.if((0, codegen_1$13._)`${to} !== true`, () => {
      if (from === true) {
        gen.assign(to, true);
      } else {
        gen.assign(to, (0, codegen_1$13._)`${to} || {}`);
        setEvaluated$1(gen, to, from);
      }
    }),
    mergeValues: (from, to) => from === true ? true : { ...from, ...to },
    resultToName: evaluatedPropsToName$1
  }),
  items: makeMergeEvaluated$1({
    mergeNames: (gen, from, to) => gen.if((0, codegen_1$13._)`${to} !== true && ${from} !== undefined`, () => gen.assign(to, (0, codegen_1$13._)`${from} === true ? true : ${to} > ${from} ? ${to} : ${from}`)),
    mergeToName: (gen, from, to) => gen.if((0, codegen_1$13._)`${to} !== true`, () => gen.assign(to, from === true ? true : (0, codegen_1$13._)`${to} > ${from} ? ${to} : ${from}`)),
    mergeValues: (from, to) => from === true ? true : Math.max(from, to),
    resultToName: (gen, items2) => gen.var("items", items2)
  })
};
function evaluatedPropsToName$1(gen, ps) {
  if (ps === true)
    return gen.var("props", true);
  const props = gen.var("props", (0, codegen_1$13._)`{}`);
  if (ps !== void 0)
    setEvaluated$1(gen, props, ps);
  return props;
}
util$2.evaluatedPropsToName = evaluatedPropsToName$1;
function setEvaluated$1(gen, props, ps) {
  Object.keys(ps).forEach((p) => gen.assign((0, codegen_1$13._)`${props}${(0, codegen_1$13.getProperty)(p)}`, true));
}
util$2.setEvaluated = setEvaluated$1;
const snippets$1 = {};
function useFunc$1(gen, f) {
  return gen.scopeValue("func", {
    ref: f,
    code: snippets$1[f.code] || (snippets$1[f.code] = new code_1$l._Code(f.code))
  });
}
util$2.useFunc = useFunc$1;
var Type$1;
(function(Type2) {
  Type2[Type2["Num"] = 0] = "Num";
  Type2[Type2["Str"] = 1] = "Str";
})(Type$1 || (util$2.Type = Type$1 = {}));
function getErrorPath$1(dataProp, dataPropType, jsPropertySyntax) {
  if (dataProp instanceof codegen_1$13.Name) {
    const isNumber = dataPropType === Type$1.Num;
    return jsPropertySyntax ? isNumber ? (0, codegen_1$13._)`"[" + ${dataProp} + "]"` : (0, codegen_1$13._)`"['" + ${dataProp} + "']"` : isNumber ? (0, codegen_1$13._)`"/" + ${dataProp}` : (0, codegen_1$13._)`"/" + ${dataProp}.replace(/~/g, "~0").replace(/\\//g, "~1")`;
  }
  return jsPropertySyntax ? (0, codegen_1$13.getProperty)(dataProp).toString() : "/" + escapeJsonPointer$1(dataProp);
}
util$2.getErrorPath = getErrorPath$1;
function checkStrictMode$1(it, msg, mode = it.opts.strictSchema) {
  if (!mode)
    return;
  msg = `strict mode: ${msg}`;
  if (mode === true)
    throw new Error(msg);
  it.self.logger.warn(msg);
}
util$2.checkStrictMode = checkStrictMode$1;
var names$3 = {};
Object.defineProperty(names$3, "__esModule", { value: true });
const codegen_1$12 = codegen$1;
const names$2 = {
  // validation function arguments
  data: new codegen_1$12.Name("data"),
  // data passed to validation function
  // args passed from referencing schema
  valCxt: new codegen_1$12.Name("valCxt"),
  // validation/data context - should not be used directly, it is destructured to the names below
  instancePath: new codegen_1$12.Name("instancePath"),
  parentData: new codegen_1$12.Name("parentData"),
  parentDataProperty: new codegen_1$12.Name("parentDataProperty"),
  rootData: new codegen_1$12.Name("rootData"),
  // root data - same as the data passed to the first/top validation function
  dynamicAnchors: new codegen_1$12.Name("dynamicAnchors"),
  // used to support recursiveRef and dynamicRef
  // function scoped variables
  vErrors: new codegen_1$12.Name("vErrors"),
  // null or array of validation errors
  errors: new codegen_1$12.Name("errors"),
  // counter of validation errors
  this: new codegen_1$12.Name("this"),
  // "globals"
  self: new codegen_1$12.Name("self"),
  scope: new codegen_1$12.Name("scope"),
  // JTD serialize/parse name for JSON string and position
  json: new codegen_1$12.Name("json"),
  jsonPos: new codegen_1$12.Name("jsonPos"),
  jsonLen: new codegen_1$12.Name("jsonLen"),
  jsonPart: new codegen_1$12.Name("jsonPart")
};
names$3.default = names$2;
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.extendErrors = exports$12.resetErrorsCount = exports$12.reportExtraError = exports$12.reportError = exports$12.keyword$DataError = exports$12.keywordError = void 0;
  const codegen_12 = codegen$1;
  const util_12 = util$2;
  const names_12 = names$3;
  exports$12.keywordError = {
    message: ({ keyword: keyword2 }) => (0, codegen_12.str)`must pass "${keyword2}" keyword validation`
  };
  exports$12.keyword$DataError = {
    message: ({ keyword: keyword2, schemaType }) => schemaType ? (0, codegen_12.str)`"${keyword2}" keyword must be ${schemaType} ($data)` : (0, codegen_12.str)`"${keyword2}" keyword is invalid ($data)`
  };
  function reportError(cxt, error2 = exports$12.keywordError, errorPaths, overrideAllErrors) {
    const { it } = cxt;
    const { gen, compositeRule, allErrors } = it;
    const errObj = errorObjectCode(cxt, error2, errorPaths);
    if (overrideAllErrors !== null && overrideAllErrors !== void 0 ? overrideAllErrors : compositeRule || allErrors) {
      addError(gen, errObj);
    } else {
      returnErrors(it, (0, codegen_12._)`[${errObj}]`);
    }
  }
  exports$12.reportError = reportError;
  function reportExtraError(cxt, error2 = exports$12.keywordError, errorPaths) {
    const { it } = cxt;
    const { gen, compositeRule, allErrors } = it;
    const errObj = errorObjectCode(cxt, error2, errorPaths);
    addError(gen, errObj);
    if (!(compositeRule || allErrors)) {
      returnErrors(it, names_12.default.vErrors);
    }
  }
  exports$12.reportExtraError = reportExtraError;
  function resetErrorsCount(gen, errsCount) {
    gen.assign(names_12.default.errors, errsCount);
    gen.if((0, codegen_12._)`${names_12.default.vErrors} !== null`, () => gen.if(errsCount, () => gen.assign((0, codegen_12._)`${names_12.default.vErrors}.length`, errsCount), () => gen.assign(names_12.default.vErrors, null)));
  }
  exports$12.resetErrorsCount = resetErrorsCount;
  function extendErrors({ gen, keyword: keyword2, schemaValue, data, errsCount, it }) {
    if (errsCount === void 0)
      throw new Error("ajv implementation error");
    const err = gen.name("err");
    gen.forRange("i", errsCount, names_12.default.errors, (i2) => {
      gen.const(err, (0, codegen_12._)`${names_12.default.vErrors}[${i2}]`);
      gen.if((0, codegen_12._)`${err}.instancePath === undefined`, () => gen.assign((0, codegen_12._)`${err}.instancePath`, (0, codegen_12.strConcat)(names_12.default.instancePath, it.errorPath)));
      gen.assign((0, codegen_12._)`${err}.schemaPath`, (0, codegen_12.str)`${it.errSchemaPath}/${keyword2}`);
      if (it.opts.verbose) {
        gen.assign((0, codegen_12._)`${err}.schema`, schemaValue);
        gen.assign((0, codegen_12._)`${err}.data`, data);
      }
    });
  }
  exports$12.extendErrors = extendErrors;
  function addError(gen, errObj) {
    const err = gen.const("err", errObj);
    gen.if((0, codegen_12._)`${names_12.default.vErrors} === null`, () => gen.assign(names_12.default.vErrors, (0, codegen_12._)`[${err}]`), (0, codegen_12._)`${names_12.default.vErrors}.push(${err})`);
    gen.code((0, codegen_12._)`${names_12.default.errors}++`);
  }
  function returnErrors(it, errs) {
    const { gen, validateName, schemaEnv } = it;
    if (schemaEnv.$async) {
      gen.throw((0, codegen_12._)`new ${it.ValidationError}(${errs})`);
    } else {
      gen.assign((0, codegen_12._)`${validateName}.errors`, errs);
      gen.return(false);
    }
  }
  const E = {
    keyword: new codegen_12.Name("keyword"),
    schemaPath: new codegen_12.Name("schemaPath"),
    // also used in JTD errors
    params: new codegen_12.Name("params"),
    propertyName: new codegen_12.Name("propertyName"),
    message: new codegen_12.Name("message"),
    schema: new codegen_12.Name("schema"),
    parentSchema: new codegen_12.Name("parentSchema")
  };
  function errorObjectCode(cxt, error2, errorPaths) {
    const { createErrors } = cxt.it;
    if (createErrors === false)
      return (0, codegen_12._)`{}`;
    return errorObject(cxt, error2, errorPaths);
  }
  function errorObject(cxt, error2, errorPaths = {}) {
    const { gen, it } = cxt;
    const keyValues = [
      errorInstancePath(it, errorPaths),
      errorSchemaPath(cxt, errorPaths)
    ];
    extraErrorProps(cxt, error2, keyValues);
    return gen.object(...keyValues);
  }
  function errorInstancePath({ errorPath }, { instancePath }) {
    const instPath = instancePath ? (0, codegen_12.str)`${errorPath}${(0, util_12.getErrorPath)(instancePath, util_12.Type.Str)}` : errorPath;
    return [names_12.default.instancePath, (0, codegen_12.strConcat)(names_12.default.instancePath, instPath)];
  }
  function errorSchemaPath({ keyword: keyword2, it: { errSchemaPath } }, { schemaPath, parentSchema }) {
    let schPath = parentSchema ? errSchemaPath : (0, codegen_12.str)`${errSchemaPath}/${keyword2}`;
    if (schemaPath) {
      schPath = (0, codegen_12.str)`${schPath}${(0, util_12.getErrorPath)(schemaPath, util_12.Type.Str)}`;
    }
    return [E.schemaPath, schPath];
  }
  function extraErrorProps(cxt, { params, message }, keyValues) {
    const { keyword: keyword2, data, schemaValue, it } = cxt;
    const { opts, propertyName, topSchemaRef, schemaPath } = it;
    keyValues.push([E.keyword, keyword2], [E.params, typeof params == "function" ? params(cxt) : params || (0, codegen_12._)`{}`]);
    if (opts.messages) {
      keyValues.push([E.message, typeof message == "function" ? message(cxt) : message]);
    }
    if (opts.verbose) {
      keyValues.push([E.schema, schemaValue], [E.parentSchema, (0, codegen_12._)`${topSchemaRef}${schemaPath}`], [names_12.default.data, data]);
    }
    if (propertyName)
      keyValues.push([E.propertyName, propertyName]);
  }
})(errors$1);
Object.defineProperty(boolSchema$1, "__esModule", { value: true });
boolSchema$1.boolOrEmptySchema = boolSchema$1.topBoolOrEmptySchema = void 0;
const errors_1$7 = errors$1;
const codegen_1$11 = codegen$1;
const names_1$g = names$3;
const boolError$1 = {
  message: "boolean schema is false"
};
function topBoolOrEmptySchema$1(it) {
  const { gen, schema, validateName } = it;
  if (schema === false) {
    falseSchemaError$1(it, false);
  } else if (typeof schema == "object" && schema.$async === true) {
    gen.return(names_1$g.default.data);
  } else {
    gen.assign((0, codegen_1$11._)`${validateName}.errors`, null);
    gen.return(true);
  }
}
boolSchema$1.topBoolOrEmptySchema = topBoolOrEmptySchema$1;
function boolOrEmptySchema$1(it, valid2) {
  const { gen, schema } = it;
  if (schema === false) {
    gen.var(valid2, false);
    falseSchemaError$1(it);
  } else {
    gen.var(valid2, true);
  }
}
boolSchema$1.boolOrEmptySchema = boolOrEmptySchema$1;
function falseSchemaError$1(it, overrideAllErrors) {
  const { gen, data } = it;
  const cxt = {
    gen,
    keyword: "false schema",
    data,
    schema: false,
    schemaCode: false,
    schemaValue: false,
    params: {},
    it
  };
  (0, errors_1$7.reportError)(cxt, boolError$1, void 0, overrideAllErrors);
}
var dataType$1 = {};
var rules$1 = {};
Object.defineProperty(rules$1, "__esModule", { value: true });
rules$1.getRules = rules$1.isJSONType = void 0;
const _jsonTypes$1 = ["string", "number", "integer", "boolean", "null", "object", "array"];
const jsonTypes$1 = new Set(_jsonTypes$1);
function isJSONType$1(x) {
  return typeof x == "string" && jsonTypes$1.has(x);
}
rules$1.isJSONType = isJSONType$1;
function getRules$1() {
  const groups = {
    number: { type: "number", rules: [] },
    string: { type: "string", rules: [] },
    array: { type: "array", rules: [] },
    object: { type: "object", rules: [] }
  };
  return {
    types: { ...groups, integer: true, boolean: true, null: true },
    rules: [{ rules: [] }, groups.number, groups.string, groups.array, groups.object],
    post: { rules: [] },
    all: {},
    keywords: {}
  };
}
rules$1.getRules = getRules$1;
var applicability$1 = {};
Object.defineProperty(applicability$1, "__esModule", { value: true });
applicability$1.shouldUseRule = applicability$1.shouldUseGroup = applicability$1.schemaHasRulesForType = void 0;
function schemaHasRulesForType$1({ schema, self: self2 }, type2) {
  const group = self2.RULES.types[type2];
  return group && group !== true && shouldUseGroup$1(schema, group);
}
applicability$1.schemaHasRulesForType = schemaHasRulesForType$1;
function shouldUseGroup$1(schema, group) {
  return group.rules.some((rule) => shouldUseRule$1(schema, rule));
}
applicability$1.shouldUseGroup = shouldUseGroup$1;
function shouldUseRule$1(schema, rule) {
  var _a2;
  return schema[rule.keyword] !== void 0 || ((_a2 = rule.definition.implements) === null || _a2 === void 0 ? void 0 : _a2.some((kwd) => schema[kwd] !== void 0));
}
applicability$1.shouldUseRule = shouldUseRule$1;
Object.defineProperty(dataType$1, "__esModule", { value: true });
dataType$1.reportTypeError = dataType$1.checkDataTypes = dataType$1.checkDataType = dataType$1.coerceAndCheckDataType = dataType$1.getJSONTypes = dataType$1.getSchemaTypes = dataType$1.DataType = void 0;
const rules_1$1 = rules$1;
const applicability_1$3 = applicability$1;
const errors_1$6 = errors$1;
const codegen_1$10 = codegen$1;
const util_1$X = util$2;
var DataType$1;
(function(DataType2) {
  DataType2[DataType2["Correct"] = 0] = "Correct";
  DataType2[DataType2["Wrong"] = 1] = "Wrong";
})(DataType$1 || (dataType$1.DataType = DataType$1 = {}));
function getSchemaTypes$1(schema) {
  const types2 = getJSONTypes$1(schema.type);
  const hasNull = types2.includes("null");
  if (hasNull) {
    if (schema.nullable === false)
      throw new Error("type: null contradicts nullable: false");
  } else {
    if (!types2.length && schema.nullable !== void 0) {
      throw new Error('"nullable" cannot be used without "type"');
    }
    if (schema.nullable === true)
      types2.push("null");
  }
  return types2;
}
dataType$1.getSchemaTypes = getSchemaTypes$1;
function getJSONTypes$1(ts) {
  const types2 = Array.isArray(ts) ? ts : ts ? [ts] : [];
  if (types2.every(rules_1$1.isJSONType))
    return types2;
  throw new Error("type must be JSONType or JSONType[]: " + types2.join(","));
}
dataType$1.getJSONTypes = getJSONTypes$1;
function coerceAndCheckDataType$1(it, types2) {
  const { gen, data, opts } = it;
  const coerceTo = coerceToTypes$1(types2, opts.coerceTypes);
  const checkTypes = types2.length > 0 && !(coerceTo.length === 0 && types2.length === 1 && (0, applicability_1$3.schemaHasRulesForType)(it, types2[0]));
  if (checkTypes) {
    const wrongType = checkDataTypes$1(types2, data, opts.strictNumbers, DataType$1.Wrong);
    gen.if(wrongType, () => {
      if (coerceTo.length)
        coerceData$1(it, types2, coerceTo);
      else
        reportTypeError$1(it);
    });
  }
  return checkTypes;
}
dataType$1.coerceAndCheckDataType = coerceAndCheckDataType$1;
const COERCIBLE$1 = /* @__PURE__ */ new Set(["string", "number", "integer", "boolean", "null"]);
function coerceToTypes$1(types2, coerceTypes) {
  return coerceTypes ? types2.filter((t2) => COERCIBLE$1.has(t2) || coerceTypes === "array" && t2 === "array") : [];
}
function coerceData$1(it, types2, coerceTo) {
  const { gen, data, opts } = it;
  const dataType2 = gen.let("dataType", (0, codegen_1$10._)`typeof ${data}`);
  const coerced = gen.let("coerced", (0, codegen_1$10._)`undefined`);
  if (opts.coerceTypes === "array") {
    gen.if((0, codegen_1$10._)`${dataType2} == 'object' && Array.isArray(${data}) && ${data}.length == 1`, () => gen.assign(data, (0, codegen_1$10._)`${data}[0]`).assign(dataType2, (0, codegen_1$10._)`typeof ${data}`).if(checkDataTypes$1(types2, data, opts.strictNumbers), () => gen.assign(coerced, data)));
  }
  gen.if((0, codegen_1$10._)`${coerced} !== undefined`);
  for (const t2 of coerceTo) {
    if (COERCIBLE$1.has(t2) || t2 === "array" && opts.coerceTypes === "array") {
      coerceSpecificType(t2);
    }
  }
  gen.else();
  reportTypeError$1(it);
  gen.endIf();
  gen.if((0, codegen_1$10._)`${coerced} !== undefined`, () => {
    gen.assign(data, coerced);
    assignParentData$1(it, coerced);
  });
  function coerceSpecificType(t2) {
    switch (t2) {
      case "string":
        gen.elseIf((0, codegen_1$10._)`${dataType2} == "number" || ${dataType2} == "boolean"`).assign(coerced, (0, codegen_1$10._)`"" + ${data}`).elseIf((0, codegen_1$10._)`${data} === null`).assign(coerced, (0, codegen_1$10._)`""`);
        return;
      case "number":
        gen.elseIf((0, codegen_1$10._)`${dataType2} == "boolean" || ${data} === null
              || (${dataType2} == "string" && ${data} && ${data} == +${data})`).assign(coerced, (0, codegen_1$10._)`+${data}`);
        return;
      case "integer":
        gen.elseIf((0, codegen_1$10._)`${dataType2} === "boolean" || ${data} === null
              || (${dataType2} === "string" && ${data} && ${data} == +${data} && !(${data} % 1))`).assign(coerced, (0, codegen_1$10._)`+${data}`);
        return;
      case "boolean":
        gen.elseIf((0, codegen_1$10._)`${data} === "false" || ${data} === 0 || ${data} === null`).assign(coerced, false).elseIf((0, codegen_1$10._)`${data} === "true" || ${data} === 1`).assign(coerced, true);
        return;
      case "null":
        gen.elseIf((0, codegen_1$10._)`${data} === "" || ${data} === 0 || ${data} === false`);
        gen.assign(coerced, null);
        return;
      case "array":
        gen.elseIf((0, codegen_1$10._)`${dataType2} === "string" || ${dataType2} === "number"
              || ${dataType2} === "boolean" || ${data} === null`).assign(coerced, (0, codegen_1$10._)`[${data}]`);
    }
  }
}
function assignParentData$1({ gen, parentData, parentDataProperty }, expr) {
  gen.if((0, codegen_1$10._)`${parentData} !== undefined`, () => gen.assign((0, codegen_1$10._)`${parentData}[${parentDataProperty}]`, expr));
}
function checkDataType$1(dataType2, data, strictNums, correct = DataType$1.Correct) {
  const EQ = correct === DataType$1.Correct ? codegen_1$10.operators.EQ : codegen_1$10.operators.NEQ;
  let cond;
  switch (dataType2) {
    case "null":
      return (0, codegen_1$10._)`${data} ${EQ} null`;
    case "array":
      cond = (0, codegen_1$10._)`Array.isArray(${data})`;
      break;
    case "object":
      cond = (0, codegen_1$10._)`${data} && typeof ${data} == "object" && !Array.isArray(${data})`;
      break;
    case "integer":
      cond = numCond((0, codegen_1$10._)`!(${data} % 1) && !isNaN(${data})`);
      break;
    case "number":
      cond = numCond();
      break;
    default:
      return (0, codegen_1$10._)`typeof ${data} ${EQ} ${dataType2}`;
  }
  return correct === DataType$1.Correct ? cond : (0, codegen_1$10.not)(cond);
  function numCond(_cond = codegen_1$10.nil) {
    return (0, codegen_1$10.and)((0, codegen_1$10._)`typeof ${data} == "number"`, _cond, strictNums ? (0, codegen_1$10._)`isFinite(${data})` : codegen_1$10.nil);
  }
}
dataType$1.checkDataType = checkDataType$1;
function checkDataTypes$1(dataTypes, data, strictNums, correct) {
  if (dataTypes.length === 1) {
    return checkDataType$1(dataTypes[0], data, strictNums, correct);
  }
  let cond;
  const types2 = (0, util_1$X.toHash)(dataTypes);
  if (types2.array && types2.object) {
    const notObj = (0, codegen_1$10._)`typeof ${data} != "object"`;
    cond = types2.null ? notObj : (0, codegen_1$10._)`!${data} || ${notObj}`;
    delete types2.null;
    delete types2.array;
    delete types2.object;
  } else {
    cond = codegen_1$10.nil;
  }
  if (types2.number)
    delete types2.integer;
  for (const t2 in types2)
    cond = (0, codegen_1$10.and)(cond, checkDataType$1(t2, data, strictNums, correct));
  return cond;
}
dataType$1.checkDataTypes = checkDataTypes$1;
const typeError$1 = {
  message: ({ schema }) => `must be ${schema}`,
  params: ({ schema, schemaValue }) => typeof schema == "string" ? (0, codegen_1$10._)`{type: ${schema}}` : (0, codegen_1$10._)`{type: ${schemaValue}}`
};
function reportTypeError$1(it) {
  const cxt = getTypeErrorContext$1(it);
  (0, errors_1$6.reportError)(cxt, typeError$1);
}
dataType$1.reportTypeError = reportTypeError$1;
function getTypeErrorContext$1(it) {
  const { gen, data, schema } = it;
  const schemaCode = (0, util_1$X.schemaRefOrVal)(it, schema, "type");
  return {
    gen,
    keyword: "type",
    data,
    schema: schema.type,
    schemaCode,
    schemaValue: schemaCode,
    parentSchema: schema,
    params: {},
    it
  };
}
var defaults$1 = {};
Object.defineProperty(defaults$1, "__esModule", { value: true });
defaults$1.assignDefaults = void 0;
const codegen_1$$ = codegen$1;
const util_1$W = util$2;
function assignDefaults$1(it, ty) {
  const { properties: properties2, items: items2 } = it.schema;
  if (ty === "object" && properties2) {
    for (const key in properties2) {
      assignDefault$1(it, key, properties2[key].default);
    }
  } else if (ty === "array" && Array.isArray(items2)) {
    items2.forEach((sch, i2) => assignDefault$1(it, i2, sch.default));
  }
}
defaults$1.assignDefaults = assignDefaults$1;
function assignDefault$1(it, prop, defaultValue) {
  const { gen, compositeRule, data, opts } = it;
  if (defaultValue === void 0)
    return;
  const childData = (0, codegen_1$$._)`${data}${(0, codegen_1$$.getProperty)(prop)}`;
  if (compositeRule) {
    (0, util_1$W.checkStrictMode)(it, `default is ignored for: ${childData}`);
    return;
  }
  let condition = (0, codegen_1$$._)`${childData} === undefined`;
  if (opts.useDefaults === "empty") {
    condition = (0, codegen_1$$._)`${condition} || ${childData} === null || ${childData} === ""`;
  }
  gen.if(condition, (0, codegen_1$$._)`${childData} = ${(0, codegen_1$$.stringify)(defaultValue)}`);
}
var keyword$1 = {};
var code$2 = {};
Object.defineProperty(code$2, "__esModule", { value: true });
code$2.validateUnion = code$2.validateArray = code$2.usePattern = code$2.callValidateCode = code$2.schemaProperties = code$2.allSchemaProperties = code$2.noPropertyInData = code$2.propertyInData = code$2.isOwnProperty = code$2.hasPropFunc = code$2.reportMissingProp = code$2.checkMissingProp = code$2.checkReportMissingProp = void 0;
const codegen_1$_ = codegen$1;
const util_1$V = util$2;
const names_1$f = names$3;
const util_2$3 = util$2;
function checkReportMissingProp$1(cxt, prop) {
  const { gen, data, it } = cxt;
  gen.if(noPropertyInData$1(gen, data, prop, it.opts.ownProperties), () => {
    cxt.setParams({ missingProperty: (0, codegen_1$_._)`${prop}` }, true);
    cxt.error();
  });
}
code$2.checkReportMissingProp = checkReportMissingProp$1;
function checkMissingProp$1({ gen, data, it: { opts } }, properties2, missing) {
  return (0, codegen_1$_.or)(...properties2.map((prop) => (0, codegen_1$_.and)(noPropertyInData$1(gen, data, prop, opts.ownProperties), (0, codegen_1$_._)`${missing} = ${prop}`)));
}
code$2.checkMissingProp = checkMissingProp$1;
function reportMissingProp$1(cxt, missing) {
  cxt.setParams({ missingProperty: missing }, true);
  cxt.error();
}
code$2.reportMissingProp = reportMissingProp$1;
function hasPropFunc$1(gen) {
  return gen.scopeValue("func", {
    // eslint-disable-next-line @typescript-eslint/unbound-method
    ref: Object.prototype.hasOwnProperty,
    code: (0, codegen_1$_._)`Object.prototype.hasOwnProperty`
  });
}
code$2.hasPropFunc = hasPropFunc$1;
function isOwnProperty$1(gen, data, property) {
  return (0, codegen_1$_._)`${hasPropFunc$1(gen)}.call(${data}, ${property})`;
}
code$2.isOwnProperty = isOwnProperty$1;
function propertyInData$1(gen, data, property, ownProperties) {
  const cond = (0, codegen_1$_._)`${data}${(0, codegen_1$_.getProperty)(property)} !== undefined`;
  return ownProperties ? (0, codegen_1$_._)`${cond} && ${isOwnProperty$1(gen, data, property)}` : cond;
}
code$2.propertyInData = propertyInData$1;
function noPropertyInData$1(gen, data, property, ownProperties) {
  const cond = (0, codegen_1$_._)`${data}${(0, codegen_1$_.getProperty)(property)} === undefined`;
  return ownProperties ? (0, codegen_1$_.or)(cond, (0, codegen_1$_.not)(isOwnProperty$1(gen, data, property))) : cond;
}
code$2.noPropertyInData = noPropertyInData$1;
function allSchemaProperties$1(schemaMap) {
  return schemaMap ? Object.keys(schemaMap).filter((p) => p !== "__proto__") : [];
}
code$2.allSchemaProperties = allSchemaProperties$1;
function schemaProperties$1(it, schemaMap) {
  return allSchemaProperties$1(schemaMap).filter((p) => !(0, util_1$V.alwaysValidSchema)(it, schemaMap[p]));
}
code$2.schemaProperties = schemaProperties$1;
function callValidateCode$1({ schemaCode, data, it: { gen, topSchemaRef, schemaPath, errorPath }, it }, func, context, passSchema) {
  const dataAndSchema = passSchema ? (0, codegen_1$_._)`${schemaCode}, ${data}, ${topSchemaRef}${schemaPath}` : data;
  const valCxt = [
    [names_1$f.default.instancePath, (0, codegen_1$_.strConcat)(names_1$f.default.instancePath, errorPath)],
    [names_1$f.default.parentData, it.parentData],
    [names_1$f.default.parentDataProperty, it.parentDataProperty],
    [names_1$f.default.rootData, names_1$f.default.rootData]
  ];
  if (it.opts.dynamicRef)
    valCxt.push([names_1$f.default.dynamicAnchors, names_1$f.default.dynamicAnchors]);
  const args = (0, codegen_1$_._)`${dataAndSchema}, ${gen.object(...valCxt)}`;
  return context !== codegen_1$_.nil ? (0, codegen_1$_._)`${func}.call(${context}, ${args})` : (0, codegen_1$_._)`${func}(${args})`;
}
code$2.callValidateCode = callValidateCode$1;
const newRegExp$1 = (0, codegen_1$_._)`new RegExp`;
function usePattern$1({ gen, it: { opts } }, pattern2) {
  const u = opts.unicodeRegExp ? "u" : "";
  const { regExp } = opts.code;
  const rx = regExp(pattern2, u);
  return gen.scopeValue("pattern", {
    key: rx.toString(),
    ref: rx,
    code: (0, codegen_1$_._)`${regExp.code === "new RegExp" ? newRegExp$1 : (0, util_2$3.useFunc)(gen, regExp)}(${pattern2}, ${u})`
  });
}
code$2.usePattern = usePattern$1;
function validateArray$1(cxt) {
  const { gen, data, keyword: keyword2, it } = cxt;
  const valid2 = gen.name("valid");
  if (it.allErrors) {
    const validArr = gen.let("valid", true);
    validateItems(() => gen.assign(validArr, false));
    return validArr;
  }
  gen.var(valid2, true);
  validateItems(() => gen.break());
  return valid2;
  function validateItems(notValid) {
    const len = gen.const("len", (0, codegen_1$_._)`${data}.length`);
    gen.forRange("i", 0, len, (i2) => {
      cxt.subschema({
        keyword: keyword2,
        dataProp: i2,
        dataPropType: util_1$V.Type.Num
      }, valid2);
      gen.if((0, codegen_1$_.not)(valid2), notValid);
    });
  }
}
code$2.validateArray = validateArray$1;
function validateUnion$1(cxt) {
  const { gen, schema, keyword: keyword2, it } = cxt;
  if (!Array.isArray(schema))
    throw new Error("ajv implementation error");
  const alwaysValid = schema.some((sch) => (0, util_1$V.alwaysValidSchema)(it, sch));
  if (alwaysValid && !it.opts.unevaluated)
    return;
  const valid2 = gen.let("valid", false);
  const schValid = gen.name("_valid");
  gen.block(() => schema.forEach((_sch, i2) => {
    const schCxt = cxt.subschema({
      keyword: keyword2,
      schemaProp: i2,
      compositeRule: true
    }, schValid);
    gen.assign(valid2, (0, codegen_1$_._)`${valid2} || ${schValid}`);
    const merged = cxt.mergeValidEvaluated(schCxt, schValid);
    if (!merged)
      gen.if((0, codegen_1$_.not)(valid2));
  }));
  cxt.result(valid2, () => cxt.reset(), () => cxt.error(true));
}
code$2.validateUnion = validateUnion$1;
Object.defineProperty(keyword$1, "__esModule", { value: true });
keyword$1.validateKeywordUsage = keyword$1.validSchemaType = keyword$1.funcKeywordCode = keyword$1.macroKeywordCode = void 0;
const codegen_1$Z = codegen$1;
const names_1$e = names$3;
const code_1$k = code$2;
const errors_1$5 = errors$1;
function macroKeywordCode$1(cxt, def2) {
  const { gen, keyword: keyword2, schema, parentSchema, it } = cxt;
  const macroSchema = def2.macro.call(it.self, schema, parentSchema, it);
  const schemaRef = useKeyword$1(gen, keyword2, macroSchema);
  if (it.opts.validateSchema !== false)
    it.self.validateSchema(macroSchema, true);
  const valid2 = gen.name("valid");
  cxt.subschema({
    schema: macroSchema,
    schemaPath: codegen_1$Z.nil,
    errSchemaPath: `${it.errSchemaPath}/${keyword2}`,
    topSchemaRef: schemaRef,
    compositeRule: true
  }, valid2);
  cxt.pass(valid2, () => cxt.error(true));
}
keyword$1.macroKeywordCode = macroKeywordCode$1;
function funcKeywordCode$1(cxt, def2) {
  var _a2;
  const { gen, keyword: keyword2, schema, parentSchema, $data, it } = cxt;
  checkAsyncKeyword$1(it, def2);
  const validate2 = !$data && def2.compile ? def2.compile.call(it.self, schema, parentSchema, it) : def2.validate;
  const validateRef = useKeyword$1(gen, keyword2, validate2);
  const valid2 = gen.let("valid");
  cxt.block$data(valid2, validateKeyword);
  cxt.ok((_a2 = def2.valid) !== null && _a2 !== void 0 ? _a2 : valid2);
  function validateKeyword() {
    if (def2.errors === false) {
      assignValid();
      if (def2.modifying)
        modifyData$1(cxt);
      reportErrs(() => cxt.error());
    } else {
      const ruleErrs = def2.async ? validateAsync() : validateSync();
      if (def2.modifying)
        modifyData$1(cxt);
      reportErrs(() => addErrs$1(cxt, ruleErrs));
    }
  }
  function validateAsync() {
    const ruleErrs = gen.let("ruleErrs", null);
    gen.try(() => assignValid((0, codegen_1$Z._)`await `), (e) => gen.assign(valid2, false).if((0, codegen_1$Z._)`${e} instanceof ${it.ValidationError}`, () => gen.assign(ruleErrs, (0, codegen_1$Z._)`${e}.errors`), () => gen.throw(e)));
    return ruleErrs;
  }
  function validateSync() {
    const validateErrs = (0, codegen_1$Z._)`${validateRef}.errors`;
    gen.assign(validateErrs, null);
    assignValid(codegen_1$Z.nil);
    return validateErrs;
  }
  function assignValid(_await = def2.async ? (0, codegen_1$Z._)`await ` : codegen_1$Z.nil) {
    const passCxt = it.opts.passContext ? names_1$e.default.this : names_1$e.default.self;
    const passSchema = !("compile" in def2 && !$data || def2.schema === false);
    gen.assign(valid2, (0, codegen_1$Z._)`${_await}${(0, code_1$k.callValidateCode)(cxt, validateRef, passCxt, passSchema)}`, def2.modifying);
  }
  function reportErrs(errors2) {
    var _a3;
    gen.if((0, codegen_1$Z.not)((_a3 = def2.valid) !== null && _a3 !== void 0 ? _a3 : valid2), errors2);
  }
}
keyword$1.funcKeywordCode = funcKeywordCode$1;
function modifyData$1(cxt) {
  const { gen, data, it } = cxt;
  gen.if(it.parentData, () => gen.assign(data, (0, codegen_1$Z._)`${it.parentData}[${it.parentDataProperty}]`));
}
function addErrs$1(cxt, errs) {
  const { gen } = cxt;
  gen.if((0, codegen_1$Z._)`Array.isArray(${errs})`, () => {
    gen.assign(names_1$e.default.vErrors, (0, codegen_1$Z._)`${names_1$e.default.vErrors} === null ? ${errs} : ${names_1$e.default.vErrors}.concat(${errs})`).assign(names_1$e.default.errors, (0, codegen_1$Z._)`${names_1$e.default.vErrors}.length`);
    (0, errors_1$5.extendErrors)(cxt);
  }, () => cxt.error());
}
function checkAsyncKeyword$1({ schemaEnv }, def2) {
  if (def2.async && !schemaEnv.$async)
    throw new Error("async keyword in sync schema");
}
function useKeyword$1(gen, keyword2, result) {
  if (result === void 0)
    throw new Error(`keyword "${keyword2}" failed to compile`);
  return gen.scopeValue("keyword", typeof result == "function" ? { ref: result } : { ref: result, code: (0, codegen_1$Z.stringify)(result) });
}
function validSchemaType$1(schema, schemaType, allowUndefined = false) {
  return !schemaType.length || schemaType.some((st) => st === "array" ? Array.isArray(schema) : st === "object" ? schema && typeof schema == "object" && !Array.isArray(schema) : typeof schema == st || allowUndefined && typeof schema == "undefined");
}
keyword$1.validSchemaType = validSchemaType$1;
function validateKeywordUsage$1({ schema, opts, self: self2, errSchemaPath }, def2, keyword2) {
  if (Array.isArray(def2.keyword) ? !def2.keyword.includes(keyword2) : def2.keyword !== keyword2) {
    throw new Error("ajv implementation error");
  }
  const deps = def2.dependencies;
  if (deps === null || deps === void 0 ? void 0 : deps.some((kwd) => !Object.prototype.hasOwnProperty.call(schema, kwd))) {
    throw new Error(`parent schema must have dependencies of ${keyword2}: ${deps.join(",")}`);
  }
  if (def2.validateSchema) {
    const valid2 = def2.validateSchema(schema[keyword2]);
    if (!valid2) {
      const msg = `keyword "${keyword2}" value is invalid at path "${errSchemaPath}": ` + self2.errorsText(def2.validateSchema.errors);
      if (opts.validateSchema === "log")
        self2.logger.error(msg);
      else
        throw new Error(msg);
    }
  }
}
keyword$1.validateKeywordUsage = validateKeywordUsage$1;
var subschema$1 = {};
Object.defineProperty(subschema$1, "__esModule", { value: true });
subschema$1.extendSubschemaMode = subschema$1.extendSubschemaData = subschema$1.getSubschema = void 0;
const codegen_1$Y = codegen$1;
const util_1$U = util$2;
function getSubschema$1(it, { keyword: keyword2, schemaProp, schema, schemaPath, errSchemaPath, topSchemaRef }) {
  if (keyword2 !== void 0 && schema !== void 0) {
    throw new Error('both "keyword" and "schema" passed, only one allowed');
  }
  if (keyword2 !== void 0) {
    const sch = it.schema[keyword2];
    return schemaProp === void 0 ? {
      schema: sch,
      schemaPath: (0, codegen_1$Y._)`${it.schemaPath}${(0, codegen_1$Y.getProperty)(keyword2)}`,
      errSchemaPath: `${it.errSchemaPath}/${keyword2}`
    } : {
      schema: sch[schemaProp],
      schemaPath: (0, codegen_1$Y._)`${it.schemaPath}${(0, codegen_1$Y.getProperty)(keyword2)}${(0, codegen_1$Y.getProperty)(schemaProp)}`,
      errSchemaPath: `${it.errSchemaPath}/${keyword2}/${(0, util_1$U.escapeFragment)(schemaProp)}`
    };
  }
  if (schema !== void 0) {
    if (schemaPath === void 0 || errSchemaPath === void 0 || topSchemaRef === void 0) {
      throw new Error('"schemaPath", "errSchemaPath" and "topSchemaRef" are required with "schema"');
    }
    return {
      schema,
      schemaPath,
      topSchemaRef,
      errSchemaPath
    };
  }
  throw new Error('either "keyword" or "schema" must be passed');
}
subschema$1.getSubschema = getSubschema$1;
function extendSubschemaData$1(subschema2, it, { dataProp, dataPropType: dpType, data, dataTypes, propertyName }) {
  if (data !== void 0 && dataProp !== void 0) {
    throw new Error('both "data" and "dataProp" passed, only one allowed');
  }
  const { gen } = it;
  if (dataProp !== void 0) {
    const { errorPath, dataPathArr, opts } = it;
    const nextData = gen.let("data", (0, codegen_1$Y._)`${it.data}${(0, codegen_1$Y.getProperty)(dataProp)}`, true);
    dataContextProps(nextData);
    subschema2.errorPath = (0, codegen_1$Y.str)`${errorPath}${(0, util_1$U.getErrorPath)(dataProp, dpType, opts.jsPropertySyntax)}`;
    subschema2.parentDataProperty = (0, codegen_1$Y._)`${dataProp}`;
    subschema2.dataPathArr = [...dataPathArr, subschema2.parentDataProperty];
  }
  if (data !== void 0) {
    const nextData = data instanceof codegen_1$Y.Name ? data : gen.let("data", data, true);
    dataContextProps(nextData);
    if (propertyName !== void 0)
      subschema2.propertyName = propertyName;
  }
  if (dataTypes)
    subschema2.dataTypes = dataTypes;
  function dataContextProps(_nextData) {
    subschema2.data = _nextData;
    subschema2.dataLevel = it.dataLevel + 1;
    subschema2.dataTypes = [];
    it.definedProperties = /* @__PURE__ */ new Set();
    subschema2.parentData = it.data;
    subschema2.dataNames = [...it.dataNames, _nextData];
  }
}
subschema$1.extendSubschemaData = extendSubschemaData$1;
function extendSubschemaMode$1(subschema2, { jtdDiscriminator, jtdMetadata, compositeRule, createErrors, allErrors }) {
  if (compositeRule !== void 0)
    subschema2.compositeRule = compositeRule;
  if (createErrors !== void 0)
    subschema2.createErrors = createErrors;
  if (allErrors !== void 0)
    subschema2.allErrors = allErrors;
  subschema2.jtdDiscriminator = jtdDiscriminator;
  subschema2.jtdMetadata = jtdMetadata;
}
subschema$1.extendSubschemaMode = extendSubschemaMode$1;
var resolve$4 = {};
var fastDeepEqual = function equal2(a, b) {
  if (a === b) return true;
  if (a && b && typeof a == "object" && typeof b == "object") {
    if (a.constructor !== b.constructor) return false;
    var length, i2, keys;
    if (Array.isArray(a)) {
      length = a.length;
      if (length != b.length) return false;
      for (i2 = length; i2-- !== 0; )
        if (!equal2(a[i2], b[i2])) return false;
      return true;
    }
    if (a.constructor === RegExp) return a.source === b.source && a.flags === b.flags;
    if (a.valueOf !== Object.prototype.valueOf) return a.valueOf() === b.valueOf();
    if (a.toString !== Object.prototype.toString) return a.toString() === b.toString();
    keys = Object.keys(a);
    length = keys.length;
    if (length !== Object.keys(b).length) return false;
    for (i2 = length; i2-- !== 0; )
      if (!Object.prototype.hasOwnProperty.call(b, keys[i2])) return false;
    for (i2 = length; i2-- !== 0; ) {
      var key = keys[i2];
      if (!equal2(a[key], b[key])) return false;
    }
    return true;
  }
  return a !== a && b !== b;
};
var jsonSchemaTraverse$1 = { exports: {} };
var traverse$3 = jsonSchemaTraverse$1.exports = function(schema, opts, cb) {
  if (typeof opts == "function") {
    cb = opts;
    opts = {};
  }
  cb = opts.cb || cb;
  var pre = typeof cb == "function" ? cb : cb.pre || function() {
  };
  var post = cb.post || function() {
  };
  _traverse$1(opts, pre, post, schema, "", schema);
};
traverse$3.keywords = {
  additionalItems: true,
  items: true,
  contains: true,
  additionalProperties: true,
  propertyNames: true,
  not: true,
  if: true,
  then: true,
  else: true
};
traverse$3.arrayKeywords = {
  items: true,
  allOf: true,
  anyOf: true,
  oneOf: true
};
traverse$3.propsKeywords = {
  $defs: true,
  definitions: true,
  properties: true,
  patternProperties: true,
  dependencies: true
};
traverse$3.skipKeywords = {
  default: true,
  enum: true,
  const: true,
  required: true,
  maximum: true,
  minimum: true,
  exclusiveMaximum: true,
  exclusiveMinimum: true,
  multipleOf: true,
  maxLength: true,
  minLength: true,
  pattern: true,
  format: true,
  maxItems: true,
  minItems: true,
  uniqueItems: true,
  maxProperties: true,
  minProperties: true
};
function _traverse$1(opts, pre, post, schema, jsonPtr, rootSchema, parentJsonPtr, parentKeyword, parentSchema, keyIndex) {
  if (schema && typeof schema == "object" && !Array.isArray(schema)) {
    pre(schema, jsonPtr, rootSchema, parentJsonPtr, parentKeyword, parentSchema, keyIndex);
    for (var key in schema) {
      var sch = schema[key];
      if (Array.isArray(sch)) {
        if (key in traverse$3.arrayKeywords) {
          for (var i2 = 0; i2 < sch.length; i2++)
            _traverse$1(opts, pre, post, sch[i2], jsonPtr + "/" + key + "/" + i2, rootSchema, jsonPtr, key, schema, i2);
        }
      } else if (key in traverse$3.propsKeywords) {
        if (sch && typeof sch == "object") {
          for (var prop in sch)
            _traverse$1(opts, pre, post, sch[prop], jsonPtr + "/" + key + "/" + escapeJsonPtr$1(prop), rootSchema, jsonPtr, key, schema, prop);
        }
      } else if (key in traverse$3.keywords || opts.allKeys && !(key in traverse$3.skipKeywords)) {
        _traverse$1(opts, pre, post, sch, jsonPtr + "/" + key, rootSchema, jsonPtr, key, schema);
      }
    }
    post(schema, jsonPtr, rootSchema, parentJsonPtr, parentKeyword, parentSchema, keyIndex);
  }
}
function escapeJsonPtr$1(str) {
  return str.replace(/~/g, "~0").replace(/\//g, "~1");
}
var jsonSchemaTraverseExports$1 = jsonSchemaTraverse$1.exports;
Object.defineProperty(resolve$4, "__esModule", { value: true });
resolve$4.getSchemaRefs = resolve$4.resolveUrl = resolve$4.normalizeId = resolve$4._getFullPath = resolve$4.getFullPath = resolve$4.inlineRef = void 0;
const util_1$T = util$2;
const equal$6 = fastDeepEqual;
const traverse$2 = jsonSchemaTraverseExports$1;
const SIMPLE_INLINED$1 = /* @__PURE__ */ new Set([
  "type",
  "format",
  "pattern",
  "maxLength",
  "minLength",
  "maxProperties",
  "minProperties",
  "maxItems",
  "minItems",
  "maximum",
  "minimum",
  "uniqueItems",
  "multipleOf",
  "required",
  "enum",
  "const"
]);
function inlineRef$1(schema, limit2 = true) {
  if (typeof schema == "boolean")
    return true;
  if (limit2 === true)
    return !hasRef$1(schema);
  if (!limit2)
    return false;
  return countKeys$1(schema) <= limit2;
}
resolve$4.inlineRef = inlineRef$1;
const REF_KEYWORDS$1 = /* @__PURE__ */ new Set([
  "$ref",
  "$recursiveRef",
  "$recursiveAnchor",
  "$dynamicRef",
  "$dynamicAnchor"
]);
function hasRef$1(schema) {
  for (const key in schema) {
    if (REF_KEYWORDS$1.has(key))
      return true;
    const sch = schema[key];
    if (Array.isArray(sch) && sch.some(hasRef$1))
      return true;
    if (typeof sch == "object" && hasRef$1(sch))
      return true;
  }
  return false;
}
function countKeys$1(schema) {
  let count = 0;
  for (const key in schema) {
    if (key === "$ref")
      return Infinity;
    count++;
    if (SIMPLE_INLINED$1.has(key))
      continue;
    if (typeof schema[key] == "object") {
      (0, util_1$T.eachItem)(schema[key], (sch) => count += countKeys$1(sch));
    }
    if (count === Infinity)
      return Infinity;
  }
  return count;
}
function getFullPath$1(resolver, id2 = "", normalize2) {
  if (normalize2 !== false)
    id2 = normalizeId$1(id2);
  const p = resolver.parse(id2);
  return _getFullPath$1(resolver, p);
}
resolve$4.getFullPath = getFullPath$1;
function _getFullPath$1(resolver, p) {
  const serialized = resolver.serialize(p);
  return serialized.split("#")[0] + "#";
}
resolve$4._getFullPath = _getFullPath$1;
const TRAILING_SLASH_HASH$1 = /#\/?$/;
function normalizeId$1(id2) {
  return id2 ? id2.replace(TRAILING_SLASH_HASH$1, "") : "";
}
resolve$4.normalizeId = normalizeId$1;
function resolveUrl$1(resolver, baseId, id2) {
  id2 = normalizeId$1(id2);
  return resolver.resolve(baseId, id2);
}
resolve$4.resolveUrl = resolveUrl$1;
const ANCHOR$1 = /^[a-z_][-a-z0-9._]*$/i;
function getSchemaRefs$1(schema, baseId) {
  if (typeof schema == "boolean")
    return {};
  const { schemaId, uriResolver } = this.opts;
  const schId = normalizeId$1(schema[schemaId] || baseId);
  const baseIds = { "": schId };
  const pathPrefix = getFullPath$1(uriResolver, schId, false);
  const localRefs = {};
  const schemaRefs = /* @__PURE__ */ new Set();
  traverse$2(schema, { allKeys: true }, (sch, jsonPtr, _, parentJsonPtr) => {
    if (parentJsonPtr === void 0)
      return;
    const fullPath = pathPrefix + jsonPtr;
    let innerBaseId = baseIds[parentJsonPtr];
    if (typeof sch[schemaId] == "string")
      innerBaseId = addRef.call(this, sch[schemaId]);
    addAnchor.call(this, sch.$anchor);
    addAnchor.call(this, sch.$dynamicAnchor);
    baseIds[jsonPtr] = innerBaseId;
    function addRef(ref2) {
      const _resolve = this.opts.uriResolver.resolve;
      ref2 = normalizeId$1(innerBaseId ? _resolve(innerBaseId, ref2) : ref2);
      if (schemaRefs.has(ref2))
        throw ambiguos(ref2);
      schemaRefs.add(ref2);
      let schOrRef = this.refs[ref2];
      if (typeof schOrRef == "string")
        schOrRef = this.refs[schOrRef];
      if (typeof schOrRef == "object") {
        checkAmbiguosRef(sch, schOrRef.schema, ref2);
      } else if (ref2 !== normalizeId$1(fullPath)) {
        if (ref2[0] === "#") {
          checkAmbiguosRef(sch, localRefs[ref2], ref2);
          localRefs[ref2] = sch;
        } else {
          this.refs[ref2] = fullPath;
        }
      }
      return ref2;
    }
    function addAnchor(anchor) {
      if (typeof anchor == "string") {
        if (!ANCHOR$1.test(anchor))
          throw new Error(`invalid anchor "${anchor}"`);
        addRef.call(this, `#${anchor}`);
      }
    }
  });
  return localRefs;
  function checkAmbiguosRef(sch1, sch2, ref2) {
    if (sch2 !== void 0 && !equal$6(sch1, sch2))
      throw ambiguos(ref2);
  }
  function ambiguos(ref2) {
    return new Error(`reference "${ref2}" resolves to more than one schema`);
  }
}
resolve$4.getSchemaRefs = getSchemaRefs$1;
Object.defineProperty(validate$1, "__esModule", { value: true });
validate$1.getData = validate$1.KeywordCxt = validate$1.validateFunctionCode = void 0;
const boolSchema_1$1 = boolSchema$1;
const dataType_1$3 = dataType$1;
const applicability_1$2 = applicability$1;
const dataType_2$1 = dataType$1;
const defaults_1$1 = defaults$1;
const keyword_1$1 = keyword$1;
const subschema_1$1 = subschema$1;
const codegen_1$X = codegen$1;
const names_1$d = names$3;
const resolve_1$5 = resolve$4;
const util_1$S = util$2;
const errors_1$4 = errors$1;
function validateFunctionCode$1(it) {
  if (isSchemaObj$1(it)) {
    checkKeywords$1(it);
    if (schemaCxtHasRules$1(it)) {
      topSchemaObjCode$1(it);
      return;
    }
  }
  validateFunction$1(it, () => (0, boolSchema_1$1.topBoolOrEmptySchema)(it));
}
validate$1.validateFunctionCode = validateFunctionCode$1;
function validateFunction$1({ gen, validateName, schema, schemaEnv, opts }, body) {
  if (opts.code.es5) {
    gen.func(validateName, (0, codegen_1$X._)`${names_1$d.default.data}, ${names_1$d.default.valCxt}`, schemaEnv.$async, () => {
      gen.code((0, codegen_1$X._)`"use strict"; ${funcSourceUrl$1(schema, opts)}`);
      destructureValCxtES5$1(gen, opts);
      gen.code(body);
    });
  } else {
    gen.func(validateName, (0, codegen_1$X._)`${names_1$d.default.data}, ${destructureValCxt$1(opts)}`, schemaEnv.$async, () => gen.code(funcSourceUrl$1(schema, opts)).code(body));
  }
}
function destructureValCxt$1(opts) {
  return (0, codegen_1$X._)`{${names_1$d.default.instancePath}="", ${names_1$d.default.parentData}, ${names_1$d.default.parentDataProperty}, ${names_1$d.default.rootData}=${names_1$d.default.data}${opts.dynamicRef ? (0, codegen_1$X._)`, ${names_1$d.default.dynamicAnchors}={}` : codegen_1$X.nil}}={}`;
}
function destructureValCxtES5$1(gen, opts) {
  gen.if(names_1$d.default.valCxt, () => {
    gen.var(names_1$d.default.instancePath, (0, codegen_1$X._)`${names_1$d.default.valCxt}.${names_1$d.default.instancePath}`);
    gen.var(names_1$d.default.parentData, (0, codegen_1$X._)`${names_1$d.default.valCxt}.${names_1$d.default.parentData}`);
    gen.var(names_1$d.default.parentDataProperty, (0, codegen_1$X._)`${names_1$d.default.valCxt}.${names_1$d.default.parentDataProperty}`);
    gen.var(names_1$d.default.rootData, (0, codegen_1$X._)`${names_1$d.default.valCxt}.${names_1$d.default.rootData}`);
    if (opts.dynamicRef)
      gen.var(names_1$d.default.dynamicAnchors, (0, codegen_1$X._)`${names_1$d.default.valCxt}.${names_1$d.default.dynamicAnchors}`);
  }, () => {
    gen.var(names_1$d.default.instancePath, (0, codegen_1$X._)`""`);
    gen.var(names_1$d.default.parentData, (0, codegen_1$X._)`undefined`);
    gen.var(names_1$d.default.parentDataProperty, (0, codegen_1$X._)`undefined`);
    gen.var(names_1$d.default.rootData, names_1$d.default.data);
    if (opts.dynamicRef)
      gen.var(names_1$d.default.dynamicAnchors, (0, codegen_1$X._)`{}`);
  });
}
function topSchemaObjCode$1(it) {
  const { schema, opts, gen } = it;
  validateFunction$1(it, () => {
    if (opts.$comment && schema.$comment)
      commentKeyword$1(it);
    checkNoDefault$1(it);
    gen.let(names_1$d.default.vErrors, null);
    gen.let(names_1$d.default.errors, 0);
    if (opts.unevaluated)
      resetEvaluated$1(it);
    typeAndKeywords$1(it);
    returnResults$1(it);
  });
  return;
}
function resetEvaluated$1(it) {
  const { gen, validateName } = it;
  it.evaluated = gen.const("evaluated", (0, codegen_1$X._)`${validateName}.evaluated`);
  gen.if((0, codegen_1$X._)`${it.evaluated}.dynamicProps`, () => gen.assign((0, codegen_1$X._)`${it.evaluated}.props`, (0, codegen_1$X._)`undefined`));
  gen.if((0, codegen_1$X._)`${it.evaluated}.dynamicItems`, () => gen.assign((0, codegen_1$X._)`${it.evaluated}.items`, (0, codegen_1$X._)`undefined`));
}
function funcSourceUrl$1(schema, opts) {
  const schId = typeof schema == "object" && schema[opts.schemaId];
  return schId && (opts.code.source || opts.code.process) ? (0, codegen_1$X._)`/*# sourceURL=${schId} */` : codegen_1$X.nil;
}
function subschemaCode$1(it, valid2) {
  if (isSchemaObj$1(it)) {
    checkKeywords$1(it);
    if (schemaCxtHasRules$1(it)) {
      subSchemaObjCode$1(it, valid2);
      return;
    }
  }
  (0, boolSchema_1$1.boolOrEmptySchema)(it, valid2);
}
function schemaCxtHasRules$1({ schema, self: self2 }) {
  if (typeof schema == "boolean")
    return !schema;
  for (const key in schema)
    if (self2.RULES.all[key])
      return true;
  return false;
}
function isSchemaObj$1(it) {
  return typeof it.schema != "boolean";
}
function subSchemaObjCode$1(it, valid2) {
  const { schema, gen, opts } = it;
  if (opts.$comment && schema.$comment)
    commentKeyword$1(it);
  updateContext$1(it);
  checkAsyncSchema$1(it);
  const errsCount = gen.const("_errs", names_1$d.default.errors);
  typeAndKeywords$1(it, errsCount);
  gen.var(valid2, (0, codegen_1$X._)`${errsCount} === ${names_1$d.default.errors}`);
}
function checkKeywords$1(it) {
  (0, util_1$S.checkUnknownRules)(it);
  checkRefsAndKeywords$1(it);
}
function typeAndKeywords$1(it, errsCount) {
  if (it.opts.jtd)
    return schemaKeywords$1(it, [], false, errsCount);
  const types2 = (0, dataType_1$3.getSchemaTypes)(it.schema);
  const checkedTypes = (0, dataType_1$3.coerceAndCheckDataType)(it, types2);
  schemaKeywords$1(it, types2, !checkedTypes, errsCount);
}
function checkRefsAndKeywords$1(it) {
  const { schema, errSchemaPath, opts, self: self2 } = it;
  if (schema.$ref && opts.ignoreKeywordsWithRef && (0, util_1$S.schemaHasRulesButRef)(schema, self2.RULES)) {
    self2.logger.warn(`$ref: keywords ignored in schema at path "${errSchemaPath}"`);
  }
}
function checkNoDefault$1(it) {
  const { schema, opts } = it;
  if (schema.default !== void 0 && opts.useDefaults && opts.strictSchema) {
    (0, util_1$S.checkStrictMode)(it, "default is ignored in the schema root");
  }
}
function updateContext$1(it) {
  const schId = it.schema[it.opts.schemaId];
  if (schId)
    it.baseId = (0, resolve_1$5.resolveUrl)(it.opts.uriResolver, it.baseId, schId);
}
function checkAsyncSchema$1(it) {
  if (it.schema.$async && !it.schemaEnv.$async)
    throw new Error("async schema in sync schema");
}
function commentKeyword$1({ gen, schemaEnv, schema, errSchemaPath, opts }) {
  const msg = schema.$comment;
  if (opts.$comment === true) {
    gen.code((0, codegen_1$X._)`${names_1$d.default.self}.logger.log(${msg})`);
  } else if (typeof opts.$comment == "function") {
    const schemaPath = (0, codegen_1$X.str)`${errSchemaPath}/$comment`;
    const rootName = gen.scopeValue("root", { ref: schemaEnv.root });
    gen.code((0, codegen_1$X._)`${names_1$d.default.self}.opts.$comment(${msg}, ${schemaPath}, ${rootName}.schema)`);
  }
}
function returnResults$1(it) {
  const { gen, schemaEnv, validateName, ValidationError: ValidationError3, opts } = it;
  if (schemaEnv.$async) {
    gen.if((0, codegen_1$X._)`${names_1$d.default.errors} === 0`, () => gen.return(names_1$d.default.data), () => gen.throw((0, codegen_1$X._)`new ${ValidationError3}(${names_1$d.default.vErrors})`));
  } else {
    gen.assign((0, codegen_1$X._)`${validateName}.errors`, names_1$d.default.vErrors);
    if (opts.unevaluated)
      assignEvaluated$1(it);
    gen.return((0, codegen_1$X._)`${names_1$d.default.errors} === 0`);
  }
}
function assignEvaluated$1({ gen, evaluated, props, items: items2 }) {
  if (props instanceof codegen_1$X.Name)
    gen.assign((0, codegen_1$X._)`${evaluated}.props`, props);
  if (items2 instanceof codegen_1$X.Name)
    gen.assign((0, codegen_1$X._)`${evaluated}.items`, items2);
}
function schemaKeywords$1(it, types2, typeErrors, errsCount) {
  const { gen, schema, data, allErrors, opts, self: self2 } = it;
  const { RULES } = self2;
  if (schema.$ref && (opts.ignoreKeywordsWithRef || !(0, util_1$S.schemaHasRulesButRef)(schema, RULES))) {
    gen.block(() => keywordCode$1(it, "$ref", RULES.all.$ref.definition));
    return;
  }
  if (!opts.jtd)
    checkStrictTypes$1(it, types2);
  gen.block(() => {
    for (const group of RULES.rules)
      groupKeywords(group);
    groupKeywords(RULES.post);
  });
  function groupKeywords(group) {
    if (!(0, applicability_1$2.shouldUseGroup)(schema, group))
      return;
    if (group.type) {
      gen.if((0, dataType_2$1.checkDataType)(group.type, data, opts.strictNumbers));
      iterateKeywords$1(it, group);
      if (types2.length === 1 && types2[0] === group.type && typeErrors) {
        gen.else();
        (0, dataType_2$1.reportTypeError)(it);
      }
      gen.endIf();
    } else {
      iterateKeywords$1(it, group);
    }
    if (!allErrors)
      gen.if((0, codegen_1$X._)`${names_1$d.default.errors} === ${errsCount || 0}`);
  }
}
function iterateKeywords$1(it, group) {
  const { gen, schema, opts: { useDefaults } } = it;
  if (useDefaults)
    (0, defaults_1$1.assignDefaults)(it, group.type);
  gen.block(() => {
    for (const rule of group.rules) {
      if ((0, applicability_1$2.shouldUseRule)(schema, rule)) {
        keywordCode$1(it, rule.keyword, rule.definition, group.type);
      }
    }
  });
}
function checkStrictTypes$1(it, types2) {
  if (it.schemaEnv.meta || !it.opts.strictTypes)
    return;
  checkContextTypes$1(it, types2);
  if (!it.opts.allowUnionTypes)
    checkMultipleTypes$1(it, types2);
  checkKeywordTypes$1(it, it.dataTypes);
}
function checkContextTypes$1(it, types2) {
  if (!types2.length)
    return;
  if (!it.dataTypes.length) {
    it.dataTypes = types2;
    return;
  }
  types2.forEach((t2) => {
    if (!includesType$1(it.dataTypes, t2)) {
      strictTypesError$1(it, `type "${t2}" not allowed by context "${it.dataTypes.join(",")}"`);
    }
  });
  narrowSchemaTypes$1(it, types2);
}
function checkMultipleTypes$1(it, ts) {
  if (ts.length > 1 && !(ts.length === 2 && ts.includes("null"))) {
    strictTypesError$1(it, "use allowUnionTypes to allow union type keyword");
  }
}
function checkKeywordTypes$1(it, ts) {
  const rules2 = it.self.RULES.all;
  for (const keyword2 in rules2) {
    const rule = rules2[keyword2];
    if (typeof rule == "object" && (0, applicability_1$2.shouldUseRule)(it.schema, rule)) {
      const { type: type2 } = rule.definition;
      if (type2.length && !type2.some((t2) => hasApplicableType$1(ts, t2))) {
        strictTypesError$1(it, `missing type "${type2.join(",")}" for keyword "${keyword2}"`);
      }
    }
  }
}
function hasApplicableType$1(schTs, kwdT) {
  return schTs.includes(kwdT) || kwdT === "number" && schTs.includes("integer");
}
function includesType$1(ts, t2) {
  return ts.includes(t2) || t2 === "integer" && ts.includes("number");
}
function narrowSchemaTypes$1(it, withTypes) {
  const ts = [];
  for (const t2 of it.dataTypes) {
    if (includesType$1(withTypes, t2))
      ts.push(t2);
    else if (withTypes.includes("integer") && t2 === "number")
      ts.push("integer");
  }
  it.dataTypes = ts;
}
function strictTypesError$1(it, msg) {
  const schemaPath = it.schemaEnv.baseId + it.errSchemaPath;
  msg += ` at "${schemaPath}" (strictTypes)`;
  (0, util_1$S.checkStrictMode)(it, msg, it.opts.strictTypes);
}
let KeywordCxt$1 = class KeywordCxt2 {
  constructor(it, def2, keyword2) {
    (0, keyword_1$1.validateKeywordUsage)(it, def2, keyword2);
    this.gen = it.gen;
    this.allErrors = it.allErrors;
    this.keyword = keyword2;
    this.data = it.data;
    this.schema = it.schema[keyword2];
    this.$data = def2.$data && it.opts.$data && this.schema && this.schema.$data;
    this.schemaValue = (0, util_1$S.schemaRefOrVal)(it, this.schema, keyword2, this.$data);
    this.schemaType = def2.schemaType;
    this.parentSchema = it.schema;
    this.params = {};
    this.it = it;
    this.def = def2;
    if (this.$data) {
      this.schemaCode = it.gen.const("vSchema", getData$1(this.$data, it));
    } else {
      this.schemaCode = this.schemaValue;
      if (!(0, keyword_1$1.validSchemaType)(this.schema, def2.schemaType, def2.allowUndefined)) {
        throw new Error(`${keyword2} value must be ${JSON.stringify(def2.schemaType)}`);
      }
    }
    if ("code" in def2 ? def2.trackErrors : def2.errors !== false) {
      this.errsCount = it.gen.const("_errs", names_1$d.default.errors);
    }
  }
  result(condition, successAction, failAction) {
    this.failResult((0, codegen_1$X.not)(condition), successAction, failAction);
  }
  failResult(condition, successAction, failAction) {
    this.gen.if(condition);
    if (failAction)
      failAction();
    else
      this.error();
    if (successAction) {
      this.gen.else();
      successAction();
      if (this.allErrors)
        this.gen.endIf();
    } else {
      if (this.allErrors)
        this.gen.endIf();
      else
        this.gen.else();
    }
  }
  pass(condition, failAction) {
    this.failResult((0, codegen_1$X.not)(condition), void 0, failAction);
  }
  fail(condition) {
    if (condition === void 0) {
      this.error();
      if (!this.allErrors)
        this.gen.if(false);
      return;
    }
    this.gen.if(condition);
    this.error();
    if (this.allErrors)
      this.gen.endIf();
    else
      this.gen.else();
  }
  fail$data(condition) {
    if (!this.$data)
      return this.fail(condition);
    const { schemaCode } = this;
    this.fail((0, codegen_1$X._)`${schemaCode} !== undefined && (${(0, codegen_1$X.or)(this.invalid$data(), condition)})`);
  }
  error(append, errorParams, errorPaths) {
    if (errorParams) {
      this.setParams(errorParams);
      this._error(append, errorPaths);
      this.setParams({});
      return;
    }
    this._error(append, errorPaths);
  }
  _error(append, errorPaths) {
    (append ? errors_1$4.reportExtraError : errors_1$4.reportError)(this, this.def.error, errorPaths);
  }
  $dataError() {
    (0, errors_1$4.reportError)(this, this.def.$dataError || errors_1$4.keyword$DataError);
  }
  reset() {
    if (this.errsCount === void 0)
      throw new Error('add "trackErrors" to keyword definition');
    (0, errors_1$4.resetErrorsCount)(this.gen, this.errsCount);
  }
  ok(cond) {
    if (!this.allErrors)
      this.gen.if(cond);
  }
  setParams(obj, assign) {
    if (assign)
      Object.assign(this.params, obj);
    else
      this.params = obj;
  }
  block$data(valid2, codeBlock, $dataValid = codegen_1$X.nil) {
    this.gen.block(() => {
      this.check$data(valid2, $dataValid);
      codeBlock();
    });
  }
  check$data(valid2 = codegen_1$X.nil, $dataValid = codegen_1$X.nil) {
    if (!this.$data)
      return;
    const { gen, schemaCode, schemaType, def: def2 } = this;
    gen.if((0, codegen_1$X.or)((0, codegen_1$X._)`${schemaCode} === undefined`, $dataValid));
    if (valid2 !== codegen_1$X.nil)
      gen.assign(valid2, true);
    if (schemaType.length || def2.validateSchema) {
      gen.elseIf(this.invalid$data());
      this.$dataError();
      if (valid2 !== codegen_1$X.nil)
        gen.assign(valid2, false);
    }
    gen.else();
  }
  invalid$data() {
    const { gen, schemaCode, schemaType, def: def2, it } = this;
    return (0, codegen_1$X.or)(wrong$DataType(), invalid$DataSchema());
    function wrong$DataType() {
      if (schemaType.length) {
        if (!(schemaCode instanceof codegen_1$X.Name))
          throw new Error("ajv implementation error");
        const st = Array.isArray(schemaType) ? schemaType : [schemaType];
        return (0, codegen_1$X._)`${(0, dataType_2$1.checkDataTypes)(st, schemaCode, it.opts.strictNumbers, dataType_2$1.DataType.Wrong)}`;
      }
      return codegen_1$X.nil;
    }
    function invalid$DataSchema() {
      if (def2.validateSchema) {
        const validateSchemaRef = gen.scopeValue("validate$data", { ref: def2.validateSchema });
        return (0, codegen_1$X._)`!${validateSchemaRef}(${schemaCode})`;
      }
      return codegen_1$X.nil;
    }
  }
  subschema(appl, valid2) {
    const subschema2 = (0, subschema_1$1.getSubschema)(this.it, appl);
    (0, subschema_1$1.extendSubschemaData)(subschema2, this.it, appl);
    (0, subschema_1$1.extendSubschemaMode)(subschema2, appl);
    const nextContext = { ...this.it, ...subschema2, items: void 0, props: void 0 };
    subschemaCode$1(nextContext, valid2);
    return nextContext;
  }
  mergeEvaluated(schemaCxt, toName) {
    const { it, gen } = this;
    if (!it.opts.unevaluated)
      return;
    if (it.props !== true && schemaCxt.props !== void 0) {
      it.props = util_1$S.mergeEvaluated.props(gen, schemaCxt.props, it.props, toName);
    }
    if (it.items !== true && schemaCxt.items !== void 0) {
      it.items = util_1$S.mergeEvaluated.items(gen, schemaCxt.items, it.items, toName);
    }
  }
  mergeValidEvaluated(schemaCxt, valid2) {
    const { it, gen } = this;
    if (it.opts.unevaluated && (it.props !== true || it.items !== true)) {
      gen.if(valid2, () => this.mergeEvaluated(schemaCxt, codegen_1$X.Name));
      return true;
    }
  }
};
validate$1.KeywordCxt = KeywordCxt$1;
function keywordCode$1(it, keyword2, def2, ruleType) {
  const cxt = new KeywordCxt$1(it, def2, keyword2);
  if ("code" in def2) {
    def2.code(cxt, ruleType);
  } else if (cxt.$data && def2.validate) {
    (0, keyword_1$1.funcKeywordCode)(cxt, def2);
  } else if ("macro" in def2) {
    (0, keyword_1$1.macroKeywordCode)(cxt, def2);
  } else if (def2.compile || def2.validate) {
    (0, keyword_1$1.funcKeywordCode)(cxt, def2);
  }
}
const JSON_POINTER$1 = /^\/(?:[^~]|~0|~1)*$/;
const RELATIVE_JSON_POINTER$1 = /^([0-9]+)(#|\/(?:[^~]|~0|~1)*)?$/;
function getData$1($data, { dataLevel, dataNames, dataPathArr }) {
  let jsonPointer;
  let data;
  if ($data === "")
    return names_1$d.default.rootData;
  if ($data[0] === "/") {
    if (!JSON_POINTER$1.test($data))
      throw new Error(`Invalid JSON-pointer: ${$data}`);
    jsonPointer = $data;
    data = names_1$d.default.rootData;
  } else {
    const matches = RELATIVE_JSON_POINTER$1.exec($data);
    if (!matches)
      throw new Error(`Invalid JSON-pointer: ${$data}`);
    const up = +matches[1];
    jsonPointer = matches[2];
    if (jsonPointer === "#") {
      if (up >= dataLevel)
        throw new Error(errorMsg("property/index", up));
      return dataPathArr[dataLevel - up];
    }
    if (up > dataLevel)
      throw new Error(errorMsg("data", up));
    data = dataNames[dataLevel - up];
    if (!jsonPointer)
      return data;
  }
  let expr = data;
  const segments = jsonPointer.split("/");
  for (const segment of segments) {
    if (segment) {
      data = (0, codegen_1$X._)`${data}${(0, codegen_1$X.getProperty)((0, util_1$S.unescapeJsonPointer)(segment))}`;
      expr = (0, codegen_1$X._)`${expr} && ${data}`;
    }
  }
  return expr;
  function errorMsg(pointerType, up) {
    return `Cannot access ${pointerType} ${up} levels up, current level is ${dataLevel}`;
  }
}
validate$1.getData = getData$1;
var validation_error$1 = {};
Object.defineProperty(validation_error$1, "__esModule", { value: true });
let ValidationError$1 = class ValidationError2 extends Error {
  constructor(errors2) {
    super("validation failed");
    this.errors = errors2;
    this.ajv = this.validation = true;
  }
};
validation_error$1.default = ValidationError$1;
var ref_error$1 = {};
Object.defineProperty(ref_error$1, "__esModule", { value: true });
const resolve_1$4 = resolve$4;
let MissingRefError$1 = class MissingRefError2 extends Error {
  constructor(resolver, baseId, ref2, msg) {
    super(msg || `can't resolve reference ${ref2} from id ${baseId}`);
    this.missingRef = (0, resolve_1$4.resolveUrl)(resolver, baseId, ref2);
    this.missingSchema = (0, resolve_1$4.normalizeId)((0, resolve_1$4.getFullPath)(resolver, this.missingRef));
  }
};
ref_error$1.default = MissingRefError$1;
var compile$1 = {};
Object.defineProperty(compile$1, "__esModule", { value: true });
compile$1.resolveSchema = compile$1.getCompilingSchema = compile$1.resolveRef = compile$1.compileSchema = compile$1.SchemaEnv = void 0;
const codegen_1$W = codegen$1;
const validation_error_1$1 = validation_error$1;
const names_1$c = names$3;
const resolve_1$3 = resolve$4;
const util_1$R = util$2;
const validate_1$3 = validate$1;
let SchemaEnv$1 = class SchemaEnv2 {
  constructor(env2) {
    var _a2;
    this.refs = {};
    this.dynamicAnchors = {};
    let schema;
    if (typeof env2.schema == "object")
      schema = env2.schema;
    this.schema = env2.schema;
    this.schemaId = env2.schemaId;
    this.root = env2.root || this;
    this.baseId = (_a2 = env2.baseId) !== null && _a2 !== void 0 ? _a2 : (0, resolve_1$3.normalizeId)(schema === null || schema === void 0 ? void 0 : schema[env2.schemaId || "$id"]);
    this.schemaPath = env2.schemaPath;
    this.localRefs = env2.localRefs;
    this.meta = env2.meta;
    this.$async = schema === null || schema === void 0 ? void 0 : schema.$async;
    this.refs = {};
  }
};
compile$1.SchemaEnv = SchemaEnv$1;
function compileSchema$1(sch) {
  const _sch = getCompilingSchema$1.call(this, sch);
  if (_sch)
    return _sch;
  const rootId = (0, resolve_1$3.getFullPath)(this.opts.uriResolver, sch.root.baseId);
  const { es5, lines } = this.opts.code;
  const { ownProperties } = this.opts;
  const gen = new codegen_1$W.CodeGen(this.scope, { es5, lines, ownProperties });
  let _ValidationError;
  if (sch.$async) {
    _ValidationError = gen.scopeValue("Error", {
      ref: validation_error_1$1.default,
      code: (0, codegen_1$W._)`require("ajv/dist/runtime/validation_error").default`
    });
  }
  const validateName = gen.scopeName("validate");
  sch.validateName = validateName;
  const schemaCxt = {
    gen,
    allErrors: this.opts.allErrors,
    data: names_1$c.default.data,
    parentData: names_1$c.default.parentData,
    parentDataProperty: names_1$c.default.parentDataProperty,
    dataNames: [names_1$c.default.data],
    dataPathArr: [codegen_1$W.nil],
    // TODO can its length be used as dataLevel if nil is removed?
    dataLevel: 0,
    dataTypes: [],
    definedProperties: /* @__PURE__ */ new Set(),
    topSchemaRef: gen.scopeValue("schema", this.opts.code.source === true ? { ref: sch.schema, code: (0, codegen_1$W.stringify)(sch.schema) } : { ref: sch.schema }),
    validateName,
    ValidationError: _ValidationError,
    schema: sch.schema,
    schemaEnv: sch,
    rootId,
    baseId: sch.baseId || rootId,
    schemaPath: codegen_1$W.nil,
    errSchemaPath: sch.schemaPath || (this.opts.jtd ? "" : "#"),
    errorPath: (0, codegen_1$W._)`""`,
    opts: this.opts,
    self: this
  };
  let sourceCode;
  try {
    this._compilations.add(sch);
    (0, validate_1$3.validateFunctionCode)(schemaCxt);
    gen.optimize(this.opts.code.optimize);
    const validateCode = gen.toString();
    sourceCode = `${gen.scopeRefs(names_1$c.default.scope)}return ${validateCode}`;
    if (this.opts.code.process)
      sourceCode = this.opts.code.process(sourceCode, sch);
    const makeValidate = new Function(`${names_1$c.default.self}`, `${names_1$c.default.scope}`, sourceCode);
    const validate2 = makeValidate(this, this.scope.get());
    this.scope.value(validateName, { ref: validate2 });
    validate2.errors = null;
    validate2.schema = sch.schema;
    validate2.schemaEnv = sch;
    if (sch.$async)
      validate2.$async = true;
    if (this.opts.code.source === true) {
      validate2.source = { validateName, validateCode, scopeValues: gen._values };
    }
    if (this.opts.unevaluated) {
      const { props, items: items2 } = schemaCxt;
      validate2.evaluated = {
        props: props instanceof codegen_1$W.Name ? void 0 : props,
        items: items2 instanceof codegen_1$W.Name ? void 0 : items2,
        dynamicProps: props instanceof codegen_1$W.Name,
        dynamicItems: items2 instanceof codegen_1$W.Name
      };
      if (validate2.source)
        validate2.source.evaluated = (0, codegen_1$W.stringify)(validate2.evaluated);
    }
    sch.validate = validate2;
    return sch;
  } catch (e) {
    delete sch.validate;
    delete sch.validateName;
    if (sourceCode)
      this.logger.error("Error compiling schema, function code:", sourceCode);
    throw e;
  } finally {
    this._compilations.delete(sch);
  }
}
compile$1.compileSchema = compileSchema$1;
function resolveRef$1(root, baseId, ref2) {
  var _a2;
  ref2 = (0, resolve_1$3.resolveUrl)(this.opts.uriResolver, baseId, ref2);
  const schOrFunc = root.refs[ref2];
  if (schOrFunc)
    return schOrFunc;
  let _sch = resolve$3.call(this, root, ref2);
  if (_sch === void 0) {
    const schema = (_a2 = root.localRefs) === null || _a2 === void 0 ? void 0 : _a2[ref2];
    const { schemaId } = this.opts;
    if (schema)
      _sch = new SchemaEnv$1({ schema, schemaId, root, baseId });
  }
  if (_sch === void 0)
    return;
  return root.refs[ref2] = inlineOrCompile$1.call(this, _sch);
}
compile$1.resolveRef = resolveRef$1;
function inlineOrCompile$1(sch) {
  if ((0, resolve_1$3.inlineRef)(sch.schema, this.opts.inlineRefs))
    return sch.schema;
  return sch.validate ? sch : compileSchema$1.call(this, sch);
}
function getCompilingSchema$1(schEnv) {
  for (const sch of this._compilations) {
    if (sameSchemaEnv$1(sch, schEnv))
      return sch;
  }
}
compile$1.getCompilingSchema = getCompilingSchema$1;
function sameSchemaEnv$1(s1, s2) {
  return s1.schema === s2.schema && s1.root === s2.root && s1.baseId === s2.baseId;
}
function resolve$3(root, ref2) {
  let sch;
  while (typeof (sch = this.refs[ref2]) == "string")
    ref2 = sch;
  return sch || this.schemas[ref2] || resolveSchema$1.call(this, root, ref2);
}
function resolveSchema$1(root, ref2) {
  const p = this.opts.uriResolver.parse(ref2);
  const refPath = (0, resolve_1$3._getFullPath)(this.opts.uriResolver, p);
  let baseId = (0, resolve_1$3.getFullPath)(this.opts.uriResolver, root.baseId, void 0);
  if (Object.keys(root.schema).length > 0 && refPath === baseId) {
    return getJsonPointer$1.call(this, p, root);
  }
  const id2 = (0, resolve_1$3.normalizeId)(refPath);
  const schOrRef = this.refs[id2] || this.schemas[id2];
  if (typeof schOrRef == "string") {
    const sch = resolveSchema$1.call(this, root, schOrRef);
    if (typeof (sch === null || sch === void 0 ? void 0 : sch.schema) !== "object")
      return;
    return getJsonPointer$1.call(this, p, sch);
  }
  if (typeof (schOrRef === null || schOrRef === void 0 ? void 0 : schOrRef.schema) !== "object")
    return;
  if (!schOrRef.validate)
    compileSchema$1.call(this, schOrRef);
  if (id2 === (0, resolve_1$3.normalizeId)(ref2)) {
    const { schema } = schOrRef;
    const { schemaId } = this.opts;
    const schId = schema[schemaId];
    if (schId)
      baseId = (0, resolve_1$3.resolveUrl)(this.opts.uriResolver, baseId, schId);
    return new SchemaEnv$1({ schema, schemaId, root, baseId });
  }
  return getJsonPointer$1.call(this, p, schOrRef);
}
compile$1.resolveSchema = resolveSchema$1;
const PREVENT_SCOPE_CHANGE$1 = /* @__PURE__ */ new Set([
  "properties",
  "patternProperties",
  "enum",
  "dependencies",
  "definitions"
]);
function getJsonPointer$1(parsedRef, { baseId, schema, root }) {
  var _a2;
  if (((_a2 = parsedRef.fragment) === null || _a2 === void 0 ? void 0 : _a2[0]) !== "/")
    return;
  for (const part of parsedRef.fragment.slice(1).split("/")) {
    if (typeof schema === "boolean")
      return;
    const partSchema = schema[(0, util_1$R.unescapeFragment)(part)];
    if (partSchema === void 0)
      return;
    schema = partSchema;
    const schId = typeof schema === "object" && schema[this.opts.schemaId];
    if (!PREVENT_SCOPE_CHANGE$1.has(part) && schId) {
      baseId = (0, resolve_1$3.resolveUrl)(this.opts.uriResolver, baseId, schId);
    }
  }
  let env2;
  if (typeof schema != "boolean" && schema.$ref && !(0, util_1$R.schemaHasRulesButRef)(schema, this.RULES)) {
    const $ref = (0, resolve_1$3.resolveUrl)(this.opts.uriResolver, baseId, schema.$ref);
    env2 = resolveSchema$1.call(this, root, $ref);
  }
  const { schemaId } = this.opts;
  env2 = env2 || new SchemaEnv$1({ schema, schemaId, root, baseId });
  if (env2.schema !== env2.root.schema)
    return env2;
  return void 0;
}
const $id$a = "https://raw.githubusercontent.com/ajv-validator/ajv/master/lib/refs/data.json#";
const description$1 = "Meta-schema for $data reference (JSON AnySchema extension proposal)";
const type$a = "object";
const required$3 = [
  "$data"
];
const properties$c = {
  $data: {
    type: "string",
    anyOf: [
      {
        format: "relative-json-pointer"
      },
      {
        format: "json-pointer"
      }
    ]
  }
};
const additionalProperties$3 = false;
const require$$9$1 = {
  $id: $id$a,
  description: description$1,
  type: type$a,
  required: required$3,
  properties: properties$c,
  additionalProperties: additionalProperties$3
};
var uri$3 = {};
var fastUri$1 = { exports: {} };
const isUUID$1 = RegExp.prototype.test.bind(/^[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12}$/iu);
const isIPv4$1 = RegExp.prototype.test.bind(/^(?:(?:25[0-5]|2[0-4]\d|1\d{2}|[1-9]\d|\d)\.){3}(?:25[0-5]|2[0-4]\d|1\d{2}|[1-9]\d|\d)$/u);
function stringArrayToHexStripped(input2) {
  let acc = "";
  let code2 = 0;
  let i2 = 0;
  for (i2 = 0; i2 < input2.length; i2++) {
    code2 = input2[i2].charCodeAt(0);
    if (code2 === 48) {
      continue;
    }
    if (!(code2 >= 48 && code2 <= 57 || code2 >= 65 && code2 <= 70 || code2 >= 97 && code2 <= 102)) {
      return "";
    }
    acc += input2[i2];
    break;
  }
  for (i2 += 1; i2 < input2.length; i2++) {
    code2 = input2[i2].charCodeAt(0);
    if (!(code2 >= 48 && code2 <= 57 || code2 >= 65 && code2 <= 70 || code2 >= 97 && code2 <= 102)) {
      return "";
    }
    acc += input2[i2];
  }
  return acc;
}
const nonSimpleDomain$1 = RegExp.prototype.test.bind(/[^!"$&'()*+,\-.;=_`a-z{}~]/u);
function consumeIsZone(buffer2) {
  buffer2.length = 0;
  return true;
}
function consumeHextets(buffer2, address, output2) {
  if (buffer2.length) {
    const hex = stringArrayToHexStripped(buffer2);
    if (hex !== "") {
      address.push(hex);
    } else {
      output2.error = true;
      return false;
    }
    buffer2.length = 0;
  }
  return true;
}
function getIPV6(input2) {
  let tokenCount = 0;
  const output2 = { error: false, address: "", zone: "" };
  const address = [];
  const buffer2 = [];
  let endipv6Encountered = false;
  let endIpv6 = false;
  let consume = consumeHextets;
  for (let i2 = 0; i2 < input2.length; i2++) {
    const cursor = input2[i2];
    if (cursor === "[" || cursor === "]") {
      continue;
    }
    if (cursor === ":") {
      if (endipv6Encountered === true) {
        endIpv6 = true;
      }
      if (!consume(buffer2, address, output2)) {
        break;
      }
      if (++tokenCount > 7) {
        output2.error = true;
        break;
      }
      if (i2 > 0 && input2[i2 - 1] === ":") {
        endipv6Encountered = true;
      }
      address.push(":");
      continue;
    } else if (cursor === "%") {
      if (!consume(buffer2, address, output2)) {
        break;
      }
      consume = consumeIsZone;
    } else {
      buffer2.push(cursor);
      continue;
    }
  }
  if (buffer2.length) {
    if (consume === consumeIsZone) {
      output2.zone = buffer2.join("");
    } else if (endIpv6) {
      address.push(buffer2.join(""));
    } else {
      address.push(stringArrayToHexStripped(buffer2));
    }
  }
  output2.address = address.join("");
  return output2;
}
function normalizeIPv6$1(host) {
  if (findToken(host, ":") < 2) {
    return { host, isIPV6: false };
  }
  const ipv6 = getIPV6(host);
  if (!ipv6.error) {
    let newHost = ipv6.address;
    let escapedHost = ipv6.address;
    if (ipv6.zone) {
      newHost += "%" + ipv6.zone;
      escapedHost += "%25" + ipv6.zone;
    }
    return { host: newHost, isIPV6: true, escapedHost };
  } else {
    return { host, isIPV6: false };
  }
}
function findToken(str, token) {
  let ind = 0;
  for (let i2 = 0; i2 < str.length; i2++) {
    if (str[i2] === token) ind++;
  }
  return ind;
}
function removeDotSegments$1(path2) {
  let input2 = path2;
  const output2 = [];
  let nextSlash = -1;
  let len = 0;
  while (len = input2.length) {
    if (len === 1) {
      if (input2 === ".") {
        break;
      } else if (input2 === "/") {
        output2.push("/");
        break;
      } else {
        output2.push(input2);
        break;
      }
    } else if (len === 2) {
      if (input2[0] === ".") {
        if (input2[1] === ".") {
          break;
        } else if (input2[1] === "/") {
          input2 = input2.slice(2);
          continue;
        }
      } else if (input2[0] === "/") {
        if (input2[1] === "." || input2[1] === "/") {
          output2.push("/");
          break;
        }
      }
    } else if (len === 3) {
      if (input2 === "/..") {
        if (output2.length !== 0) {
          output2.pop();
        }
        output2.push("/");
        break;
      }
    }
    if (input2[0] === ".") {
      if (input2[1] === ".") {
        if (input2[2] === "/") {
          input2 = input2.slice(3);
          continue;
        }
      } else if (input2[1] === "/") {
        input2 = input2.slice(2);
        continue;
      }
    } else if (input2[0] === "/") {
      if (input2[1] === ".") {
        if (input2[2] === "/") {
          input2 = input2.slice(2);
          continue;
        } else if (input2[2] === ".") {
          if (input2[3] === "/") {
            input2 = input2.slice(3);
            if (output2.length !== 0) {
              output2.pop();
            }
            continue;
          }
        }
      }
    }
    if ((nextSlash = input2.indexOf("/", 1)) === -1) {
      output2.push(input2);
      break;
    } else {
      output2.push(input2.slice(0, nextSlash));
      input2 = input2.slice(nextSlash);
    }
  }
  return output2.join("");
}
function normalizeComponentEncoding$1(component, esc) {
  const func = esc !== true ? escape : unescape;
  if (component.scheme !== void 0) {
    component.scheme = func(component.scheme);
  }
  if (component.userinfo !== void 0) {
    component.userinfo = func(component.userinfo);
  }
  if (component.host !== void 0) {
    component.host = func(component.host);
  }
  if (component.path !== void 0) {
    component.path = func(component.path);
  }
  if (component.query !== void 0) {
    component.query = func(component.query);
  }
  if (component.fragment !== void 0) {
    component.fragment = func(component.fragment);
  }
  return component;
}
function recomposeAuthority$1(component) {
  const uriTokens = [];
  if (component.userinfo !== void 0) {
    uriTokens.push(component.userinfo);
    uriTokens.push("@");
  }
  if (component.host !== void 0) {
    let host = unescape(component.host);
    if (!isIPv4$1(host)) {
      const ipV6res = normalizeIPv6$1(host);
      if (ipV6res.isIPV6 === true) {
        host = `[${ipV6res.escapedHost}]`;
      } else {
        host = component.host;
      }
    }
    uriTokens.push(host);
  }
  if (typeof component.port === "number" || typeof component.port === "string") {
    uriTokens.push(":");
    uriTokens.push(String(component.port));
  }
  return uriTokens.length ? uriTokens.join("") : void 0;
}
var utils = {
  nonSimpleDomain: nonSimpleDomain$1,
  recomposeAuthority: recomposeAuthority$1,
  normalizeComponentEncoding: normalizeComponentEncoding$1,
  removeDotSegments: removeDotSegments$1,
  isIPv4: isIPv4$1,
  isUUID: isUUID$1,
  normalizeIPv6: normalizeIPv6$1
};
const { isUUID } = utils;
const URN_REG = /([\da-z][\d\-a-z]{0,31}):((?:[\w!$'()*+,\-.:;=@]|%[\da-f]{2})+)/iu;
function wsIsSecure(wsComponent) {
  if (wsComponent.secure === true) {
    return true;
  } else if (wsComponent.secure === false) {
    return false;
  } else if (wsComponent.scheme) {
    return wsComponent.scheme.length === 3 && (wsComponent.scheme[0] === "w" || wsComponent.scheme[0] === "W") && (wsComponent.scheme[1] === "s" || wsComponent.scheme[1] === "S") && (wsComponent.scheme[2] === "s" || wsComponent.scheme[2] === "S");
  } else {
    return false;
  }
}
function httpParse(component) {
  if (!component.host) {
    component.error = component.error || "HTTP URIs must have a host.";
  }
  return component;
}
function httpSerialize(component) {
  const secure = String(component.scheme).toLowerCase() === "https";
  if (component.port === (secure ? 443 : 80) || component.port === "") {
    component.port = void 0;
  }
  if (!component.path) {
    component.path = "/";
  }
  return component;
}
function wsParse(wsComponent) {
  wsComponent.secure = wsIsSecure(wsComponent);
  wsComponent.resourceName = (wsComponent.path || "/") + (wsComponent.query ? "?" + wsComponent.query : "");
  wsComponent.path = void 0;
  wsComponent.query = void 0;
  return wsComponent;
}
function wsSerialize(wsComponent) {
  if (wsComponent.port === (wsIsSecure(wsComponent) ? 443 : 80) || wsComponent.port === "") {
    wsComponent.port = void 0;
  }
  if (typeof wsComponent.secure === "boolean") {
    wsComponent.scheme = wsComponent.secure ? "wss" : "ws";
    wsComponent.secure = void 0;
  }
  if (wsComponent.resourceName) {
    const [path2, query] = wsComponent.resourceName.split("?");
    wsComponent.path = path2 && path2 !== "/" ? path2 : void 0;
    wsComponent.query = query;
    wsComponent.resourceName = void 0;
  }
  wsComponent.fragment = void 0;
  return wsComponent;
}
function urnParse(urnComponent, options) {
  if (!urnComponent.path) {
    urnComponent.error = "URN can not be parsed";
    return urnComponent;
  }
  const matches = urnComponent.path.match(URN_REG);
  if (matches) {
    const scheme = options.scheme || urnComponent.scheme || "urn";
    urnComponent.nid = matches[1].toLowerCase();
    urnComponent.nss = matches[2];
    const urnScheme = `${scheme}:${options.nid || urnComponent.nid}`;
    const schemeHandler = getSchemeHandler$1(urnScheme);
    urnComponent.path = void 0;
    if (schemeHandler) {
      urnComponent = schemeHandler.parse(urnComponent, options);
    }
  } else {
    urnComponent.error = urnComponent.error || "URN can not be parsed.";
  }
  return urnComponent;
}
function urnSerialize(urnComponent, options) {
  if (urnComponent.nid === void 0) {
    throw new Error("URN without nid cannot be serialized");
  }
  const scheme = options.scheme || urnComponent.scheme || "urn";
  const nid = urnComponent.nid.toLowerCase();
  const urnScheme = `${scheme}:${options.nid || nid}`;
  const schemeHandler = getSchemeHandler$1(urnScheme);
  if (schemeHandler) {
    urnComponent = schemeHandler.serialize(urnComponent, options);
  }
  const uriComponent = urnComponent;
  const nss = urnComponent.nss;
  uriComponent.path = `${nid || options.nid}:${nss}`;
  options.skipEscape = true;
  return uriComponent;
}
function urnuuidParse(urnComponent, options) {
  const uuidComponent = urnComponent;
  uuidComponent.uuid = uuidComponent.nss;
  uuidComponent.nss = void 0;
  if (!options.tolerant && (!uuidComponent.uuid || !isUUID(uuidComponent.uuid))) {
    uuidComponent.error = uuidComponent.error || "UUID is not valid.";
  }
  return uuidComponent;
}
function urnuuidSerialize(uuidComponent) {
  const urnComponent = uuidComponent;
  urnComponent.nss = (uuidComponent.uuid || "").toLowerCase();
  return urnComponent;
}
const http = (
  /** @type {SchemeHandler} */
  {
    scheme: "http",
    domainHost: true,
    parse: httpParse,
    serialize: httpSerialize
  }
);
const https = (
  /** @type {SchemeHandler} */
  {
    scheme: "https",
    domainHost: http.domainHost,
    parse: httpParse,
    serialize: httpSerialize
  }
);
const ws = (
  /** @type {SchemeHandler} */
  {
    scheme: "ws",
    domainHost: true,
    parse: wsParse,
    serialize: wsSerialize
  }
);
const wss = (
  /** @type {SchemeHandler} */
  {
    scheme: "wss",
    domainHost: ws.domainHost,
    parse: ws.parse,
    serialize: ws.serialize
  }
);
const urn = (
  /** @type {SchemeHandler} */
  {
    scheme: "urn",
    parse: urnParse,
    serialize: urnSerialize,
    skipNormalize: true
  }
);
const urnuuid = (
  /** @type {SchemeHandler} */
  {
    scheme: "urn:uuid",
    parse: urnuuidParse,
    serialize: urnuuidSerialize,
    skipNormalize: true
  }
);
const SCHEMES$1 = (
  /** @type {Record<SchemeName, SchemeHandler>} */
  {
    http,
    https,
    ws,
    wss,
    urn,
    "urn:uuid": urnuuid
  }
);
Object.setPrototypeOf(SCHEMES$1, null);
function getSchemeHandler$1(scheme) {
  return scheme && (SCHEMES$1[
    /** @type {SchemeName} */
    scheme
  ] || SCHEMES$1[
    /** @type {SchemeName} */
    scheme.toLowerCase()
  ]) || void 0;
}
var schemes = {
  SCHEMES: SCHEMES$1,
  getSchemeHandler: getSchemeHandler$1
};
const { normalizeIPv6, removeDotSegments, recomposeAuthority, normalizeComponentEncoding, isIPv4, nonSimpleDomain } = utils;
const { SCHEMES, getSchemeHandler } = schemes;
function normalize$1(uri2, options) {
  if (typeof uri2 === "string") {
    uri2 = /** @type {T} */
    serialize(parse$a(uri2, options), options);
  } else if (typeof uri2 === "object") {
    uri2 = /** @type {T} */
    parse$a(serialize(uri2, options), options);
  }
  return uri2;
}
function resolve$2(baseURI, relativeURI, options) {
  const schemelessOptions = options ? Object.assign({ scheme: "null" }, options) : { scheme: "null" };
  const resolved = resolveComponent(parse$a(baseURI, schemelessOptions), parse$a(relativeURI, schemelessOptions), schemelessOptions, true);
  schemelessOptions.skipEscape = true;
  return serialize(resolved, schemelessOptions);
}
function resolveComponent(base, relative, options, skipNormalization) {
  const target = {};
  if (!skipNormalization) {
    base = parse$a(serialize(base, options), options);
    relative = parse$a(serialize(relative, options), options);
  }
  options = options || {};
  if (!options.tolerant && relative.scheme) {
    target.scheme = relative.scheme;
    target.userinfo = relative.userinfo;
    target.host = relative.host;
    target.port = relative.port;
    target.path = removeDotSegments(relative.path || "");
    target.query = relative.query;
  } else {
    if (relative.userinfo !== void 0 || relative.host !== void 0 || relative.port !== void 0) {
      target.userinfo = relative.userinfo;
      target.host = relative.host;
      target.port = relative.port;
      target.path = removeDotSegments(relative.path || "");
      target.query = relative.query;
    } else {
      if (!relative.path) {
        target.path = base.path;
        if (relative.query !== void 0) {
          target.query = relative.query;
        } else {
          target.query = base.query;
        }
      } else {
        if (relative.path[0] === "/") {
          target.path = removeDotSegments(relative.path);
        } else {
          if ((base.userinfo !== void 0 || base.host !== void 0 || base.port !== void 0) && !base.path) {
            target.path = "/" + relative.path;
          } else if (!base.path) {
            target.path = relative.path;
          } else {
            target.path = base.path.slice(0, base.path.lastIndexOf("/") + 1) + relative.path;
          }
          target.path = removeDotSegments(target.path);
        }
        target.query = relative.query;
      }
      target.userinfo = base.userinfo;
      target.host = base.host;
      target.port = base.port;
    }
    target.scheme = base.scheme;
  }
  target.fragment = relative.fragment;
  return target;
}
function equal$5(uriA, uriB, options) {
  if (typeof uriA === "string") {
    uriA = unescape(uriA);
    uriA = serialize(normalizeComponentEncoding(parse$a(uriA, options), true), { ...options, skipEscape: true });
  } else if (typeof uriA === "object") {
    uriA = serialize(normalizeComponentEncoding(uriA, true), { ...options, skipEscape: true });
  }
  if (typeof uriB === "string") {
    uriB = unescape(uriB);
    uriB = serialize(normalizeComponentEncoding(parse$a(uriB, options), true), { ...options, skipEscape: true });
  } else if (typeof uriB === "object") {
    uriB = serialize(normalizeComponentEncoding(uriB, true), { ...options, skipEscape: true });
  }
  return uriA.toLowerCase() === uriB.toLowerCase();
}
function serialize(cmpts, opts) {
  const component = {
    host: cmpts.host,
    scheme: cmpts.scheme,
    userinfo: cmpts.userinfo,
    port: cmpts.port,
    path: cmpts.path,
    query: cmpts.query,
    nid: cmpts.nid,
    nss: cmpts.nss,
    uuid: cmpts.uuid,
    fragment: cmpts.fragment,
    reference: cmpts.reference,
    resourceName: cmpts.resourceName,
    secure: cmpts.secure,
    error: ""
  };
  const options = Object.assign({}, opts);
  const uriTokens = [];
  const schemeHandler = getSchemeHandler(options.scheme || component.scheme);
  if (schemeHandler && schemeHandler.serialize) schemeHandler.serialize(component, options);
  if (component.path !== void 0) {
    if (!options.skipEscape) {
      component.path = escape(component.path);
      if (component.scheme !== void 0) {
        component.path = component.path.split("%3A").join(":");
      }
    } else {
      component.path = unescape(component.path);
    }
  }
  if (options.reference !== "suffix" && component.scheme) {
    uriTokens.push(component.scheme, ":");
  }
  const authority = recomposeAuthority(component);
  if (authority !== void 0) {
    if (options.reference !== "suffix") {
      uriTokens.push("//");
    }
    uriTokens.push(authority);
    if (component.path && component.path[0] !== "/") {
      uriTokens.push("/");
    }
  }
  if (component.path !== void 0) {
    let s = component.path;
    if (!options.absolutePath && (!schemeHandler || !schemeHandler.absolutePath)) {
      s = removeDotSegments(s);
    }
    if (authority === void 0 && s[0] === "/" && s[1] === "/") {
      s = "/%2F" + s.slice(2);
    }
    uriTokens.push(s);
  }
  if (component.query !== void 0) {
    uriTokens.push("?", component.query);
  }
  if (component.fragment !== void 0) {
    uriTokens.push("#", component.fragment);
  }
  return uriTokens.join("");
}
const URI_PARSE = /^(?:([^#/:?]+):)?(?:\/\/((?:([^#/?@]*)@)?(\[[^#/?\]]+\]|[^#/:?]*)(?::(\d*))?))?([^#?]*)(?:\?([^#]*))?(?:#((?:.|[\n\r])*))?/u;
function parse$a(uri2, opts) {
  const options = Object.assign({}, opts);
  const parsed = {
    scheme: void 0,
    userinfo: void 0,
    host: "",
    port: void 0,
    path: "",
    query: void 0,
    fragment: void 0
  };
  let isIP = false;
  if (options.reference === "suffix") {
    if (options.scheme) {
      uri2 = options.scheme + ":" + uri2;
    } else {
      uri2 = "//" + uri2;
    }
  }
  const matches = uri2.match(URI_PARSE);
  if (matches) {
    parsed.scheme = matches[1];
    parsed.userinfo = matches[3];
    parsed.host = matches[4];
    parsed.port = parseInt(matches[5], 10);
    parsed.path = matches[6] || "";
    parsed.query = matches[7];
    parsed.fragment = matches[8];
    if (isNaN(parsed.port)) {
      parsed.port = matches[5];
    }
    if (parsed.host) {
      const ipv4result = isIPv4(parsed.host);
      if (ipv4result === false) {
        const ipv6result = normalizeIPv6(parsed.host);
        parsed.host = ipv6result.host.toLowerCase();
        isIP = ipv6result.isIPV6;
      } else {
        isIP = true;
      }
    }
    if (parsed.scheme === void 0 && parsed.userinfo === void 0 && parsed.host === void 0 && parsed.port === void 0 && parsed.query === void 0 && !parsed.path) {
      parsed.reference = "same-document";
    } else if (parsed.scheme === void 0) {
      parsed.reference = "relative";
    } else if (parsed.fragment === void 0) {
      parsed.reference = "absolute";
    } else {
      parsed.reference = "uri";
    }
    if (options.reference && options.reference !== "suffix" && options.reference !== parsed.reference) {
      parsed.error = parsed.error || "URI is not a " + options.reference + " reference.";
    }
    const schemeHandler = getSchemeHandler(options.scheme || parsed.scheme);
    if (!options.unicodeSupport && (!schemeHandler || !schemeHandler.unicodeSupport)) {
      if (parsed.host && (options.domainHost || schemeHandler && schemeHandler.domainHost) && isIP === false && nonSimpleDomain(parsed.host)) {
        try {
          parsed.host = URL.domainToASCII(parsed.host.toLowerCase());
        } catch (e) {
          parsed.error = parsed.error || "Host's domain name can not be converted to ASCII: " + e;
        }
      }
    }
    if (!schemeHandler || schemeHandler && !schemeHandler.skipNormalize) {
      if (uri2.indexOf("%") !== -1) {
        if (parsed.scheme !== void 0) {
          parsed.scheme = unescape(parsed.scheme);
        }
        if (parsed.host !== void 0) {
          parsed.host = unescape(parsed.host);
        }
      }
      if (parsed.path) {
        parsed.path = escape(unescape(parsed.path));
      }
      if (parsed.fragment) {
        parsed.fragment = encodeURI(decodeURIComponent(parsed.fragment));
      }
    }
    if (schemeHandler && schemeHandler.parse) {
      schemeHandler.parse(parsed, options);
    }
  } else {
    parsed.error = parsed.error || "URI can not be parsed.";
  }
  return parsed;
}
const fastUri = {
  SCHEMES,
  normalize: normalize$1,
  resolve: resolve$2,
  resolveComponent,
  equal: equal$5,
  serialize,
  parse: parse$a
};
fastUri$1.exports = fastUri;
fastUri$1.exports.default = fastUri;
fastUri$1.exports.fastUri = fastUri;
var fastUriExports = fastUri$1.exports;
Object.defineProperty(uri$3, "__esModule", { value: true });
const uri$2 = fastUriExports;
uri$2.code = 'require("ajv/dist/runtime/uri").default';
uri$3.default = uri$2;
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.CodeGen = exports$12.Name = exports$12.nil = exports$12.stringify = exports$12.str = exports$12._ = exports$12.KeywordCxt = void 0;
  var validate_12 = validate$1;
  Object.defineProperty(exports$12, "KeywordCxt", { enumerable: true, get: function() {
    return validate_12.KeywordCxt;
  } });
  var codegen_12 = codegen$1;
  Object.defineProperty(exports$12, "_", { enumerable: true, get: function() {
    return codegen_12._;
  } });
  Object.defineProperty(exports$12, "str", { enumerable: true, get: function() {
    return codegen_12.str;
  } });
  Object.defineProperty(exports$12, "stringify", { enumerable: true, get: function() {
    return codegen_12.stringify;
  } });
  Object.defineProperty(exports$12, "nil", { enumerable: true, get: function() {
    return codegen_12.nil;
  } });
  Object.defineProperty(exports$12, "Name", { enumerable: true, get: function() {
    return codegen_12.Name;
  } });
  Object.defineProperty(exports$12, "CodeGen", { enumerable: true, get: function() {
    return codegen_12.CodeGen;
  } });
  const validation_error_12 = validation_error$1;
  const ref_error_12 = ref_error$1;
  const rules_12 = rules$1;
  const compile_12 = compile$1;
  const codegen_2 = codegen$1;
  const resolve_12 = resolve$4;
  const dataType_12 = dataType$1;
  const util_12 = util$2;
  const $dataRefSchema = require$$9$1;
  const uri_1 = uri$3;
  const defaultRegExp = (str, flags) => new RegExp(str, flags);
  defaultRegExp.code = "new RegExp";
  const META_IGNORE_OPTIONS = ["removeAdditional", "useDefaults", "coerceTypes"];
  const EXT_SCOPE_NAMES = /* @__PURE__ */ new Set([
    "validate",
    "serialize",
    "parse",
    "wrapper",
    "root",
    "schema",
    "keyword",
    "pattern",
    "formats",
    "validate$data",
    "func",
    "obj",
    "Error"
  ]);
  const removedOptions = {
    errorDataPath: "",
    format: "`validateFormats: false` can be used instead.",
    nullable: '"nullable" keyword is supported by default.',
    jsonPointers: "Deprecated jsPropertySyntax can be used instead.",
    extendRefs: "Deprecated ignoreKeywordsWithRef can be used instead.",
    missingRefs: "Pass empty schema with $id that should be ignored to ajv.addSchema.",
    processCode: "Use option `code: {process: (code, schemaEnv: object) => string}`",
    sourceCode: "Use option `code: {source: true}`",
    strictDefaults: "It is default now, see option `strict`.",
    strictKeywords: "It is default now, see option `strict`.",
    uniqueItems: '"uniqueItems" keyword is always validated.',
    unknownFormats: "Disable strict mode or pass `true` to `ajv.addFormat` (or `formats` option).",
    cache: "Map is used as cache, schema object as key.",
    serialize: "Map is used as cache, schema object as key.",
    ajvErrors: "It is default now."
  };
  const deprecatedOptions = {
    ignoreKeywordsWithRef: "",
    jsPropertySyntax: "",
    unicode: '"minLength"/"maxLength" account for unicode characters by default.'
  };
  const MAX_EXPRESSION = 200;
  function requiredOptions(o) {
    var _a2, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v, _w, _x, _y, _z, _0;
    const s = o.strict;
    const _optz = (_a2 = o.code) === null || _a2 === void 0 ? void 0 : _a2.optimize;
    const optimize = _optz === true || _optz === void 0 ? 1 : _optz || 0;
    const regExp = (_c = (_b = o.code) === null || _b === void 0 ? void 0 : _b.regExp) !== null && _c !== void 0 ? _c : defaultRegExp;
    const uriResolver = (_d = o.uriResolver) !== null && _d !== void 0 ? _d : uri_1.default;
    return {
      strictSchema: (_f = (_e = o.strictSchema) !== null && _e !== void 0 ? _e : s) !== null && _f !== void 0 ? _f : true,
      strictNumbers: (_h = (_g = o.strictNumbers) !== null && _g !== void 0 ? _g : s) !== null && _h !== void 0 ? _h : true,
      strictTypes: (_k = (_j = o.strictTypes) !== null && _j !== void 0 ? _j : s) !== null && _k !== void 0 ? _k : "log",
      strictTuples: (_m = (_l = o.strictTuples) !== null && _l !== void 0 ? _l : s) !== null && _m !== void 0 ? _m : "log",
      strictRequired: (_p = (_o = o.strictRequired) !== null && _o !== void 0 ? _o : s) !== null && _p !== void 0 ? _p : false,
      code: o.code ? { ...o.code, optimize, regExp } : { optimize, regExp },
      loopRequired: (_q = o.loopRequired) !== null && _q !== void 0 ? _q : MAX_EXPRESSION,
      loopEnum: (_r = o.loopEnum) !== null && _r !== void 0 ? _r : MAX_EXPRESSION,
      meta: (_s = o.meta) !== null && _s !== void 0 ? _s : true,
      messages: (_t = o.messages) !== null && _t !== void 0 ? _t : true,
      inlineRefs: (_u = o.inlineRefs) !== null && _u !== void 0 ? _u : true,
      schemaId: (_v = o.schemaId) !== null && _v !== void 0 ? _v : "$id",
      addUsedSchema: (_w = o.addUsedSchema) !== null && _w !== void 0 ? _w : true,
      validateSchema: (_x = o.validateSchema) !== null && _x !== void 0 ? _x : true,
      validateFormats: (_y = o.validateFormats) !== null && _y !== void 0 ? _y : true,
      unicodeRegExp: (_z = o.unicodeRegExp) !== null && _z !== void 0 ? _z : true,
      int32range: (_0 = o.int32range) !== null && _0 !== void 0 ? _0 : true,
      uriResolver
    };
  }
  class Ajv {
    constructor(opts = {}) {
      this.schemas = {};
      this.refs = {};
      this.formats = {};
      this._compilations = /* @__PURE__ */ new Set();
      this._loading = {};
      this._cache = /* @__PURE__ */ new Map();
      opts = this.opts = { ...opts, ...requiredOptions(opts) };
      const { es5, lines } = this.opts.code;
      this.scope = new codegen_2.ValueScope({ scope: {}, prefixes: EXT_SCOPE_NAMES, es5, lines });
      this.logger = getLogger(opts.logger);
      const formatOpt = opts.validateFormats;
      opts.validateFormats = false;
      this.RULES = (0, rules_12.getRules)();
      checkOptions.call(this, removedOptions, opts, "NOT SUPPORTED");
      checkOptions.call(this, deprecatedOptions, opts, "DEPRECATED", "warn");
      this._metaOpts = getMetaSchemaOptions.call(this);
      if (opts.formats)
        addInitialFormats.call(this);
      this._addVocabularies();
      this._addDefaultMetaSchema();
      if (opts.keywords)
        addInitialKeywords.call(this, opts.keywords);
      if (typeof opts.meta == "object")
        this.addMetaSchema(opts.meta);
      addInitialSchemas.call(this);
      opts.validateFormats = formatOpt;
    }
    _addVocabularies() {
      this.addKeyword("$async");
    }
    _addDefaultMetaSchema() {
      const { $data, meta, schemaId } = this.opts;
      let _dataRefSchema = $dataRefSchema;
      if (schemaId === "id") {
        _dataRefSchema = { ...$dataRefSchema };
        _dataRefSchema.id = _dataRefSchema.$id;
        delete _dataRefSchema.$id;
      }
      if (meta && $data)
        this.addMetaSchema(_dataRefSchema, _dataRefSchema[schemaId], false);
    }
    defaultMeta() {
      const { meta, schemaId } = this.opts;
      return this.opts.defaultMeta = typeof meta == "object" ? meta[schemaId] || meta : void 0;
    }
    validate(schemaKeyRef, data) {
      let v;
      if (typeof schemaKeyRef == "string") {
        v = this.getSchema(schemaKeyRef);
        if (!v)
          throw new Error(`no schema with key or ref "${schemaKeyRef}"`);
      } else {
        v = this.compile(schemaKeyRef);
      }
      const valid2 = v(data);
      if (!("$async" in v))
        this.errors = v.errors;
      return valid2;
    }
    compile(schema, _meta) {
      const sch = this._addSchema(schema, _meta);
      return sch.validate || this._compileSchemaEnv(sch);
    }
    compileAsync(schema, meta) {
      if (typeof this.opts.loadSchema != "function") {
        throw new Error("options.loadSchema should be a function");
      }
      const { loadSchema } = this.opts;
      return runCompileAsync.call(this, schema, meta);
      async function runCompileAsync(_schema, _meta) {
        await loadMetaSchema.call(this, _schema.$schema);
        const sch = this._addSchema(_schema, _meta);
        return sch.validate || _compileAsync.call(this, sch);
      }
      async function loadMetaSchema($ref) {
        if ($ref && !this.getSchema($ref)) {
          await runCompileAsync.call(this, { $ref }, true);
        }
      }
      async function _compileAsync(sch) {
        try {
          return this._compileSchemaEnv(sch);
        } catch (e) {
          if (!(e instanceof ref_error_12.default))
            throw e;
          checkLoaded.call(this, e);
          await loadMissingSchema.call(this, e.missingSchema);
          return _compileAsync.call(this, sch);
        }
      }
      function checkLoaded({ missingSchema: ref2, missingRef }) {
        if (this.refs[ref2]) {
          throw new Error(`AnySchema ${ref2} is loaded but ${missingRef} cannot be resolved`);
        }
      }
      async function loadMissingSchema(ref2) {
        const _schema = await _loadSchema.call(this, ref2);
        if (!this.refs[ref2])
          await loadMetaSchema.call(this, _schema.$schema);
        if (!this.refs[ref2])
          this.addSchema(_schema, ref2, meta);
      }
      async function _loadSchema(ref2) {
        const p = this._loading[ref2];
        if (p)
          return p;
        try {
          return await (this._loading[ref2] = loadSchema(ref2));
        } finally {
          delete this._loading[ref2];
        }
      }
    }
    // Adds schema to the instance
    addSchema(schema, key, _meta, _validateSchema = this.opts.validateSchema) {
      if (Array.isArray(schema)) {
        for (const sch of schema)
          this.addSchema(sch, void 0, _meta, _validateSchema);
        return this;
      }
      let id2;
      if (typeof schema === "object") {
        const { schemaId } = this.opts;
        id2 = schema[schemaId];
        if (id2 !== void 0 && typeof id2 != "string") {
          throw new Error(`schema ${schemaId} must be string`);
        }
      }
      key = (0, resolve_12.normalizeId)(key || id2);
      this._checkUnique(key);
      this.schemas[key] = this._addSchema(schema, _meta, key, _validateSchema, true);
      return this;
    }
    // Add schema that will be used to validate other schemas
    // options in META_IGNORE_OPTIONS are alway set to false
    addMetaSchema(schema, key, _validateSchema = this.opts.validateSchema) {
      this.addSchema(schema, key, true, _validateSchema);
      return this;
    }
    //  Validate schema against its meta-schema
    validateSchema(schema, throwOrLogError) {
      if (typeof schema == "boolean")
        return true;
      let $schema2;
      $schema2 = schema.$schema;
      if ($schema2 !== void 0 && typeof $schema2 != "string") {
        throw new Error("$schema must be a string");
      }
      $schema2 = $schema2 || this.opts.defaultMeta || this.defaultMeta();
      if (!$schema2) {
        this.logger.warn("meta-schema not available");
        this.errors = null;
        return true;
      }
      const valid2 = this.validate($schema2, schema);
      if (!valid2 && throwOrLogError) {
        const message = "schema is invalid: " + this.errorsText();
        if (this.opts.validateSchema === "log")
          this.logger.error(message);
        else
          throw new Error(message);
      }
      return valid2;
    }
    // Get compiled schema by `key` or `ref`.
    // (`key` that was passed to `addSchema` or full schema reference - `schema.$id` or resolved id)
    getSchema(keyRef) {
      let sch;
      while (typeof (sch = getSchEnv.call(this, keyRef)) == "string")
        keyRef = sch;
      if (sch === void 0) {
        const { schemaId } = this.opts;
        const root = new compile_12.SchemaEnv({ schema: {}, schemaId });
        sch = compile_12.resolveSchema.call(this, root, keyRef);
        if (!sch)
          return;
        this.refs[keyRef] = sch;
      }
      return sch.validate || this._compileSchemaEnv(sch);
    }
    // Remove cached schema(s).
    // If no parameter is passed all schemas but meta-schemas are removed.
    // If RegExp is passed all schemas with key/id matching pattern but meta-schemas are removed.
    // Even if schema is referenced by other schemas it still can be removed as other schemas have local references.
    removeSchema(schemaKeyRef) {
      if (schemaKeyRef instanceof RegExp) {
        this._removeAllSchemas(this.schemas, schemaKeyRef);
        this._removeAllSchemas(this.refs, schemaKeyRef);
        return this;
      }
      switch (typeof schemaKeyRef) {
        case "undefined":
          this._removeAllSchemas(this.schemas);
          this._removeAllSchemas(this.refs);
          this._cache.clear();
          return this;
        case "string": {
          const sch = getSchEnv.call(this, schemaKeyRef);
          if (typeof sch == "object")
            this._cache.delete(sch.schema);
          delete this.schemas[schemaKeyRef];
          delete this.refs[schemaKeyRef];
          return this;
        }
        case "object": {
          const cacheKey = schemaKeyRef;
          this._cache.delete(cacheKey);
          let id2 = schemaKeyRef[this.opts.schemaId];
          if (id2) {
            id2 = (0, resolve_12.normalizeId)(id2);
            delete this.schemas[id2];
            delete this.refs[id2];
          }
          return this;
        }
        default:
          throw new Error("ajv.removeSchema: invalid parameter");
      }
    }
    // add "vocabulary" - a collection of keywords
    addVocabulary(definitions2) {
      for (const def2 of definitions2)
        this.addKeyword(def2);
      return this;
    }
    addKeyword(kwdOrDef, def2) {
      let keyword2;
      if (typeof kwdOrDef == "string") {
        keyword2 = kwdOrDef;
        if (typeof def2 == "object") {
          this.logger.warn("these parameters are deprecated, see docs for addKeyword");
          def2.keyword = keyword2;
        }
      } else if (typeof kwdOrDef == "object" && def2 === void 0) {
        def2 = kwdOrDef;
        keyword2 = def2.keyword;
        if (Array.isArray(keyword2) && !keyword2.length) {
          throw new Error("addKeywords: keyword must be string or non-empty array");
        }
      } else {
        throw new Error("invalid addKeywords parameters");
      }
      checkKeyword.call(this, keyword2, def2);
      if (!def2) {
        (0, util_12.eachItem)(keyword2, (kwd) => addRule.call(this, kwd));
        return this;
      }
      keywordMetaschema.call(this, def2);
      const definition = {
        ...def2,
        type: (0, dataType_12.getJSONTypes)(def2.type),
        schemaType: (0, dataType_12.getJSONTypes)(def2.schemaType)
      };
      (0, util_12.eachItem)(keyword2, definition.type.length === 0 ? (k) => addRule.call(this, k, definition) : (k) => definition.type.forEach((t2) => addRule.call(this, k, definition, t2)));
      return this;
    }
    getKeyword(keyword2) {
      const rule = this.RULES.all[keyword2];
      return typeof rule == "object" ? rule.definition : !!rule;
    }
    // Remove keyword
    removeKeyword(keyword2) {
      const { RULES } = this;
      delete RULES.keywords[keyword2];
      delete RULES.all[keyword2];
      for (const group of RULES.rules) {
        const i2 = group.rules.findIndex((rule) => rule.keyword === keyword2);
        if (i2 >= 0)
          group.rules.splice(i2, 1);
      }
      return this;
    }
    // Add format
    addFormat(name2, format2) {
      if (typeof format2 == "string")
        format2 = new RegExp(format2);
      this.formats[name2] = format2;
      return this;
    }
    errorsText(errors2 = this.errors, { separator = ", ", dataVar = "data" } = {}) {
      if (!errors2 || errors2.length === 0)
        return "No errors";
      return errors2.map((e) => `${dataVar}${e.instancePath} ${e.message}`).reduce((text, msg) => text + separator + msg);
    }
    $dataMetaSchema(metaSchema2, keywordsJsonPointers) {
      const rules2 = this.RULES.all;
      metaSchema2 = JSON.parse(JSON.stringify(metaSchema2));
      for (const jsonPointer of keywordsJsonPointers) {
        const segments = jsonPointer.split("/").slice(1);
        let keywords = metaSchema2;
        for (const seg of segments)
          keywords = keywords[seg];
        for (const key in rules2) {
          const rule = rules2[key];
          if (typeof rule != "object")
            continue;
          const { $data } = rule.definition;
          const schema = keywords[key];
          if ($data && schema)
            keywords[key] = schemaOrData(schema);
        }
      }
      return metaSchema2;
    }
    _removeAllSchemas(schemas, regex) {
      for (const keyRef in schemas) {
        const sch = schemas[keyRef];
        if (!regex || regex.test(keyRef)) {
          if (typeof sch == "string") {
            delete schemas[keyRef];
          } else if (sch && !sch.meta) {
            this._cache.delete(sch.schema);
            delete schemas[keyRef];
          }
        }
      }
    }
    _addSchema(schema, meta, baseId, validateSchema = this.opts.validateSchema, addSchema = this.opts.addUsedSchema) {
      let id2;
      const { schemaId } = this.opts;
      if (typeof schema == "object") {
        id2 = schema[schemaId];
      } else {
        if (this.opts.jtd)
          throw new Error("schema must be object");
        else if (typeof schema != "boolean")
          throw new Error("schema must be object or boolean");
      }
      let sch = this._cache.get(schema);
      if (sch !== void 0)
        return sch;
      baseId = (0, resolve_12.normalizeId)(id2 || baseId);
      const localRefs = resolve_12.getSchemaRefs.call(this, schema, baseId);
      sch = new compile_12.SchemaEnv({ schema, schemaId, meta, baseId, localRefs });
      this._cache.set(sch.schema, sch);
      if (addSchema && !baseId.startsWith("#")) {
        if (baseId)
          this._checkUnique(baseId);
        this.refs[baseId] = sch;
      }
      if (validateSchema)
        this.validateSchema(schema, true);
      return sch;
    }
    _checkUnique(id2) {
      if (this.schemas[id2] || this.refs[id2]) {
        throw new Error(`schema with key or id "${id2}" already exists`);
      }
    }
    _compileSchemaEnv(sch) {
      if (sch.meta)
        this._compileMetaSchema(sch);
      else
        compile_12.compileSchema.call(this, sch);
      if (!sch.validate)
        throw new Error("ajv implementation error");
      return sch.validate;
    }
    _compileMetaSchema(sch) {
      const currentOpts = this.opts;
      this.opts = this._metaOpts;
      try {
        compile_12.compileSchema.call(this, sch);
      } finally {
        this.opts = currentOpts;
      }
    }
  }
  Ajv.ValidationError = validation_error_12.default;
  Ajv.MissingRefError = ref_error_12.default;
  exports$12.default = Ajv;
  function checkOptions(checkOpts, options, msg, log2 = "error") {
    for (const key in checkOpts) {
      const opt = key;
      if (opt in options)
        this.logger[log2](`${msg}: option ${key}. ${checkOpts[opt]}`);
    }
  }
  function getSchEnv(keyRef) {
    keyRef = (0, resolve_12.normalizeId)(keyRef);
    return this.schemas[keyRef] || this.refs[keyRef];
  }
  function addInitialSchemas() {
    const optsSchemas = this.opts.schemas;
    if (!optsSchemas)
      return;
    if (Array.isArray(optsSchemas))
      this.addSchema(optsSchemas);
    else
      for (const key in optsSchemas)
        this.addSchema(optsSchemas[key], key);
  }
  function addInitialFormats() {
    for (const name2 in this.opts.formats) {
      const format2 = this.opts.formats[name2];
      if (format2)
        this.addFormat(name2, format2);
    }
  }
  function addInitialKeywords(defs) {
    if (Array.isArray(defs)) {
      this.addVocabulary(defs);
      return;
    }
    this.logger.warn("keywords option as map is deprecated, pass array");
    for (const keyword2 in defs) {
      const def2 = defs[keyword2];
      if (!def2.keyword)
        def2.keyword = keyword2;
      this.addKeyword(def2);
    }
  }
  function getMetaSchemaOptions() {
    const metaOpts = { ...this.opts };
    for (const opt of META_IGNORE_OPTIONS)
      delete metaOpts[opt];
    return metaOpts;
  }
  const noLogs = { log() {
  }, warn() {
  }, error() {
  } };
  function getLogger(logger) {
    if (logger === false)
      return noLogs;
    if (logger === void 0)
      return console;
    if (logger.log && logger.warn && logger.error)
      return logger;
    throw new Error("logger must implement log, warn and error methods");
  }
  const KEYWORD_NAME = /^[a-z_$][a-z0-9_$:-]*$/i;
  function checkKeyword(keyword2, def2) {
    const { RULES } = this;
    (0, util_12.eachItem)(keyword2, (kwd) => {
      if (RULES.keywords[kwd])
        throw new Error(`Keyword ${kwd} is already defined`);
      if (!KEYWORD_NAME.test(kwd))
        throw new Error(`Keyword ${kwd} has invalid name`);
    });
    if (!def2)
      return;
    if (def2.$data && !("code" in def2 || "validate" in def2)) {
      throw new Error('$data keyword must have "code" or "validate" function');
    }
  }
  function addRule(keyword2, definition, dataType2) {
    var _a2;
    const post = definition === null || definition === void 0 ? void 0 : definition.post;
    if (dataType2 && post)
      throw new Error('keyword with "post" flag cannot have "type"');
    const { RULES } = this;
    let ruleGroup = post ? RULES.post : RULES.rules.find(({ type: t2 }) => t2 === dataType2);
    if (!ruleGroup) {
      ruleGroup = { type: dataType2, rules: [] };
      RULES.rules.push(ruleGroup);
    }
    RULES.keywords[keyword2] = true;
    if (!definition)
      return;
    const rule = {
      keyword: keyword2,
      definition: {
        ...definition,
        type: (0, dataType_12.getJSONTypes)(definition.type),
        schemaType: (0, dataType_12.getJSONTypes)(definition.schemaType)
      }
    };
    if (definition.before)
      addBeforeRule.call(this, ruleGroup, rule, definition.before);
    else
      ruleGroup.rules.push(rule);
    RULES.all[keyword2] = rule;
    (_a2 = definition.implements) === null || _a2 === void 0 ? void 0 : _a2.forEach((kwd) => this.addKeyword(kwd));
  }
  function addBeforeRule(ruleGroup, rule, before) {
    const i2 = ruleGroup.rules.findIndex((_rule) => _rule.keyword === before);
    if (i2 >= 0) {
      ruleGroup.rules.splice(i2, 0, rule);
    } else {
      ruleGroup.rules.push(rule);
      this.logger.warn(`rule ${before} is not defined`);
    }
  }
  function keywordMetaschema(def2) {
    let { metaSchema: metaSchema2 } = def2;
    if (metaSchema2 === void 0)
      return;
    if (def2.$data && this.opts.$data)
      metaSchema2 = schemaOrData(metaSchema2);
    def2.validateSchema = this.compile(metaSchema2, true);
  }
  const $dataRef = {
    $ref: "https://raw.githubusercontent.com/ajv-validator/ajv/master/lib/refs/data.json#"
  };
  function schemaOrData(schema) {
    return { anyOf: [schema, $dataRef] };
  }
})(core$6);
var draft2020 = {};
var core$5 = {};
var id$1 = {};
Object.defineProperty(id$1, "__esModule", { value: true });
const def$12 = {
  keyword: "id",
  code() {
    throw new Error('NOT SUPPORTED: keyword "id", use "$id" for schema ID');
  }
};
id$1.default = def$12;
var ref$1 = {};
Object.defineProperty(ref$1, "__esModule", { value: true });
ref$1.callRef = ref$1.getValidate = void 0;
const ref_error_1$3 = ref_error$1;
const code_1$j = code$2;
const codegen_1$V = codegen$1;
const names_1$b = names$3;
const compile_1$4 = compile$1;
const util_1$Q = util$2;
const def$11 = {
  keyword: "$ref",
  schemaType: "string",
  code(cxt) {
    const { gen, schema: $ref, it } = cxt;
    const { baseId, schemaEnv: env2, validateName, opts, self: self2 } = it;
    const { root } = env2;
    if (($ref === "#" || $ref === "#/") && baseId === root.baseId)
      return callRootRef();
    const schOrEnv = compile_1$4.resolveRef.call(self2, root, baseId, $ref);
    if (schOrEnv === void 0)
      throw new ref_error_1$3.default(it.opts.uriResolver, baseId, $ref);
    if (schOrEnv instanceof compile_1$4.SchemaEnv)
      return callValidate(schOrEnv);
    return inlineRefSchema(schOrEnv);
    function callRootRef() {
      if (env2 === root)
        return callRef$1(cxt, validateName, env2, env2.$async);
      const rootName = gen.scopeValue("root", { ref: root });
      return callRef$1(cxt, (0, codegen_1$V._)`${rootName}.validate`, root, root.$async);
    }
    function callValidate(sch) {
      const v = getValidate$1(cxt, sch);
      callRef$1(cxt, v, sch, sch.$async);
    }
    function inlineRefSchema(sch) {
      const schName = gen.scopeValue("schema", opts.code.source === true ? { ref: sch, code: (0, codegen_1$V.stringify)(sch) } : { ref: sch });
      const valid2 = gen.name("valid");
      const schCxt = cxt.subschema({
        schema: sch,
        dataTypes: [],
        schemaPath: codegen_1$V.nil,
        topSchemaRef: schName,
        errSchemaPath: $ref
      }, valid2);
      cxt.mergeEvaluated(schCxt);
      cxt.ok(valid2);
    }
  }
};
function getValidate$1(cxt, sch) {
  const { gen } = cxt;
  return sch.validate ? gen.scopeValue("validate", { ref: sch.validate }) : (0, codegen_1$V._)`${gen.scopeValue("wrapper", { ref: sch })}.validate`;
}
ref$1.getValidate = getValidate$1;
function callRef$1(cxt, v, sch, $async) {
  const { gen, it } = cxt;
  const { allErrors, schemaEnv: env2, opts } = it;
  const passCxt = opts.passContext ? names_1$b.default.this : codegen_1$V.nil;
  if ($async)
    callAsyncRef();
  else
    callSyncRef();
  function callAsyncRef() {
    if (!env2.$async)
      throw new Error("async schema referenced by sync schema");
    const valid2 = gen.let("valid");
    gen.try(() => {
      gen.code((0, codegen_1$V._)`await ${(0, code_1$j.callValidateCode)(cxt, v, passCxt)}`);
      addEvaluatedFrom(v);
      if (!allErrors)
        gen.assign(valid2, true);
    }, (e) => {
      gen.if((0, codegen_1$V._)`!(${e} instanceof ${it.ValidationError})`, () => gen.throw(e));
      addErrorsFrom(e);
      if (!allErrors)
        gen.assign(valid2, false);
    });
    cxt.ok(valid2);
  }
  function callSyncRef() {
    cxt.result((0, code_1$j.callValidateCode)(cxt, v, passCxt), () => addEvaluatedFrom(v), () => addErrorsFrom(v));
  }
  function addErrorsFrom(source) {
    const errs = (0, codegen_1$V._)`${source}.errors`;
    gen.assign(names_1$b.default.vErrors, (0, codegen_1$V._)`${names_1$b.default.vErrors} === null ? ${errs} : ${names_1$b.default.vErrors}.concat(${errs})`);
    gen.assign(names_1$b.default.errors, (0, codegen_1$V._)`${names_1$b.default.vErrors}.length`);
  }
  function addEvaluatedFrom(source) {
    var _a2;
    if (!it.opts.unevaluated)
      return;
    const schEvaluated = (_a2 = sch === null || sch === void 0 ? void 0 : sch.validate) === null || _a2 === void 0 ? void 0 : _a2.evaluated;
    if (it.props !== true) {
      if (schEvaluated && !schEvaluated.dynamicProps) {
        if (schEvaluated.props !== void 0) {
          it.props = util_1$Q.mergeEvaluated.props(gen, schEvaluated.props, it.props);
        }
      } else {
        const props = gen.var("props", (0, codegen_1$V._)`${source}.evaluated.props`);
        it.props = util_1$Q.mergeEvaluated.props(gen, props, it.props, codegen_1$V.Name);
      }
    }
    if (it.items !== true) {
      if (schEvaluated && !schEvaluated.dynamicItems) {
        if (schEvaluated.items !== void 0) {
          it.items = util_1$Q.mergeEvaluated.items(gen, schEvaluated.items, it.items);
        }
      } else {
        const items2 = gen.var("items", (0, codegen_1$V._)`${source}.evaluated.items`);
        it.items = util_1$Q.mergeEvaluated.items(gen, items2, it.items, codegen_1$V.Name);
      }
    }
  }
}
ref$1.callRef = callRef$1;
ref$1.default = def$11;
Object.defineProperty(core$5, "__esModule", { value: true });
const id_1$1 = id$1;
const ref_1$3 = ref$1;
const core$4 = [
  "$schema",
  "$id",
  "$defs",
  "$vocabulary",
  { keyword: "$comment" },
  "definitions",
  id_1$1.default,
  ref_1$3.default
];
core$5.default = core$4;
var validation$4 = {};
var limitNumber$1 = {};
Object.defineProperty(limitNumber$1, "__esModule", { value: true });
const codegen_1$U = codegen$1;
const ops$1 = codegen_1$U.operators;
const KWDs$1 = {
  maximum: { okStr: "<=", ok: ops$1.LTE, fail: ops$1.GT },
  minimum: { okStr: ">=", ok: ops$1.GTE, fail: ops$1.LT },
  exclusiveMaximum: { okStr: "<", ok: ops$1.LT, fail: ops$1.GTE },
  exclusiveMinimum: { okStr: ">", ok: ops$1.GT, fail: ops$1.LTE }
};
const error$D = {
  message: ({ keyword: keyword2, schemaCode }) => (0, codegen_1$U.str)`must be ${KWDs$1[keyword2].okStr} ${schemaCode}`,
  params: ({ keyword: keyword2, schemaCode }) => (0, codegen_1$U._)`{comparison: ${KWDs$1[keyword2].okStr}, limit: ${schemaCode}}`
};
const def$10 = {
  keyword: Object.keys(KWDs$1),
  type: "number",
  schemaType: "number",
  $data: true,
  error: error$D,
  code(cxt) {
    const { keyword: keyword2, data, schemaCode } = cxt;
    cxt.fail$data((0, codegen_1$U._)`${data} ${KWDs$1[keyword2].fail} ${schemaCode} || isNaN(${data})`);
  }
};
limitNumber$1.default = def$10;
var multipleOf$1 = {};
Object.defineProperty(multipleOf$1, "__esModule", { value: true });
const codegen_1$T = codegen$1;
const error$C = {
  message: ({ schemaCode }) => (0, codegen_1$T.str)`must be multiple of ${schemaCode}`,
  params: ({ schemaCode }) => (0, codegen_1$T._)`{multipleOf: ${schemaCode}}`
};
const def$$ = {
  keyword: "multipleOf",
  type: "number",
  schemaType: "number",
  $data: true,
  error: error$C,
  code(cxt) {
    const { gen, data, schemaCode, it } = cxt;
    const prec = it.opts.multipleOfPrecision;
    const res = gen.let("res");
    const invalid = prec ? (0, codegen_1$T._)`Math.abs(Math.round(${res}) - ${res}) > 1e-${prec}` : (0, codegen_1$T._)`${res} !== parseInt(${res})`;
    cxt.fail$data((0, codegen_1$T._)`(${schemaCode} === 0 || (${res} = ${data}/${schemaCode}, ${invalid}))`);
  }
};
multipleOf$1.default = def$$;
var limitLength$1 = {};
var ucs2length$3 = {};
Object.defineProperty(ucs2length$3, "__esModule", { value: true });
function ucs2length$2(str) {
  const len = str.length;
  let length = 0;
  let pos = 0;
  let value;
  while (pos < len) {
    length++;
    value = str.charCodeAt(pos++);
    if (value >= 55296 && value <= 56319 && pos < len) {
      value = str.charCodeAt(pos);
      if ((value & 64512) === 56320)
        pos++;
    }
  }
  return length;
}
ucs2length$3.default = ucs2length$2;
ucs2length$2.code = 'require("ajv/dist/runtime/ucs2length").default';
Object.defineProperty(limitLength$1, "__esModule", { value: true });
const codegen_1$S = codegen$1;
const util_1$P = util$2;
const ucs2length_1$1 = ucs2length$3;
const error$B = {
  message({ keyword: keyword2, schemaCode }) {
    const comp = keyword2 === "maxLength" ? "more" : "fewer";
    return (0, codegen_1$S.str)`must NOT have ${comp} than ${schemaCode} characters`;
  },
  params: ({ schemaCode }) => (0, codegen_1$S._)`{limit: ${schemaCode}}`
};
const def$_ = {
  keyword: ["maxLength", "minLength"],
  type: "string",
  schemaType: "number",
  $data: true,
  error: error$B,
  code(cxt) {
    const { keyword: keyword2, data, schemaCode, it } = cxt;
    const op = keyword2 === "maxLength" ? codegen_1$S.operators.GT : codegen_1$S.operators.LT;
    const len = it.opts.unicode === false ? (0, codegen_1$S._)`${data}.length` : (0, codegen_1$S._)`${(0, util_1$P.useFunc)(cxt.gen, ucs2length_1$1.default)}(${data})`;
    cxt.fail$data((0, codegen_1$S._)`${len} ${op} ${schemaCode}`);
  }
};
limitLength$1.default = def$_;
var pattern$1 = {};
Object.defineProperty(pattern$1, "__esModule", { value: true });
const code_1$i = code$2;
const util_1$O = util$2;
const codegen_1$R = codegen$1;
const error$A = {
  message: ({ schemaCode }) => (0, codegen_1$R.str)`must match pattern "${schemaCode}"`,
  params: ({ schemaCode }) => (0, codegen_1$R._)`{pattern: ${schemaCode}}`
};
const def$Z = {
  keyword: "pattern",
  type: "string",
  schemaType: "string",
  $data: true,
  error: error$A,
  code(cxt) {
    const { gen, data, $data, schema, schemaCode, it } = cxt;
    const u = it.opts.unicodeRegExp ? "u" : "";
    if ($data) {
      const { regExp } = it.opts.code;
      const regExpCode = regExp.code === "new RegExp" ? (0, codegen_1$R._)`new RegExp` : (0, util_1$O.useFunc)(gen, regExp);
      const valid2 = gen.let("valid");
      gen.try(() => gen.assign(valid2, (0, codegen_1$R._)`${regExpCode}(${schemaCode}, ${u}).test(${data})`), () => gen.assign(valid2, false));
      cxt.fail$data((0, codegen_1$R._)`!${valid2}`);
    } else {
      const regExp = (0, code_1$i.usePattern)(cxt, schema);
      cxt.fail$data((0, codegen_1$R._)`!${regExp}.test(${data})`);
    }
  }
};
pattern$1.default = def$Z;
var limitProperties$1 = {};
Object.defineProperty(limitProperties$1, "__esModule", { value: true });
const codegen_1$Q = codegen$1;
const error$z = {
  message({ keyword: keyword2, schemaCode }) {
    const comp = keyword2 === "maxProperties" ? "more" : "fewer";
    return (0, codegen_1$Q.str)`must NOT have ${comp} than ${schemaCode} properties`;
  },
  params: ({ schemaCode }) => (0, codegen_1$Q._)`{limit: ${schemaCode}}`
};
const def$Y = {
  keyword: ["maxProperties", "minProperties"],
  type: "object",
  schemaType: "number",
  $data: true,
  error: error$z,
  code(cxt) {
    const { keyword: keyword2, data, schemaCode } = cxt;
    const op = keyword2 === "maxProperties" ? codegen_1$Q.operators.GT : codegen_1$Q.operators.LT;
    cxt.fail$data((0, codegen_1$Q._)`Object.keys(${data}).length ${op} ${schemaCode}`);
  }
};
limitProperties$1.default = def$Y;
var required$2 = {};
Object.defineProperty(required$2, "__esModule", { value: true });
const code_1$h = code$2;
const codegen_1$P = codegen$1;
const util_1$N = util$2;
const error$y = {
  message: ({ params: { missingProperty } }) => (0, codegen_1$P.str)`must have required property '${missingProperty}'`,
  params: ({ params: { missingProperty } }) => (0, codegen_1$P._)`{missingProperty: ${missingProperty}}`
};
const def$X = {
  keyword: "required",
  type: "object",
  schemaType: "array",
  $data: true,
  error: error$y,
  code(cxt) {
    const { gen, schema, schemaCode, data, $data, it } = cxt;
    const { opts } = it;
    if (!$data && schema.length === 0)
      return;
    const useLoop = schema.length >= opts.loopRequired;
    if (it.allErrors)
      allErrorsMode();
    else
      exitOnErrorMode();
    if (opts.strictRequired) {
      const props = cxt.parentSchema.properties;
      const { definedProperties } = cxt.it;
      for (const requiredKey of schema) {
        if ((props === null || props === void 0 ? void 0 : props[requiredKey]) === void 0 && !definedProperties.has(requiredKey)) {
          const schemaPath = it.schemaEnv.baseId + it.errSchemaPath;
          const msg = `required property "${requiredKey}" is not defined at "${schemaPath}" (strictRequired)`;
          (0, util_1$N.checkStrictMode)(it, msg, it.opts.strictRequired);
        }
      }
    }
    function allErrorsMode() {
      if (useLoop || $data) {
        cxt.block$data(codegen_1$P.nil, loopAllRequired);
      } else {
        for (const prop of schema) {
          (0, code_1$h.checkReportMissingProp)(cxt, prop);
        }
      }
    }
    function exitOnErrorMode() {
      const missing = gen.let("missing");
      if (useLoop || $data) {
        const valid2 = gen.let("valid", true);
        cxt.block$data(valid2, () => loopUntilMissing(missing, valid2));
        cxt.ok(valid2);
      } else {
        gen.if((0, code_1$h.checkMissingProp)(cxt, schema, missing));
        (0, code_1$h.reportMissingProp)(cxt, missing);
        gen.else();
      }
    }
    function loopAllRequired() {
      gen.forOf("prop", schemaCode, (prop) => {
        cxt.setParams({ missingProperty: prop });
        gen.if((0, code_1$h.noPropertyInData)(gen, data, prop, opts.ownProperties), () => cxt.error());
      });
    }
    function loopUntilMissing(missing, valid2) {
      cxt.setParams({ missingProperty: missing });
      gen.forOf(missing, schemaCode, () => {
        gen.assign(valid2, (0, code_1$h.propertyInData)(gen, data, missing, opts.ownProperties));
        gen.if((0, codegen_1$P.not)(valid2), () => {
          cxt.error();
          gen.break();
        });
      }, codegen_1$P.nil);
    }
  }
};
required$2.default = def$X;
var limitItems$1 = {};
Object.defineProperty(limitItems$1, "__esModule", { value: true });
const codegen_1$O = codegen$1;
const error$x = {
  message({ keyword: keyword2, schemaCode }) {
    const comp = keyword2 === "maxItems" ? "more" : "fewer";
    return (0, codegen_1$O.str)`must NOT have ${comp} than ${schemaCode} items`;
  },
  params: ({ schemaCode }) => (0, codegen_1$O._)`{limit: ${schemaCode}}`
};
const def$W = {
  keyword: ["maxItems", "minItems"],
  type: "array",
  schemaType: "number",
  $data: true,
  error: error$x,
  code(cxt) {
    const { keyword: keyword2, data, schemaCode } = cxt;
    const op = keyword2 === "maxItems" ? codegen_1$O.operators.GT : codegen_1$O.operators.LT;
    cxt.fail$data((0, codegen_1$O._)`${data}.length ${op} ${schemaCode}`);
  }
};
limitItems$1.default = def$W;
var uniqueItems$1 = {};
var equal$4 = {};
Object.defineProperty(equal$4, "__esModule", { value: true });
const equal$3 = fastDeepEqual;
equal$3.code = 'require("ajv/dist/runtime/equal").default';
equal$4.default = equal$3;
Object.defineProperty(uniqueItems$1, "__esModule", { value: true });
const dataType_1$2 = dataType$1;
const codegen_1$N = codegen$1;
const util_1$M = util$2;
const equal_1$5 = equal$4;
const error$w = {
  message: ({ params: { i: i2, j } }) => (0, codegen_1$N.str)`must NOT have duplicate items (items ## ${j} and ${i2} are identical)`,
  params: ({ params: { i: i2, j } }) => (0, codegen_1$N._)`{i: ${i2}, j: ${j}}`
};
const def$V = {
  keyword: "uniqueItems",
  type: "array",
  schemaType: "boolean",
  $data: true,
  error: error$w,
  code(cxt) {
    const { gen, data, $data, schema, parentSchema, schemaCode, it } = cxt;
    if (!$data && !schema)
      return;
    const valid2 = gen.let("valid");
    const itemTypes = parentSchema.items ? (0, dataType_1$2.getSchemaTypes)(parentSchema.items) : [];
    cxt.block$data(valid2, validateUniqueItems, (0, codegen_1$N._)`${schemaCode} === false`);
    cxt.ok(valid2);
    function validateUniqueItems() {
      const i2 = gen.let("i", (0, codegen_1$N._)`${data}.length`);
      const j = gen.let("j");
      cxt.setParams({ i: i2, j });
      gen.assign(valid2, true);
      gen.if((0, codegen_1$N._)`${i2} > 1`, () => (canOptimize() ? loopN : loopN2)(i2, j));
    }
    function canOptimize() {
      return itemTypes.length > 0 && !itemTypes.some((t2) => t2 === "object" || t2 === "array");
    }
    function loopN(i2, j) {
      const item = gen.name("item");
      const wrongType = (0, dataType_1$2.checkDataTypes)(itemTypes, item, it.opts.strictNumbers, dataType_1$2.DataType.Wrong);
      const indices = gen.const("indices", (0, codegen_1$N._)`{}`);
      gen.for((0, codegen_1$N._)`;${i2}--;`, () => {
        gen.let(item, (0, codegen_1$N._)`${data}[${i2}]`);
        gen.if(wrongType, (0, codegen_1$N._)`continue`);
        if (itemTypes.length > 1)
          gen.if((0, codegen_1$N._)`typeof ${item} == "string"`, (0, codegen_1$N._)`${item} += "_"`);
        gen.if((0, codegen_1$N._)`typeof ${indices}[${item}] == "number"`, () => {
          gen.assign(j, (0, codegen_1$N._)`${indices}[${item}]`);
          cxt.error();
          gen.assign(valid2, false).break();
        }).code((0, codegen_1$N._)`${indices}[${item}] = ${i2}`);
      });
    }
    function loopN2(i2, j) {
      const eql = (0, util_1$M.useFunc)(gen, equal_1$5.default);
      const outer = gen.name("outer");
      gen.label(outer).for((0, codegen_1$N._)`;${i2}--;`, () => gen.for((0, codegen_1$N._)`${j} = ${i2}; ${j}--;`, () => gen.if((0, codegen_1$N._)`${eql}(${data}[${i2}], ${data}[${j}])`, () => {
        cxt.error();
        gen.assign(valid2, false).break(outer);
      })));
    }
  }
};
uniqueItems$1.default = def$V;
var _const$1 = {};
Object.defineProperty(_const$1, "__esModule", { value: true });
const codegen_1$M = codegen$1;
const util_1$L = util$2;
const equal_1$4 = equal$4;
const error$v = {
  message: "must be equal to constant",
  params: ({ schemaCode }) => (0, codegen_1$M._)`{allowedValue: ${schemaCode}}`
};
const def$U = {
  keyword: "const",
  $data: true,
  error: error$v,
  code(cxt) {
    const { gen, data, $data, schemaCode, schema } = cxt;
    if ($data || schema && typeof schema == "object") {
      cxt.fail$data((0, codegen_1$M._)`!${(0, util_1$L.useFunc)(gen, equal_1$4.default)}(${data}, ${schemaCode})`);
    } else {
      cxt.fail((0, codegen_1$M._)`${schema} !== ${data}`);
    }
  }
};
_const$1.default = def$U;
var _enum$1 = {};
Object.defineProperty(_enum$1, "__esModule", { value: true });
const codegen_1$L = codegen$1;
const util_1$K = util$2;
const equal_1$3 = equal$4;
const error$u = {
  message: "must be equal to one of the allowed values",
  params: ({ schemaCode }) => (0, codegen_1$L._)`{allowedValues: ${schemaCode}}`
};
const def$T = {
  keyword: "enum",
  schemaType: "array",
  $data: true,
  error: error$u,
  code(cxt) {
    const { gen, data, $data, schema, schemaCode, it } = cxt;
    if (!$data && schema.length === 0)
      throw new Error("enum must have non-empty array");
    const useLoop = schema.length >= it.opts.loopEnum;
    let eql;
    const getEql = () => eql !== null && eql !== void 0 ? eql : eql = (0, util_1$K.useFunc)(gen, equal_1$3.default);
    let valid2;
    if (useLoop || $data) {
      valid2 = gen.let("valid");
      cxt.block$data(valid2, loopEnum);
    } else {
      if (!Array.isArray(schema))
        throw new Error("ajv implementation error");
      const vSchema = gen.const("vSchema", schemaCode);
      valid2 = (0, codegen_1$L.or)(...schema.map((_x, i2) => equalCode(vSchema, i2)));
    }
    cxt.pass(valid2);
    function loopEnum() {
      gen.assign(valid2, false);
      gen.forOf("v", schemaCode, (v) => gen.if((0, codegen_1$L._)`${getEql()}(${data}, ${v})`, () => gen.assign(valid2, true).break()));
    }
    function equalCode(vSchema, i2) {
      const sch = schema[i2];
      return typeof sch === "object" && sch !== null ? (0, codegen_1$L._)`${getEql()}(${data}, ${vSchema}[${i2}])` : (0, codegen_1$L._)`${data} === ${sch}`;
    }
  }
};
_enum$1.default = def$T;
Object.defineProperty(validation$4, "__esModule", { value: true });
const limitNumber_1$1 = limitNumber$1;
const multipleOf_1$1 = multipleOf$1;
const limitLength_1$1 = limitLength$1;
const pattern_1$1 = pattern$1;
const limitProperties_1$1 = limitProperties$1;
const required_1$1 = required$2;
const limitItems_1$1 = limitItems$1;
const uniqueItems_1$1 = uniqueItems$1;
const const_1$1 = _const$1;
const enum_1$1 = _enum$1;
const validation$3 = [
  // number
  limitNumber_1$1.default,
  multipleOf_1$1.default,
  // string
  limitLength_1$1.default,
  pattern_1$1.default,
  // object
  limitProperties_1$1.default,
  required_1$1.default,
  // array
  limitItems_1$1.default,
  uniqueItems_1$1.default,
  // any
  { keyword: "type", schemaType: ["string", "array"] },
  { keyword: "nullable", schemaType: "boolean" },
  const_1$1.default,
  enum_1$1.default
];
validation$4.default = validation$3;
var applicator$2 = {};
var additionalItems$1 = {};
Object.defineProperty(additionalItems$1, "__esModule", { value: true });
additionalItems$1.validateAdditionalItems = void 0;
const codegen_1$K = codegen$1;
const util_1$J = util$2;
const error$t = {
  message: ({ params: { len } }) => (0, codegen_1$K.str)`must NOT have more than ${len} items`,
  params: ({ params: { len } }) => (0, codegen_1$K._)`{limit: ${len}}`
};
const def$S = {
  keyword: "additionalItems",
  type: "array",
  schemaType: ["boolean", "object"],
  before: "uniqueItems",
  error: error$t,
  code(cxt) {
    const { parentSchema, it } = cxt;
    const { items: items2 } = parentSchema;
    if (!Array.isArray(items2)) {
      (0, util_1$J.checkStrictMode)(it, '"additionalItems" is ignored when "items" is not an array of schemas');
      return;
    }
    validateAdditionalItems$1(cxt, items2);
  }
};
function validateAdditionalItems$1(cxt, items2) {
  const { gen, schema, data, keyword: keyword2, it } = cxt;
  it.items = true;
  const len = gen.const("len", (0, codegen_1$K._)`${data}.length`);
  if (schema === false) {
    cxt.setParams({ len: items2.length });
    cxt.pass((0, codegen_1$K._)`${len} <= ${items2.length}`);
  } else if (typeof schema == "object" && !(0, util_1$J.alwaysValidSchema)(it, schema)) {
    const valid2 = gen.var("valid", (0, codegen_1$K._)`${len} <= ${items2.length}`);
    gen.if((0, codegen_1$K.not)(valid2), () => validateItems(valid2));
    cxt.ok(valid2);
  }
  function validateItems(valid2) {
    gen.forRange("i", items2.length, len, (i2) => {
      cxt.subschema({ keyword: keyword2, dataProp: i2, dataPropType: util_1$J.Type.Num }, valid2);
      if (!it.allErrors)
        gen.if((0, codegen_1$K.not)(valid2), () => gen.break());
    });
  }
}
additionalItems$1.validateAdditionalItems = validateAdditionalItems$1;
additionalItems$1.default = def$S;
var prefixItems$1 = {};
var items$1 = {};
Object.defineProperty(items$1, "__esModule", { value: true });
items$1.validateTuple = void 0;
const codegen_1$J = codegen$1;
const util_1$I = util$2;
const code_1$g = code$2;
const def$R = {
  keyword: "items",
  type: "array",
  schemaType: ["object", "array", "boolean"],
  before: "uniqueItems",
  code(cxt) {
    const { schema, it } = cxt;
    if (Array.isArray(schema))
      return validateTuple$1(cxt, "additionalItems", schema);
    it.items = true;
    if ((0, util_1$I.alwaysValidSchema)(it, schema))
      return;
    cxt.ok((0, code_1$g.validateArray)(cxt));
  }
};
function validateTuple$1(cxt, extraItems, schArr = cxt.schema) {
  const { gen, parentSchema, data, keyword: keyword2, it } = cxt;
  checkStrictTuple(parentSchema);
  if (it.opts.unevaluated && schArr.length && it.items !== true) {
    it.items = util_1$I.mergeEvaluated.items(gen, schArr.length, it.items);
  }
  const valid2 = gen.name("valid");
  const len = gen.const("len", (0, codegen_1$J._)`${data}.length`);
  schArr.forEach((sch, i2) => {
    if ((0, util_1$I.alwaysValidSchema)(it, sch))
      return;
    gen.if((0, codegen_1$J._)`${len} > ${i2}`, () => cxt.subschema({
      keyword: keyword2,
      schemaProp: i2,
      dataProp: i2
    }, valid2));
    cxt.ok(valid2);
  });
  function checkStrictTuple(sch) {
    const { opts, errSchemaPath } = it;
    const l = schArr.length;
    const fullTuple = l === sch.minItems && (l === sch.maxItems || sch[extraItems] === false);
    if (opts.strictTuples && !fullTuple) {
      const msg = `"${keyword2}" is ${l}-tuple, but minItems or maxItems/${extraItems} are not specified or different at path "${errSchemaPath}"`;
      (0, util_1$I.checkStrictMode)(it, msg, opts.strictTuples);
    }
  }
}
items$1.validateTuple = validateTuple$1;
items$1.default = def$R;
Object.defineProperty(prefixItems$1, "__esModule", { value: true });
const items_1$3 = items$1;
const def$Q = {
  keyword: "prefixItems",
  type: "array",
  schemaType: ["array"],
  before: "uniqueItems",
  code: (cxt) => (0, items_1$3.validateTuple)(cxt, "items")
};
prefixItems$1.default = def$Q;
var items2020$1 = {};
Object.defineProperty(items2020$1, "__esModule", { value: true });
const codegen_1$I = codegen$1;
const util_1$H = util$2;
const code_1$f = code$2;
const additionalItems_1$3 = additionalItems$1;
const error$s = {
  message: ({ params: { len } }) => (0, codegen_1$I.str)`must NOT have more than ${len} items`,
  params: ({ params: { len } }) => (0, codegen_1$I._)`{limit: ${len}}`
};
const def$P = {
  keyword: "items",
  type: "array",
  schemaType: ["object", "boolean"],
  before: "uniqueItems",
  error: error$s,
  code(cxt) {
    const { schema, parentSchema, it } = cxt;
    const { prefixItems: prefixItems2 } = parentSchema;
    it.items = true;
    if ((0, util_1$H.alwaysValidSchema)(it, schema))
      return;
    if (prefixItems2)
      (0, additionalItems_1$3.validateAdditionalItems)(cxt, prefixItems2);
    else
      cxt.ok((0, code_1$f.validateArray)(cxt));
  }
};
items2020$1.default = def$P;
var contains$1 = {};
Object.defineProperty(contains$1, "__esModule", { value: true });
const codegen_1$H = codegen$1;
const util_1$G = util$2;
const error$r = {
  message: ({ params: { min: min2, max: max2 } }) => max2 === void 0 ? (0, codegen_1$H.str)`must contain at least ${min2} valid item(s)` : (0, codegen_1$H.str)`must contain at least ${min2} and no more than ${max2} valid item(s)`,
  params: ({ params: { min: min2, max: max2 } }) => max2 === void 0 ? (0, codegen_1$H._)`{minContains: ${min2}}` : (0, codegen_1$H._)`{minContains: ${min2}, maxContains: ${max2}}`
};
const def$O = {
  keyword: "contains",
  type: "array",
  schemaType: ["object", "boolean"],
  before: "uniqueItems",
  trackErrors: true,
  error: error$r,
  code(cxt) {
    const { gen, schema, parentSchema, data, it } = cxt;
    let min2;
    let max2;
    const { minContains, maxContains } = parentSchema;
    if (it.opts.next) {
      min2 = minContains === void 0 ? 1 : minContains;
      max2 = maxContains;
    } else {
      min2 = 1;
    }
    const len = gen.const("len", (0, codegen_1$H._)`${data}.length`);
    cxt.setParams({ min: min2, max: max2 });
    if (max2 === void 0 && min2 === 0) {
      (0, util_1$G.checkStrictMode)(it, `"minContains" == 0 without "maxContains": "contains" keyword ignored`);
      return;
    }
    if (max2 !== void 0 && min2 > max2) {
      (0, util_1$G.checkStrictMode)(it, `"minContains" > "maxContains" is always invalid`);
      cxt.fail();
      return;
    }
    if ((0, util_1$G.alwaysValidSchema)(it, schema)) {
      let cond = (0, codegen_1$H._)`${len} >= ${min2}`;
      if (max2 !== void 0)
        cond = (0, codegen_1$H._)`${cond} && ${len} <= ${max2}`;
      cxt.pass(cond);
      return;
    }
    it.items = true;
    const valid2 = gen.name("valid");
    if (max2 === void 0 && min2 === 1) {
      validateItems(valid2, () => gen.if(valid2, () => gen.break()));
    } else if (min2 === 0) {
      gen.let(valid2, true);
      if (max2 !== void 0)
        gen.if((0, codegen_1$H._)`${data}.length > 0`, validateItemsWithCount);
    } else {
      gen.let(valid2, false);
      validateItemsWithCount();
    }
    cxt.result(valid2, () => cxt.reset());
    function validateItemsWithCount() {
      const schValid = gen.name("_valid");
      const count = gen.let("count", 0);
      validateItems(schValid, () => gen.if(schValid, () => checkLimits(count)));
    }
    function validateItems(_valid, block2) {
      gen.forRange("i", 0, len, (i2) => {
        cxt.subschema({
          keyword: "contains",
          dataProp: i2,
          dataPropType: util_1$G.Type.Num,
          compositeRule: true
        }, _valid);
        block2();
      });
    }
    function checkLimits(count) {
      gen.code((0, codegen_1$H._)`${count}++`);
      if (max2 === void 0) {
        gen.if((0, codegen_1$H._)`${count} >= ${min2}`, () => gen.assign(valid2, true).break());
      } else {
        gen.if((0, codegen_1$H._)`${count} > ${max2}`, () => gen.assign(valid2, false).break());
        if (min2 === 1)
          gen.assign(valid2, true);
        else
          gen.if((0, codegen_1$H._)`${count} >= ${min2}`, () => gen.assign(valid2, true));
      }
    }
  }
};
contains$1.default = def$O;
var dependencies$1 = {};
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.validateSchemaDeps = exports$12.validatePropertyDeps = exports$12.error = void 0;
  const codegen_12 = codegen$1;
  const util_12 = util$2;
  const code_12 = code$2;
  exports$12.error = {
    message: ({ params: { property, depsCount, deps } }) => {
      const property_ies = depsCount === 1 ? "property" : "properties";
      return (0, codegen_12.str)`must have ${property_ies} ${deps} when property ${property} is present`;
    },
    params: ({ params: { property, depsCount, deps, missingProperty } }) => (0, codegen_12._)`{property: ${property},
    missingProperty: ${missingProperty},
    depsCount: ${depsCount},
    deps: ${deps}}`
    // TODO change to reference
  };
  const def2 = {
    keyword: "dependencies",
    type: "object",
    schemaType: "object",
    error: exports$12.error,
    code(cxt) {
      const [propDeps, schDeps] = splitDependencies(cxt);
      validatePropertyDeps(cxt, propDeps);
      validateSchemaDeps(cxt, schDeps);
    }
  };
  function splitDependencies({ schema }) {
    const propertyDeps = {};
    const schemaDeps = {};
    for (const key in schema) {
      if (key === "__proto__")
        continue;
      const deps = Array.isArray(schema[key]) ? propertyDeps : schemaDeps;
      deps[key] = schema[key];
    }
    return [propertyDeps, schemaDeps];
  }
  function validatePropertyDeps(cxt, propertyDeps = cxt.schema) {
    const { gen, data, it } = cxt;
    if (Object.keys(propertyDeps).length === 0)
      return;
    const missing = gen.let("missing");
    for (const prop in propertyDeps) {
      const deps = propertyDeps[prop];
      if (deps.length === 0)
        continue;
      const hasProperty2 = (0, code_12.propertyInData)(gen, data, prop, it.opts.ownProperties);
      cxt.setParams({
        property: prop,
        depsCount: deps.length,
        deps: deps.join(", ")
      });
      if (it.allErrors) {
        gen.if(hasProperty2, () => {
          for (const depProp of deps) {
            (0, code_12.checkReportMissingProp)(cxt, depProp);
          }
        });
      } else {
        gen.if((0, codegen_12._)`${hasProperty2} && (${(0, code_12.checkMissingProp)(cxt, deps, missing)})`);
        (0, code_12.reportMissingProp)(cxt, missing);
        gen.else();
      }
    }
  }
  exports$12.validatePropertyDeps = validatePropertyDeps;
  function validateSchemaDeps(cxt, schemaDeps = cxt.schema) {
    const { gen, data, keyword: keyword2, it } = cxt;
    const valid2 = gen.name("valid");
    for (const prop in schemaDeps) {
      if ((0, util_12.alwaysValidSchema)(it, schemaDeps[prop]))
        continue;
      gen.if(
        (0, code_12.propertyInData)(gen, data, prop, it.opts.ownProperties),
        () => {
          const schCxt = cxt.subschema({ keyword: keyword2, schemaProp: prop }, valid2);
          cxt.mergeValidEvaluated(schCxt, valid2);
        },
        () => gen.var(valid2, true)
        // TODO var
      );
      cxt.ok(valid2);
    }
  }
  exports$12.validateSchemaDeps = validateSchemaDeps;
  exports$12.default = def2;
})(dependencies$1);
var propertyNames$1 = {};
Object.defineProperty(propertyNames$1, "__esModule", { value: true });
const codegen_1$G = codegen$1;
const util_1$F = util$2;
const error$q = {
  message: "property name must be valid",
  params: ({ params }) => (0, codegen_1$G._)`{propertyName: ${params.propertyName}}`
};
const def$N = {
  keyword: "propertyNames",
  type: "object",
  schemaType: ["object", "boolean"],
  error: error$q,
  code(cxt) {
    const { gen, schema, data, it } = cxt;
    if ((0, util_1$F.alwaysValidSchema)(it, schema))
      return;
    const valid2 = gen.name("valid");
    gen.forIn("key", data, (key) => {
      cxt.setParams({ propertyName: key });
      cxt.subschema({
        keyword: "propertyNames",
        data: key,
        dataTypes: ["string"],
        propertyName: key,
        compositeRule: true
      }, valid2);
      gen.if((0, codegen_1$G.not)(valid2), () => {
        cxt.error(true);
        if (!it.allErrors)
          gen.break();
      });
    });
    cxt.ok(valid2);
  }
};
propertyNames$1.default = def$N;
var additionalProperties$2 = {};
Object.defineProperty(additionalProperties$2, "__esModule", { value: true });
const code_1$e = code$2;
const codegen_1$F = codegen$1;
const names_1$a = names$3;
const util_1$E = util$2;
const error$p = {
  message: "must NOT have additional properties",
  params: ({ params }) => (0, codegen_1$F._)`{additionalProperty: ${params.additionalProperty}}`
};
const def$M = {
  keyword: "additionalProperties",
  type: ["object"],
  schemaType: ["boolean", "object"],
  allowUndefined: true,
  trackErrors: true,
  error: error$p,
  code(cxt) {
    const { gen, schema, parentSchema, data, errsCount, it } = cxt;
    if (!errsCount)
      throw new Error("ajv implementation error");
    const { allErrors, opts } = it;
    it.props = true;
    if (opts.removeAdditional !== "all" && (0, util_1$E.alwaysValidSchema)(it, schema))
      return;
    const props = (0, code_1$e.allSchemaProperties)(parentSchema.properties);
    const patProps = (0, code_1$e.allSchemaProperties)(parentSchema.patternProperties);
    checkAdditionalProperties();
    cxt.ok((0, codegen_1$F._)`${errsCount} === ${names_1$a.default.errors}`);
    function checkAdditionalProperties() {
      gen.forIn("key", data, (key) => {
        if (!props.length && !patProps.length)
          additionalPropertyCode(key);
        else
          gen.if(isAdditional(key), () => additionalPropertyCode(key));
      });
    }
    function isAdditional(key) {
      let definedProp;
      if (props.length > 8) {
        const propsSchema = (0, util_1$E.schemaRefOrVal)(it, parentSchema.properties, "properties");
        definedProp = (0, code_1$e.isOwnProperty)(gen, propsSchema, key);
      } else if (props.length) {
        definedProp = (0, codegen_1$F.or)(...props.map((p) => (0, codegen_1$F._)`${key} === ${p}`));
      } else {
        definedProp = codegen_1$F.nil;
      }
      if (patProps.length) {
        definedProp = (0, codegen_1$F.or)(definedProp, ...patProps.map((p) => (0, codegen_1$F._)`${(0, code_1$e.usePattern)(cxt, p)}.test(${key})`));
      }
      return (0, codegen_1$F.not)(definedProp);
    }
    function deleteAdditional(key) {
      gen.code((0, codegen_1$F._)`delete ${data}[${key}]`);
    }
    function additionalPropertyCode(key) {
      if (opts.removeAdditional === "all" || opts.removeAdditional && schema === false) {
        deleteAdditional(key);
        return;
      }
      if (schema === false) {
        cxt.setParams({ additionalProperty: key });
        cxt.error();
        if (!allErrors)
          gen.break();
        return;
      }
      if (typeof schema == "object" && !(0, util_1$E.alwaysValidSchema)(it, schema)) {
        const valid2 = gen.name("valid");
        if (opts.removeAdditional === "failing") {
          applyAdditionalSchema(key, valid2, false);
          gen.if((0, codegen_1$F.not)(valid2), () => {
            cxt.reset();
            deleteAdditional(key);
          });
        } else {
          applyAdditionalSchema(key, valid2);
          if (!allErrors)
            gen.if((0, codegen_1$F.not)(valid2), () => gen.break());
        }
      }
    }
    function applyAdditionalSchema(key, valid2, errors2) {
      const subschema2 = {
        keyword: "additionalProperties",
        dataProp: key,
        dataPropType: util_1$E.Type.Str
      };
      if (errors2 === false) {
        Object.assign(subschema2, {
          compositeRule: true,
          createErrors: false,
          allErrors: false
        });
      }
      cxt.subschema(subschema2, valid2);
    }
  }
};
additionalProperties$2.default = def$M;
var properties$b = {};
Object.defineProperty(properties$b, "__esModule", { value: true });
const validate_1$2 = validate$1;
const code_1$d = code$2;
const util_1$D = util$2;
const additionalProperties_1$3 = additionalProperties$2;
const def$L = {
  keyword: "properties",
  type: "object",
  schemaType: "object",
  code(cxt) {
    const { gen, schema, parentSchema, data, it } = cxt;
    if (it.opts.removeAdditional === "all" && parentSchema.additionalProperties === void 0) {
      additionalProperties_1$3.default.code(new validate_1$2.KeywordCxt(it, additionalProperties_1$3.default, "additionalProperties"));
    }
    const allProps = (0, code_1$d.allSchemaProperties)(schema);
    for (const prop of allProps) {
      it.definedProperties.add(prop);
    }
    if (it.opts.unevaluated && allProps.length && it.props !== true) {
      it.props = util_1$D.mergeEvaluated.props(gen, (0, util_1$D.toHash)(allProps), it.props);
    }
    const properties2 = allProps.filter((p) => !(0, util_1$D.alwaysValidSchema)(it, schema[p]));
    if (properties2.length === 0)
      return;
    const valid2 = gen.name("valid");
    for (const prop of properties2) {
      if (hasDefault(prop)) {
        applyPropertySchema(prop);
      } else {
        gen.if((0, code_1$d.propertyInData)(gen, data, prop, it.opts.ownProperties));
        applyPropertySchema(prop);
        if (!it.allErrors)
          gen.else().var(valid2, true);
        gen.endIf();
      }
      cxt.it.definedProperties.add(prop);
      cxt.ok(valid2);
    }
    function hasDefault(prop) {
      return it.opts.useDefaults && !it.compositeRule && schema[prop].default !== void 0;
    }
    function applyPropertySchema(prop) {
      cxt.subschema({
        keyword: "properties",
        schemaProp: prop,
        dataProp: prop
      }, valid2);
    }
  }
};
properties$b.default = def$L;
var patternProperties$1 = {};
Object.defineProperty(patternProperties$1, "__esModule", { value: true });
const code_1$c = code$2;
const codegen_1$E = codegen$1;
const util_1$C = util$2;
const util_2$2 = util$2;
const def$K = {
  keyword: "patternProperties",
  type: "object",
  schemaType: "object",
  code(cxt) {
    const { gen, schema, data, parentSchema, it } = cxt;
    const { opts } = it;
    const patterns = (0, code_1$c.allSchemaProperties)(schema);
    const alwaysValidPatterns = patterns.filter((p) => (0, util_1$C.alwaysValidSchema)(it, schema[p]));
    if (patterns.length === 0 || alwaysValidPatterns.length === patterns.length && (!it.opts.unevaluated || it.props === true)) {
      return;
    }
    const checkProperties = opts.strictSchema && !opts.allowMatchingProperties && parentSchema.properties;
    const valid2 = gen.name("valid");
    if (it.props !== true && !(it.props instanceof codegen_1$E.Name)) {
      it.props = (0, util_2$2.evaluatedPropsToName)(gen, it.props);
    }
    const { props } = it;
    validatePatternProperties();
    function validatePatternProperties() {
      for (const pat of patterns) {
        if (checkProperties)
          checkMatchingProperties(pat);
        if (it.allErrors) {
          validateProperties(pat);
        } else {
          gen.var(valid2, true);
          validateProperties(pat);
          gen.if(valid2);
        }
      }
    }
    function checkMatchingProperties(pat) {
      for (const prop in checkProperties) {
        if (new RegExp(pat).test(prop)) {
          (0, util_1$C.checkStrictMode)(it, `property ${prop} matches pattern ${pat} (use allowMatchingProperties)`);
        }
      }
    }
    function validateProperties(pat) {
      gen.forIn("key", data, (key) => {
        gen.if((0, codegen_1$E._)`${(0, code_1$c.usePattern)(cxt, pat)}.test(${key})`, () => {
          const alwaysValid = alwaysValidPatterns.includes(pat);
          if (!alwaysValid) {
            cxt.subschema({
              keyword: "patternProperties",
              schemaProp: pat,
              dataProp: key,
              dataPropType: util_2$2.Type.Str
            }, valid2);
          }
          if (it.opts.unevaluated && props !== true) {
            gen.assign((0, codegen_1$E._)`${props}[${key}]`, true);
          } else if (!alwaysValid && !it.allErrors) {
            gen.if((0, codegen_1$E.not)(valid2), () => gen.break());
          }
        });
      });
    }
  }
};
patternProperties$1.default = def$K;
var not$1 = {};
Object.defineProperty(not$1, "__esModule", { value: true });
const util_1$B = util$2;
const def$J = {
  keyword: "not",
  schemaType: ["object", "boolean"],
  trackErrors: true,
  code(cxt) {
    const { gen, schema, it } = cxt;
    if ((0, util_1$B.alwaysValidSchema)(it, schema)) {
      cxt.fail();
      return;
    }
    const valid2 = gen.name("valid");
    cxt.subschema({
      keyword: "not",
      compositeRule: true,
      createErrors: false,
      allErrors: false
    }, valid2);
    cxt.failResult(valid2, () => cxt.reset(), () => cxt.error());
  },
  error: { message: "must NOT be valid" }
};
not$1.default = def$J;
var anyOf$1 = {};
Object.defineProperty(anyOf$1, "__esModule", { value: true });
const code_1$b = code$2;
const def$I = {
  keyword: "anyOf",
  schemaType: "array",
  trackErrors: true,
  code: code_1$b.validateUnion,
  error: { message: "must match a schema in anyOf" }
};
anyOf$1.default = def$I;
var oneOf$1 = {};
Object.defineProperty(oneOf$1, "__esModule", { value: true });
const codegen_1$D = codegen$1;
const util_1$A = util$2;
const error$o = {
  message: "must match exactly one schema in oneOf",
  params: ({ params }) => (0, codegen_1$D._)`{passingSchemas: ${params.passing}}`
};
const def$H = {
  keyword: "oneOf",
  schemaType: "array",
  trackErrors: true,
  error: error$o,
  code(cxt) {
    const { gen, schema, parentSchema, it } = cxt;
    if (!Array.isArray(schema))
      throw new Error("ajv implementation error");
    if (it.opts.discriminator && parentSchema.discriminator)
      return;
    const schArr = schema;
    const valid2 = gen.let("valid", false);
    const passing = gen.let("passing", null);
    const schValid = gen.name("_valid");
    cxt.setParams({ passing });
    gen.block(validateOneOf);
    cxt.result(valid2, () => cxt.reset(), () => cxt.error(true));
    function validateOneOf() {
      schArr.forEach((sch, i2) => {
        let schCxt;
        if ((0, util_1$A.alwaysValidSchema)(it, sch)) {
          gen.var(schValid, true);
        } else {
          schCxt = cxt.subschema({
            keyword: "oneOf",
            schemaProp: i2,
            compositeRule: true
          }, schValid);
        }
        if (i2 > 0) {
          gen.if((0, codegen_1$D._)`${schValid} && ${valid2}`).assign(valid2, false).assign(passing, (0, codegen_1$D._)`[${passing}, ${i2}]`).else();
        }
        gen.if(schValid, () => {
          gen.assign(valid2, true);
          gen.assign(passing, i2);
          if (schCxt)
            cxt.mergeEvaluated(schCxt, codegen_1$D.Name);
        });
      });
    }
  }
};
oneOf$1.default = def$H;
var allOf$2 = {};
Object.defineProperty(allOf$2, "__esModule", { value: true });
const util_1$z = util$2;
const def$G = {
  keyword: "allOf",
  schemaType: "array",
  code(cxt) {
    const { gen, schema, it } = cxt;
    if (!Array.isArray(schema))
      throw new Error("ajv implementation error");
    const valid2 = gen.name("valid");
    schema.forEach((sch, i2) => {
      if ((0, util_1$z.alwaysValidSchema)(it, sch))
        return;
      const schCxt = cxt.subschema({ keyword: "allOf", schemaProp: i2 }, valid2);
      cxt.ok(valid2);
      cxt.mergeEvaluated(schCxt);
    });
  }
};
allOf$2.default = def$G;
var _if$1 = {};
Object.defineProperty(_if$1, "__esModule", { value: true });
const codegen_1$C = codegen$1;
const util_1$y = util$2;
const error$n = {
  message: ({ params }) => (0, codegen_1$C.str)`must match "${params.ifClause}" schema`,
  params: ({ params }) => (0, codegen_1$C._)`{failingKeyword: ${params.ifClause}}`
};
const def$F = {
  keyword: "if",
  schemaType: ["object", "boolean"],
  trackErrors: true,
  error: error$n,
  code(cxt) {
    const { gen, parentSchema, it } = cxt;
    if (parentSchema.then === void 0 && parentSchema.else === void 0) {
      (0, util_1$y.checkStrictMode)(it, '"if" without "then" and "else" is ignored');
    }
    const hasThen = hasSchema$1(it, "then");
    const hasElse = hasSchema$1(it, "else");
    if (!hasThen && !hasElse)
      return;
    const valid2 = gen.let("valid", true);
    const schValid = gen.name("_valid");
    validateIf();
    cxt.reset();
    if (hasThen && hasElse) {
      const ifClause = gen.let("ifClause");
      cxt.setParams({ ifClause });
      gen.if(schValid, validateClause("then", ifClause), validateClause("else", ifClause));
    } else if (hasThen) {
      gen.if(schValid, validateClause("then"));
    } else {
      gen.if((0, codegen_1$C.not)(schValid), validateClause("else"));
    }
    cxt.pass(valid2, () => cxt.error(true));
    function validateIf() {
      const schCxt = cxt.subschema({
        keyword: "if",
        compositeRule: true,
        createErrors: false,
        allErrors: false
      }, schValid);
      cxt.mergeEvaluated(schCxt);
    }
    function validateClause(keyword2, ifClause) {
      return () => {
        const schCxt = cxt.subschema({ keyword: keyword2 }, schValid);
        gen.assign(valid2, schValid);
        cxt.mergeValidEvaluated(schCxt, valid2);
        if (ifClause)
          gen.assign(ifClause, (0, codegen_1$C._)`${keyword2}`);
        else
          cxt.setParams({ ifClause: keyword2 });
      };
    }
  }
};
function hasSchema$1(it, keyword2) {
  const schema = it.schema[keyword2];
  return schema !== void 0 && !(0, util_1$y.alwaysValidSchema)(it, schema);
}
_if$1.default = def$F;
var thenElse$1 = {};
Object.defineProperty(thenElse$1, "__esModule", { value: true });
const util_1$x = util$2;
const def$E = {
  keyword: ["then", "else"],
  schemaType: ["object", "boolean"],
  code({ keyword: keyword2, parentSchema, it }) {
    if (parentSchema.if === void 0)
      (0, util_1$x.checkStrictMode)(it, `"${keyword2}" without "if" is ignored`);
  }
};
thenElse$1.default = def$E;
Object.defineProperty(applicator$2, "__esModule", { value: true });
const additionalItems_1$2 = additionalItems$1;
const prefixItems_1$1 = prefixItems$1;
const items_1$2 = items$1;
const items2020_1$1 = items2020$1;
const contains_1$1 = contains$1;
const dependencies_1$3 = dependencies$1;
const propertyNames_1$1 = propertyNames$1;
const additionalProperties_1$2 = additionalProperties$2;
const properties_1$1 = properties$b;
const patternProperties_1$1 = patternProperties$1;
const not_1$1 = not$1;
const anyOf_1$1 = anyOf$1;
const oneOf_1$1 = oneOf$1;
const allOf_1$1 = allOf$2;
const if_1$1 = _if$1;
const thenElse_1$1 = thenElse$1;
function getApplicator$1(draft20202 = false) {
  const applicator2 = [
    // any
    not_1$1.default,
    anyOf_1$1.default,
    oneOf_1$1.default,
    allOf_1$1.default,
    if_1$1.default,
    thenElse_1$1.default,
    // object
    propertyNames_1$1.default,
    additionalProperties_1$2.default,
    dependencies_1$3.default,
    properties_1$1.default,
    patternProperties_1$1.default
  ];
  if (draft20202)
    applicator2.push(prefixItems_1$1.default, items2020_1$1.default);
  else
    applicator2.push(additionalItems_1$2.default, items_1$2.default);
  applicator2.push(contains_1$1.default);
  return applicator2;
}
applicator$2.default = getApplicator$1;
var dynamic$1 = {};
var dynamicAnchor$1 = {};
Object.defineProperty(dynamicAnchor$1, "__esModule", { value: true });
dynamicAnchor$1.dynamicAnchor = void 0;
const codegen_1$B = codegen$1;
const names_1$9 = names$3;
const compile_1$3 = compile$1;
const ref_1$2 = ref$1;
const def$D = {
  keyword: "$dynamicAnchor",
  schemaType: "string",
  code: (cxt) => dynamicAnchor(cxt, cxt.schema)
};
function dynamicAnchor(cxt, anchor) {
  const { gen, it } = cxt;
  it.schemaEnv.root.dynamicAnchors[anchor] = true;
  const v = (0, codegen_1$B._)`${names_1$9.default.dynamicAnchors}${(0, codegen_1$B.getProperty)(anchor)}`;
  const validate2 = it.errSchemaPath === "#" ? it.validateName : _getValidate(cxt);
  gen.if((0, codegen_1$B._)`!${v}`, () => gen.assign(v, validate2));
}
dynamicAnchor$1.dynamicAnchor = dynamicAnchor;
function _getValidate(cxt) {
  const { schemaEnv, schema, self: self2 } = cxt.it;
  const { root, baseId, localRefs, meta } = schemaEnv.root;
  const { schemaId } = self2.opts;
  const sch = new compile_1$3.SchemaEnv({ schema, schemaId, root, baseId, localRefs, meta });
  compile_1$3.compileSchema.call(self2, sch);
  return (0, ref_1$2.getValidate)(cxt, sch);
}
dynamicAnchor$1.default = def$D;
var dynamicRef$1 = {};
Object.defineProperty(dynamicRef$1, "__esModule", { value: true });
dynamicRef$1.dynamicRef = void 0;
const codegen_1$A = codegen$1;
const names_1$8 = names$3;
const ref_1$1 = ref$1;
const def$C = {
  keyword: "$dynamicRef",
  schemaType: "string",
  code: (cxt) => dynamicRef(cxt, cxt.schema)
};
function dynamicRef(cxt, ref2) {
  const { gen, keyword: keyword2, it } = cxt;
  if (ref2[0] !== "#")
    throw new Error(`"${keyword2}" only supports hash fragment reference`);
  const anchor = ref2.slice(1);
  if (it.allErrors) {
    _dynamicRef();
  } else {
    const valid2 = gen.let("valid", false);
    _dynamicRef(valid2);
    cxt.ok(valid2);
  }
  function _dynamicRef(valid2) {
    if (it.schemaEnv.root.dynamicAnchors[anchor]) {
      const v = gen.let("_v", (0, codegen_1$A._)`${names_1$8.default.dynamicAnchors}${(0, codegen_1$A.getProperty)(anchor)}`);
      gen.if(v, _callRef(v, valid2), _callRef(it.validateName, valid2));
    } else {
      _callRef(it.validateName, valid2)();
    }
  }
  function _callRef(validate2, valid2) {
    return valid2 ? () => gen.block(() => {
      (0, ref_1$1.callRef)(cxt, validate2);
      gen.let(valid2, true);
    }) : () => (0, ref_1$1.callRef)(cxt, validate2);
  }
}
dynamicRef$1.dynamicRef = dynamicRef;
dynamicRef$1.default = def$C;
var recursiveAnchor = {};
Object.defineProperty(recursiveAnchor, "__esModule", { value: true });
const dynamicAnchor_1$1 = dynamicAnchor$1;
const util_1$w = util$2;
const def$B = {
  keyword: "$recursiveAnchor",
  schemaType: "boolean",
  code(cxt) {
    if (cxt.schema)
      (0, dynamicAnchor_1$1.dynamicAnchor)(cxt, "");
    else
      (0, util_1$w.checkStrictMode)(cxt.it, "$recursiveAnchor: false is ignored");
  }
};
recursiveAnchor.default = def$B;
var recursiveRef = {};
Object.defineProperty(recursiveRef, "__esModule", { value: true });
const dynamicRef_1$1 = dynamicRef$1;
const def$A = {
  keyword: "$recursiveRef",
  schemaType: "string",
  code: (cxt) => (0, dynamicRef_1$1.dynamicRef)(cxt, cxt.schema)
};
recursiveRef.default = def$A;
Object.defineProperty(dynamic$1, "__esModule", { value: true });
const dynamicAnchor_1 = dynamicAnchor$1;
const dynamicRef_1 = dynamicRef$1;
const recursiveAnchor_1 = recursiveAnchor;
const recursiveRef_1 = recursiveRef;
const dynamic = [dynamicAnchor_1.default, dynamicRef_1.default, recursiveAnchor_1.default, recursiveRef_1.default];
dynamic$1.default = dynamic;
var next$1 = {};
var dependentRequired = {};
Object.defineProperty(dependentRequired, "__esModule", { value: true });
const dependencies_1$2 = dependencies$1;
const def$z = {
  keyword: "dependentRequired",
  type: "object",
  schemaType: "object",
  error: dependencies_1$2.error,
  code: (cxt) => (0, dependencies_1$2.validatePropertyDeps)(cxt)
};
dependentRequired.default = def$z;
var dependentSchemas = {};
Object.defineProperty(dependentSchemas, "__esModule", { value: true });
const dependencies_1$1 = dependencies$1;
const def$y = {
  keyword: "dependentSchemas",
  type: "object",
  schemaType: "object",
  code: (cxt) => (0, dependencies_1$1.validateSchemaDeps)(cxt)
};
dependentSchemas.default = def$y;
var limitContains = {};
Object.defineProperty(limitContains, "__esModule", { value: true });
const util_1$v = util$2;
const def$x = {
  keyword: ["maxContains", "minContains"],
  type: "array",
  schemaType: "number",
  code({ keyword: keyword2, parentSchema, it }) {
    if (parentSchema.contains === void 0) {
      (0, util_1$v.checkStrictMode)(it, `"${keyword2}" without "contains" is ignored`);
    }
  }
};
limitContains.default = def$x;
Object.defineProperty(next$1, "__esModule", { value: true });
const dependentRequired_1 = dependentRequired;
const dependentSchemas_1 = dependentSchemas;
const limitContains_1 = limitContains;
const next = [dependentRequired_1.default, dependentSchemas_1.default, limitContains_1.default];
next$1.default = next;
var unevaluated$2 = {};
var unevaluatedProperties = {};
Object.defineProperty(unevaluatedProperties, "__esModule", { value: true });
const codegen_1$z = codegen$1;
const util_1$u = util$2;
const names_1$7 = names$3;
const error$m = {
  message: "must NOT have unevaluated properties",
  params: ({ params }) => (0, codegen_1$z._)`{unevaluatedProperty: ${params.unevaluatedProperty}}`
};
const def$w = {
  keyword: "unevaluatedProperties",
  type: "object",
  schemaType: ["boolean", "object"],
  trackErrors: true,
  error: error$m,
  code(cxt) {
    const { gen, schema, data, errsCount, it } = cxt;
    if (!errsCount)
      throw new Error("ajv implementation error");
    const { allErrors, props } = it;
    if (props instanceof codegen_1$z.Name) {
      gen.if((0, codegen_1$z._)`${props} !== true`, () => gen.forIn("key", data, (key) => gen.if(unevaluatedDynamic(props, key), () => unevaluatedPropCode(key))));
    } else if (props !== true) {
      gen.forIn("key", data, (key) => props === void 0 ? unevaluatedPropCode(key) : gen.if(unevaluatedStatic(props, key), () => unevaluatedPropCode(key)));
    }
    it.props = true;
    cxt.ok((0, codegen_1$z._)`${errsCount} === ${names_1$7.default.errors}`);
    function unevaluatedPropCode(key) {
      if (schema === false) {
        cxt.setParams({ unevaluatedProperty: key });
        cxt.error();
        if (!allErrors)
          gen.break();
        return;
      }
      if (!(0, util_1$u.alwaysValidSchema)(it, schema)) {
        const valid2 = gen.name("valid");
        cxt.subschema({
          keyword: "unevaluatedProperties",
          dataProp: key,
          dataPropType: util_1$u.Type.Str
        }, valid2);
        if (!allErrors)
          gen.if((0, codegen_1$z.not)(valid2), () => gen.break());
      }
    }
    function unevaluatedDynamic(evaluatedProps, key) {
      return (0, codegen_1$z._)`!${evaluatedProps} || !${evaluatedProps}[${key}]`;
    }
    function unevaluatedStatic(evaluatedProps, key) {
      const ps = [];
      for (const p in evaluatedProps) {
        if (evaluatedProps[p] === true)
          ps.push((0, codegen_1$z._)`${key} !== ${p}`);
      }
      return (0, codegen_1$z.and)(...ps);
    }
  }
};
unevaluatedProperties.default = def$w;
var unevaluatedItems = {};
Object.defineProperty(unevaluatedItems, "__esModule", { value: true });
const codegen_1$y = codegen$1;
const util_1$t = util$2;
const error$l = {
  message: ({ params: { len } }) => (0, codegen_1$y.str)`must NOT have more than ${len} items`,
  params: ({ params: { len } }) => (0, codegen_1$y._)`{limit: ${len}}`
};
const def$v = {
  keyword: "unevaluatedItems",
  type: "array",
  schemaType: ["boolean", "object"],
  error: error$l,
  code(cxt) {
    const { gen, schema, data, it } = cxt;
    const items2 = it.items || 0;
    if (items2 === true)
      return;
    const len = gen.const("len", (0, codegen_1$y._)`${data}.length`);
    if (schema === false) {
      cxt.setParams({ len: items2 });
      cxt.fail((0, codegen_1$y._)`${len} > ${items2}`);
    } else if (typeof schema == "object" && !(0, util_1$t.alwaysValidSchema)(it, schema)) {
      const valid2 = gen.var("valid", (0, codegen_1$y._)`${len} <= ${items2}`);
      gen.if((0, codegen_1$y.not)(valid2), () => validateItems(valid2, items2));
      cxt.ok(valid2);
    }
    it.items = true;
    function validateItems(valid2, from) {
      gen.forRange("i", from, len, (i2) => {
        cxt.subschema({ keyword: "unevaluatedItems", dataProp: i2, dataPropType: util_1$t.Type.Num }, valid2);
        if (!it.allErrors)
          gen.if((0, codegen_1$y.not)(valid2), () => gen.break());
      });
    }
  }
};
unevaluatedItems.default = def$v;
Object.defineProperty(unevaluated$2, "__esModule", { value: true });
const unevaluatedProperties_1 = unevaluatedProperties;
const unevaluatedItems_1 = unevaluatedItems;
const unevaluated$1 = [unevaluatedProperties_1.default, unevaluatedItems_1.default];
unevaluated$2.default = unevaluated$1;
var format$7 = {};
var format$6 = {};
Object.defineProperty(format$6, "__esModule", { value: true });
const codegen_1$x = codegen$1;
const error$k = {
  message: ({ schemaCode }) => (0, codegen_1$x.str)`must match format "${schemaCode}"`,
  params: ({ schemaCode }) => (0, codegen_1$x._)`{format: ${schemaCode}}`
};
const def$u = {
  keyword: "format",
  type: ["number", "string"],
  schemaType: "string",
  $data: true,
  error: error$k,
  code(cxt, ruleType) {
    const { gen, data, $data, schema, schemaCode, it } = cxt;
    const { opts, errSchemaPath, schemaEnv, self: self2 } = it;
    if (!opts.validateFormats)
      return;
    if ($data)
      validate$DataFormat();
    else
      validateFormat();
    function validate$DataFormat() {
      const fmts = gen.scopeValue("formats", {
        ref: self2.formats,
        code: opts.code.formats
      });
      const fDef = gen.const("fDef", (0, codegen_1$x._)`${fmts}[${schemaCode}]`);
      const fType = gen.let("fType");
      const format2 = gen.let("format");
      gen.if((0, codegen_1$x._)`typeof ${fDef} == "object" && !(${fDef} instanceof RegExp)`, () => gen.assign(fType, (0, codegen_1$x._)`${fDef}.type || "string"`).assign(format2, (0, codegen_1$x._)`${fDef}.validate`), () => gen.assign(fType, (0, codegen_1$x._)`"string"`).assign(format2, fDef));
      cxt.fail$data((0, codegen_1$x.or)(unknownFmt(), invalidFmt()));
      function unknownFmt() {
        if (opts.strictSchema === false)
          return codegen_1$x.nil;
        return (0, codegen_1$x._)`${schemaCode} && !${format2}`;
      }
      function invalidFmt() {
        const callFormat = schemaEnv.$async ? (0, codegen_1$x._)`(${fDef}.async ? await ${format2}(${data}) : ${format2}(${data}))` : (0, codegen_1$x._)`${format2}(${data})`;
        const validData = (0, codegen_1$x._)`(typeof ${format2} == "function" ? ${callFormat} : ${format2}.test(${data}))`;
        return (0, codegen_1$x._)`${format2} && ${format2} !== true && ${fType} === ${ruleType} && !${validData}`;
      }
    }
    function validateFormat() {
      const formatDef = self2.formats[schema];
      if (!formatDef) {
        unknownFormat();
        return;
      }
      if (formatDef === true)
        return;
      const [fmtType, format2, fmtRef] = getFormat(formatDef);
      if (fmtType === ruleType)
        cxt.pass(validCondition());
      function unknownFormat() {
        if (opts.strictSchema === false) {
          self2.logger.warn(unknownMsg());
          return;
        }
        throw new Error(unknownMsg());
        function unknownMsg() {
          return `unknown format "${schema}" ignored in schema at path "${errSchemaPath}"`;
        }
      }
      function getFormat(fmtDef) {
        const code2 = fmtDef instanceof RegExp ? (0, codegen_1$x.regexpCode)(fmtDef) : opts.code.formats ? (0, codegen_1$x._)`${opts.code.formats}${(0, codegen_1$x.getProperty)(schema)}` : void 0;
        const fmt = gen.scopeValue("formats", { key: schema, ref: fmtDef, code: code2 });
        if (typeof fmtDef == "object" && !(fmtDef instanceof RegExp)) {
          return [fmtDef.type || "string", fmtDef.validate, (0, codegen_1$x._)`${fmt}.validate`];
        }
        return ["string", fmtDef, fmt];
      }
      function validCondition() {
        if (typeof formatDef == "object" && !(formatDef instanceof RegExp) && formatDef.async) {
          if (!schemaEnv.$async)
            throw new Error("async format in sync schema");
          return (0, codegen_1$x._)`await ${fmtRef}(${data})`;
        }
        return typeof format2 == "function" ? (0, codegen_1$x._)`${fmtRef}(${data})` : (0, codegen_1$x._)`${fmtRef}.test(${data})`;
      }
    }
  }
};
format$6.default = def$u;
Object.defineProperty(format$7, "__esModule", { value: true });
const format_1$3 = format$6;
const format$5 = [format_1$3.default];
format$7.default = format$5;
var metadata$3 = {};
Object.defineProperty(metadata$3, "__esModule", { value: true });
metadata$3.contentVocabulary = metadata$3.metadataVocabulary = void 0;
metadata$3.metadataVocabulary = [
  "title",
  "description",
  "default",
  "deprecated",
  "readOnly",
  "writeOnly",
  "examples"
];
metadata$3.contentVocabulary = [
  "contentMediaType",
  "contentEncoding",
  "contentSchema"
];
Object.defineProperty(draft2020, "__esModule", { value: true });
const core_1$1 = core$5;
const validation_1$1 = validation$4;
const applicator_1$1 = applicator$2;
const dynamic_1 = dynamic$1;
const next_1 = next$1;
const unevaluated_1 = unevaluated$2;
const format_1$2 = format$7;
const metadata_1$1 = metadata$3;
const draft2020Vocabularies = [
  dynamic_1.default,
  core_1$1.default,
  validation_1$1.default,
  (0, applicator_1$1.default)(true),
  format_1$2.default,
  metadata_1$1.metadataVocabulary,
  metadata_1$1.contentVocabulary,
  next_1.default,
  unevaluated_1.default
];
draft2020.default = draft2020Vocabularies;
var discriminator$1 = {};
var types$1 = {};
Object.defineProperty(types$1, "__esModule", { value: true });
types$1.DiscrError = void 0;
var DiscrError$1;
(function(DiscrError2) {
  DiscrError2["Tag"] = "tag";
  DiscrError2["Mapping"] = "mapping";
})(DiscrError$1 || (types$1.DiscrError = DiscrError$1 = {}));
Object.defineProperty(discriminator$1, "__esModule", { value: true });
const codegen_1$w = codegen$1;
const types_1$1 = types$1;
const compile_1$2 = compile$1;
const ref_error_1$2 = ref_error$1;
const util_1$s = util$2;
const error$j = {
  message: ({ params: { discrError, tagName } }) => discrError === types_1$1.DiscrError.Tag ? `tag "${tagName}" must be string` : `value of tag "${tagName}" must be in oneOf`,
  params: ({ params: { discrError, tag, tagName } }) => (0, codegen_1$w._)`{error: ${discrError}, tag: ${tagName}, tagValue: ${tag}}`
};
const def$t = {
  keyword: "discriminator",
  type: "object",
  schemaType: "object",
  error: error$j,
  code(cxt) {
    const { gen, data, schema, parentSchema, it } = cxt;
    const { oneOf: oneOf2 } = parentSchema;
    if (!it.opts.discriminator) {
      throw new Error("discriminator: requires discriminator option");
    }
    const tagName = schema.propertyName;
    if (typeof tagName != "string")
      throw new Error("discriminator: requires propertyName");
    if (schema.mapping)
      throw new Error("discriminator: mapping is not supported");
    if (!oneOf2)
      throw new Error("discriminator: requires oneOf keyword");
    const valid2 = gen.let("valid", false);
    const tag = gen.const("tag", (0, codegen_1$w._)`${data}${(0, codegen_1$w.getProperty)(tagName)}`);
    gen.if((0, codegen_1$w._)`typeof ${tag} == "string"`, () => validateMapping(), () => cxt.error(false, { discrError: types_1$1.DiscrError.Tag, tag, tagName }));
    cxt.ok(valid2);
    function validateMapping() {
      const mapping = getMapping();
      gen.if(false);
      for (const tagValue in mapping) {
        gen.elseIf((0, codegen_1$w._)`${tag} === ${tagValue}`);
        gen.assign(valid2, applyTagSchema(mapping[tagValue]));
      }
      gen.else();
      cxt.error(false, { discrError: types_1$1.DiscrError.Mapping, tag, tagName });
      gen.endIf();
    }
    function applyTagSchema(schemaProp) {
      const _valid = gen.name("valid");
      const schCxt = cxt.subschema({ keyword: "oneOf", schemaProp }, _valid);
      cxt.mergeEvaluated(schCxt, codegen_1$w.Name);
      return _valid;
    }
    function getMapping() {
      var _a2;
      const oneOfMapping = {};
      const topRequired = hasRequired(parentSchema);
      let tagRequired = true;
      for (let i2 = 0; i2 < oneOf2.length; i2++) {
        let sch = oneOf2[i2];
        if ((sch === null || sch === void 0 ? void 0 : sch.$ref) && !(0, util_1$s.schemaHasRulesButRef)(sch, it.self.RULES)) {
          const ref2 = sch.$ref;
          sch = compile_1$2.resolveRef.call(it.self, it.schemaEnv.root, it.baseId, ref2);
          if (sch instanceof compile_1$2.SchemaEnv)
            sch = sch.schema;
          if (sch === void 0)
            throw new ref_error_1$2.default(it.opts.uriResolver, it.baseId, ref2);
        }
        const propSch = (_a2 = sch === null || sch === void 0 ? void 0 : sch.properties) === null || _a2 === void 0 ? void 0 : _a2[tagName];
        if (typeof propSch != "object") {
          throw new Error(`discriminator: oneOf subschemas (or referenced schemas) must have "properties/${tagName}"`);
        }
        tagRequired = tagRequired && (topRequired || hasRequired(sch));
        addMappings(propSch, i2);
      }
      if (!tagRequired)
        throw new Error(`discriminator: "${tagName}" must be required`);
      return oneOfMapping;
      function hasRequired({ required: required2 }) {
        return Array.isArray(required2) && required2.includes(tagName);
      }
      function addMappings(sch, i2) {
        if (sch.const) {
          addMapping(sch.const, i2);
        } else if (sch.enum) {
          for (const tagValue of sch.enum) {
            addMapping(tagValue, i2);
          }
        } else {
          throw new Error(`discriminator: "properties/${tagName}" must have "const" or "enum"`);
        }
      }
      function addMapping(tagValue, i2) {
        if (typeof tagValue != "string" || tagValue in oneOfMapping) {
          throw new Error(`discriminator: "${tagName}" values must be unique strings`);
        }
        oneOfMapping[tagValue] = i2;
      }
    }
  }
};
discriminator$1.default = def$t;
var jsonSchema202012 = {};
const $schema$8 = "https://json-schema.org/draft/2020-12/schema";
const $id$9 = "https://json-schema.org/draft/2020-12/schema";
const $vocabulary$7 = {
  "https://json-schema.org/draft/2020-12/vocab/core": true,
  "https://json-schema.org/draft/2020-12/vocab/applicator": true,
  "https://json-schema.org/draft/2020-12/vocab/unevaluated": true,
  "https://json-schema.org/draft/2020-12/vocab/validation": true,
  "https://json-schema.org/draft/2020-12/vocab/meta-data": true,
  "https://json-schema.org/draft/2020-12/vocab/format-annotation": true,
  "https://json-schema.org/draft/2020-12/vocab/content": true
};
const $dynamicAnchor$7 = "meta";
const title$8 = "Core and Validation specifications meta-schema";
const allOf$1 = [
  {
    $ref: "meta/core"
  },
  {
    $ref: "meta/applicator"
  },
  {
    $ref: "meta/unevaluated"
  },
  {
    $ref: "meta/validation"
  },
  {
    $ref: "meta/meta-data"
  },
  {
    $ref: "meta/format-annotation"
  },
  {
    $ref: "meta/content"
  }
];
const type$9 = [
  "object",
  "boolean"
];
const $comment = "This meta-schema also defines keywords that have appeared in previous drafts in order to prevent incompatible extensions as they remain in common use.";
const properties$a = {
  definitions: {
    $comment: '"definitions" has been replaced by "$defs".',
    type: "object",
    additionalProperties: {
      $dynamicRef: "#meta"
    },
    deprecated: true,
    "default": {}
  },
  dependencies: {
    $comment: '"dependencies" has been split and replaced by "dependentSchemas" and "dependentRequired" in order to serve their differing semantics.',
    type: "object",
    additionalProperties: {
      anyOf: [
        {
          $dynamicRef: "#meta"
        },
        {
          $ref: "meta/validation#/$defs/stringArray"
        }
      ]
    },
    deprecated: true,
    "default": {}
  },
  $recursiveAnchor: {
    $comment: '"$recursiveAnchor" has been replaced by "$dynamicAnchor".',
    $ref: "meta/core#/$defs/anchorString",
    deprecated: true
  },
  $recursiveRef: {
    $comment: '"$recursiveRef" has been replaced by "$dynamicRef".',
    $ref: "meta/core#/$defs/uriReferenceString",
    deprecated: true
  }
};
const require$$0 = {
  $schema: $schema$8,
  $id: $id$9,
  $vocabulary: $vocabulary$7,
  $dynamicAnchor: $dynamicAnchor$7,
  title: title$8,
  allOf: allOf$1,
  type: type$9,
  $comment,
  properties: properties$a
};
const $schema$7 = "https://json-schema.org/draft/2020-12/schema";
const $id$8 = "https://json-schema.org/draft/2020-12/meta/applicator";
const $vocabulary$6 = {
  "https://json-schema.org/draft/2020-12/vocab/applicator": true
};
const $dynamicAnchor$6 = "meta";
const title$7 = "Applicator vocabulary meta-schema";
const type$8 = [
  "object",
  "boolean"
];
const properties$9 = {
  prefixItems: {
    $ref: "#/$defs/schemaArray"
  },
  items: {
    $dynamicRef: "#meta"
  },
  contains: {
    $dynamicRef: "#meta"
  },
  additionalProperties: {
    $dynamicRef: "#meta"
  },
  properties: {
    type: "object",
    additionalProperties: {
      $dynamicRef: "#meta"
    },
    "default": {}
  },
  patternProperties: {
    type: "object",
    additionalProperties: {
      $dynamicRef: "#meta"
    },
    propertyNames: {
      format: "regex"
    },
    "default": {}
  },
  dependentSchemas: {
    type: "object",
    additionalProperties: {
      $dynamicRef: "#meta"
    },
    "default": {}
  },
  propertyNames: {
    $dynamicRef: "#meta"
  },
  "if": {
    $dynamicRef: "#meta"
  },
  then: {
    $dynamicRef: "#meta"
  },
  "else": {
    $dynamicRef: "#meta"
  },
  allOf: {
    $ref: "#/$defs/schemaArray"
  },
  anyOf: {
    $ref: "#/$defs/schemaArray"
  },
  oneOf: {
    $ref: "#/$defs/schemaArray"
  },
  not: {
    $dynamicRef: "#meta"
  }
};
const $defs$2 = {
  schemaArray: {
    type: "array",
    minItems: 1,
    items: {
      $dynamicRef: "#meta"
    }
  }
};
const require$$1 = {
  $schema: $schema$7,
  $id: $id$8,
  $vocabulary: $vocabulary$6,
  $dynamicAnchor: $dynamicAnchor$6,
  title: title$7,
  type: type$8,
  properties: properties$9,
  $defs: $defs$2
};
const $schema$6 = "https://json-schema.org/draft/2020-12/schema";
const $id$7 = "https://json-schema.org/draft/2020-12/meta/unevaluated";
const $vocabulary$5 = {
  "https://json-schema.org/draft/2020-12/vocab/unevaluated": true
};
const $dynamicAnchor$5 = "meta";
const title$6 = "Unevaluated applicator vocabulary meta-schema";
const type$7 = [
  "object",
  "boolean"
];
const properties$8 = {
  unevaluatedItems: {
    $dynamicRef: "#meta"
  },
  unevaluatedProperties: {
    $dynamicRef: "#meta"
  }
};
const require$$2 = {
  $schema: $schema$6,
  $id: $id$7,
  $vocabulary: $vocabulary$5,
  $dynamicAnchor: $dynamicAnchor$5,
  title: title$6,
  type: type$7,
  properties: properties$8
};
const $schema$5 = "https://json-schema.org/draft/2020-12/schema";
const $id$6 = "https://json-schema.org/draft/2020-12/meta/content";
const $vocabulary$4 = {
  "https://json-schema.org/draft/2020-12/vocab/content": true
};
const $dynamicAnchor$4 = "meta";
const title$5 = "Content vocabulary meta-schema";
const type$6 = [
  "object",
  "boolean"
];
const properties$7 = {
  contentEncoding: {
    type: "string"
  },
  contentMediaType: {
    type: "string"
  },
  contentSchema: {
    $dynamicRef: "#meta"
  }
};
const require$$3$1 = {
  $schema: $schema$5,
  $id: $id$6,
  $vocabulary: $vocabulary$4,
  $dynamicAnchor: $dynamicAnchor$4,
  title: title$5,
  type: type$6,
  properties: properties$7
};
const $schema$4 = "https://json-schema.org/draft/2020-12/schema";
const $id$5 = "https://json-schema.org/draft/2020-12/meta/core";
const $vocabulary$3 = {
  "https://json-schema.org/draft/2020-12/vocab/core": true
};
const $dynamicAnchor$3 = "meta";
const title$4 = "Core vocabulary meta-schema";
const type$5 = [
  "object",
  "boolean"
];
const properties$6 = {
  $id: {
    $ref: "#/$defs/uriReferenceString",
    $comment: "Non-empty fragments not allowed.",
    pattern: "^[^#]*#?$"
  },
  $schema: {
    $ref: "#/$defs/uriString"
  },
  $ref: {
    $ref: "#/$defs/uriReferenceString"
  },
  $anchor: {
    $ref: "#/$defs/anchorString"
  },
  $dynamicRef: {
    $ref: "#/$defs/uriReferenceString"
  },
  $dynamicAnchor: {
    $ref: "#/$defs/anchorString"
  },
  $vocabulary: {
    type: "object",
    propertyNames: {
      $ref: "#/$defs/uriString"
    },
    additionalProperties: {
      type: "boolean"
    }
  },
  $comment: {
    type: "string"
  },
  $defs: {
    type: "object",
    additionalProperties: {
      $dynamicRef: "#meta"
    }
  }
};
const $defs$1 = {
  anchorString: {
    type: "string",
    pattern: "^[A-Za-z_][-A-Za-z0-9._]*$"
  },
  uriString: {
    type: "string",
    format: "uri"
  },
  uriReferenceString: {
    type: "string",
    format: "uri-reference"
  }
};
const require$$4 = {
  $schema: $schema$4,
  $id: $id$5,
  $vocabulary: $vocabulary$3,
  $dynamicAnchor: $dynamicAnchor$3,
  title: title$4,
  type: type$5,
  properties: properties$6,
  $defs: $defs$1
};
const $schema$3 = "https://json-schema.org/draft/2020-12/schema";
const $id$4 = "https://json-schema.org/draft/2020-12/meta/format-annotation";
const $vocabulary$2 = {
  "https://json-schema.org/draft/2020-12/vocab/format-annotation": true
};
const $dynamicAnchor$2 = "meta";
const title$3 = "Format vocabulary meta-schema for annotation results";
const type$4 = [
  "object",
  "boolean"
];
const properties$5 = {
  format: {
    type: "string"
  }
};
const require$$5 = {
  $schema: $schema$3,
  $id: $id$4,
  $vocabulary: $vocabulary$2,
  $dynamicAnchor: $dynamicAnchor$2,
  title: title$3,
  type: type$4,
  properties: properties$5
};
const $schema$2 = "https://json-schema.org/draft/2020-12/schema";
const $id$3 = "https://json-schema.org/draft/2020-12/meta/meta-data";
const $vocabulary$1 = {
  "https://json-schema.org/draft/2020-12/vocab/meta-data": true
};
const $dynamicAnchor$1 = "meta";
const title$2 = "Meta-data vocabulary meta-schema";
const type$3 = [
  "object",
  "boolean"
];
const properties$4 = {
  title: {
    type: "string"
  },
  description: {
    type: "string"
  },
  "default": true,
  deprecated: {
    type: "boolean",
    "default": false
  },
  readOnly: {
    type: "boolean",
    "default": false
  },
  writeOnly: {
    type: "boolean",
    "default": false
  },
  examples: {
    type: "array",
    items: true
  }
};
const require$$6$1 = {
  $schema: $schema$2,
  $id: $id$3,
  $vocabulary: $vocabulary$1,
  $dynamicAnchor: $dynamicAnchor$1,
  title: title$2,
  type: type$3,
  properties: properties$4
};
const $schema$1 = "https://json-schema.org/draft/2020-12/schema";
const $id$2 = "https://json-schema.org/draft/2020-12/meta/validation";
const $vocabulary = {
  "https://json-schema.org/draft/2020-12/vocab/validation": true
};
const $dynamicAnchor = "meta";
const title$1 = "Validation vocabulary meta-schema";
const type$2 = [
  "object",
  "boolean"
];
const properties$3 = {
  type: {
    anyOf: [
      {
        $ref: "#/$defs/simpleTypes"
      },
      {
        type: "array",
        items: {
          $ref: "#/$defs/simpleTypes"
        },
        minItems: 1,
        uniqueItems: true
      }
    ]
  },
  "const": true,
  "enum": {
    type: "array",
    items: true
  },
  multipleOf: {
    type: "number",
    exclusiveMinimum: 0
  },
  maximum: {
    type: "number"
  },
  exclusiveMaximum: {
    type: "number"
  },
  minimum: {
    type: "number"
  },
  exclusiveMinimum: {
    type: "number"
  },
  maxLength: {
    $ref: "#/$defs/nonNegativeInteger"
  },
  minLength: {
    $ref: "#/$defs/nonNegativeIntegerDefault0"
  },
  pattern: {
    type: "string",
    format: "regex"
  },
  maxItems: {
    $ref: "#/$defs/nonNegativeInteger"
  },
  minItems: {
    $ref: "#/$defs/nonNegativeIntegerDefault0"
  },
  uniqueItems: {
    type: "boolean",
    "default": false
  },
  maxContains: {
    $ref: "#/$defs/nonNegativeInteger"
  },
  minContains: {
    $ref: "#/$defs/nonNegativeInteger",
    "default": 1
  },
  maxProperties: {
    $ref: "#/$defs/nonNegativeInteger"
  },
  minProperties: {
    $ref: "#/$defs/nonNegativeIntegerDefault0"
  },
  required: {
    $ref: "#/$defs/stringArray"
  },
  dependentRequired: {
    type: "object",
    additionalProperties: {
      $ref: "#/$defs/stringArray"
    }
  }
};
const $defs = {
  nonNegativeInteger: {
    type: "integer",
    minimum: 0
  },
  nonNegativeIntegerDefault0: {
    $ref: "#/$defs/nonNegativeInteger",
    "default": 0
  },
  simpleTypes: {
    "enum": [
      "array",
      "boolean",
      "integer",
      "null",
      "number",
      "object",
      "string"
    ]
  },
  stringArray: {
    type: "array",
    items: {
      type: "string"
    },
    uniqueItems: true,
    "default": []
  }
};
const require$$7$1 = {
  $schema: $schema$1,
  $id: $id$2,
  $vocabulary,
  $dynamicAnchor,
  title: title$1,
  type: type$2,
  properties: properties$3,
  $defs
};
Object.defineProperty(jsonSchema202012, "__esModule", { value: true });
const metaSchema = require$$0;
const applicator$1 = require$$1;
const unevaluated = require$$2;
const content = require$$3$1;
const core$3 = require$$4;
const format$4 = require$$5;
const metadata$2 = require$$6$1;
const validation$2 = require$$7$1;
const META_SUPPORT_DATA = ["/properties"];
function addMetaSchema2020($data) {
  [
    metaSchema,
    applicator$1,
    unevaluated,
    content,
    core$3,
    with$data(this, format$4),
    metadata$2,
    with$data(this, validation$2)
  ].forEach((sch) => this.addMetaSchema(sch, void 0, false));
  return this;
  function with$data(ajv2, sch) {
    return $data ? ajv2.$dataMetaSchema(sch, META_SUPPORT_DATA) : sch;
  }
}
jsonSchema202012.default = addMetaSchema2020;
(function(module2, exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.MissingRefError = exports$12.ValidationError = exports$12.CodeGen = exports$12.Name = exports$12.nil = exports$12.stringify = exports$12.str = exports$12._ = exports$12.KeywordCxt = exports$12.Ajv2020 = void 0;
  const core_12 = core$6;
  const draft2020_1 = draft2020;
  const discriminator_1 = discriminator$1;
  const json_schema_2020_12_1 = jsonSchema202012;
  const META_SCHEMA_ID = "https://json-schema.org/draft/2020-12/schema";
  class Ajv2020 extends core_12.default {
    constructor(opts = {}) {
      super({
        ...opts,
        dynamicRef: true,
        next: true,
        unevaluated: true
      });
    }
    _addVocabularies() {
      super._addVocabularies();
      draft2020_1.default.forEach((v) => this.addVocabulary(v));
      if (this.opts.discriminator)
        this.addKeyword(discriminator_1.default);
    }
    _addDefaultMetaSchema() {
      super._addDefaultMetaSchema();
      const { $data, meta } = this.opts;
      if (!meta)
        return;
      json_schema_2020_12_1.default.call(this, $data);
      this.refs["http://json-schema.org/schema"] = META_SCHEMA_ID;
    }
    defaultMeta() {
      return this.opts.defaultMeta = super.defaultMeta() || (this.getSchema(META_SCHEMA_ID) ? META_SCHEMA_ID : void 0);
    }
  }
  exports$12.Ajv2020 = Ajv2020;
  module2.exports = exports$12 = Ajv2020;
  module2.exports.Ajv2020 = Ajv2020;
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.default = Ajv2020;
  var validate_12 = validate$1;
  Object.defineProperty(exports$12, "KeywordCxt", { enumerable: true, get: function() {
    return validate_12.KeywordCxt;
  } });
  var codegen_12 = codegen$1;
  Object.defineProperty(exports$12, "_", { enumerable: true, get: function() {
    return codegen_12._;
  } });
  Object.defineProperty(exports$12, "str", { enumerable: true, get: function() {
    return codegen_12.str;
  } });
  Object.defineProperty(exports$12, "stringify", { enumerable: true, get: function() {
    return codegen_12.stringify;
  } });
  Object.defineProperty(exports$12, "nil", { enumerable: true, get: function() {
    return codegen_12.nil;
  } });
  Object.defineProperty(exports$12, "Name", { enumerable: true, get: function() {
    return codegen_12.Name;
  } });
  Object.defineProperty(exports$12, "CodeGen", { enumerable: true, get: function() {
    return codegen_12.CodeGen;
  } });
  var validation_error_12 = validation_error$1;
  Object.defineProperty(exports$12, "ValidationError", { enumerable: true, get: function() {
    return validation_error_12.default;
  } });
  var ref_error_12 = ref_error$1;
  Object.defineProperty(exports$12, "MissingRefError", { enumerable: true, get: function() {
    return ref_error_12.default;
  } });
})(_2020, _2020.exports);
var _2020Exports = _2020.exports;
var dist$1 = { exports: {} };
var formats$1 = {};
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.formatNames = exports$12.fastFormats = exports$12.fullFormats = void 0;
  function fmtDef(validate2, compare2) {
    return { validate: validate2, compare: compare2 };
  }
  exports$12.fullFormats = {
    // date: http://tools.ietf.org/html/rfc3339#section-5.6
    date: fmtDef(date, compareDate),
    // date-time: http://tools.ietf.org/html/rfc3339#section-5.6
    time: fmtDef(getTime(true), compareTime),
    "date-time": fmtDef(getDateTime(true), compareDateTime),
    "iso-time": fmtDef(getTime(), compareIsoTime),
    "iso-date-time": fmtDef(getDateTime(), compareIsoDateTime),
    // duration: https://tools.ietf.org/html/rfc3339#appendix-A
    duration: /^P(?!$)((\d+Y)?(\d+M)?(\d+D)?(T(?=\d)(\d+H)?(\d+M)?(\d+S)?)?|(\d+W)?)$/,
    uri: uri2,
    "uri-reference": /^(?:[a-z][a-z0-9+\-.]*:)?(?:\/?\/(?:(?:[a-z0-9\-._~!$&'()*+,;=:]|%[0-9a-f]{2})*@)?(?:\[(?:(?:(?:(?:[0-9a-f]{1,4}:){6}|::(?:[0-9a-f]{1,4}:){5}|(?:[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){4}|(?:(?:[0-9a-f]{1,4}:){0,1}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){3}|(?:(?:[0-9a-f]{1,4}:){0,2}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){2}|(?:(?:[0-9a-f]{1,4}:){0,3}[0-9a-f]{1,4})?::[0-9a-f]{1,4}:|(?:(?:[0-9a-f]{1,4}:){0,4}[0-9a-f]{1,4})?::)(?:[0-9a-f]{1,4}:[0-9a-f]{1,4}|(?:(?:25[0-5]|2[0-4]\d|[01]?\d\d?)\.){3}(?:25[0-5]|2[0-4]\d|[01]?\d\d?))|(?:(?:[0-9a-f]{1,4}:){0,5}[0-9a-f]{1,4})?::[0-9a-f]{1,4}|(?:(?:[0-9a-f]{1,4}:){0,6}[0-9a-f]{1,4})?::)|[Vv][0-9a-f]+\.[a-z0-9\-._~!$&'()*+,;=:]+)\]|(?:(?:25[0-5]|2[0-4]\d|[01]?\d\d?)\.){3}(?:25[0-5]|2[0-4]\d|[01]?\d\d?)|(?:[a-z0-9\-._~!$&'"()*+,;=]|%[0-9a-f]{2})*)(?::\d*)?(?:\/(?:[a-z0-9\-._~!$&'"()*+,;=:@]|%[0-9a-f]{2})*)*|\/(?:(?:[a-z0-9\-._~!$&'"()*+,;=:@]|%[0-9a-f]{2})+(?:\/(?:[a-z0-9\-._~!$&'"()*+,;=:@]|%[0-9a-f]{2})*)*)?|(?:[a-z0-9\-._~!$&'"()*+,;=:@]|%[0-9a-f]{2})+(?:\/(?:[a-z0-9\-._~!$&'"()*+,;=:@]|%[0-9a-f]{2})*)*)?(?:\?(?:[a-z0-9\-._~!$&'"()*+,;=:@/?]|%[0-9a-f]{2})*)?(?:#(?:[a-z0-9\-._~!$&'"()*+,;=:@/?]|%[0-9a-f]{2})*)?$/i,
    // uri-template: https://tools.ietf.org/html/rfc6570
    "uri-template": /^(?:(?:[^\x00-\x20"'<>%\\^`{|}]|%[0-9a-f]{2})|\{[+#./;?&=,!@|]?(?:[a-z0-9_]|%[0-9a-f]{2})+(?::[1-9][0-9]{0,3}|\*)?(?:,(?:[a-z0-9_]|%[0-9a-f]{2})+(?::[1-9][0-9]{0,3}|\*)?)*\})*$/i,
    // For the source: https://gist.github.com/dperini/729294
    // For test cases: https://mathiasbynens.be/demo/url-regex
    url: /^(?:https?|ftp):\/\/(?:\S+(?::\S*)?@)?(?:(?!(?:10|127)(?:\.\d{1,3}){3})(?!(?:169\.254|192\.168)(?:\.\d{1,3}){2})(?!172\.(?:1[6-9]|2\d|3[0-1])(?:\.\d{1,3}){2})(?:[1-9]\d?|1\d\d|2[01]\d|22[0-3])(?:\.(?:1?\d{1,2}|2[0-4]\d|25[0-5])){2}(?:\.(?:[1-9]\d?|1\d\d|2[0-4]\d|25[0-4]))|(?:(?:[a-z0-9\u{00a1}-\u{ffff}]+-)*[a-z0-9\u{00a1}-\u{ffff}]+)(?:\.(?:[a-z0-9\u{00a1}-\u{ffff}]+-)*[a-z0-9\u{00a1}-\u{ffff}]+)*(?:\.(?:[a-z\u{00a1}-\u{ffff}]{2,})))(?::\d{2,5})?(?:\/[^\s]*)?$/iu,
    email: /^[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?$/i,
    hostname: /^(?=.{1,253}\.?$)[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?(?:\.[a-z0-9](?:[-0-9a-z]{0,61}[0-9a-z])?)*\.?$/i,
    // optimized https://www.safaribooksonline.com/library/view/regular-expressions-cookbook/9780596802837/ch07s16.html
    ipv4: /^(?:(?:25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)\.){3}(?:25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)$/,
    ipv6: /^((([0-9a-f]{1,4}:){7}([0-9a-f]{1,4}|:))|(([0-9a-f]{1,4}:){6}(:[0-9a-f]{1,4}|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9a-f]{1,4}:){5}(((:[0-9a-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9a-f]{1,4}:){4}(((:[0-9a-f]{1,4}){1,3})|((:[0-9a-f]{1,4})?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9a-f]{1,4}:){3}(((:[0-9a-f]{1,4}){1,4})|((:[0-9a-f]{1,4}){0,2}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9a-f]{1,4}:){2}(((:[0-9a-f]{1,4}){1,5})|((:[0-9a-f]{1,4}){0,3}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9a-f]{1,4}:){1}(((:[0-9a-f]{1,4}){1,6})|((:[0-9a-f]{1,4}){0,4}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(:(((:[0-9a-f]{1,4}){1,7})|((:[0-9a-f]{1,4}){0,5}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:)))$/i,
    regex,
    // uuid: http://tools.ietf.org/html/rfc4122
    uuid: /^(?:urn:uuid:)?[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12}$/i,
    // JSON-pointer: https://tools.ietf.org/html/rfc6901
    // uri fragment: https://tools.ietf.org/html/rfc3986#appendix-A
    "json-pointer": /^(?:\/(?:[^~/]|~0|~1)*)*$/,
    "json-pointer-uri-fragment": /^#(?:\/(?:[a-z0-9_\-.!$&'()*+,;:=@]|%[0-9a-f]{2}|~0|~1)*)*$/i,
    // relative JSON-pointer: http://tools.ietf.org/html/draft-luff-relative-json-pointer-00
    "relative-json-pointer": /^(?:0|[1-9][0-9]*)(?:#|(?:\/(?:[^~/]|~0|~1)*)*)$/,
    // the following formats are used by the openapi specification: https://spec.openapis.org/oas/v3.0.0#data-types
    // byte: https://github.com/miguelmota/is-base64
    byte,
    // signed 32 bit integer
    int32: { type: "number", validate: validateInt32 },
    // signed 64 bit integer
    int64: { type: "number", validate: validateInt64 },
    // C-type float
    float: { type: "number", validate: validateNumber },
    // C-type double
    double: { type: "number", validate: validateNumber },
    // hint to the UI to hide input strings
    password: true,
    // unchecked string payload
    binary: true
  };
  exports$12.fastFormats = {
    ...exports$12.fullFormats,
    date: fmtDef(/^\d\d\d\d-[0-1]\d-[0-3]\d$/, compareDate),
    time: fmtDef(/^(?:[0-2]\d:[0-5]\d:[0-5]\d|23:59:60)(?:\.\d+)?(?:z|[+-]\d\d(?::?\d\d)?)$/i, compareTime),
    "date-time": fmtDef(/^\d\d\d\d-[0-1]\d-[0-3]\dt(?:[0-2]\d:[0-5]\d:[0-5]\d|23:59:60)(?:\.\d+)?(?:z|[+-]\d\d(?::?\d\d)?)$/i, compareDateTime),
    "iso-time": fmtDef(/^(?:[0-2]\d:[0-5]\d:[0-5]\d|23:59:60)(?:\.\d+)?(?:z|[+-]\d\d(?::?\d\d)?)?$/i, compareIsoTime),
    "iso-date-time": fmtDef(/^\d\d\d\d-[0-1]\d-[0-3]\d[t\s](?:[0-2]\d:[0-5]\d:[0-5]\d|23:59:60)(?:\.\d+)?(?:z|[+-]\d\d(?::?\d\d)?)?$/i, compareIsoDateTime),
    // uri: https://github.com/mafintosh/is-my-json-valid/blob/master/formats.js
    uri: /^(?:[a-z][a-z0-9+\-.]*:)(?:\/?\/)?[^\s]*$/i,
    "uri-reference": /^(?:(?:[a-z][a-z0-9+\-.]*:)?\/?\/)?(?:[^\\\s#][^\s#]*)?(?:#[^\\\s]*)?$/i,
    // email (sources from jsen validator):
    // http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address#answer-8829363
    // http://www.w3.org/TR/html5/forms.html#valid-e-mail-address (search for 'wilful violation')
    email: /^[a-z0-9.!#$%&'*+/=?^_`{|}~-]+@[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?(?:\.[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?)*$/i
  };
  exports$12.formatNames = Object.keys(exports$12.fullFormats);
  function isLeapYear(year) {
    return year % 4 === 0 && (year % 100 !== 0 || year % 400 === 0);
  }
  const DATE = /^(\d\d\d\d)-(\d\d)-(\d\d)$/;
  const DAYS = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];
  function date(str) {
    const matches = DATE.exec(str);
    if (!matches)
      return false;
    const year = +matches[1];
    const month = +matches[2];
    const day = +matches[3];
    return month >= 1 && month <= 12 && day >= 1 && day <= (month === 2 && isLeapYear(year) ? 29 : DAYS[month]);
  }
  function compareDate(d1, d2) {
    if (!(d1 && d2))
      return void 0;
    if (d1 > d2)
      return 1;
    if (d1 < d2)
      return -1;
    return 0;
  }
  const TIME = /^(\d\d):(\d\d):(\d\d(?:\.\d+)?)(z|([+-])(\d\d)(?::?(\d\d))?)?$/i;
  function getTime(strictTimeZone) {
    return function time(str) {
      const matches = TIME.exec(str);
      if (!matches)
        return false;
      const hr = +matches[1];
      const min2 = +matches[2];
      const sec = +matches[3];
      const tz = matches[4];
      const tzSign = matches[5] === "-" ? -1 : 1;
      const tzH = +(matches[6] || 0);
      const tzM = +(matches[7] || 0);
      if (tzH > 23 || tzM > 59 || strictTimeZone && !tz)
        return false;
      if (hr <= 23 && min2 <= 59 && sec < 60)
        return true;
      const utcMin = min2 - tzM * tzSign;
      const utcHr = hr - tzH * tzSign - (utcMin < 0 ? 1 : 0);
      return (utcHr === 23 || utcHr === -1) && (utcMin === 59 || utcMin === -1) && sec < 61;
    };
  }
  function compareTime(s1, s2) {
    if (!(s1 && s2))
      return void 0;
    const t1 = (/* @__PURE__ */ new Date("2020-01-01T" + s1)).valueOf();
    const t2 = (/* @__PURE__ */ new Date("2020-01-01T" + s2)).valueOf();
    if (!(t1 && t2))
      return void 0;
    return t1 - t2;
  }
  function compareIsoTime(t1, t2) {
    if (!(t1 && t2))
      return void 0;
    const a1 = TIME.exec(t1);
    const a2 = TIME.exec(t2);
    if (!(a1 && a2))
      return void 0;
    t1 = a1[1] + a1[2] + a1[3];
    t2 = a2[1] + a2[2] + a2[3];
    if (t1 > t2)
      return 1;
    if (t1 < t2)
      return -1;
    return 0;
  }
  const DATE_TIME_SEPARATOR = /t|\s/i;
  function getDateTime(strictTimeZone) {
    const time = getTime(strictTimeZone);
    return function date_time(str) {
      const dateTime = str.split(DATE_TIME_SEPARATOR);
      return dateTime.length === 2 && date(dateTime[0]) && time(dateTime[1]);
    };
  }
  function compareDateTime(dt1, dt2) {
    if (!(dt1 && dt2))
      return void 0;
    const d1 = new Date(dt1).valueOf();
    const d2 = new Date(dt2).valueOf();
    if (!(d1 && d2))
      return void 0;
    return d1 - d2;
  }
  function compareIsoDateTime(dt1, dt2) {
    if (!(dt1 && dt2))
      return void 0;
    const [d1, t1] = dt1.split(DATE_TIME_SEPARATOR);
    const [d2, t2] = dt2.split(DATE_TIME_SEPARATOR);
    const res = compareDate(d1, d2);
    if (res === void 0)
      return void 0;
    return res || compareTime(t1, t2);
  }
  const NOT_URI_FRAGMENT = /\/|:/;
  const URI = /^(?:[a-z][a-z0-9+\-.]*:)(?:\/?\/(?:(?:[a-z0-9\-._~!$&'()*+,;=:]|%[0-9a-f]{2})*@)?(?:\[(?:(?:(?:(?:[0-9a-f]{1,4}:){6}|::(?:[0-9a-f]{1,4}:){5}|(?:[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){4}|(?:(?:[0-9a-f]{1,4}:){0,1}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){3}|(?:(?:[0-9a-f]{1,4}:){0,2}[0-9a-f]{1,4})?::(?:[0-9a-f]{1,4}:){2}|(?:(?:[0-9a-f]{1,4}:){0,3}[0-9a-f]{1,4})?::[0-9a-f]{1,4}:|(?:(?:[0-9a-f]{1,4}:){0,4}[0-9a-f]{1,4})?::)(?:[0-9a-f]{1,4}:[0-9a-f]{1,4}|(?:(?:25[0-5]|2[0-4]\d|[01]?\d\d?)\.){3}(?:25[0-5]|2[0-4]\d|[01]?\d\d?))|(?:(?:[0-9a-f]{1,4}:){0,5}[0-9a-f]{1,4})?::[0-9a-f]{1,4}|(?:(?:[0-9a-f]{1,4}:){0,6}[0-9a-f]{1,4})?::)|[Vv][0-9a-f]+\.[a-z0-9\-._~!$&'()*+,;=:]+)\]|(?:(?:25[0-5]|2[0-4]\d|[01]?\d\d?)\.){3}(?:25[0-5]|2[0-4]\d|[01]?\d\d?)|(?:[a-z0-9\-._~!$&'()*+,;=]|%[0-9a-f]{2})*)(?::\d*)?(?:\/(?:[a-z0-9\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})*)*|\/(?:(?:[a-z0-9\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})+(?:\/(?:[a-z0-9\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})*)*)?|(?:[a-z0-9\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})+(?:\/(?:[a-z0-9\-._~!$&'()*+,;=:@]|%[0-9a-f]{2})*)*)(?:\?(?:[a-z0-9\-._~!$&'()*+,;=:@/?]|%[0-9a-f]{2})*)?(?:#(?:[a-z0-9\-._~!$&'()*+,;=:@/?]|%[0-9a-f]{2})*)?$/i;
  function uri2(str) {
    return NOT_URI_FRAGMENT.test(str) && URI.test(str);
  }
  const BYTE = /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/gm;
  function byte(str) {
    BYTE.lastIndex = 0;
    return BYTE.test(str);
  }
  const MIN_INT32 = -2147483648;
  const MAX_INT32 = 2 ** 31 - 1;
  function validateInt32(value) {
    return Number.isInteger(value) && value <= MAX_INT32 && value >= MIN_INT32;
  }
  function validateInt64(value) {
    return Number.isInteger(value);
  }
  function validateNumber() {
    return true;
  }
  const Z_ANCHOR = /[^\\]\\Z/;
  function regex(str) {
    if (Z_ANCHOR.test(str))
      return false;
    try {
      new RegExp(str);
      return true;
    } catch (e) {
      return false;
    }
  }
})(formats$1);
var limit = {};
var ajv = { exports: {} };
var core$2 = {};
var validate = {};
var boolSchema = {};
var errors = {};
var codegen = {};
var code$1 = {};
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.regexpCode = exports$12.getEsmExportName = exports$12.getProperty = exports$12.safeStringify = exports$12.stringify = exports$12.strConcat = exports$12.addCodeArg = exports$12.str = exports$12._ = exports$12.nil = exports$12._Code = exports$12.Name = exports$12.IDENTIFIER = exports$12._CodeOrName = void 0;
  class _CodeOrName {
  }
  exports$12._CodeOrName = _CodeOrName;
  exports$12.IDENTIFIER = /^[a-z$_][a-z$_0-9]*$/i;
  class Name extends _CodeOrName {
    constructor(s) {
      super();
      if (!exports$12.IDENTIFIER.test(s))
        throw new Error("CodeGen: name must be a valid identifier");
      this.str = s;
    }
    toString() {
      return this.str;
    }
    emptyStr() {
      return false;
    }
    get names() {
      return { [this.str]: 1 };
    }
  }
  exports$12.Name = Name;
  class _Code extends _CodeOrName {
    constructor(code2) {
      super();
      this._items = typeof code2 === "string" ? [code2] : code2;
    }
    toString() {
      return this.str;
    }
    emptyStr() {
      if (this._items.length > 1)
        return false;
      const item = this._items[0];
      return item === "" || item === '""';
    }
    get str() {
      var _a2;
      return (_a2 = this._str) !== null && _a2 !== void 0 ? _a2 : this._str = this._items.reduce((s, c) => `${s}${c}`, "");
    }
    get names() {
      var _a2;
      return (_a2 = this._names) !== null && _a2 !== void 0 ? _a2 : this._names = this._items.reduce((names2, c) => {
        if (c instanceof Name)
          names2[c.str] = (names2[c.str] || 0) + 1;
        return names2;
      }, {});
    }
  }
  exports$12._Code = _Code;
  exports$12.nil = new _Code("");
  function _(strs, ...args) {
    const code2 = [strs[0]];
    let i2 = 0;
    while (i2 < args.length) {
      addCodeArg(code2, args[i2]);
      code2.push(strs[++i2]);
    }
    return new _Code(code2);
  }
  exports$12._ = _;
  const plus = new _Code("+");
  function str(strs, ...args) {
    const expr = [safeStringify(strs[0])];
    let i2 = 0;
    while (i2 < args.length) {
      expr.push(plus);
      addCodeArg(expr, args[i2]);
      expr.push(plus, safeStringify(strs[++i2]));
    }
    optimize(expr);
    return new _Code(expr);
  }
  exports$12.str = str;
  function addCodeArg(code2, arg) {
    if (arg instanceof _Code)
      code2.push(...arg._items);
    else if (arg instanceof Name)
      code2.push(arg);
    else
      code2.push(interpolate2(arg));
  }
  exports$12.addCodeArg = addCodeArg;
  function optimize(expr) {
    let i2 = 1;
    while (i2 < expr.length - 1) {
      if (expr[i2] === plus) {
        const res = mergeExprItems(expr[i2 - 1], expr[i2 + 1]);
        if (res !== void 0) {
          expr.splice(i2 - 1, 3, res);
          continue;
        }
        expr[i2++] = "+";
      }
      i2++;
    }
  }
  function mergeExprItems(a, b) {
    if (b === '""')
      return a;
    if (a === '""')
      return b;
    if (typeof a == "string") {
      if (b instanceof Name || a[a.length - 1] !== '"')
        return;
      if (typeof b != "string")
        return `${a.slice(0, -1)}${b}"`;
      if (b[0] === '"')
        return a.slice(0, -1) + b.slice(1);
      return;
    }
    if (typeof b == "string" && b[0] === '"' && !(a instanceof Name))
      return `"${a}${b.slice(1)}`;
    return;
  }
  function strConcat(c1, c2) {
    return c2.emptyStr() ? c1 : c1.emptyStr() ? c2 : str`${c1}${c2}`;
  }
  exports$12.strConcat = strConcat;
  function interpolate2(x) {
    return typeof x == "number" || typeof x == "boolean" || x === null ? x : safeStringify(Array.isArray(x) ? x.join(",") : x);
  }
  function stringify(x) {
    return new _Code(safeStringify(x));
  }
  exports$12.stringify = stringify;
  function safeStringify(x) {
    return JSON.stringify(x).replace(/\u2028/g, "\\u2028").replace(/\u2029/g, "\\u2029");
  }
  exports$12.safeStringify = safeStringify;
  function getProperty2(key) {
    return typeof key == "string" && exports$12.IDENTIFIER.test(key) ? new _Code(`.${key}`) : _`[${key}]`;
  }
  exports$12.getProperty = getProperty2;
  function getEsmExportName(key) {
    if (typeof key == "string" && exports$12.IDENTIFIER.test(key)) {
      return new _Code(`${key}`);
    }
    throw new Error(`CodeGen: invalid export name: ${key}, use explicit $id name mapping`);
  }
  exports$12.getEsmExportName = getEsmExportName;
  function regexpCode(rx) {
    return new _Code(rx.toString());
  }
  exports$12.regexpCode = regexpCode;
})(code$1);
var scope = {};
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.ValueScope = exports$12.ValueScopeName = exports$12.Scope = exports$12.varKinds = exports$12.UsedValueState = void 0;
  const code_12 = code$1;
  class ValueError extends Error {
    constructor(name2) {
      super(`CodeGen: "code" for ${name2} not defined`);
      this.value = name2.value;
    }
  }
  var UsedValueState;
  (function(UsedValueState2) {
    UsedValueState2[UsedValueState2["Started"] = 0] = "Started";
    UsedValueState2[UsedValueState2["Completed"] = 1] = "Completed";
  })(UsedValueState || (exports$12.UsedValueState = UsedValueState = {}));
  exports$12.varKinds = {
    const: new code_12.Name("const"),
    let: new code_12.Name("let"),
    var: new code_12.Name("var")
  };
  class Scope {
    constructor({ prefixes, parent } = {}) {
      this._names = {};
      this._prefixes = prefixes;
      this._parent = parent;
    }
    toName(nameOrPrefix) {
      return nameOrPrefix instanceof code_12.Name ? nameOrPrefix : this.name(nameOrPrefix);
    }
    name(prefix) {
      return new code_12.Name(this._newName(prefix));
    }
    _newName(prefix) {
      const ng = this._names[prefix] || this._nameGroup(prefix);
      return `${prefix}${ng.index++}`;
    }
    _nameGroup(prefix) {
      var _a2, _b;
      if (((_b = (_a2 = this._parent) === null || _a2 === void 0 ? void 0 : _a2._prefixes) === null || _b === void 0 ? void 0 : _b.has(prefix)) || this._prefixes && !this._prefixes.has(prefix)) {
        throw new Error(`CodeGen: prefix "${prefix}" is not allowed in this scope`);
      }
      return this._names[prefix] = { prefix, index: 0 };
    }
  }
  exports$12.Scope = Scope;
  class ValueScopeName extends code_12.Name {
    constructor(prefix, nameStr) {
      super(nameStr);
      this.prefix = prefix;
    }
    setValue(value, { property, itemIndex }) {
      this.value = value;
      this.scopePath = (0, code_12._)`.${new code_12.Name(property)}[${itemIndex}]`;
    }
  }
  exports$12.ValueScopeName = ValueScopeName;
  const line = (0, code_12._)`\n`;
  class ValueScope extends Scope {
    constructor(opts) {
      super(opts);
      this._values = {};
      this._scope = opts.scope;
      this.opts = { ...opts, _n: opts.lines ? line : code_12.nil };
    }
    get() {
      return this._scope;
    }
    name(prefix) {
      return new ValueScopeName(prefix, this._newName(prefix));
    }
    value(nameOrPrefix, value) {
      var _a2;
      if (value.ref === void 0)
        throw new Error("CodeGen: ref must be passed in value");
      const name2 = this.toName(nameOrPrefix);
      const { prefix } = name2;
      const valueKey = (_a2 = value.key) !== null && _a2 !== void 0 ? _a2 : value.ref;
      let vs = this._values[prefix];
      if (vs) {
        const _name = vs.get(valueKey);
        if (_name)
          return _name;
      } else {
        vs = this._values[prefix] = /* @__PURE__ */ new Map();
      }
      vs.set(valueKey, name2);
      const s = this._scope[prefix] || (this._scope[prefix] = []);
      const itemIndex = s.length;
      s[itemIndex] = value.ref;
      name2.setValue(value, { property: prefix, itemIndex });
      return name2;
    }
    getValue(prefix, keyOrRef) {
      const vs = this._values[prefix];
      if (!vs)
        return;
      return vs.get(keyOrRef);
    }
    scopeRefs(scopeName, values = this._values) {
      return this._reduceValues(values, (name2) => {
        if (name2.scopePath === void 0)
          throw new Error(`CodeGen: name "${name2}" has no value`);
        return (0, code_12._)`${scopeName}${name2.scopePath}`;
      });
    }
    scopeCode(values = this._values, usedValues, getCode) {
      return this._reduceValues(values, (name2) => {
        if (name2.value === void 0)
          throw new Error(`CodeGen: name "${name2}" has no value`);
        return name2.value.code;
      }, usedValues, getCode);
    }
    _reduceValues(values, valueCode, usedValues = {}, getCode) {
      let code2 = code_12.nil;
      for (const prefix in values) {
        const vs = values[prefix];
        if (!vs)
          continue;
        const nameSet = usedValues[prefix] = usedValues[prefix] || /* @__PURE__ */ new Map();
        vs.forEach((name2) => {
          if (nameSet.has(name2))
            return;
          nameSet.set(name2, UsedValueState.Started);
          let c = valueCode(name2);
          if (c) {
            const def2 = this.opts.es5 ? exports$12.varKinds.var : exports$12.varKinds.const;
            code2 = (0, code_12._)`${code2}${def2} ${name2} = ${c};${this.opts._n}`;
          } else if (c = getCode === null || getCode === void 0 ? void 0 : getCode(name2)) {
            code2 = (0, code_12._)`${code2}${c}${this.opts._n}`;
          } else {
            throw new ValueError(name2);
          }
          nameSet.set(name2, UsedValueState.Completed);
        });
      }
      return code2;
    }
  }
  exports$12.ValueScope = ValueScope;
})(scope);
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.or = exports$12.and = exports$12.not = exports$12.CodeGen = exports$12.operators = exports$12.varKinds = exports$12.ValueScopeName = exports$12.ValueScope = exports$12.Scope = exports$12.Name = exports$12.regexpCode = exports$12.stringify = exports$12.getProperty = exports$12.nil = exports$12.strConcat = exports$12.str = exports$12._ = void 0;
  const code_12 = code$1;
  const scope_1 = scope;
  var code_2 = code$1;
  Object.defineProperty(exports$12, "_", { enumerable: true, get: function() {
    return code_2._;
  } });
  Object.defineProperty(exports$12, "str", { enumerable: true, get: function() {
    return code_2.str;
  } });
  Object.defineProperty(exports$12, "strConcat", { enumerable: true, get: function() {
    return code_2.strConcat;
  } });
  Object.defineProperty(exports$12, "nil", { enumerable: true, get: function() {
    return code_2.nil;
  } });
  Object.defineProperty(exports$12, "getProperty", { enumerable: true, get: function() {
    return code_2.getProperty;
  } });
  Object.defineProperty(exports$12, "stringify", { enumerable: true, get: function() {
    return code_2.stringify;
  } });
  Object.defineProperty(exports$12, "regexpCode", { enumerable: true, get: function() {
    return code_2.regexpCode;
  } });
  Object.defineProperty(exports$12, "Name", { enumerable: true, get: function() {
    return code_2.Name;
  } });
  var scope_2 = scope;
  Object.defineProperty(exports$12, "Scope", { enumerable: true, get: function() {
    return scope_2.Scope;
  } });
  Object.defineProperty(exports$12, "ValueScope", { enumerable: true, get: function() {
    return scope_2.ValueScope;
  } });
  Object.defineProperty(exports$12, "ValueScopeName", { enumerable: true, get: function() {
    return scope_2.ValueScopeName;
  } });
  Object.defineProperty(exports$12, "varKinds", { enumerable: true, get: function() {
    return scope_2.varKinds;
  } });
  exports$12.operators = {
    GT: new code_12._Code(">"),
    GTE: new code_12._Code(">="),
    LT: new code_12._Code("<"),
    LTE: new code_12._Code("<="),
    EQ: new code_12._Code("==="),
    NEQ: new code_12._Code("!=="),
    NOT: new code_12._Code("!"),
    OR: new code_12._Code("||"),
    AND: new code_12._Code("&&"),
    ADD: new code_12._Code("+")
  };
  class Node {
    optimizeNodes() {
      return this;
    }
    optimizeNames(_names, _constants) {
      return this;
    }
  }
  class Def extends Node {
    constructor(varKind, name2, rhs) {
      super();
      this.varKind = varKind;
      this.name = name2;
      this.rhs = rhs;
    }
    render({ es5, _n }) {
      const varKind = es5 ? scope_1.varKinds.var : this.varKind;
      const rhs = this.rhs === void 0 ? "" : ` = ${this.rhs}`;
      return `${varKind} ${this.name}${rhs};` + _n;
    }
    optimizeNames(names2, constants2) {
      if (!names2[this.name.str])
        return;
      if (this.rhs)
        this.rhs = optimizeExpr(this.rhs, names2, constants2);
      return this;
    }
    get names() {
      return this.rhs instanceof code_12._CodeOrName ? this.rhs.names : {};
    }
  }
  class Assign extends Node {
    constructor(lhs, rhs, sideEffects) {
      super();
      this.lhs = lhs;
      this.rhs = rhs;
      this.sideEffects = sideEffects;
    }
    render({ _n }) {
      return `${this.lhs} = ${this.rhs};` + _n;
    }
    optimizeNames(names2, constants2) {
      if (this.lhs instanceof code_12.Name && !names2[this.lhs.str] && !this.sideEffects)
        return;
      this.rhs = optimizeExpr(this.rhs, names2, constants2);
      return this;
    }
    get names() {
      const names2 = this.lhs instanceof code_12.Name ? {} : { ...this.lhs.names };
      return addExprNames(names2, this.rhs);
    }
  }
  class AssignOp extends Assign {
    constructor(lhs, op, rhs, sideEffects) {
      super(lhs, rhs, sideEffects);
      this.op = op;
    }
    render({ _n }) {
      return `${this.lhs} ${this.op}= ${this.rhs};` + _n;
    }
  }
  class Label extends Node {
    constructor(label) {
      super();
      this.label = label;
      this.names = {};
    }
    render({ _n }) {
      return `${this.label}:` + _n;
    }
  }
  class Break extends Node {
    constructor(label) {
      super();
      this.label = label;
      this.names = {};
    }
    render({ _n }) {
      const label = this.label ? ` ${this.label}` : "";
      return `break${label};` + _n;
    }
  }
  class Throw extends Node {
    constructor(error2) {
      super();
      this.error = error2;
    }
    render({ _n }) {
      return `throw ${this.error};` + _n;
    }
    get names() {
      return this.error.names;
    }
  }
  class AnyCode extends Node {
    constructor(code2) {
      super();
      this.code = code2;
    }
    render({ _n }) {
      return `${this.code};` + _n;
    }
    optimizeNodes() {
      return `${this.code}` ? this : void 0;
    }
    optimizeNames(names2, constants2) {
      this.code = optimizeExpr(this.code, names2, constants2);
      return this;
    }
    get names() {
      return this.code instanceof code_12._CodeOrName ? this.code.names : {};
    }
  }
  class ParentNode extends Node {
    constructor(nodes = []) {
      super();
      this.nodes = nodes;
    }
    render(opts) {
      return this.nodes.reduce((code2, n) => code2 + n.render(opts), "");
    }
    optimizeNodes() {
      const { nodes } = this;
      let i2 = nodes.length;
      while (i2--) {
        const n = nodes[i2].optimizeNodes();
        if (Array.isArray(n))
          nodes.splice(i2, 1, ...n);
        else if (n)
          nodes[i2] = n;
        else
          nodes.splice(i2, 1);
      }
      return nodes.length > 0 ? this : void 0;
    }
    optimizeNames(names2, constants2) {
      const { nodes } = this;
      let i2 = nodes.length;
      while (i2--) {
        const n = nodes[i2];
        if (n.optimizeNames(names2, constants2))
          continue;
        subtractNames(names2, n.names);
        nodes.splice(i2, 1);
      }
      return nodes.length > 0 ? this : void 0;
    }
    get names() {
      return this.nodes.reduce((names2, n) => addNames(names2, n.names), {});
    }
  }
  class BlockNode extends ParentNode {
    render(opts) {
      return "{" + opts._n + super.render(opts) + "}" + opts._n;
    }
  }
  class Root extends ParentNode {
  }
  class Else extends BlockNode {
  }
  Else.kind = "else";
  class If2 extends BlockNode {
    constructor(condition, nodes) {
      super(nodes);
      this.condition = condition;
    }
    render(opts) {
      let code2 = `if(${this.condition})` + super.render(opts);
      if (this.else)
        code2 += "else " + this.else.render(opts);
      return code2;
    }
    optimizeNodes() {
      super.optimizeNodes();
      const cond = this.condition;
      if (cond === true)
        return this.nodes;
      let e = this.else;
      if (e) {
        const ns = e.optimizeNodes();
        e = this.else = Array.isArray(ns) ? new Else(ns) : ns;
      }
      if (e) {
        if (cond === false)
          return e instanceof If2 ? e : e.nodes;
        if (this.nodes.length)
          return this;
        return new If2(not2(cond), e instanceof If2 ? [e] : e.nodes);
      }
      if (cond === false || !this.nodes.length)
        return void 0;
      return this;
    }
    optimizeNames(names2, constants2) {
      var _a2;
      this.else = (_a2 = this.else) === null || _a2 === void 0 ? void 0 : _a2.optimizeNames(names2, constants2);
      if (!(super.optimizeNames(names2, constants2) || this.else))
        return;
      this.condition = optimizeExpr(this.condition, names2, constants2);
      return this;
    }
    get names() {
      const names2 = super.names;
      addExprNames(names2, this.condition);
      if (this.else)
        addNames(names2, this.else.names);
      return names2;
    }
  }
  If2.kind = "if";
  class For2 extends BlockNode {
  }
  For2.kind = "for";
  class ForLoop extends For2 {
    constructor(iteration) {
      super();
      this.iteration = iteration;
    }
    render(opts) {
      return `for(${this.iteration})` + super.render(opts);
    }
    optimizeNames(names2, constants2) {
      if (!super.optimizeNames(names2, constants2))
        return;
      this.iteration = optimizeExpr(this.iteration, names2, constants2);
      return this;
    }
    get names() {
      return addNames(super.names, this.iteration.names);
    }
  }
  class ForRange extends For2 {
    constructor(varKind, name2, from, to) {
      super();
      this.varKind = varKind;
      this.name = name2;
      this.from = from;
      this.to = to;
    }
    render(opts) {
      const varKind = opts.es5 ? scope_1.varKinds.var : this.varKind;
      const { name: name2, from, to } = this;
      return `for(${varKind} ${name2}=${from}; ${name2}<${to}; ${name2}++)` + super.render(opts);
    }
    get names() {
      const names2 = addExprNames(super.names, this.from);
      return addExprNames(names2, this.to);
    }
  }
  class ForIter extends For2 {
    constructor(loop, varKind, name2, iterable) {
      super();
      this.loop = loop;
      this.varKind = varKind;
      this.name = name2;
      this.iterable = iterable;
    }
    render(opts) {
      return `for(${this.varKind} ${this.name} ${this.loop} ${this.iterable})` + super.render(opts);
    }
    optimizeNames(names2, constants2) {
      if (!super.optimizeNames(names2, constants2))
        return;
      this.iterable = optimizeExpr(this.iterable, names2, constants2);
      return this;
    }
    get names() {
      return addNames(super.names, this.iterable.names);
    }
  }
  class Func extends BlockNode {
    constructor(name2, args, async) {
      super();
      this.name = name2;
      this.args = args;
      this.async = async;
    }
    render(opts) {
      const _async = this.async ? "async " : "";
      return `${_async}function ${this.name}(${this.args})` + super.render(opts);
    }
  }
  Func.kind = "func";
  class Return extends ParentNode {
    render(opts) {
      return "return " + super.render(opts);
    }
  }
  Return.kind = "return";
  class Try extends BlockNode {
    render(opts) {
      let code2 = "try" + super.render(opts);
      if (this.catch)
        code2 += this.catch.render(opts);
      if (this.finally)
        code2 += this.finally.render(opts);
      return code2;
    }
    optimizeNodes() {
      var _a2, _b;
      super.optimizeNodes();
      (_a2 = this.catch) === null || _a2 === void 0 ? void 0 : _a2.optimizeNodes();
      (_b = this.finally) === null || _b === void 0 ? void 0 : _b.optimizeNodes();
      return this;
    }
    optimizeNames(names2, constants2) {
      var _a2, _b;
      super.optimizeNames(names2, constants2);
      (_a2 = this.catch) === null || _a2 === void 0 ? void 0 : _a2.optimizeNames(names2, constants2);
      (_b = this.finally) === null || _b === void 0 ? void 0 : _b.optimizeNames(names2, constants2);
      return this;
    }
    get names() {
      const names2 = super.names;
      if (this.catch)
        addNames(names2, this.catch.names);
      if (this.finally)
        addNames(names2, this.finally.names);
      return names2;
    }
  }
  class Catch extends BlockNode {
    constructor(error2) {
      super();
      this.error = error2;
    }
    render(opts) {
      return `catch(${this.error})` + super.render(opts);
    }
  }
  Catch.kind = "catch";
  class Finally extends BlockNode {
    render(opts) {
      return "finally" + super.render(opts);
    }
  }
  Finally.kind = "finally";
  class CodeGen {
    constructor(extScope, opts = {}) {
      this._values = {};
      this._blockStarts = [];
      this._constants = {};
      this.opts = { ...opts, _n: opts.lines ? "\n" : "" };
      this._extScope = extScope;
      this._scope = new scope_1.Scope({ parent: extScope });
      this._nodes = [new Root()];
    }
    toString() {
      return this._root.render(this.opts);
    }
    // returns unique name in the internal scope
    name(prefix) {
      return this._scope.name(prefix);
    }
    // reserves unique name in the external scope
    scopeName(prefix) {
      return this._extScope.name(prefix);
    }
    // reserves unique name in the external scope and assigns value to it
    scopeValue(prefixOrName, value) {
      const name2 = this._extScope.value(prefixOrName, value);
      const vs = this._values[name2.prefix] || (this._values[name2.prefix] = /* @__PURE__ */ new Set());
      vs.add(name2);
      return name2;
    }
    getScopeValue(prefix, keyOrRef) {
      return this._extScope.getValue(prefix, keyOrRef);
    }
    // return code that assigns values in the external scope to the names that are used internally
    // (same names that were returned by gen.scopeName or gen.scopeValue)
    scopeRefs(scopeName) {
      return this._extScope.scopeRefs(scopeName, this._values);
    }
    scopeCode() {
      return this._extScope.scopeCode(this._values);
    }
    _def(varKind, nameOrPrefix, rhs, constant) {
      const name2 = this._scope.toName(nameOrPrefix);
      if (rhs !== void 0 && constant)
        this._constants[name2.str] = rhs;
      this._leafNode(new Def(varKind, name2, rhs));
      return name2;
    }
    // `const` declaration (`var` in es5 mode)
    const(nameOrPrefix, rhs, _constant) {
      return this._def(scope_1.varKinds.const, nameOrPrefix, rhs, _constant);
    }
    // `let` declaration with optional assignment (`var` in es5 mode)
    let(nameOrPrefix, rhs, _constant) {
      return this._def(scope_1.varKinds.let, nameOrPrefix, rhs, _constant);
    }
    // `var` declaration with optional assignment
    var(nameOrPrefix, rhs, _constant) {
      return this._def(scope_1.varKinds.var, nameOrPrefix, rhs, _constant);
    }
    // assignment code
    assign(lhs, rhs, sideEffects) {
      return this._leafNode(new Assign(lhs, rhs, sideEffects));
    }
    // `+=` code
    add(lhs, rhs) {
      return this._leafNode(new AssignOp(lhs, exports$12.operators.ADD, rhs));
    }
    // appends passed SafeExpr to code or executes Block
    code(c) {
      if (typeof c == "function")
        c();
      else if (c !== code_12.nil)
        this._leafNode(new AnyCode(c));
      return this;
    }
    // returns code for object literal for the passed argument list of key-value pairs
    object(...keyValues) {
      const code2 = ["{"];
      for (const [key, value] of keyValues) {
        if (code2.length > 1)
          code2.push(",");
        code2.push(key);
        if (key !== value || this.opts.es5) {
          code2.push(":");
          (0, code_12.addCodeArg)(code2, value);
        }
      }
      code2.push("}");
      return new code_12._Code(code2);
    }
    // `if` clause (or statement if `thenBody` and, optionally, `elseBody` are passed)
    if(condition, thenBody, elseBody) {
      this._blockNode(new If2(condition));
      if (thenBody && elseBody) {
        this.code(thenBody).else().code(elseBody).endIf();
      } else if (thenBody) {
        this.code(thenBody).endIf();
      } else if (elseBody) {
        throw new Error('CodeGen: "else" body without "then" body');
      }
      return this;
    }
    // `else if` clause - invalid without `if` or after `else` clauses
    elseIf(condition) {
      return this._elseNode(new If2(condition));
    }
    // `else` clause - only valid after `if` or `else if` clauses
    else() {
      return this._elseNode(new Else());
    }
    // end `if` statement (needed if gen.if was used only with condition)
    endIf() {
      return this._endBlockNode(If2, Else);
    }
    _for(node, forBody) {
      this._blockNode(node);
      if (forBody)
        this.code(forBody).endFor();
      return this;
    }
    // a generic `for` clause (or statement if `forBody` is passed)
    for(iteration, forBody) {
      return this._for(new ForLoop(iteration), forBody);
    }
    // `for` statement for a range of values
    forRange(nameOrPrefix, from, to, forBody, varKind = this.opts.es5 ? scope_1.varKinds.var : scope_1.varKinds.let) {
      const name2 = this._scope.toName(nameOrPrefix);
      return this._for(new ForRange(varKind, name2, from, to), () => forBody(name2));
    }
    // `for-of` statement (in es5 mode replace with a normal for loop)
    forOf(nameOrPrefix, iterable, forBody, varKind = scope_1.varKinds.const) {
      const name2 = this._scope.toName(nameOrPrefix);
      if (this.opts.es5) {
        const arr = iterable instanceof code_12.Name ? iterable : this.var("_arr", iterable);
        return this.forRange("_i", 0, (0, code_12._)`${arr}.length`, (i2) => {
          this.var(name2, (0, code_12._)`${arr}[${i2}]`);
          forBody(name2);
        });
      }
      return this._for(new ForIter("of", varKind, name2, iterable), () => forBody(name2));
    }
    // `for-in` statement.
    // With option `ownProperties` replaced with a `for-of` loop for object keys
    forIn(nameOrPrefix, obj, forBody, varKind = this.opts.es5 ? scope_1.varKinds.var : scope_1.varKinds.const) {
      if (this.opts.ownProperties) {
        return this.forOf(nameOrPrefix, (0, code_12._)`Object.keys(${obj})`, forBody);
      }
      const name2 = this._scope.toName(nameOrPrefix);
      return this._for(new ForIter("in", varKind, name2, obj), () => forBody(name2));
    }
    // end `for` loop
    endFor() {
      return this._endBlockNode(For2);
    }
    // `label` statement
    label(label) {
      return this._leafNode(new Label(label));
    }
    // `break` statement
    break(label) {
      return this._leafNode(new Break(label));
    }
    // `return` statement
    return(value) {
      const node = new Return();
      this._blockNode(node);
      this.code(value);
      if (node.nodes.length !== 1)
        throw new Error('CodeGen: "return" should have one node');
      return this._endBlockNode(Return);
    }
    // `try` statement
    try(tryBody, catchCode, finallyCode) {
      if (!catchCode && !finallyCode)
        throw new Error('CodeGen: "try" without "catch" and "finally"');
      const node = new Try();
      this._blockNode(node);
      this.code(tryBody);
      if (catchCode) {
        const error2 = this.name("e");
        this._currNode = node.catch = new Catch(error2);
        catchCode(error2);
      }
      if (finallyCode) {
        this._currNode = node.finally = new Finally();
        this.code(finallyCode);
      }
      return this._endBlockNode(Catch, Finally);
    }
    // `throw` statement
    throw(error2) {
      return this._leafNode(new Throw(error2));
    }
    // start self-balancing block
    block(body, nodeCount) {
      this._blockStarts.push(this._nodes.length);
      if (body)
        this.code(body).endBlock(nodeCount);
      return this;
    }
    // end the current self-balancing block
    endBlock(nodeCount) {
      const len = this._blockStarts.pop();
      if (len === void 0)
        throw new Error("CodeGen: not in self-balancing block");
      const toClose = this._nodes.length - len;
      if (toClose < 0 || nodeCount !== void 0 && toClose !== nodeCount) {
        throw new Error(`CodeGen: wrong number of nodes: ${toClose} vs ${nodeCount} expected`);
      }
      this._nodes.length = len;
      return this;
    }
    // `function` heading (or definition if funcBody is passed)
    func(name2, args = code_12.nil, async, funcBody) {
      this._blockNode(new Func(name2, args, async));
      if (funcBody)
        this.code(funcBody).endFunc();
      return this;
    }
    // end function definition
    endFunc() {
      return this._endBlockNode(Func);
    }
    optimize(n = 1) {
      while (n-- > 0) {
        this._root.optimizeNodes();
        this._root.optimizeNames(this._root.names, this._constants);
      }
    }
    _leafNode(node) {
      this._currNode.nodes.push(node);
      return this;
    }
    _blockNode(node) {
      this._currNode.nodes.push(node);
      this._nodes.push(node);
    }
    _endBlockNode(N1, N2) {
      const n = this._currNode;
      if (n instanceof N1 || N2 && n instanceof N2) {
        this._nodes.pop();
        return this;
      }
      throw new Error(`CodeGen: not in block "${N2 ? `${N1.kind}/${N2.kind}` : N1.kind}"`);
    }
    _elseNode(node) {
      const n = this._currNode;
      if (!(n instanceof If2)) {
        throw new Error('CodeGen: "else" without "if"');
      }
      this._currNode = n.else = node;
      return this;
    }
    get _root() {
      return this._nodes[0];
    }
    get _currNode() {
      const ns = this._nodes;
      return ns[ns.length - 1];
    }
    set _currNode(node) {
      const ns = this._nodes;
      ns[ns.length - 1] = node;
    }
  }
  exports$12.CodeGen = CodeGen;
  function addNames(names2, from) {
    for (const n in from)
      names2[n] = (names2[n] || 0) + (from[n] || 0);
    return names2;
  }
  function addExprNames(names2, from) {
    return from instanceof code_12._CodeOrName ? addNames(names2, from.names) : names2;
  }
  function optimizeExpr(expr, names2, constants2) {
    if (expr instanceof code_12.Name)
      return replaceName(expr);
    if (!canOptimize(expr))
      return expr;
    return new code_12._Code(expr._items.reduce((items2, c) => {
      if (c instanceof code_12.Name)
        c = replaceName(c);
      if (c instanceof code_12._Code)
        items2.push(...c._items);
      else
        items2.push(c);
      return items2;
    }, []));
    function replaceName(n) {
      const c = constants2[n.str];
      if (c === void 0 || names2[n.str] !== 1)
        return n;
      delete names2[n.str];
      return c;
    }
    function canOptimize(e) {
      return e instanceof code_12._Code && e._items.some((c) => c instanceof code_12.Name && names2[c.str] === 1 && constants2[c.str] !== void 0);
    }
  }
  function subtractNames(names2, from) {
    for (const n in from)
      names2[n] = (names2[n] || 0) - (from[n] || 0);
  }
  function not2(x) {
    return typeof x == "boolean" || typeof x == "number" || x === null ? !x : (0, code_12._)`!${par(x)}`;
  }
  exports$12.not = not2;
  const andCode = mappend(exports$12.operators.AND);
  function and(...args) {
    return args.reduce(andCode);
  }
  exports$12.and = and;
  const orCode = mappend(exports$12.operators.OR);
  function or(...args) {
    return args.reduce(orCode);
  }
  exports$12.or = or;
  function mappend(op) {
    return (x, y) => x === code_12.nil ? y : y === code_12.nil ? x : (0, code_12._)`${par(x)} ${op} ${par(y)}`;
  }
  function par(x) {
    return x instanceof code_12.Name ? x : (0, code_12._)`(${x})`;
  }
})(codegen);
var util$1 = {};
Object.defineProperty(util$1, "__esModule", { value: true });
util$1.checkStrictMode = util$1.getErrorPath = util$1.Type = util$1.useFunc = util$1.setEvaluated = util$1.evaluatedPropsToName = util$1.mergeEvaluated = util$1.eachItem = util$1.unescapeJsonPointer = util$1.escapeJsonPointer = util$1.escapeFragment = util$1.unescapeFragment = util$1.schemaRefOrVal = util$1.schemaHasRulesButRef = util$1.schemaHasRules = util$1.checkUnknownRules = util$1.alwaysValidSchema = util$1.toHash = void 0;
const codegen_1$v = codegen;
const code_1$a = code$1;
function toHash(arr) {
  const hash = {};
  for (const item of arr)
    hash[item] = true;
  return hash;
}
util$1.toHash = toHash;
function alwaysValidSchema(it, schema) {
  if (typeof schema == "boolean")
    return schema;
  if (Object.keys(schema).length === 0)
    return true;
  checkUnknownRules(it, schema);
  return !schemaHasRules(schema, it.self.RULES.all);
}
util$1.alwaysValidSchema = alwaysValidSchema;
function checkUnknownRules(it, schema = it.schema) {
  const { opts, self: self2 } = it;
  if (!opts.strictSchema)
    return;
  if (typeof schema === "boolean")
    return;
  const rules2 = self2.RULES.keywords;
  for (const key in schema) {
    if (!rules2[key])
      checkStrictMode(it, `unknown keyword: "${key}"`);
  }
}
util$1.checkUnknownRules = checkUnknownRules;
function schemaHasRules(schema, rules2) {
  if (typeof schema == "boolean")
    return !schema;
  for (const key in schema)
    if (rules2[key])
      return true;
  return false;
}
util$1.schemaHasRules = schemaHasRules;
function schemaHasRulesButRef(schema, RULES) {
  if (typeof schema == "boolean")
    return !schema;
  for (const key in schema)
    if (key !== "$ref" && RULES.all[key])
      return true;
  return false;
}
util$1.schemaHasRulesButRef = schemaHasRulesButRef;
function schemaRefOrVal({ topSchemaRef, schemaPath }, schema, keyword2, $data) {
  if (!$data) {
    if (typeof schema == "number" || typeof schema == "boolean")
      return schema;
    if (typeof schema == "string")
      return (0, codegen_1$v._)`${schema}`;
  }
  return (0, codegen_1$v._)`${topSchemaRef}${schemaPath}${(0, codegen_1$v.getProperty)(keyword2)}`;
}
util$1.schemaRefOrVal = schemaRefOrVal;
function unescapeFragment(str) {
  return unescapeJsonPointer(decodeURIComponent(str));
}
util$1.unescapeFragment = unescapeFragment;
function escapeFragment(str) {
  return encodeURIComponent(escapeJsonPointer(str));
}
util$1.escapeFragment = escapeFragment;
function escapeJsonPointer(str) {
  if (typeof str == "number")
    return `${str}`;
  return str.replace(/~/g, "~0").replace(/\//g, "~1");
}
util$1.escapeJsonPointer = escapeJsonPointer;
function unescapeJsonPointer(str) {
  return str.replace(/~1/g, "/").replace(/~0/g, "~");
}
util$1.unescapeJsonPointer = unescapeJsonPointer;
function eachItem(xs, f) {
  if (Array.isArray(xs)) {
    for (const x of xs)
      f(x);
  } else {
    f(xs);
  }
}
util$1.eachItem = eachItem;
function makeMergeEvaluated({ mergeNames, mergeToName, mergeValues, resultToName }) {
  return (gen, from, to, toName) => {
    const res = to === void 0 ? from : to instanceof codegen_1$v.Name ? (from instanceof codegen_1$v.Name ? mergeNames(gen, from, to) : mergeToName(gen, from, to), to) : from instanceof codegen_1$v.Name ? (mergeToName(gen, to, from), from) : mergeValues(from, to);
    return toName === codegen_1$v.Name && !(res instanceof codegen_1$v.Name) ? resultToName(gen, res) : res;
  };
}
util$1.mergeEvaluated = {
  props: makeMergeEvaluated({
    mergeNames: (gen, from, to) => gen.if((0, codegen_1$v._)`${to} !== true && ${from} !== undefined`, () => {
      gen.if((0, codegen_1$v._)`${from} === true`, () => gen.assign(to, true), () => gen.assign(to, (0, codegen_1$v._)`${to} || {}`).code((0, codegen_1$v._)`Object.assign(${to}, ${from})`));
    }),
    mergeToName: (gen, from, to) => gen.if((0, codegen_1$v._)`${to} !== true`, () => {
      if (from === true) {
        gen.assign(to, true);
      } else {
        gen.assign(to, (0, codegen_1$v._)`${to} || {}`);
        setEvaluated(gen, to, from);
      }
    }),
    mergeValues: (from, to) => from === true ? true : { ...from, ...to },
    resultToName: evaluatedPropsToName
  }),
  items: makeMergeEvaluated({
    mergeNames: (gen, from, to) => gen.if((0, codegen_1$v._)`${to} !== true && ${from} !== undefined`, () => gen.assign(to, (0, codegen_1$v._)`${from} === true ? true : ${to} > ${from} ? ${to} : ${from}`)),
    mergeToName: (gen, from, to) => gen.if((0, codegen_1$v._)`${to} !== true`, () => gen.assign(to, from === true ? true : (0, codegen_1$v._)`${to} > ${from} ? ${to} : ${from}`)),
    mergeValues: (from, to) => from === true ? true : Math.max(from, to),
    resultToName: (gen, items2) => gen.var("items", items2)
  })
};
function evaluatedPropsToName(gen, ps) {
  if (ps === true)
    return gen.var("props", true);
  const props = gen.var("props", (0, codegen_1$v._)`{}`);
  if (ps !== void 0)
    setEvaluated(gen, props, ps);
  return props;
}
util$1.evaluatedPropsToName = evaluatedPropsToName;
function setEvaluated(gen, props, ps) {
  Object.keys(ps).forEach((p) => gen.assign((0, codegen_1$v._)`${props}${(0, codegen_1$v.getProperty)(p)}`, true));
}
util$1.setEvaluated = setEvaluated;
const snippets = {};
function useFunc(gen, f) {
  return gen.scopeValue("func", {
    ref: f,
    code: snippets[f.code] || (snippets[f.code] = new code_1$a._Code(f.code))
  });
}
util$1.useFunc = useFunc;
var Type;
(function(Type2) {
  Type2[Type2["Num"] = 0] = "Num";
  Type2[Type2["Str"] = 1] = "Str";
})(Type || (util$1.Type = Type = {}));
function getErrorPath(dataProp, dataPropType, jsPropertySyntax) {
  if (dataProp instanceof codegen_1$v.Name) {
    const isNumber = dataPropType === Type.Num;
    return jsPropertySyntax ? isNumber ? (0, codegen_1$v._)`"[" + ${dataProp} + "]"` : (0, codegen_1$v._)`"['" + ${dataProp} + "']"` : isNumber ? (0, codegen_1$v._)`"/" + ${dataProp}` : (0, codegen_1$v._)`"/" + ${dataProp}.replace(/~/g, "~0").replace(/\\//g, "~1")`;
  }
  return jsPropertySyntax ? (0, codegen_1$v.getProperty)(dataProp).toString() : "/" + escapeJsonPointer(dataProp);
}
util$1.getErrorPath = getErrorPath;
function checkStrictMode(it, msg, mode = it.opts.strictSchema) {
  if (!mode)
    return;
  msg = `strict mode: ${msg}`;
  if (mode === true)
    throw new Error(msg);
  it.self.logger.warn(msg);
}
util$1.checkStrictMode = checkStrictMode;
var names$1 = {};
Object.defineProperty(names$1, "__esModule", { value: true });
const codegen_1$u = codegen;
const names = {
  // validation function arguments
  data: new codegen_1$u.Name("data"),
  // data passed to validation function
  // args passed from referencing schema
  valCxt: new codegen_1$u.Name("valCxt"),
  // validation/data context - should not be used directly, it is destructured to the names below
  instancePath: new codegen_1$u.Name("instancePath"),
  parentData: new codegen_1$u.Name("parentData"),
  parentDataProperty: new codegen_1$u.Name("parentDataProperty"),
  rootData: new codegen_1$u.Name("rootData"),
  // root data - same as the data passed to the first/top validation function
  dynamicAnchors: new codegen_1$u.Name("dynamicAnchors"),
  // used to support recursiveRef and dynamicRef
  // function scoped variables
  vErrors: new codegen_1$u.Name("vErrors"),
  // null or array of validation errors
  errors: new codegen_1$u.Name("errors"),
  // counter of validation errors
  this: new codegen_1$u.Name("this"),
  // "globals"
  self: new codegen_1$u.Name("self"),
  scope: new codegen_1$u.Name("scope"),
  // JTD serialize/parse name for JSON string and position
  json: new codegen_1$u.Name("json"),
  jsonPos: new codegen_1$u.Name("jsonPos"),
  jsonLen: new codegen_1$u.Name("jsonLen"),
  jsonPart: new codegen_1$u.Name("jsonPart")
};
names$1.default = names;
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.extendErrors = exports$12.resetErrorsCount = exports$12.reportExtraError = exports$12.reportError = exports$12.keyword$DataError = exports$12.keywordError = void 0;
  const codegen_12 = codegen;
  const util_12 = util$1;
  const names_12 = names$1;
  exports$12.keywordError = {
    message: ({ keyword: keyword2 }) => (0, codegen_12.str)`must pass "${keyword2}" keyword validation`
  };
  exports$12.keyword$DataError = {
    message: ({ keyword: keyword2, schemaType }) => schemaType ? (0, codegen_12.str)`"${keyword2}" keyword must be ${schemaType} ($data)` : (0, codegen_12.str)`"${keyword2}" keyword is invalid ($data)`
  };
  function reportError(cxt, error2 = exports$12.keywordError, errorPaths, overrideAllErrors) {
    const { it } = cxt;
    const { gen, compositeRule, allErrors } = it;
    const errObj = errorObjectCode(cxt, error2, errorPaths);
    if (overrideAllErrors !== null && overrideAllErrors !== void 0 ? overrideAllErrors : compositeRule || allErrors) {
      addError(gen, errObj);
    } else {
      returnErrors(it, (0, codegen_12._)`[${errObj}]`);
    }
  }
  exports$12.reportError = reportError;
  function reportExtraError(cxt, error2 = exports$12.keywordError, errorPaths) {
    const { it } = cxt;
    const { gen, compositeRule, allErrors } = it;
    const errObj = errorObjectCode(cxt, error2, errorPaths);
    addError(gen, errObj);
    if (!(compositeRule || allErrors)) {
      returnErrors(it, names_12.default.vErrors);
    }
  }
  exports$12.reportExtraError = reportExtraError;
  function resetErrorsCount(gen, errsCount) {
    gen.assign(names_12.default.errors, errsCount);
    gen.if((0, codegen_12._)`${names_12.default.vErrors} !== null`, () => gen.if(errsCount, () => gen.assign((0, codegen_12._)`${names_12.default.vErrors}.length`, errsCount), () => gen.assign(names_12.default.vErrors, null)));
  }
  exports$12.resetErrorsCount = resetErrorsCount;
  function extendErrors({ gen, keyword: keyword2, schemaValue, data, errsCount, it }) {
    if (errsCount === void 0)
      throw new Error("ajv implementation error");
    const err = gen.name("err");
    gen.forRange("i", errsCount, names_12.default.errors, (i2) => {
      gen.const(err, (0, codegen_12._)`${names_12.default.vErrors}[${i2}]`);
      gen.if((0, codegen_12._)`${err}.instancePath === undefined`, () => gen.assign((0, codegen_12._)`${err}.instancePath`, (0, codegen_12.strConcat)(names_12.default.instancePath, it.errorPath)));
      gen.assign((0, codegen_12._)`${err}.schemaPath`, (0, codegen_12.str)`${it.errSchemaPath}/${keyword2}`);
      if (it.opts.verbose) {
        gen.assign((0, codegen_12._)`${err}.schema`, schemaValue);
        gen.assign((0, codegen_12._)`${err}.data`, data);
      }
    });
  }
  exports$12.extendErrors = extendErrors;
  function addError(gen, errObj) {
    const err = gen.const("err", errObj);
    gen.if((0, codegen_12._)`${names_12.default.vErrors} === null`, () => gen.assign(names_12.default.vErrors, (0, codegen_12._)`[${err}]`), (0, codegen_12._)`${names_12.default.vErrors}.push(${err})`);
    gen.code((0, codegen_12._)`${names_12.default.errors}++`);
  }
  function returnErrors(it, errs) {
    const { gen, validateName, schemaEnv } = it;
    if (schemaEnv.$async) {
      gen.throw((0, codegen_12._)`new ${it.ValidationError}(${errs})`);
    } else {
      gen.assign((0, codegen_12._)`${validateName}.errors`, errs);
      gen.return(false);
    }
  }
  const E = {
    keyword: new codegen_12.Name("keyword"),
    schemaPath: new codegen_12.Name("schemaPath"),
    // also used in JTD errors
    params: new codegen_12.Name("params"),
    propertyName: new codegen_12.Name("propertyName"),
    message: new codegen_12.Name("message"),
    schema: new codegen_12.Name("schema"),
    parentSchema: new codegen_12.Name("parentSchema")
  };
  function errorObjectCode(cxt, error2, errorPaths) {
    const { createErrors } = cxt.it;
    if (createErrors === false)
      return (0, codegen_12._)`{}`;
    return errorObject(cxt, error2, errorPaths);
  }
  function errorObject(cxt, error2, errorPaths = {}) {
    const { gen, it } = cxt;
    const keyValues = [
      errorInstancePath(it, errorPaths),
      errorSchemaPath(cxt, errorPaths)
    ];
    extraErrorProps(cxt, error2, keyValues);
    return gen.object(...keyValues);
  }
  function errorInstancePath({ errorPath }, { instancePath }) {
    const instPath = instancePath ? (0, codegen_12.str)`${errorPath}${(0, util_12.getErrorPath)(instancePath, util_12.Type.Str)}` : errorPath;
    return [names_12.default.instancePath, (0, codegen_12.strConcat)(names_12.default.instancePath, instPath)];
  }
  function errorSchemaPath({ keyword: keyword2, it: { errSchemaPath } }, { schemaPath, parentSchema }) {
    let schPath = parentSchema ? errSchemaPath : (0, codegen_12.str)`${errSchemaPath}/${keyword2}`;
    if (schemaPath) {
      schPath = (0, codegen_12.str)`${schPath}${(0, util_12.getErrorPath)(schemaPath, util_12.Type.Str)}`;
    }
    return [E.schemaPath, schPath];
  }
  function extraErrorProps(cxt, { params, message }, keyValues) {
    const { keyword: keyword2, data, schemaValue, it } = cxt;
    const { opts, propertyName, topSchemaRef, schemaPath } = it;
    keyValues.push([E.keyword, keyword2], [E.params, typeof params == "function" ? params(cxt) : params || (0, codegen_12._)`{}`]);
    if (opts.messages) {
      keyValues.push([E.message, typeof message == "function" ? message(cxt) : message]);
    }
    if (opts.verbose) {
      keyValues.push([E.schema, schemaValue], [E.parentSchema, (0, codegen_12._)`${topSchemaRef}${schemaPath}`], [names_12.default.data, data]);
    }
    if (propertyName)
      keyValues.push([E.propertyName, propertyName]);
  }
})(errors);
Object.defineProperty(boolSchema, "__esModule", { value: true });
boolSchema.boolOrEmptySchema = boolSchema.topBoolOrEmptySchema = void 0;
const errors_1$3 = errors;
const codegen_1$t = codegen;
const names_1$6 = names$1;
const boolError = {
  message: "boolean schema is false"
};
function topBoolOrEmptySchema(it) {
  const { gen, schema, validateName } = it;
  if (schema === false) {
    falseSchemaError(it, false);
  } else if (typeof schema == "object" && schema.$async === true) {
    gen.return(names_1$6.default.data);
  } else {
    gen.assign((0, codegen_1$t._)`${validateName}.errors`, null);
    gen.return(true);
  }
}
boolSchema.topBoolOrEmptySchema = topBoolOrEmptySchema;
function boolOrEmptySchema(it, valid2) {
  const { gen, schema } = it;
  if (schema === false) {
    gen.var(valid2, false);
    falseSchemaError(it);
  } else {
    gen.var(valid2, true);
  }
}
boolSchema.boolOrEmptySchema = boolOrEmptySchema;
function falseSchemaError(it, overrideAllErrors) {
  const { gen, data } = it;
  const cxt = {
    gen,
    keyword: "false schema",
    data,
    schema: false,
    schemaCode: false,
    schemaValue: false,
    params: {},
    it
  };
  (0, errors_1$3.reportError)(cxt, boolError, void 0, overrideAllErrors);
}
var dataType = {};
var rules = {};
Object.defineProperty(rules, "__esModule", { value: true });
rules.getRules = rules.isJSONType = void 0;
const _jsonTypes = ["string", "number", "integer", "boolean", "null", "object", "array"];
const jsonTypes = new Set(_jsonTypes);
function isJSONType(x) {
  return typeof x == "string" && jsonTypes.has(x);
}
rules.isJSONType = isJSONType;
function getRules() {
  const groups = {
    number: { type: "number", rules: [] },
    string: { type: "string", rules: [] },
    array: { type: "array", rules: [] },
    object: { type: "object", rules: [] }
  };
  return {
    types: { ...groups, integer: true, boolean: true, null: true },
    rules: [{ rules: [] }, groups.number, groups.string, groups.array, groups.object],
    post: { rules: [] },
    all: {},
    keywords: {}
  };
}
rules.getRules = getRules;
var applicability = {};
Object.defineProperty(applicability, "__esModule", { value: true });
applicability.shouldUseRule = applicability.shouldUseGroup = applicability.schemaHasRulesForType = void 0;
function schemaHasRulesForType({ schema, self: self2 }, type2) {
  const group = self2.RULES.types[type2];
  return group && group !== true && shouldUseGroup(schema, group);
}
applicability.schemaHasRulesForType = schemaHasRulesForType;
function shouldUseGroup(schema, group) {
  return group.rules.some((rule) => shouldUseRule(schema, rule));
}
applicability.shouldUseGroup = shouldUseGroup;
function shouldUseRule(schema, rule) {
  var _a2;
  return schema[rule.keyword] !== void 0 || ((_a2 = rule.definition.implements) === null || _a2 === void 0 ? void 0 : _a2.some((kwd) => schema[kwd] !== void 0));
}
applicability.shouldUseRule = shouldUseRule;
Object.defineProperty(dataType, "__esModule", { value: true });
dataType.reportTypeError = dataType.checkDataTypes = dataType.checkDataType = dataType.coerceAndCheckDataType = dataType.getJSONTypes = dataType.getSchemaTypes = dataType.DataType = void 0;
const rules_1 = rules;
const applicability_1$1 = applicability;
const errors_1$2 = errors;
const codegen_1$s = codegen;
const util_1$r = util$1;
var DataType;
(function(DataType2) {
  DataType2[DataType2["Correct"] = 0] = "Correct";
  DataType2[DataType2["Wrong"] = 1] = "Wrong";
})(DataType || (dataType.DataType = DataType = {}));
function getSchemaTypes(schema) {
  const types2 = getJSONTypes(schema.type);
  const hasNull = types2.includes("null");
  if (hasNull) {
    if (schema.nullable === false)
      throw new Error("type: null contradicts nullable: false");
  } else {
    if (!types2.length && schema.nullable !== void 0) {
      throw new Error('"nullable" cannot be used without "type"');
    }
    if (schema.nullable === true)
      types2.push("null");
  }
  return types2;
}
dataType.getSchemaTypes = getSchemaTypes;
function getJSONTypes(ts) {
  const types2 = Array.isArray(ts) ? ts : ts ? [ts] : [];
  if (types2.every(rules_1.isJSONType))
    return types2;
  throw new Error("type must be JSONType or JSONType[]: " + types2.join(","));
}
dataType.getJSONTypes = getJSONTypes;
function coerceAndCheckDataType(it, types2) {
  const { gen, data, opts } = it;
  const coerceTo = coerceToTypes(types2, opts.coerceTypes);
  const checkTypes = types2.length > 0 && !(coerceTo.length === 0 && types2.length === 1 && (0, applicability_1$1.schemaHasRulesForType)(it, types2[0]));
  if (checkTypes) {
    const wrongType = checkDataTypes(types2, data, opts.strictNumbers, DataType.Wrong);
    gen.if(wrongType, () => {
      if (coerceTo.length)
        coerceData(it, types2, coerceTo);
      else
        reportTypeError(it);
    });
  }
  return checkTypes;
}
dataType.coerceAndCheckDataType = coerceAndCheckDataType;
const COERCIBLE = /* @__PURE__ */ new Set(["string", "number", "integer", "boolean", "null"]);
function coerceToTypes(types2, coerceTypes) {
  return coerceTypes ? types2.filter((t2) => COERCIBLE.has(t2) || coerceTypes === "array" && t2 === "array") : [];
}
function coerceData(it, types2, coerceTo) {
  const { gen, data, opts } = it;
  const dataType2 = gen.let("dataType", (0, codegen_1$s._)`typeof ${data}`);
  const coerced = gen.let("coerced", (0, codegen_1$s._)`undefined`);
  if (opts.coerceTypes === "array") {
    gen.if((0, codegen_1$s._)`${dataType2} == 'object' && Array.isArray(${data}) && ${data}.length == 1`, () => gen.assign(data, (0, codegen_1$s._)`${data}[0]`).assign(dataType2, (0, codegen_1$s._)`typeof ${data}`).if(checkDataTypes(types2, data, opts.strictNumbers), () => gen.assign(coerced, data)));
  }
  gen.if((0, codegen_1$s._)`${coerced} !== undefined`);
  for (const t2 of coerceTo) {
    if (COERCIBLE.has(t2) || t2 === "array" && opts.coerceTypes === "array") {
      coerceSpecificType(t2);
    }
  }
  gen.else();
  reportTypeError(it);
  gen.endIf();
  gen.if((0, codegen_1$s._)`${coerced} !== undefined`, () => {
    gen.assign(data, coerced);
    assignParentData(it, coerced);
  });
  function coerceSpecificType(t2) {
    switch (t2) {
      case "string":
        gen.elseIf((0, codegen_1$s._)`${dataType2} == "number" || ${dataType2} == "boolean"`).assign(coerced, (0, codegen_1$s._)`"" + ${data}`).elseIf((0, codegen_1$s._)`${data} === null`).assign(coerced, (0, codegen_1$s._)`""`);
        return;
      case "number":
        gen.elseIf((0, codegen_1$s._)`${dataType2} == "boolean" || ${data} === null
              || (${dataType2} == "string" && ${data} && ${data} == +${data})`).assign(coerced, (0, codegen_1$s._)`+${data}`);
        return;
      case "integer":
        gen.elseIf((0, codegen_1$s._)`${dataType2} === "boolean" || ${data} === null
              || (${dataType2} === "string" && ${data} && ${data} == +${data} && !(${data} % 1))`).assign(coerced, (0, codegen_1$s._)`+${data}`);
        return;
      case "boolean":
        gen.elseIf((0, codegen_1$s._)`${data} === "false" || ${data} === 0 || ${data} === null`).assign(coerced, false).elseIf((0, codegen_1$s._)`${data} === "true" || ${data} === 1`).assign(coerced, true);
        return;
      case "null":
        gen.elseIf((0, codegen_1$s._)`${data} === "" || ${data} === 0 || ${data} === false`);
        gen.assign(coerced, null);
        return;
      case "array":
        gen.elseIf((0, codegen_1$s._)`${dataType2} === "string" || ${dataType2} === "number"
              || ${dataType2} === "boolean" || ${data} === null`).assign(coerced, (0, codegen_1$s._)`[${data}]`);
    }
  }
}
function assignParentData({ gen, parentData, parentDataProperty }, expr) {
  gen.if((0, codegen_1$s._)`${parentData} !== undefined`, () => gen.assign((0, codegen_1$s._)`${parentData}[${parentDataProperty}]`, expr));
}
function checkDataType(dataType2, data, strictNums, correct = DataType.Correct) {
  const EQ = correct === DataType.Correct ? codegen_1$s.operators.EQ : codegen_1$s.operators.NEQ;
  let cond;
  switch (dataType2) {
    case "null":
      return (0, codegen_1$s._)`${data} ${EQ} null`;
    case "array":
      cond = (0, codegen_1$s._)`Array.isArray(${data})`;
      break;
    case "object":
      cond = (0, codegen_1$s._)`${data} && typeof ${data} == "object" && !Array.isArray(${data})`;
      break;
    case "integer":
      cond = numCond((0, codegen_1$s._)`!(${data} % 1) && !isNaN(${data})`);
      break;
    case "number":
      cond = numCond();
      break;
    default:
      return (0, codegen_1$s._)`typeof ${data} ${EQ} ${dataType2}`;
  }
  return correct === DataType.Correct ? cond : (0, codegen_1$s.not)(cond);
  function numCond(_cond = codegen_1$s.nil) {
    return (0, codegen_1$s.and)((0, codegen_1$s._)`typeof ${data} == "number"`, _cond, strictNums ? (0, codegen_1$s._)`isFinite(${data})` : codegen_1$s.nil);
  }
}
dataType.checkDataType = checkDataType;
function checkDataTypes(dataTypes, data, strictNums, correct) {
  if (dataTypes.length === 1) {
    return checkDataType(dataTypes[0], data, strictNums, correct);
  }
  let cond;
  const types2 = (0, util_1$r.toHash)(dataTypes);
  if (types2.array && types2.object) {
    const notObj = (0, codegen_1$s._)`typeof ${data} != "object"`;
    cond = types2.null ? notObj : (0, codegen_1$s._)`!${data} || ${notObj}`;
    delete types2.null;
    delete types2.array;
    delete types2.object;
  } else {
    cond = codegen_1$s.nil;
  }
  if (types2.number)
    delete types2.integer;
  for (const t2 in types2)
    cond = (0, codegen_1$s.and)(cond, checkDataType(t2, data, strictNums, correct));
  return cond;
}
dataType.checkDataTypes = checkDataTypes;
const typeError = {
  message: ({ schema }) => `must be ${schema}`,
  params: ({ schema, schemaValue }) => typeof schema == "string" ? (0, codegen_1$s._)`{type: ${schema}}` : (0, codegen_1$s._)`{type: ${schemaValue}}`
};
function reportTypeError(it) {
  const cxt = getTypeErrorContext(it);
  (0, errors_1$2.reportError)(cxt, typeError);
}
dataType.reportTypeError = reportTypeError;
function getTypeErrorContext(it) {
  const { gen, data, schema } = it;
  const schemaCode = (0, util_1$r.schemaRefOrVal)(it, schema, "type");
  return {
    gen,
    keyword: "type",
    data,
    schema: schema.type,
    schemaCode,
    schemaValue: schemaCode,
    parentSchema: schema,
    params: {},
    it
  };
}
var defaults = {};
Object.defineProperty(defaults, "__esModule", { value: true });
defaults.assignDefaults = void 0;
const codegen_1$r = codegen;
const util_1$q = util$1;
function assignDefaults(it, ty) {
  const { properties: properties2, items: items2 } = it.schema;
  if (ty === "object" && properties2) {
    for (const key in properties2) {
      assignDefault(it, key, properties2[key].default);
    }
  } else if (ty === "array" && Array.isArray(items2)) {
    items2.forEach((sch, i2) => assignDefault(it, i2, sch.default));
  }
}
defaults.assignDefaults = assignDefaults;
function assignDefault(it, prop, defaultValue) {
  const { gen, compositeRule, data, opts } = it;
  if (defaultValue === void 0)
    return;
  const childData = (0, codegen_1$r._)`${data}${(0, codegen_1$r.getProperty)(prop)}`;
  if (compositeRule) {
    (0, util_1$q.checkStrictMode)(it, `default is ignored for: ${childData}`);
    return;
  }
  let condition = (0, codegen_1$r._)`${childData} === undefined`;
  if (opts.useDefaults === "empty") {
    condition = (0, codegen_1$r._)`${condition} || ${childData} === null || ${childData} === ""`;
  }
  gen.if(condition, (0, codegen_1$r._)`${childData} = ${(0, codegen_1$r.stringify)(defaultValue)}`);
}
var keyword = {};
var code = {};
Object.defineProperty(code, "__esModule", { value: true });
code.validateUnion = code.validateArray = code.usePattern = code.callValidateCode = code.schemaProperties = code.allSchemaProperties = code.noPropertyInData = code.propertyInData = code.isOwnProperty = code.hasPropFunc = code.reportMissingProp = code.checkMissingProp = code.checkReportMissingProp = void 0;
const codegen_1$q = codegen;
const util_1$p = util$1;
const names_1$5 = names$1;
const util_2$1 = util$1;
function checkReportMissingProp(cxt, prop) {
  const { gen, data, it } = cxt;
  gen.if(noPropertyInData(gen, data, prop, it.opts.ownProperties), () => {
    cxt.setParams({ missingProperty: (0, codegen_1$q._)`${prop}` }, true);
    cxt.error();
  });
}
code.checkReportMissingProp = checkReportMissingProp;
function checkMissingProp({ gen, data, it: { opts } }, properties2, missing) {
  return (0, codegen_1$q.or)(...properties2.map((prop) => (0, codegen_1$q.and)(noPropertyInData(gen, data, prop, opts.ownProperties), (0, codegen_1$q._)`${missing} = ${prop}`)));
}
code.checkMissingProp = checkMissingProp;
function reportMissingProp(cxt, missing) {
  cxt.setParams({ missingProperty: missing }, true);
  cxt.error();
}
code.reportMissingProp = reportMissingProp;
function hasPropFunc(gen) {
  return gen.scopeValue("func", {
    // eslint-disable-next-line @typescript-eslint/unbound-method
    ref: Object.prototype.hasOwnProperty,
    code: (0, codegen_1$q._)`Object.prototype.hasOwnProperty`
  });
}
code.hasPropFunc = hasPropFunc;
function isOwnProperty(gen, data, property) {
  return (0, codegen_1$q._)`${hasPropFunc(gen)}.call(${data}, ${property})`;
}
code.isOwnProperty = isOwnProperty;
function propertyInData(gen, data, property, ownProperties) {
  const cond = (0, codegen_1$q._)`${data}${(0, codegen_1$q.getProperty)(property)} !== undefined`;
  return ownProperties ? (0, codegen_1$q._)`${cond} && ${isOwnProperty(gen, data, property)}` : cond;
}
code.propertyInData = propertyInData;
function noPropertyInData(gen, data, property, ownProperties) {
  const cond = (0, codegen_1$q._)`${data}${(0, codegen_1$q.getProperty)(property)} === undefined`;
  return ownProperties ? (0, codegen_1$q.or)(cond, (0, codegen_1$q.not)(isOwnProperty(gen, data, property))) : cond;
}
code.noPropertyInData = noPropertyInData;
function allSchemaProperties(schemaMap) {
  return schemaMap ? Object.keys(schemaMap).filter((p) => p !== "__proto__") : [];
}
code.allSchemaProperties = allSchemaProperties;
function schemaProperties(it, schemaMap) {
  return allSchemaProperties(schemaMap).filter((p) => !(0, util_1$p.alwaysValidSchema)(it, schemaMap[p]));
}
code.schemaProperties = schemaProperties;
function callValidateCode({ schemaCode, data, it: { gen, topSchemaRef, schemaPath, errorPath }, it }, func, context, passSchema) {
  const dataAndSchema = passSchema ? (0, codegen_1$q._)`${schemaCode}, ${data}, ${topSchemaRef}${schemaPath}` : data;
  const valCxt = [
    [names_1$5.default.instancePath, (0, codegen_1$q.strConcat)(names_1$5.default.instancePath, errorPath)],
    [names_1$5.default.parentData, it.parentData],
    [names_1$5.default.parentDataProperty, it.parentDataProperty],
    [names_1$5.default.rootData, names_1$5.default.rootData]
  ];
  if (it.opts.dynamicRef)
    valCxt.push([names_1$5.default.dynamicAnchors, names_1$5.default.dynamicAnchors]);
  const args = (0, codegen_1$q._)`${dataAndSchema}, ${gen.object(...valCxt)}`;
  return context !== codegen_1$q.nil ? (0, codegen_1$q._)`${func}.call(${context}, ${args})` : (0, codegen_1$q._)`${func}(${args})`;
}
code.callValidateCode = callValidateCode;
const newRegExp = (0, codegen_1$q._)`new RegExp`;
function usePattern({ gen, it: { opts } }, pattern2) {
  const u = opts.unicodeRegExp ? "u" : "";
  const { regExp } = opts.code;
  const rx = regExp(pattern2, u);
  return gen.scopeValue("pattern", {
    key: rx.toString(),
    ref: rx,
    code: (0, codegen_1$q._)`${regExp.code === "new RegExp" ? newRegExp : (0, util_2$1.useFunc)(gen, regExp)}(${pattern2}, ${u})`
  });
}
code.usePattern = usePattern;
function validateArray(cxt) {
  const { gen, data, keyword: keyword2, it } = cxt;
  const valid2 = gen.name("valid");
  if (it.allErrors) {
    const validArr = gen.let("valid", true);
    validateItems(() => gen.assign(validArr, false));
    return validArr;
  }
  gen.var(valid2, true);
  validateItems(() => gen.break());
  return valid2;
  function validateItems(notValid) {
    const len = gen.const("len", (0, codegen_1$q._)`${data}.length`);
    gen.forRange("i", 0, len, (i2) => {
      cxt.subschema({
        keyword: keyword2,
        dataProp: i2,
        dataPropType: util_1$p.Type.Num
      }, valid2);
      gen.if((0, codegen_1$q.not)(valid2), notValid);
    });
  }
}
code.validateArray = validateArray;
function validateUnion(cxt) {
  const { gen, schema, keyword: keyword2, it } = cxt;
  if (!Array.isArray(schema))
    throw new Error("ajv implementation error");
  const alwaysValid = schema.some((sch) => (0, util_1$p.alwaysValidSchema)(it, sch));
  if (alwaysValid && !it.opts.unevaluated)
    return;
  const valid2 = gen.let("valid", false);
  const schValid = gen.name("_valid");
  gen.block(() => schema.forEach((_sch, i2) => {
    const schCxt = cxt.subschema({
      keyword: keyword2,
      schemaProp: i2,
      compositeRule: true
    }, schValid);
    gen.assign(valid2, (0, codegen_1$q._)`${valid2} || ${schValid}`);
    const merged = cxt.mergeValidEvaluated(schCxt, schValid);
    if (!merged)
      gen.if((0, codegen_1$q.not)(valid2));
  }));
  cxt.result(valid2, () => cxt.reset(), () => cxt.error(true));
}
code.validateUnion = validateUnion;
Object.defineProperty(keyword, "__esModule", { value: true });
keyword.validateKeywordUsage = keyword.validSchemaType = keyword.funcKeywordCode = keyword.macroKeywordCode = void 0;
const codegen_1$p = codegen;
const names_1$4 = names$1;
const code_1$9 = code;
const errors_1$1 = errors;
function macroKeywordCode(cxt, def2) {
  const { gen, keyword: keyword2, schema, parentSchema, it } = cxt;
  const macroSchema = def2.macro.call(it.self, schema, parentSchema, it);
  const schemaRef = useKeyword(gen, keyword2, macroSchema);
  if (it.opts.validateSchema !== false)
    it.self.validateSchema(macroSchema, true);
  const valid2 = gen.name("valid");
  cxt.subschema({
    schema: macroSchema,
    schemaPath: codegen_1$p.nil,
    errSchemaPath: `${it.errSchemaPath}/${keyword2}`,
    topSchemaRef: schemaRef,
    compositeRule: true
  }, valid2);
  cxt.pass(valid2, () => cxt.error(true));
}
keyword.macroKeywordCode = macroKeywordCode;
function funcKeywordCode(cxt, def2) {
  var _a2;
  const { gen, keyword: keyword2, schema, parentSchema, $data, it } = cxt;
  checkAsyncKeyword(it, def2);
  const validate2 = !$data && def2.compile ? def2.compile.call(it.self, schema, parentSchema, it) : def2.validate;
  const validateRef = useKeyword(gen, keyword2, validate2);
  const valid2 = gen.let("valid");
  cxt.block$data(valid2, validateKeyword);
  cxt.ok((_a2 = def2.valid) !== null && _a2 !== void 0 ? _a2 : valid2);
  function validateKeyword() {
    if (def2.errors === false) {
      assignValid();
      if (def2.modifying)
        modifyData(cxt);
      reportErrs(() => cxt.error());
    } else {
      const ruleErrs = def2.async ? validateAsync() : validateSync();
      if (def2.modifying)
        modifyData(cxt);
      reportErrs(() => addErrs(cxt, ruleErrs));
    }
  }
  function validateAsync() {
    const ruleErrs = gen.let("ruleErrs", null);
    gen.try(() => assignValid((0, codegen_1$p._)`await `), (e) => gen.assign(valid2, false).if((0, codegen_1$p._)`${e} instanceof ${it.ValidationError}`, () => gen.assign(ruleErrs, (0, codegen_1$p._)`${e}.errors`), () => gen.throw(e)));
    return ruleErrs;
  }
  function validateSync() {
    const validateErrs = (0, codegen_1$p._)`${validateRef}.errors`;
    gen.assign(validateErrs, null);
    assignValid(codegen_1$p.nil);
    return validateErrs;
  }
  function assignValid(_await = def2.async ? (0, codegen_1$p._)`await ` : codegen_1$p.nil) {
    const passCxt = it.opts.passContext ? names_1$4.default.this : names_1$4.default.self;
    const passSchema = !("compile" in def2 && !$data || def2.schema === false);
    gen.assign(valid2, (0, codegen_1$p._)`${_await}${(0, code_1$9.callValidateCode)(cxt, validateRef, passCxt, passSchema)}`, def2.modifying);
  }
  function reportErrs(errors2) {
    var _a3;
    gen.if((0, codegen_1$p.not)((_a3 = def2.valid) !== null && _a3 !== void 0 ? _a3 : valid2), errors2);
  }
}
keyword.funcKeywordCode = funcKeywordCode;
function modifyData(cxt) {
  const { gen, data, it } = cxt;
  gen.if(it.parentData, () => gen.assign(data, (0, codegen_1$p._)`${it.parentData}[${it.parentDataProperty}]`));
}
function addErrs(cxt, errs) {
  const { gen } = cxt;
  gen.if((0, codegen_1$p._)`Array.isArray(${errs})`, () => {
    gen.assign(names_1$4.default.vErrors, (0, codegen_1$p._)`${names_1$4.default.vErrors} === null ? ${errs} : ${names_1$4.default.vErrors}.concat(${errs})`).assign(names_1$4.default.errors, (0, codegen_1$p._)`${names_1$4.default.vErrors}.length`);
    (0, errors_1$1.extendErrors)(cxt);
  }, () => cxt.error());
}
function checkAsyncKeyword({ schemaEnv }, def2) {
  if (def2.async && !schemaEnv.$async)
    throw new Error("async keyword in sync schema");
}
function useKeyword(gen, keyword2, result) {
  if (result === void 0)
    throw new Error(`keyword "${keyword2}" failed to compile`);
  return gen.scopeValue("keyword", typeof result == "function" ? { ref: result } : { ref: result, code: (0, codegen_1$p.stringify)(result) });
}
function validSchemaType(schema, schemaType, allowUndefined = false) {
  return !schemaType.length || schemaType.some((st) => st === "array" ? Array.isArray(schema) : st === "object" ? schema && typeof schema == "object" && !Array.isArray(schema) : typeof schema == st || allowUndefined && typeof schema == "undefined");
}
keyword.validSchemaType = validSchemaType;
function validateKeywordUsage({ schema, opts, self: self2, errSchemaPath }, def2, keyword2) {
  if (Array.isArray(def2.keyword) ? !def2.keyword.includes(keyword2) : def2.keyword !== keyword2) {
    throw new Error("ajv implementation error");
  }
  const deps = def2.dependencies;
  if (deps === null || deps === void 0 ? void 0 : deps.some((kwd) => !Object.prototype.hasOwnProperty.call(schema, kwd))) {
    throw new Error(`parent schema must have dependencies of ${keyword2}: ${deps.join(",")}`);
  }
  if (def2.validateSchema) {
    const valid2 = def2.validateSchema(schema[keyword2]);
    if (!valid2) {
      const msg = `keyword "${keyword2}" value is invalid at path "${errSchemaPath}": ` + self2.errorsText(def2.validateSchema.errors);
      if (opts.validateSchema === "log")
        self2.logger.error(msg);
      else
        throw new Error(msg);
    }
  }
}
keyword.validateKeywordUsage = validateKeywordUsage;
var subschema = {};
Object.defineProperty(subschema, "__esModule", { value: true });
subschema.extendSubschemaMode = subschema.extendSubschemaData = subschema.getSubschema = void 0;
const codegen_1$o = codegen;
const util_1$o = util$1;
function getSubschema(it, { keyword: keyword2, schemaProp, schema, schemaPath, errSchemaPath, topSchemaRef }) {
  if (keyword2 !== void 0 && schema !== void 0) {
    throw new Error('both "keyword" and "schema" passed, only one allowed');
  }
  if (keyword2 !== void 0) {
    const sch = it.schema[keyword2];
    return schemaProp === void 0 ? {
      schema: sch,
      schemaPath: (0, codegen_1$o._)`${it.schemaPath}${(0, codegen_1$o.getProperty)(keyword2)}`,
      errSchemaPath: `${it.errSchemaPath}/${keyword2}`
    } : {
      schema: sch[schemaProp],
      schemaPath: (0, codegen_1$o._)`${it.schemaPath}${(0, codegen_1$o.getProperty)(keyword2)}${(0, codegen_1$o.getProperty)(schemaProp)}`,
      errSchemaPath: `${it.errSchemaPath}/${keyword2}/${(0, util_1$o.escapeFragment)(schemaProp)}`
    };
  }
  if (schema !== void 0) {
    if (schemaPath === void 0 || errSchemaPath === void 0 || topSchemaRef === void 0) {
      throw new Error('"schemaPath", "errSchemaPath" and "topSchemaRef" are required with "schema"');
    }
    return {
      schema,
      schemaPath,
      topSchemaRef,
      errSchemaPath
    };
  }
  throw new Error('either "keyword" or "schema" must be passed');
}
subschema.getSubschema = getSubschema;
function extendSubschemaData(subschema2, it, { dataProp, dataPropType: dpType, data, dataTypes, propertyName }) {
  if (data !== void 0 && dataProp !== void 0) {
    throw new Error('both "data" and "dataProp" passed, only one allowed');
  }
  const { gen } = it;
  if (dataProp !== void 0) {
    const { errorPath, dataPathArr, opts } = it;
    const nextData = gen.let("data", (0, codegen_1$o._)`${it.data}${(0, codegen_1$o.getProperty)(dataProp)}`, true);
    dataContextProps(nextData);
    subschema2.errorPath = (0, codegen_1$o.str)`${errorPath}${(0, util_1$o.getErrorPath)(dataProp, dpType, opts.jsPropertySyntax)}`;
    subschema2.parentDataProperty = (0, codegen_1$o._)`${dataProp}`;
    subschema2.dataPathArr = [...dataPathArr, subschema2.parentDataProperty];
  }
  if (data !== void 0) {
    const nextData = data instanceof codegen_1$o.Name ? data : gen.let("data", data, true);
    dataContextProps(nextData);
    if (propertyName !== void 0)
      subschema2.propertyName = propertyName;
  }
  if (dataTypes)
    subschema2.dataTypes = dataTypes;
  function dataContextProps(_nextData) {
    subschema2.data = _nextData;
    subschema2.dataLevel = it.dataLevel + 1;
    subschema2.dataTypes = [];
    it.definedProperties = /* @__PURE__ */ new Set();
    subschema2.parentData = it.data;
    subschema2.dataNames = [...it.dataNames, _nextData];
  }
}
subschema.extendSubschemaData = extendSubschemaData;
function extendSubschemaMode(subschema2, { jtdDiscriminator, jtdMetadata, compositeRule, createErrors, allErrors }) {
  if (compositeRule !== void 0)
    subschema2.compositeRule = compositeRule;
  if (createErrors !== void 0)
    subschema2.createErrors = createErrors;
  if (allErrors !== void 0)
    subschema2.allErrors = allErrors;
  subschema2.jtdDiscriminator = jtdDiscriminator;
  subschema2.jtdMetadata = jtdMetadata;
}
subschema.extendSubschemaMode = extendSubschemaMode;
var resolve$1 = {};
var jsonSchemaTraverse = { exports: {} };
var traverse$1 = jsonSchemaTraverse.exports = function(schema, opts, cb) {
  if (typeof opts == "function") {
    cb = opts;
    opts = {};
  }
  cb = opts.cb || cb;
  var pre = typeof cb == "function" ? cb : cb.pre || function() {
  };
  var post = cb.post || function() {
  };
  _traverse(opts, pre, post, schema, "", schema);
};
traverse$1.keywords = {
  additionalItems: true,
  items: true,
  contains: true,
  additionalProperties: true,
  propertyNames: true,
  not: true,
  if: true,
  then: true,
  else: true
};
traverse$1.arrayKeywords = {
  items: true,
  allOf: true,
  anyOf: true,
  oneOf: true
};
traverse$1.propsKeywords = {
  $defs: true,
  definitions: true,
  properties: true,
  patternProperties: true,
  dependencies: true
};
traverse$1.skipKeywords = {
  default: true,
  enum: true,
  const: true,
  required: true,
  maximum: true,
  minimum: true,
  exclusiveMaximum: true,
  exclusiveMinimum: true,
  multipleOf: true,
  maxLength: true,
  minLength: true,
  pattern: true,
  format: true,
  maxItems: true,
  minItems: true,
  uniqueItems: true,
  maxProperties: true,
  minProperties: true
};
function _traverse(opts, pre, post, schema, jsonPtr, rootSchema, parentJsonPtr, parentKeyword, parentSchema, keyIndex) {
  if (schema && typeof schema == "object" && !Array.isArray(schema)) {
    pre(schema, jsonPtr, rootSchema, parentJsonPtr, parentKeyword, parentSchema, keyIndex);
    for (var key in schema) {
      var sch = schema[key];
      if (Array.isArray(sch)) {
        if (key in traverse$1.arrayKeywords) {
          for (var i2 = 0; i2 < sch.length; i2++)
            _traverse(opts, pre, post, sch[i2], jsonPtr + "/" + key + "/" + i2, rootSchema, jsonPtr, key, schema, i2);
        }
      } else if (key in traverse$1.propsKeywords) {
        if (sch && typeof sch == "object") {
          for (var prop in sch)
            _traverse(opts, pre, post, sch[prop], jsonPtr + "/" + key + "/" + escapeJsonPtr(prop), rootSchema, jsonPtr, key, schema, prop);
        }
      } else if (key in traverse$1.keywords || opts.allKeys && !(key in traverse$1.skipKeywords)) {
        _traverse(opts, pre, post, sch, jsonPtr + "/" + key, rootSchema, jsonPtr, key, schema);
      }
    }
    post(schema, jsonPtr, rootSchema, parentJsonPtr, parentKeyword, parentSchema, keyIndex);
  }
}
function escapeJsonPtr(str) {
  return str.replace(/~/g, "~0").replace(/\//g, "~1");
}
var jsonSchemaTraverseExports = jsonSchemaTraverse.exports;
Object.defineProperty(resolve$1, "__esModule", { value: true });
resolve$1.getSchemaRefs = resolve$1.resolveUrl = resolve$1.normalizeId = resolve$1._getFullPath = resolve$1.getFullPath = resolve$1.inlineRef = void 0;
const util_1$n = util$1;
const equal$2 = fastDeepEqual;
const traverse = jsonSchemaTraverseExports;
const SIMPLE_INLINED = /* @__PURE__ */ new Set([
  "type",
  "format",
  "pattern",
  "maxLength",
  "minLength",
  "maxProperties",
  "minProperties",
  "maxItems",
  "minItems",
  "maximum",
  "minimum",
  "uniqueItems",
  "multipleOf",
  "required",
  "enum",
  "const"
]);
function inlineRef(schema, limit2 = true) {
  if (typeof schema == "boolean")
    return true;
  if (limit2 === true)
    return !hasRef(schema);
  if (!limit2)
    return false;
  return countKeys(schema) <= limit2;
}
resolve$1.inlineRef = inlineRef;
const REF_KEYWORDS = /* @__PURE__ */ new Set([
  "$ref",
  "$recursiveRef",
  "$recursiveAnchor",
  "$dynamicRef",
  "$dynamicAnchor"
]);
function hasRef(schema) {
  for (const key in schema) {
    if (REF_KEYWORDS.has(key))
      return true;
    const sch = schema[key];
    if (Array.isArray(sch) && sch.some(hasRef))
      return true;
    if (typeof sch == "object" && hasRef(sch))
      return true;
  }
  return false;
}
function countKeys(schema) {
  let count = 0;
  for (const key in schema) {
    if (key === "$ref")
      return Infinity;
    count++;
    if (SIMPLE_INLINED.has(key))
      continue;
    if (typeof schema[key] == "object") {
      (0, util_1$n.eachItem)(schema[key], (sch) => count += countKeys(sch));
    }
    if (count === Infinity)
      return Infinity;
  }
  return count;
}
function getFullPath(resolver, id2 = "", normalize2) {
  if (normalize2 !== false)
    id2 = normalizeId(id2);
  const p = resolver.parse(id2);
  return _getFullPath(resolver, p);
}
resolve$1.getFullPath = getFullPath;
function _getFullPath(resolver, p) {
  const serialized = resolver.serialize(p);
  return serialized.split("#")[0] + "#";
}
resolve$1._getFullPath = _getFullPath;
const TRAILING_SLASH_HASH = /#\/?$/;
function normalizeId(id2) {
  return id2 ? id2.replace(TRAILING_SLASH_HASH, "") : "";
}
resolve$1.normalizeId = normalizeId;
function resolveUrl(resolver, baseId, id2) {
  id2 = normalizeId(id2);
  return resolver.resolve(baseId, id2);
}
resolve$1.resolveUrl = resolveUrl;
const ANCHOR = /^[a-z_][-a-z0-9._]*$/i;
function getSchemaRefs(schema, baseId) {
  if (typeof schema == "boolean")
    return {};
  const { schemaId, uriResolver } = this.opts;
  const schId = normalizeId(schema[schemaId] || baseId);
  const baseIds = { "": schId };
  const pathPrefix = getFullPath(uriResolver, schId, false);
  const localRefs = {};
  const schemaRefs = /* @__PURE__ */ new Set();
  traverse(schema, { allKeys: true }, (sch, jsonPtr, _, parentJsonPtr) => {
    if (parentJsonPtr === void 0)
      return;
    const fullPath = pathPrefix + jsonPtr;
    let innerBaseId = baseIds[parentJsonPtr];
    if (typeof sch[schemaId] == "string")
      innerBaseId = addRef.call(this, sch[schemaId]);
    addAnchor.call(this, sch.$anchor);
    addAnchor.call(this, sch.$dynamicAnchor);
    baseIds[jsonPtr] = innerBaseId;
    function addRef(ref2) {
      const _resolve = this.opts.uriResolver.resolve;
      ref2 = normalizeId(innerBaseId ? _resolve(innerBaseId, ref2) : ref2);
      if (schemaRefs.has(ref2))
        throw ambiguos(ref2);
      schemaRefs.add(ref2);
      let schOrRef = this.refs[ref2];
      if (typeof schOrRef == "string")
        schOrRef = this.refs[schOrRef];
      if (typeof schOrRef == "object") {
        checkAmbiguosRef(sch, schOrRef.schema, ref2);
      } else if (ref2 !== normalizeId(fullPath)) {
        if (ref2[0] === "#") {
          checkAmbiguosRef(sch, localRefs[ref2], ref2);
          localRefs[ref2] = sch;
        } else {
          this.refs[ref2] = fullPath;
        }
      }
      return ref2;
    }
    function addAnchor(anchor) {
      if (typeof anchor == "string") {
        if (!ANCHOR.test(anchor))
          throw new Error(`invalid anchor "${anchor}"`);
        addRef.call(this, `#${anchor}`);
      }
    }
  });
  return localRefs;
  function checkAmbiguosRef(sch1, sch2, ref2) {
    if (sch2 !== void 0 && !equal$2(sch1, sch2))
      throw ambiguos(ref2);
  }
  function ambiguos(ref2) {
    return new Error(`reference "${ref2}" resolves to more than one schema`);
  }
}
resolve$1.getSchemaRefs = getSchemaRefs;
Object.defineProperty(validate, "__esModule", { value: true });
validate.getData = validate.KeywordCxt = validate.validateFunctionCode = void 0;
const boolSchema_1 = boolSchema;
const dataType_1$1 = dataType;
const applicability_1 = applicability;
const dataType_2 = dataType;
const defaults_1 = defaults;
const keyword_1 = keyword;
const subschema_1 = subschema;
const codegen_1$n = codegen;
const names_1$3 = names$1;
const resolve_1$2 = resolve$1;
const util_1$m = util$1;
const errors_1 = errors;
function validateFunctionCode(it) {
  if (isSchemaObj(it)) {
    checkKeywords(it);
    if (schemaCxtHasRules(it)) {
      topSchemaObjCode(it);
      return;
    }
  }
  validateFunction(it, () => (0, boolSchema_1.topBoolOrEmptySchema)(it));
}
validate.validateFunctionCode = validateFunctionCode;
function validateFunction({ gen, validateName, schema, schemaEnv, opts }, body) {
  if (opts.code.es5) {
    gen.func(validateName, (0, codegen_1$n._)`${names_1$3.default.data}, ${names_1$3.default.valCxt}`, schemaEnv.$async, () => {
      gen.code((0, codegen_1$n._)`"use strict"; ${funcSourceUrl(schema, opts)}`);
      destructureValCxtES5(gen, opts);
      gen.code(body);
    });
  } else {
    gen.func(validateName, (0, codegen_1$n._)`${names_1$3.default.data}, ${destructureValCxt(opts)}`, schemaEnv.$async, () => gen.code(funcSourceUrl(schema, opts)).code(body));
  }
}
function destructureValCxt(opts) {
  return (0, codegen_1$n._)`{${names_1$3.default.instancePath}="", ${names_1$3.default.parentData}, ${names_1$3.default.parentDataProperty}, ${names_1$3.default.rootData}=${names_1$3.default.data}${opts.dynamicRef ? (0, codegen_1$n._)`, ${names_1$3.default.dynamicAnchors}={}` : codegen_1$n.nil}}={}`;
}
function destructureValCxtES5(gen, opts) {
  gen.if(names_1$3.default.valCxt, () => {
    gen.var(names_1$3.default.instancePath, (0, codegen_1$n._)`${names_1$3.default.valCxt}.${names_1$3.default.instancePath}`);
    gen.var(names_1$3.default.parentData, (0, codegen_1$n._)`${names_1$3.default.valCxt}.${names_1$3.default.parentData}`);
    gen.var(names_1$3.default.parentDataProperty, (0, codegen_1$n._)`${names_1$3.default.valCxt}.${names_1$3.default.parentDataProperty}`);
    gen.var(names_1$3.default.rootData, (0, codegen_1$n._)`${names_1$3.default.valCxt}.${names_1$3.default.rootData}`);
    if (opts.dynamicRef)
      gen.var(names_1$3.default.dynamicAnchors, (0, codegen_1$n._)`${names_1$3.default.valCxt}.${names_1$3.default.dynamicAnchors}`);
  }, () => {
    gen.var(names_1$3.default.instancePath, (0, codegen_1$n._)`""`);
    gen.var(names_1$3.default.parentData, (0, codegen_1$n._)`undefined`);
    gen.var(names_1$3.default.parentDataProperty, (0, codegen_1$n._)`undefined`);
    gen.var(names_1$3.default.rootData, names_1$3.default.data);
    if (opts.dynamicRef)
      gen.var(names_1$3.default.dynamicAnchors, (0, codegen_1$n._)`{}`);
  });
}
function topSchemaObjCode(it) {
  const { schema, opts, gen } = it;
  validateFunction(it, () => {
    if (opts.$comment && schema.$comment)
      commentKeyword(it);
    checkNoDefault(it);
    gen.let(names_1$3.default.vErrors, null);
    gen.let(names_1$3.default.errors, 0);
    if (opts.unevaluated)
      resetEvaluated(it);
    typeAndKeywords(it);
    returnResults(it);
  });
  return;
}
function resetEvaluated(it) {
  const { gen, validateName } = it;
  it.evaluated = gen.const("evaluated", (0, codegen_1$n._)`${validateName}.evaluated`);
  gen.if((0, codegen_1$n._)`${it.evaluated}.dynamicProps`, () => gen.assign((0, codegen_1$n._)`${it.evaluated}.props`, (0, codegen_1$n._)`undefined`));
  gen.if((0, codegen_1$n._)`${it.evaluated}.dynamicItems`, () => gen.assign((0, codegen_1$n._)`${it.evaluated}.items`, (0, codegen_1$n._)`undefined`));
}
function funcSourceUrl(schema, opts) {
  const schId = typeof schema == "object" && schema[opts.schemaId];
  return schId && (opts.code.source || opts.code.process) ? (0, codegen_1$n._)`/*# sourceURL=${schId} */` : codegen_1$n.nil;
}
function subschemaCode(it, valid2) {
  if (isSchemaObj(it)) {
    checkKeywords(it);
    if (schemaCxtHasRules(it)) {
      subSchemaObjCode(it, valid2);
      return;
    }
  }
  (0, boolSchema_1.boolOrEmptySchema)(it, valid2);
}
function schemaCxtHasRules({ schema, self: self2 }) {
  if (typeof schema == "boolean")
    return !schema;
  for (const key in schema)
    if (self2.RULES.all[key])
      return true;
  return false;
}
function isSchemaObj(it) {
  return typeof it.schema != "boolean";
}
function subSchemaObjCode(it, valid2) {
  const { schema, gen, opts } = it;
  if (opts.$comment && schema.$comment)
    commentKeyword(it);
  updateContext(it);
  checkAsyncSchema(it);
  const errsCount = gen.const("_errs", names_1$3.default.errors);
  typeAndKeywords(it, errsCount);
  gen.var(valid2, (0, codegen_1$n._)`${errsCount} === ${names_1$3.default.errors}`);
}
function checkKeywords(it) {
  (0, util_1$m.checkUnknownRules)(it);
  checkRefsAndKeywords(it);
}
function typeAndKeywords(it, errsCount) {
  if (it.opts.jtd)
    return schemaKeywords(it, [], false, errsCount);
  const types2 = (0, dataType_1$1.getSchemaTypes)(it.schema);
  const checkedTypes = (0, dataType_1$1.coerceAndCheckDataType)(it, types2);
  schemaKeywords(it, types2, !checkedTypes, errsCount);
}
function checkRefsAndKeywords(it) {
  const { schema, errSchemaPath, opts, self: self2 } = it;
  if (schema.$ref && opts.ignoreKeywordsWithRef && (0, util_1$m.schemaHasRulesButRef)(schema, self2.RULES)) {
    self2.logger.warn(`$ref: keywords ignored in schema at path "${errSchemaPath}"`);
  }
}
function checkNoDefault(it) {
  const { schema, opts } = it;
  if (schema.default !== void 0 && opts.useDefaults && opts.strictSchema) {
    (0, util_1$m.checkStrictMode)(it, "default is ignored in the schema root");
  }
}
function updateContext(it) {
  const schId = it.schema[it.opts.schemaId];
  if (schId)
    it.baseId = (0, resolve_1$2.resolveUrl)(it.opts.uriResolver, it.baseId, schId);
}
function checkAsyncSchema(it) {
  if (it.schema.$async && !it.schemaEnv.$async)
    throw new Error("async schema in sync schema");
}
function commentKeyword({ gen, schemaEnv, schema, errSchemaPath, opts }) {
  const msg = schema.$comment;
  if (opts.$comment === true) {
    gen.code((0, codegen_1$n._)`${names_1$3.default.self}.logger.log(${msg})`);
  } else if (typeof opts.$comment == "function") {
    const schemaPath = (0, codegen_1$n.str)`${errSchemaPath}/$comment`;
    const rootName = gen.scopeValue("root", { ref: schemaEnv.root });
    gen.code((0, codegen_1$n._)`${names_1$3.default.self}.opts.$comment(${msg}, ${schemaPath}, ${rootName}.schema)`);
  }
}
function returnResults(it) {
  const { gen, schemaEnv, validateName, ValidationError: ValidationError3, opts } = it;
  if (schemaEnv.$async) {
    gen.if((0, codegen_1$n._)`${names_1$3.default.errors} === 0`, () => gen.return(names_1$3.default.data), () => gen.throw((0, codegen_1$n._)`new ${ValidationError3}(${names_1$3.default.vErrors})`));
  } else {
    gen.assign((0, codegen_1$n._)`${validateName}.errors`, names_1$3.default.vErrors);
    if (opts.unevaluated)
      assignEvaluated(it);
    gen.return((0, codegen_1$n._)`${names_1$3.default.errors} === 0`);
  }
}
function assignEvaluated({ gen, evaluated, props, items: items2 }) {
  if (props instanceof codegen_1$n.Name)
    gen.assign((0, codegen_1$n._)`${evaluated}.props`, props);
  if (items2 instanceof codegen_1$n.Name)
    gen.assign((0, codegen_1$n._)`${evaluated}.items`, items2);
}
function schemaKeywords(it, types2, typeErrors, errsCount) {
  const { gen, schema, data, allErrors, opts, self: self2 } = it;
  const { RULES } = self2;
  if (schema.$ref && (opts.ignoreKeywordsWithRef || !(0, util_1$m.schemaHasRulesButRef)(schema, RULES))) {
    gen.block(() => keywordCode(it, "$ref", RULES.all.$ref.definition));
    return;
  }
  if (!opts.jtd)
    checkStrictTypes(it, types2);
  gen.block(() => {
    for (const group of RULES.rules)
      groupKeywords(group);
    groupKeywords(RULES.post);
  });
  function groupKeywords(group) {
    if (!(0, applicability_1.shouldUseGroup)(schema, group))
      return;
    if (group.type) {
      gen.if((0, dataType_2.checkDataType)(group.type, data, opts.strictNumbers));
      iterateKeywords(it, group);
      if (types2.length === 1 && types2[0] === group.type && typeErrors) {
        gen.else();
        (0, dataType_2.reportTypeError)(it);
      }
      gen.endIf();
    } else {
      iterateKeywords(it, group);
    }
    if (!allErrors)
      gen.if((0, codegen_1$n._)`${names_1$3.default.errors} === ${errsCount || 0}`);
  }
}
function iterateKeywords(it, group) {
  const { gen, schema, opts: { useDefaults } } = it;
  if (useDefaults)
    (0, defaults_1.assignDefaults)(it, group.type);
  gen.block(() => {
    for (const rule of group.rules) {
      if ((0, applicability_1.shouldUseRule)(schema, rule)) {
        keywordCode(it, rule.keyword, rule.definition, group.type);
      }
    }
  });
}
function checkStrictTypes(it, types2) {
  if (it.schemaEnv.meta || !it.opts.strictTypes)
    return;
  checkContextTypes(it, types2);
  if (!it.opts.allowUnionTypes)
    checkMultipleTypes(it, types2);
  checkKeywordTypes(it, it.dataTypes);
}
function checkContextTypes(it, types2) {
  if (!types2.length)
    return;
  if (!it.dataTypes.length) {
    it.dataTypes = types2;
    return;
  }
  types2.forEach((t2) => {
    if (!includesType(it.dataTypes, t2)) {
      strictTypesError(it, `type "${t2}" not allowed by context "${it.dataTypes.join(",")}"`);
    }
  });
  narrowSchemaTypes(it, types2);
}
function checkMultipleTypes(it, ts) {
  if (ts.length > 1 && !(ts.length === 2 && ts.includes("null"))) {
    strictTypesError(it, "use allowUnionTypes to allow union type keyword");
  }
}
function checkKeywordTypes(it, ts) {
  const rules2 = it.self.RULES.all;
  for (const keyword2 in rules2) {
    const rule = rules2[keyword2];
    if (typeof rule == "object" && (0, applicability_1.shouldUseRule)(it.schema, rule)) {
      const { type: type2 } = rule.definition;
      if (type2.length && !type2.some((t2) => hasApplicableType(ts, t2))) {
        strictTypesError(it, `missing type "${type2.join(",")}" for keyword "${keyword2}"`);
      }
    }
  }
}
function hasApplicableType(schTs, kwdT) {
  return schTs.includes(kwdT) || kwdT === "number" && schTs.includes("integer");
}
function includesType(ts, t2) {
  return ts.includes(t2) || t2 === "integer" && ts.includes("number");
}
function narrowSchemaTypes(it, withTypes) {
  const ts = [];
  for (const t2 of it.dataTypes) {
    if (includesType(withTypes, t2))
      ts.push(t2);
    else if (withTypes.includes("integer") && t2 === "number")
      ts.push("integer");
  }
  it.dataTypes = ts;
}
function strictTypesError(it, msg) {
  const schemaPath = it.schemaEnv.baseId + it.errSchemaPath;
  msg += ` at "${schemaPath}" (strictTypes)`;
  (0, util_1$m.checkStrictMode)(it, msg, it.opts.strictTypes);
}
class KeywordCxt {
  constructor(it, def2, keyword2) {
    (0, keyword_1.validateKeywordUsage)(it, def2, keyword2);
    this.gen = it.gen;
    this.allErrors = it.allErrors;
    this.keyword = keyword2;
    this.data = it.data;
    this.schema = it.schema[keyword2];
    this.$data = def2.$data && it.opts.$data && this.schema && this.schema.$data;
    this.schemaValue = (0, util_1$m.schemaRefOrVal)(it, this.schema, keyword2, this.$data);
    this.schemaType = def2.schemaType;
    this.parentSchema = it.schema;
    this.params = {};
    this.it = it;
    this.def = def2;
    if (this.$data) {
      this.schemaCode = it.gen.const("vSchema", getData(this.$data, it));
    } else {
      this.schemaCode = this.schemaValue;
      if (!(0, keyword_1.validSchemaType)(this.schema, def2.schemaType, def2.allowUndefined)) {
        throw new Error(`${keyword2} value must be ${JSON.stringify(def2.schemaType)}`);
      }
    }
    if ("code" in def2 ? def2.trackErrors : def2.errors !== false) {
      this.errsCount = it.gen.const("_errs", names_1$3.default.errors);
    }
  }
  result(condition, successAction, failAction) {
    this.failResult((0, codegen_1$n.not)(condition), successAction, failAction);
  }
  failResult(condition, successAction, failAction) {
    this.gen.if(condition);
    if (failAction)
      failAction();
    else
      this.error();
    if (successAction) {
      this.gen.else();
      successAction();
      if (this.allErrors)
        this.gen.endIf();
    } else {
      if (this.allErrors)
        this.gen.endIf();
      else
        this.gen.else();
    }
  }
  pass(condition, failAction) {
    this.failResult((0, codegen_1$n.not)(condition), void 0, failAction);
  }
  fail(condition) {
    if (condition === void 0) {
      this.error();
      if (!this.allErrors)
        this.gen.if(false);
      return;
    }
    this.gen.if(condition);
    this.error();
    if (this.allErrors)
      this.gen.endIf();
    else
      this.gen.else();
  }
  fail$data(condition) {
    if (!this.$data)
      return this.fail(condition);
    const { schemaCode } = this;
    this.fail((0, codegen_1$n._)`${schemaCode} !== undefined && (${(0, codegen_1$n.or)(this.invalid$data(), condition)})`);
  }
  error(append, errorParams, errorPaths) {
    if (errorParams) {
      this.setParams(errorParams);
      this._error(append, errorPaths);
      this.setParams({});
      return;
    }
    this._error(append, errorPaths);
  }
  _error(append, errorPaths) {
    (append ? errors_1.reportExtraError : errors_1.reportError)(this, this.def.error, errorPaths);
  }
  $dataError() {
    (0, errors_1.reportError)(this, this.def.$dataError || errors_1.keyword$DataError);
  }
  reset() {
    if (this.errsCount === void 0)
      throw new Error('add "trackErrors" to keyword definition');
    (0, errors_1.resetErrorsCount)(this.gen, this.errsCount);
  }
  ok(cond) {
    if (!this.allErrors)
      this.gen.if(cond);
  }
  setParams(obj, assign) {
    if (assign)
      Object.assign(this.params, obj);
    else
      this.params = obj;
  }
  block$data(valid2, codeBlock, $dataValid = codegen_1$n.nil) {
    this.gen.block(() => {
      this.check$data(valid2, $dataValid);
      codeBlock();
    });
  }
  check$data(valid2 = codegen_1$n.nil, $dataValid = codegen_1$n.nil) {
    if (!this.$data)
      return;
    const { gen, schemaCode, schemaType, def: def2 } = this;
    gen.if((0, codegen_1$n.or)((0, codegen_1$n._)`${schemaCode} === undefined`, $dataValid));
    if (valid2 !== codegen_1$n.nil)
      gen.assign(valid2, true);
    if (schemaType.length || def2.validateSchema) {
      gen.elseIf(this.invalid$data());
      this.$dataError();
      if (valid2 !== codegen_1$n.nil)
        gen.assign(valid2, false);
    }
    gen.else();
  }
  invalid$data() {
    const { gen, schemaCode, schemaType, def: def2, it } = this;
    return (0, codegen_1$n.or)(wrong$DataType(), invalid$DataSchema());
    function wrong$DataType() {
      if (schemaType.length) {
        if (!(schemaCode instanceof codegen_1$n.Name))
          throw new Error("ajv implementation error");
        const st = Array.isArray(schemaType) ? schemaType : [schemaType];
        return (0, codegen_1$n._)`${(0, dataType_2.checkDataTypes)(st, schemaCode, it.opts.strictNumbers, dataType_2.DataType.Wrong)}`;
      }
      return codegen_1$n.nil;
    }
    function invalid$DataSchema() {
      if (def2.validateSchema) {
        const validateSchemaRef = gen.scopeValue("validate$data", { ref: def2.validateSchema });
        return (0, codegen_1$n._)`!${validateSchemaRef}(${schemaCode})`;
      }
      return codegen_1$n.nil;
    }
  }
  subschema(appl, valid2) {
    const subschema2 = (0, subschema_1.getSubschema)(this.it, appl);
    (0, subschema_1.extendSubschemaData)(subschema2, this.it, appl);
    (0, subschema_1.extendSubschemaMode)(subschema2, appl);
    const nextContext = { ...this.it, ...subschema2, items: void 0, props: void 0 };
    subschemaCode(nextContext, valid2);
    return nextContext;
  }
  mergeEvaluated(schemaCxt, toName) {
    const { it, gen } = this;
    if (!it.opts.unevaluated)
      return;
    if (it.props !== true && schemaCxt.props !== void 0) {
      it.props = util_1$m.mergeEvaluated.props(gen, schemaCxt.props, it.props, toName);
    }
    if (it.items !== true && schemaCxt.items !== void 0) {
      it.items = util_1$m.mergeEvaluated.items(gen, schemaCxt.items, it.items, toName);
    }
  }
  mergeValidEvaluated(schemaCxt, valid2) {
    const { it, gen } = this;
    if (it.opts.unevaluated && (it.props !== true || it.items !== true)) {
      gen.if(valid2, () => this.mergeEvaluated(schemaCxt, codegen_1$n.Name));
      return true;
    }
  }
}
validate.KeywordCxt = KeywordCxt;
function keywordCode(it, keyword2, def2, ruleType) {
  const cxt = new KeywordCxt(it, def2, keyword2);
  if ("code" in def2) {
    def2.code(cxt, ruleType);
  } else if (cxt.$data && def2.validate) {
    (0, keyword_1.funcKeywordCode)(cxt, def2);
  } else if ("macro" in def2) {
    (0, keyword_1.macroKeywordCode)(cxt, def2);
  } else if (def2.compile || def2.validate) {
    (0, keyword_1.funcKeywordCode)(cxt, def2);
  }
}
const JSON_POINTER = /^\/(?:[^~]|~0|~1)*$/;
const RELATIVE_JSON_POINTER = /^([0-9]+)(#|\/(?:[^~]|~0|~1)*)?$/;
function getData($data, { dataLevel, dataNames, dataPathArr }) {
  let jsonPointer;
  let data;
  if ($data === "")
    return names_1$3.default.rootData;
  if ($data[0] === "/") {
    if (!JSON_POINTER.test($data))
      throw new Error(`Invalid JSON-pointer: ${$data}`);
    jsonPointer = $data;
    data = names_1$3.default.rootData;
  } else {
    const matches = RELATIVE_JSON_POINTER.exec($data);
    if (!matches)
      throw new Error(`Invalid JSON-pointer: ${$data}`);
    const up = +matches[1];
    jsonPointer = matches[2];
    if (jsonPointer === "#") {
      if (up >= dataLevel)
        throw new Error(errorMsg("property/index", up));
      return dataPathArr[dataLevel - up];
    }
    if (up > dataLevel)
      throw new Error(errorMsg("data", up));
    data = dataNames[dataLevel - up];
    if (!jsonPointer)
      return data;
  }
  let expr = data;
  const segments = jsonPointer.split("/");
  for (const segment of segments) {
    if (segment) {
      data = (0, codegen_1$n._)`${data}${(0, codegen_1$n.getProperty)((0, util_1$m.unescapeJsonPointer)(segment))}`;
      expr = (0, codegen_1$n._)`${expr} && ${data}`;
    }
  }
  return expr;
  function errorMsg(pointerType, up) {
    return `Cannot access ${pointerType} ${up} levels up, current level is ${dataLevel}`;
  }
}
validate.getData = getData;
var validation_error = {};
Object.defineProperty(validation_error, "__esModule", { value: true });
class ValidationError extends Error {
  constructor(errors2) {
    super("validation failed");
    this.errors = errors2;
    this.ajv = this.validation = true;
  }
}
validation_error.default = ValidationError;
var ref_error = {};
Object.defineProperty(ref_error, "__esModule", { value: true });
const resolve_1$1 = resolve$1;
class MissingRefError extends Error {
  constructor(resolver, baseId, ref2, msg) {
    super(msg || `can't resolve reference ${ref2} from id ${baseId}`);
    this.missingRef = (0, resolve_1$1.resolveUrl)(resolver, baseId, ref2);
    this.missingSchema = (0, resolve_1$1.normalizeId)((0, resolve_1$1.getFullPath)(resolver, this.missingRef));
  }
}
ref_error.default = MissingRefError;
var compile = {};
Object.defineProperty(compile, "__esModule", { value: true });
compile.resolveSchema = compile.getCompilingSchema = compile.resolveRef = compile.compileSchema = compile.SchemaEnv = void 0;
const codegen_1$m = codegen;
const validation_error_1 = validation_error;
const names_1$2 = names$1;
const resolve_1 = resolve$1;
const util_1$l = util$1;
const validate_1$1 = validate;
class SchemaEnv {
  constructor(env2) {
    var _a2;
    this.refs = {};
    this.dynamicAnchors = {};
    let schema;
    if (typeof env2.schema == "object")
      schema = env2.schema;
    this.schema = env2.schema;
    this.schemaId = env2.schemaId;
    this.root = env2.root || this;
    this.baseId = (_a2 = env2.baseId) !== null && _a2 !== void 0 ? _a2 : (0, resolve_1.normalizeId)(schema === null || schema === void 0 ? void 0 : schema[env2.schemaId || "$id"]);
    this.schemaPath = env2.schemaPath;
    this.localRefs = env2.localRefs;
    this.meta = env2.meta;
    this.$async = schema === null || schema === void 0 ? void 0 : schema.$async;
    this.refs = {};
  }
}
compile.SchemaEnv = SchemaEnv;
function compileSchema(sch) {
  const _sch = getCompilingSchema.call(this, sch);
  if (_sch)
    return _sch;
  const rootId = (0, resolve_1.getFullPath)(this.opts.uriResolver, sch.root.baseId);
  const { es5, lines } = this.opts.code;
  const { ownProperties } = this.opts;
  const gen = new codegen_1$m.CodeGen(this.scope, { es5, lines, ownProperties });
  let _ValidationError;
  if (sch.$async) {
    _ValidationError = gen.scopeValue("Error", {
      ref: validation_error_1.default,
      code: (0, codegen_1$m._)`require("ajv/dist/runtime/validation_error").default`
    });
  }
  const validateName = gen.scopeName("validate");
  sch.validateName = validateName;
  const schemaCxt = {
    gen,
    allErrors: this.opts.allErrors,
    data: names_1$2.default.data,
    parentData: names_1$2.default.parentData,
    parentDataProperty: names_1$2.default.parentDataProperty,
    dataNames: [names_1$2.default.data],
    dataPathArr: [codegen_1$m.nil],
    // TODO can its length be used as dataLevel if nil is removed?
    dataLevel: 0,
    dataTypes: [],
    definedProperties: /* @__PURE__ */ new Set(),
    topSchemaRef: gen.scopeValue("schema", this.opts.code.source === true ? { ref: sch.schema, code: (0, codegen_1$m.stringify)(sch.schema) } : { ref: sch.schema }),
    validateName,
    ValidationError: _ValidationError,
    schema: sch.schema,
    schemaEnv: sch,
    rootId,
    baseId: sch.baseId || rootId,
    schemaPath: codegen_1$m.nil,
    errSchemaPath: sch.schemaPath || (this.opts.jtd ? "" : "#"),
    errorPath: (0, codegen_1$m._)`""`,
    opts: this.opts,
    self: this
  };
  let sourceCode;
  try {
    this._compilations.add(sch);
    (0, validate_1$1.validateFunctionCode)(schemaCxt);
    gen.optimize(this.opts.code.optimize);
    const validateCode = gen.toString();
    sourceCode = `${gen.scopeRefs(names_1$2.default.scope)}return ${validateCode}`;
    if (this.opts.code.process)
      sourceCode = this.opts.code.process(sourceCode, sch);
    const makeValidate = new Function(`${names_1$2.default.self}`, `${names_1$2.default.scope}`, sourceCode);
    const validate2 = makeValidate(this, this.scope.get());
    this.scope.value(validateName, { ref: validate2 });
    validate2.errors = null;
    validate2.schema = sch.schema;
    validate2.schemaEnv = sch;
    if (sch.$async)
      validate2.$async = true;
    if (this.opts.code.source === true) {
      validate2.source = { validateName, validateCode, scopeValues: gen._values };
    }
    if (this.opts.unevaluated) {
      const { props, items: items2 } = schemaCxt;
      validate2.evaluated = {
        props: props instanceof codegen_1$m.Name ? void 0 : props,
        items: items2 instanceof codegen_1$m.Name ? void 0 : items2,
        dynamicProps: props instanceof codegen_1$m.Name,
        dynamicItems: items2 instanceof codegen_1$m.Name
      };
      if (validate2.source)
        validate2.source.evaluated = (0, codegen_1$m.stringify)(validate2.evaluated);
    }
    sch.validate = validate2;
    return sch;
  } catch (e) {
    delete sch.validate;
    delete sch.validateName;
    if (sourceCode)
      this.logger.error("Error compiling schema, function code:", sourceCode);
    throw e;
  } finally {
    this._compilations.delete(sch);
  }
}
compile.compileSchema = compileSchema;
function resolveRef(root, baseId, ref2) {
  var _a2;
  ref2 = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, ref2);
  const schOrFunc = root.refs[ref2];
  if (schOrFunc)
    return schOrFunc;
  let _sch = resolve.call(this, root, ref2);
  if (_sch === void 0) {
    const schema = (_a2 = root.localRefs) === null || _a2 === void 0 ? void 0 : _a2[ref2];
    const { schemaId } = this.opts;
    if (schema)
      _sch = new SchemaEnv({ schema, schemaId, root, baseId });
  }
  if (_sch === void 0)
    return;
  return root.refs[ref2] = inlineOrCompile.call(this, _sch);
}
compile.resolveRef = resolveRef;
function inlineOrCompile(sch) {
  if ((0, resolve_1.inlineRef)(sch.schema, this.opts.inlineRefs))
    return sch.schema;
  return sch.validate ? sch : compileSchema.call(this, sch);
}
function getCompilingSchema(schEnv) {
  for (const sch of this._compilations) {
    if (sameSchemaEnv(sch, schEnv))
      return sch;
  }
}
compile.getCompilingSchema = getCompilingSchema;
function sameSchemaEnv(s1, s2) {
  return s1.schema === s2.schema && s1.root === s2.root && s1.baseId === s2.baseId;
}
function resolve(root, ref2) {
  let sch;
  while (typeof (sch = this.refs[ref2]) == "string")
    ref2 = sch;
  return sch || this.schemas[ref2] || resolveSchema.call(this, root, ref2);
}
function resolveSchema(root, ref2) {
  const p = this.opts.uriResolver.parse(ref2);
  const refPath = (0, resolve_1._getFullPath)(this.opts.uriResolver, p);
  let baseId = (0, resolve_1.getFullPath)(this.opts.uriResolver, root.baseId, void 0);
  if (Object.keys(root.schema).length > 0 && refPath === baseId) {
    return getJsonPointer.call(this, p, root);
  }
  const id2 = (0, resolve_1.normalizeId)(refPath);
  const schOrRef = this.refs[id2] || this.schemas[id2];
  if (typeof schOrRef == "string") {
    const sch = resolveSchema.call(this, root, schOrRef);
    if (typeof (sch === null || sch === void 0 ? void 0 : sch.schema) !== "object")
      return;
    return getJsonPointer.call(this, p, sch);
  }
  if (typeof (schOrRef === null || schOrRef === void 0 ? void 0 : schOrRef.schema) !== "object")
    return;
  if (!schOrRef.validate)
    compileSchema.call(this, schOrRef);
  if (id2 === (0, resolve_1.normalizeId)(ref2)) {
    const { schema } = schOrRef;
    const { schemaId } = this.opts;
    const schId = schema[schemaId];
    if (schId)
      baseId = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, schId);
    return new SchemaEnv({ schema, schemaId, root, baseId });
  }
  return getJsonPointer.call(this, p, schOrRef);
}
compile.resolveSchema = resolveSchema;
const PREVENT_SCOPE_CHANGE = /* @__PURE__ */ new Set([
  "properties",
  "patternProperties",
  "enum",
  "dependencies",
  "definitions"
]);
function getJsonPointer(parsedRef, { baseId, schema, root }) {
  var _a2;
  if (((_a2 = parsedRef.fragment) === null || _a2 === void 0 ? void 0 : _a2[0]) !== "/")
    return;
  for (const part of parsedRef.fragment.slice(1).split("/")) {
    if (typeof schema === "boolean")
      return;
    const partSchema = schema[(0, util_1$l.unescapeFragment)(part)];
    if (partSchema === void 0)
      return;
    schema = partSchema;
    const schId = typeof schema === "object" && schema[this.opts.schemaId];
    if (!PREVENT_SCOPE_CHANGE.has(part) && schId) {
      baseId = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, schId);
    }
  }
  let env2;
  if (typeof schema != "boolean" && schema.$ref && !(0, util_1$l.schemaHasRulesButRef)(schema, this.RULES)) {
    const $ref = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, schema.$ref);
    env2 = resolveSchema.call(this, root, $ref);
  }
  const { schemaId } = this.opts;
  env2 = env2 || new SchemaEnv({ schema, schemaId, root, baseId });
  if (env2.schema !== env2.root.schema)
    return env2;
  return void 0;
}
const $id$1 = "https://raw.githubusercontent.com/ajv-validator/ajv/master/lib/refs/data.json#";
const description = "Meta-schema for $data reference (JSON AnySchema extension proposal)";
const type$1 = "object";
const required$1 = [
  "$data"
];
const properties$2 = {
  $data: {
    type: "string",
    anyOf: [
      {
        format: "relative-json-pointer"
      },
      {
        format: "json-pointer"
      }
    ]
  }
};
const additionalProperties$1 = false;
const require$$9 = {
  $id: $id$1,
  description,
  type: type$1,
  required: required$1,
  properties: properties$2,
  additionalProperties: additionalProperties$1
};
var uri$1 = {};
Object.defineProperty(uri$1, "__esModule", { value: true });
const uri = fastUriExports;
uri.code = 'require("ajv/dist/runtime/uri").default';
uri$1.default = uri;
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.CodeGen = exports$12.Name = exports$12.nil = exports$12.stringify = exports$12.str = exports$12._ = exports$12.KeywordCxt = void 0;
  var validate_12 = validate;
  Object.defineProperty(exports$12, "KeywordCxt", { enumerable: true, get: function() {
    return validate_12.KeywordCxt;
  } });
  var codegen_12 = codegen;
  Object.defineProperty(exports$12, "_", { enumerable: true, get: function() {
    return codegen_12._;
  } });
  Object.defineProperty(exports$12, "str", { enumerable: true, get: function() {
    return codegen_12.str;
  } });
  Object.defineProperty(exports$12, "stringify", { enumerable: true, get: function() {
    return codegen_12.stringify;
  } });
  Object.defineProperty(exports$12, "nil", { enumerable: true, get: function() {
    return codegen_12.nil;
  } });
  Object.defineProperty(exports$12, "Name", { enumerable: true, get: function() {
    return codegen_12.Name;
  } });
  Object.defineProperty(exports$12, "CodeGen", { enumerable: true, get: function() {
    return codegen_12.CodeGen;
  } });
  const validation_error_12 = validation_error;
  const ref_error_12 = ref_error;
  const rules_12 = rules;
  const compile_12 = compile;
  const codegen_2 = codegen;
  const resolve_12 = resolve$1;
  const dataType_12 = dataType;
  const util_12 = util$1;
  const $dataRefSchema = require$$9;
  const uri_1 = uri$1;
  const defaultRegExp = (str, flags) => new RegExp(str, flags);
  defaultRegExp.code = "new RegExp";
  const META_IGNORE_OPTIONS = ["removeAdditional", "useDefaults", "coerceTypes"];
  const EXT_SCOPE_NAMES = /* @__PURE__ */ new Set([
    "validate",
    "serialize",
    "parse",
    "wrapper",
    "root",
    "schema",
    "keyword",
    "pattern",
    "formats",
    "validate$data",
    "func",
    "obj",
    "Error"
  ]);
  const removedOptions = {
    errorDataPath: "",
    format: "`validateFormats: false` can be used instead.",
    nullable: '"nullable" keyword is supported by default.',
    jsonPointers: "Deprecated jsPropertySyntax can be used instead.",
    extendRefs: "Deprecated ignoreKeywordsWithRef can be used instead.",
    missingRefs: "Pass empty schema with $id that should be ignored to ajv.addSchema.",
    processCode: "Use option `code: {process: (code, schemaEnv: object) => string}`",
    sourceCode: "Use option `code: {source: true}`",
    strictDefaults: "It is default now, see option `strict`.",
    strictKeywords: "It is default now, see option `strict`.",
    uniqueItems: '"uniqueItems" keyword is always validated.',
    unknownFormats: "Disable strict mode or pass `true` to `ajv.addFormat` (or `formats` option).",
    cache: "Map is used as cache, schema object as key.",
    serialize: "Map is used as cache, schema object as key.",
    ajvErrors: "It is default now."
  };
  const deprecatedOptions = {
    ignoreKeywordsWithRef: "",
    jsPropertySyntax: "",
    unicode: '"minLength"/"maxLength" account for unicode characters by default.'
  };
  const MAX_EXPRESSION = 200;
  function requiredOptions(o) {
    var _a2, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v, _w, _x, _y, _z, _0;
    const s = o.strict;
    const _optz = (_a2 = o.code) === null || _a2 === void 0 ? void 0 : _a2.optimize;
    const optimize = _optz === true || _optz === void 0 ? 1 : _optz || 0;
    const regExp = (_c = (_b = o.code) === null || _b === void 0 ? void 0 : _b.regExp) !== null && _c !== void 0 ? _c : defaultRegExp;
    const uriResolver = (_d = o.uriResolver) !== null && _d !== void 0 ? _d : uri_1.default;
    return {
      strictSchema: (_f = (_e = o.strictSchema) !== null && _e !== void 0 ? _e : s) !== null && _f !== void 0 ? _f : true,
      strictNumbers: (_h = (_g = o.strictNumbers) !== null && _g !== void 0 ? _g : s) !== null && _h !== void 0 ? _h : true,
      strictTypes: (_k = (_j = o.strictTypes) !== null && _j !== void 0 ? _j : s) !== null && _k !== void 0 ? _k : "log",
      strictTuples: (_m = (_l = o.strictTuples) !== null && _l !== void 0 ? _l : s) !== null && _m !== void 0 ? _m : "log",
      strictRequired: (_p = (_o = o.strictRequired) !== null && _o !== void 0 ? _o : s) !== null && _p !== void 0 ? _p : false,
      code: o.code ? { ...o.code, optimize, regExp } : { optimize, regExp },
      loopRequired: (_q = o.loopRequired) !== null && _q !== void 0 ? _q : MAX_EXPRESSION,
      loopEnum: (_r = o.loopEnum) !== null && _r !== void 0 ? _r : MAX_EXPRESSION,
      meta: (_s = o.meta) !== null && _s !== void 0 ? _s : true,
      messages: (_t = o.messages) !== null && _t !== void 0 ? _t : true,
      inlineRefs: (_u = o.inlineRefs) !== null && _u !== void 0 ? _u : true,
      schemaId: (_v = o.schemaId) !== null && _v !== void 0 ? _v : "$id",
      addUsedSchema: (_w = o.addUsedSchema) !== null && _w !== void 0 ? _w : true,
      validateSchema: (_x = o.validateSchema) !== null && _x !== void 0 ? _x : true,
      validateFormats: (_y = o.validateFormats) !== null && _y !== void 0 ? _y : true,
      unicodeRegExp: (_z = o.unicodeRegExp) !== null && _z !== void 0 ? _z : true,
      int32range: (_0 = o.int32range) !== null && _0 !== void 0 ? _0 : true,
      uriResolver
    };
  }
  class Ajv {
    constructor(opts = {}) {
      this.schemas = {};
      this.refs = {};
      this.formats = {};
      this._compilations = /* @__PURE__ */ new Set();
      this._loading = {};
      this._cache = /* @__PURE__ */ new Map();
      opts = this.opts = { ...opts, ...requiredOptions(opts) };
      const { es5, lines } = this.opts.code;
      this.scope = new codegen_2.ValueScope({ scope: {}, prefixes: EXT_SCOPE_NAMES, es5, lines });
      this.logger = getLogger(opts.logger);
      const formatOpt = opts.validateFormats;
      opts.validateFormats = false;
      this.RULES = (0, rules_12.getRules)();
      checkOptions.call(this, removedOptions, opts, "NOT SUPPORTED");
      checkOptions.call(this, deprecatedOptions, opts, "DEPRECATED", "warn");
      this._metaOpts = getMetaSchemaOptions.call(this);
      if (opts.formats)
        addInitialFormats.call(this);
      this._addVocabularies();
      this._addDefaultMetaSchema();
      if (opts.keywords)
        addInitialKeywords.call(this, opts.keywords);
      if (typeof opts.meta == "object")
        this.addMetaSchema(opts.meta);
      addInitialSchemas.call(this);
      opts.validateFormats = formatOpt;
    }
    _addVocabularies() {
      this.addKeyword("$async");
    }
    _addDefaultMetaSchema() {
      const { $data, meta, schemaId } = this.opts;
      let _dataRefSchema = $dataRefSchema;
      if (schemaId === "id") {
        _dataRefSchema = { ...$dataRefSchema };
        _dataRefSchema.id = _dataRefSchema.$id;
        delete _dataRefSchema.$id;
      }
      if (meta && $data)
        this.addMetaSchema(_dataRefSchema, _dataRefSchema[schemaId], false);
    }
    defaultMeta() {
      const { meta, schemaId } = this.opts;
      return this.opts.defaultMeta = typeof meta == "object" ? meta[schemaId] || meta : void 0;
    }
    validate(schemaKeyRef, data) {
      let v;
      if (typeof schemaKeyRef == "string") {
        v = this.getSchema(schemaKeyRef);
        if (!v)
          throw new Error(`no schema with key or ref "${schemaKeyRef}"`);
      } else {
        v = this.compile(schemaKeyRef);
      }
      const valid2 = v(data);
      if (!("$async" in v))
        this.errors = v.errors;
      return valid2;
    }
    compile(schema, _meta) {
      const sch = this._addSchema(schema, _meta);
      return sch.validate || this._compileSchemaEnv(sch);
    }
    compileAsync(schema, meta) {
      if (typeof this.opts.loadSchema != "function") {
        throw new Error("options.loadSchema should be a function");
      }
      const { loadSchema } = this.opts;
      return runCompileAsync.call(this, schema, meta);
      async function runCompileAsync(_schema, _meta) {
        await loadMetaSchema.call(this, _schema.$schema);
        const sch = this._addSchema(_schema, _meta);
        return sch.validate || _compileAsync.call(this, sch);
      }
      async function loadMetaSchema($ref) {
        if ($ref && !this.getSchema($ref)) {
          await runCompileAsync.call(this, { $ref }, true);
        }
      }
      async function _compileAsync(sch) {
        try {
          return this._compileSchemaEnv(sch);
        } catch (e) {
          if (!(e instanceof ref_error_12.default))
            throw e;
          checkLoaded.call(this, e);
          await loadMissingSchema.call(this, e.missingSchema);
          return _compileAsync.call(this, sch);
        }
      }
      function checkLoaded({ missingSchema: ref2, missingRef }) {
        if (this.refs[ref2]) {
          throw new Error(`AnySchema ${ref2} is loaded but ${missingRef} cannot be resolved`);
        }
      }
      async function loadMissingSchema(ref2) {
        const _schema = await _loadSchema.call(this, ref2);
        if (!this.refs[ref2])
          await loadMetaSchema.call(this, _schema.$schema);
        if (!this.refs[ref2])
          this.addSchema(_schema, ref2, meta);
      }
      async function _loadSchema(ref2) {
        const p = this._loading[ref2];
        if (p)
          return p;
        try {
          return await (this._loading[ref2] = loadSchema(ref2));
        } finally {
          delete this._loading[ref2];
        }
      }
    }
    // Adds schema to the instance
    addSchema(schema, key, _meta, _validateSchema = this.opts.validateSchema) {
      if (Array.isArray(schema)) {
        for (const sch of schema)
          this.addSchema(sch, void 0, _meta, _validateSchema);
        return this;
      }
      let id2;
      if (typeof schema === "object") {
        const { schemaId } = this.opts;
        id2 = schema[schemaId];
        if (id2 !== void 0 && typeof id2 != "string") {
          throw new Error(`schema ${schemaId} must be string`);
        }
      }
      key = (0, resolve_12.normalizeId)(key || id2);
      this._checkUnique(key);
      this.schemas[key] = this._addSchema(schema, _meta, key, _validateSchema, true);
      return this;
    }
    // Add schema that will be used to validate other schemas
    // options in META_IGNORE_OPTIONS are alway set to false
    addMetaSchema(schema, key, _validateSchema = this.opts.validateSchema) {
      this.addSchema(schema, key, true, _validateSchema);
      return this;
    }
    //  Validate schema against its meta-schema
    validateSchema(schema, throwOrLogError) {
      if (typeof schema == "boolean")
        return true;
      let $schema2;
      $schema2 = schema.$schema;
      if ($schema2 !== void 0 && typeof $schema2 != "string") {
        throw new Error("$schema must be a string");
      }
      $schema2 = $schema2 || this.opts.defaultMeta || this.defaultMeta();
      if (!$schema2) {
        this.logger.warn("meta-schema not available");
        this.errors = null;
        return true;
      }
      const valid2 = this.validate($schema2, schema);
      if (!valid2 && throwOrLogError) {
        const message = "schema is invalid: " + this.errorsText();
        if (this.opts.validateSchema === "log")
          this.logger.error(message);
        else
          throw new Error(message);
      }
      return valid2;
    }
    // Get compiled schema by `key` or `ref`.
    // (`key` that was passed to `addSchema` or full schema reference - `schema.$id` or resolved id)
    getSchema(keyRef) {
      let sch;
      while (typeof (sch = getSchEnv.call(this, keyRef)) == "string")
        keyRef = sch;
      if (sch === void 0) {
        const { schemaId } = this.opts;
        const root = new compile_12.SchemaEnv({ schema: {}, schemaId });
        sch = compile_12.resolveSchema.call(this, root, keyRef);
        if (!sch)
          return;
        this.refs[keyRef] = sch;
      }
      return sch.validate || this._compileSchemaEnv(sch);
    }
    // Remove cached schema(s).
    // If no parameter is passed all schemas but meta-schemas are removed.
    // If RegExp is passed all schemas with key/id matching pattern but meta-schemas are removed.
    // Even if schema is referenced by other schemas it still can be removed as other schemas have local references.
    removeSchema(schemaKeyRef) {
      if (schemaKeyRef instanceof RegExp) {
        this._removeAllSchemas(this.schemas, schemaKeyRef);
        this._removeAllSchemas(this.refs, schemaKeyRef);
        return this;
      }
      switch (typeof schemaKeyRef) {
        case "undefined":
          this._removeAllSchemas(this.schemas);
          this._removeAllSchemas(this.refs);
          this._cache.clear();
          return this;
        case "string": {
          const sch = getSchEnv.call(this, schemaKeyRef);
          if (typeof sch == "object")
            this._cache.delete(sch.schema);
          delete this.schemas[schemaKeyRef];
          delete this.refs[schemaKeyRef];
          return this;
        }
        case "object": {
          const cacheKey = schemaKeyRef;
          this._cache.delete(cacheKey);
          let id2 = schemaKeyRef[this.opts.schemaId];
          if (id2) {
            id2 = (0, resolve_12.normalizeId)(id2);
            delete this.schemas[id2];
            delete this.refs[id2];
          }
          return this;
        }
        default:
          throw new Error("ajv.removeSchema: invalid parameter");
      }
    }
    // add "vocabulary" - a collection of keywords
    addVocabulary(definitions2) {
      for (const def2 of definitions2)
        this.addKeyword(def2);
      return this;
    }
    addKeyword(kwdOrDef, def2) {
      let keyword2;
      if (typeof kwdOrDef == "string") {
        keyword2 = kwdOrDef;
        if (typeof def2 == "object") {
          this.logger.warn("these parameters are deprecated, see docs for addKeyword");
          def2.keyword = keyword2;
        }
      } else if (typeof kwdOrDef == "object" && def2 === void 0) {
        def2 = kwdOrDef;
        keyword2 = def2.keyword;
        if (Array.isArray(keyword2) && !keyword2.length) {
          throw new Error("addKeywords: keyword must be string or non-empty array");
        }
      } else {
        throw new Error("invalid addKeywords parameters");
      }
      checkKeyword.call(this, keyword2, def2);
      if (!def2) {
        (0, util_12.eachItem)(keyword2, (kwd) => addRule.call(this, kwd));
        return this;
      }
      keywordMetaschema.call(this, def2);
      const definition = {
        ...def2,
        type: (0, dataType_12.getJSONTypes)(def2.type),
        schemaType: (0, dataType_12.getJSONTypes)(def2.schemaType)
      };
      (0, util_12.eachItem)(keyword2, definition.type.length === 0 ? (k) => addRule.call(this, k, definition) : (k) => definition.type.forEach((t2) => addRule.call(this, k, definition, t2)));
      return this;
    }
    getKeyword(keyword2) {
      const rule = this.RULES.all[keyword2];
      return typeof rule == "object" ? rule.definition : !!rule;
    }
    // Remove keyword
    removeKeyword(keyword2) {
      const { RULES } = this;
      delete RULES.keywords[keyword2];
      delete RULES.all[keyword2];
      for (const group of RULES.rules) {
        const i2 = group.rules.findIndex((rule) => rule.keyword === keyword2);
        if (i2 >= 0)
          group.rules.splice(i2, 1);
      }
      return this;
    }
    // Add format
    addFormat(name2, format2) {
      if (typeof format2 == "string")
        format2 = new RegExp(format2);
      this.formats[name2] = format2;
      return this;
    }
    errorsText(errors2 = this.errors, { separator = ", ", dataVar = "data" } = {}) {
      if (!errors2 || errors2.length === 0)
        return "No errors";
      return errors2.map((e) => `${dataVar}${e.instancePath} ${e.message}`).reduce((text, msg) => text + separator + msg);
    }
    $dataMetaSchema(metaSchema2, keywordsJsonPointers) {
      const rules2 = this.RULES.all;
      metaSchema2 = JSON.parse(JSON.stringify(metaSchema2));
      for (const jsonPointer of keywordsJsonPointers) {
        const segments = jsonPointer.split("/").slice(1);
        let keywords = metaSchema2;
        for (const seg of segments)
          keywords = keywords[seg];
        for (const key in rules2) {
          const rule = rules2[key];
          if (typeof rule != "object")
            continue;
          const { $data } = rule.definition;
          const schema = keywords[key];
          if ($data && schema)
            keywords[key] = schemaOrData(schema);
        }
      }
      return metaSchema2;
    }
    _removeAllSchemas(schemas, regex) {
      for (const keyRef in schemas) {
        const sch = schemas[keyRef];
        if (!regex || regex.test(keyRef)) {
          if (typeof sch == "string") {
            delete schemas[keyRef];
          } else if (sch && !sch.meta) {
            this._cache.delete(sch.schema);
            delete schemas[keyRef];
          }
        }
      }
    }
    _addSchema(schema, meta, baseId, validateSchema = this.opts.validateSchema, addSchema = this.opts.addUsedSchema) {
      let id2;
      const { schemaId } = this.opts;
      if (typeof schema == "object") {
        id2 = schema[schemaId];
      } else {
        if (this.opts.jtd)
          throw new Error("schema must be object");
        else if (typeof schema != "boolean")
          throw new Error("schema must be object or boolean");
      }
      let sch = this._cache.get(schema);
      if (sch !== void 0)
        return sch;
      baseId = (0, resolve_12.normalizeId)(id2 || baseId);
      const localRefs = resolve_12.getSchemaRefs.call(this, schema, baseId);
      sch = new compile_12.SchemaEnv({ schema, schemaId, meta, baseId, localRefs });
      this._cache.set(sch.schema, sch);
      if (addSchema && !baseId.startsWith("#")) {
        if (baseId)
          this._checkUnique(baseId);
        this.refs[baseId] = sch;
      }
      if (validateSchema)
        this.validateSchema(schema, true);
      return sch;
    }
    _checkUnique(id2) {
      if (this.schemas[id2] || this.refs[id2]) {
        throw new Error(`schema with key or id "${id2}" already exists`);
      }
    }
    _compileSchemaEnv(sch) {
      if (sch.meta)
        this._compileMetaSchema(sch);
      else
        compile_12.compileSchema.call(this, sch);
      if (!sch.validate)
        throw new Error("ajv implementation error");
      return sch.validate;
    }
    _compileMetaSchema(sch) {
      const currentOpts = this.opts;
      this.opts = this._metaOpts;
      try {
        compile_12.compileSchema.call(this, sch);
      } finally {
        this.opts = currentOpts;
      }
    }
  }
  Ajv.ValidationError = validation_error_12.default;
  Ajv.MissingRefError = ref_error_12.default;
  exports$12.default = Ajv;
  function checkOptions(checkOpts, options, msg, log2 = "error") {
    for (const key in checkOpts) {
      const opt = key;
      if (opt in options)
        this.logger[log2](`${msg}: option ${key}. ${checkOpts[opt]}`);
    }
  }
  function getSchEnv(keyRef) {
    keyRef = (0, resolve_12.normalizeId)(keyRef);
    return this.schemas[keyRef] || this.refs[keyRef];
  }
  function addInitialSchemas() {
    const optsSchemas = this.opts.schemas;
    if (!optsSchemas)
      return;
    if (Array.isArray(optsSchemas))
      this.addSchema(optsSchemas);
    else
      for (const key in optsSchemas)
        this.addSchema(optsSchemas[key], key);
  }
  function addInitialFormats() {
    for (const name2 in this.opts.formats) {
      const format2 = this.opts.formats[name2];
      if (format2)
        this.addFormat(name2, format2);
    }
  }
  function addInitialKeywords(defs) {
    if (Array.isArray(defs)) {
      this.addVocabulary(defs);
      return;
    }
    this.logger.warn("keywords option as map is deprecated, pass array");
    for (const keyword2 in defs) {
      const def2 = defs[keyword2];
      if (!def2.keyword)
        def2.keyword = keyword2;
      this.addKeyword(def2);
    }
  }
  function getMetaSchemaOptions() {
    const metaOpts = { ...this.opts };
    for (const opt of META_IGNORE_OPTIONS)
      delete metaOpts[opt];
    return metaOpts;
  }
  const noLogs = { log() {
  }, warn() {
  }, error() {
  } };
  function getLogger(logger) {
    if (logger === false)
      return noLogs;
    if (logger === void 0)
      return console;
    if (logger.log && logger.warn && logger.error)
      return logger;
    throw new Error("logger must implement log, warn and error methods");
  }
  const KEYWORD_NAME = /^[a-z_$][a-z0-9_$:-]*$/i;
  function checkKeyword(keyword2, def2) {
    const { RULES } = this;
    (0, util_12.eachItem)(keyword2, (kwd) => {
      if (RULES.keywords[kwd])
        throw new Error(`Keyword ${kwd} is already defined`);
      if (!KEYWORD_NAME.test(kwd))
        throw new Error(`Keyword ${kwd} has invalid name`);
    });
    if (!def2)
      return;
    if (def2.$data && !("code" in def2 || "validate" in def2)) {
      throw new Error('$data keyword must have "code" or "validate" function');
    }
  }
  function addRule(keyword2, definition, dataType2) {
    var _a2;
    const post = definition === null || definition === void 0 ? void 0 : definition.post;
    if (dataType2 && post)
      throw new Error('keyword with "post" flag cannot have "type"');
    const { RULES } = this;
    let ruleGroup = post ? RULES.post : RULES.rules.find(({ type: t2 }) => t2 === dataType2);
    if (!ruleGroup) {
      ruleGroup = { type: dataType2, rules: [] };
      RULES.rules.push(ruleGroup);
    }
    RULES.keywords[keyword2] = true;
    if (!definition)
      return;
    const rule = {
      keyword: keyword2,
      definition: {
        ...definition,
        type: (0, dataType_12.getJSONTypes)(definition.type),
        schemaType: (0, dataType_12.getJSONTypes)(definition.schemaType)
      }
    };
    if (definition.before)
      addBeforeRule.call(this, ruleGroup, rule, definition.before);
    else
      ruleGroup.rules.push(rule);
    RULES.all[keyword2] = rule;
    (_a2 = definition.implements) === null || _a2 === void 0 ? void 0 : _a2.forEach((kwd) => this.addKeyword(kwd));
  }
  function addBeforeRule(ruleGroup, rule, before) {
    const i2 = ruleGroup.rules.findIndex((_rule) => _rule.keyword === before);
    if (i2 >= 0) {
      ruleGroup.rules.splice(i2, 0, rule);
    } else {
      ruleGroup.rules.push(rule);
      this.logger.warn(`rule ${before} is not defined`);
    }
  }
  function keywordMetaschema(def2) {
    let { metaSchema: metaSchema2 } = def2;
    if (metaSchema2 === void 0)
      return;
    if (def2.$data && this.opts.$data)
      metaSchema2 = schemaOrData(metaSchema2);
    def2.validateSchema = this.compile(metaSchema2, true);
  }
  const $dataRef = {
    $ref: "https://raw.githubusercontent.com/ajv-validator/ajv/master/lib/refs/data.json#"
  };
  function schemaOrData(schema) {
    return { anyOf: [schema, $dataRef] };
  }
})(core$2);
var draft7 = {};
var core$1 = {};
var id = {};
Object.defineProperty(id, "__esModule", { value: true });
const def$s = {
  keyword: "id",
  code() {
    throw new Error('NOT SUPPORTED: keyword "id", use "$id" for schema ID');
  }
};
id.default = def$s;
var ref = {};
Object.defineProperty(ref, "__esModule", { value: true });
ref.callRef = ref.getValidate = void 0;
const ref_error_1$1 = ref_error;
const code_1$8 = code;
const codegen_1$l = codegen;
const names_1$1 = names$1;
const compile_1$1 = compile;
const util_1$k = util$1;
const def$r = {
  keyword: "$ref",
  schemaType: "string",
  code(cxt) {
    const { gen, schema: $ref, it } = cxt;
    const { baseId, schemaEnv: env2, validateName, opts, self: self2 } = it;
    const { root } = env2;
    if (($ref === "#" || $ref === "#/") && baseId === root.baseId)
      return callRootRef();
    const schOrEnv = compile_1$1.resolveRef.call(self2, root, baseId, $ref);
    if (schOrEnv === void 0)
      throw new ref_error_1$1.default(it.opts.uriResolver, baseId, $ref);
    if (schOrEnv instanceof compile_1$1.SchemaEnv)
      return callValidate(schOrEnv);
    return inlineRefSchema(schOrEnv);
    function callRootRef() {
      if (env2 === root)
        return callRef(cxt, validateName, env2, env2.$async);
      const rootName = gen.scopeValue("root", { ref: root });
      return callRef(cxt, (0, codegen_1$l._)`${rootName}.validate`, root, root.$async);
    }
    function callValidate(sch) {
      const v = getValidate(cxt, sch);
      callRef(cxt, v, sch, sch.$async);
    }
    function inlineRefSchema(sch) {
      const schName = gen.scopeValue("schema", opts.code.source === true ? { ref: sch, code: (0, codegen_1$l.stringify)(sch) } : { ref: sch });
      const valid2 = gen.name("valid");
      const schCxt = cxt.subschema({
        schema: sch,
        dataTypes: [],
        schemaPath: codegen_1$l.nil,
        topSchemaRef: schName,
        errSchemaPath: $ref
      }, valid2);
      cxt.mergeEvaluated(schCxt);
      cxt.ok(valid2);
    }
  }
};
function getValidate(cxt, sch) {
  const { gen } = cxt;
  return sch.validate ? gen.scopeValue("validate", { ref: sch.validate }) : (0, codegen_1$l._)`${gen.scopeValue("wrapper", { ref: sch })}.validate`;
}
ref.getValidate = getValidate;
function callRef(cxt, v, sch, $async) {
  const { gen, it } = cxt;
  const { allErrors, schemaEnv: env2, opts } = it;
  const passCxt = opts.passContext ? names_1$1.default.this : codegen_1$l.nil;
  if ($async)
    callAsyncRef();
  else
    callSyncRef();
  function callAsyncRef() {
    if (!env2.$async)
      throw new Error("async schema referenced by sync schema");
    const valid2 = gen.let("valid");
    gen.try(() => {
      gen.code((0, codegen_1$l._)`await ${(0, code_1$8.callValidateCode)(cxt, v, passCxt)}`);
      addEvaluatedFrom(v);
      if (!allErrors)
        gen.assign(valid2, true);
    }, (e) => {
      gen.if((0, codegen_1$l._)`!(${e} instanceof ${it.ValidationError})`, () => gen.throw(e));
      addErrorsFrom(e);
      if (!allErrors)
        gen.assign(valid2, false);
    });
    cxt.ok(valid2);
  }
  function callSyncRef() {
    cxt.result((0, code_1$8.callValidateCode)(cxt, v, passCxt), () => addEvaluatedFrom(v), () => addErrorsFrom(v));
  }
  function addErrorsFrom(source) {
    const errs = (0, codegen_1$l._)`${source}.errors`;
    gen.assign(names_1$1.default.vErrors, (0, codegen_1$l._)`${names_1$1.default.vErrors} === null ? ${errs} : ${names_1$1.default.vErrors}.concat(${errs})`);
    gen.assign(names_1$1.default.errors, (0, codegen_1$l._)`${names_1$1.default.vErrors}.length`);
  }
  function addEvaluatedFrom(source) {
    var _a2;
    if (!it.opts.unevaluated)
      return;
    const schEvaluated = (_a2 = sch === null || sch === void 0 ? void 0 : sch.validate) === null || _a2 === void 0 ? void 0 : _a2.evaluated;
    if (it.props !== true) {
      if (schEvaluated && !schEvaluated.dynamicProps) {
        if (schEvaluated.props !== void 0) {
          it.props = util_1$k.mergeEvaluated.props(gen, schEvaluated.props, it.props);
        }
      } else {
        const props = gen.var("props", (0, codegen_1$l._)`${source}.evaluated.props`);
        it.props = util_1$k.mergeEvaluated.props(gen, props, it.props, codegen_1$l.Name);
      }
    }
    if (it.items !== true) {
      if (schEvaluated && !schEvaluated.dynamicItems) {
        if (schEvaluated.items !== void 0) {
          it.items = util_1$k.mergeEvaluated.items(gen, schEvaluated.items, it.items);
        }
      } else {
        const items2 = gen.var("items", (0, codegen_1$l._)`${source}.evaluated.items`);
        it.items = util_1$k.mergeEvaluated.items(gen, items2, it.items, codegen_1$l.Name);
      }
    }
  }
}
ref.callRef = callRef;
ref.default = def$r;
Object.defineProperty(core$1, "__esModule", { value: true });
const id_1 = id;
const ref_1 = ref;
const core = [
  "$schema",
  "$id",
  "$defs",
  "$vocabulary",
  { keyword: "$comment" },
  "definitions",
  id_1.default,
  ref_1.default
];
core$1.default = core;
var validation$1 = {};
var limitNumber = {};
Object.defineProperty(limitNumber, "__esModule", { value: true });
const codegen_1$k = codegen;
const ops = codegen_1$k.operators;
const KWDs = {
  maximum: { okStr: "<=", ok: ops.LTE, fail: ops.GT },
  minimum: { okStr: ">=", ok: ops.GTE, fail: ops.LT },
  exclusiveMaximum: { okStr: "<", ok: ops.LT, fail: ops.GTE },
  exclusiveMinimum: { okStr: ">", ok: ops.GT, fail: ops.LTE }
};
const error$i = {
  message: ({ keyword: keyword2, schemaCode }) => (0, codegen_1$k.str)`must be ${KWDs[keyword2].okStr} ${schemaCode}`,
  params: ({ keyword: keyword2, schemaCode }) => (0, codegen_1$k._)`{comparison: ${KWDs[keyword2].okStr}, limit: ${schemaCode}}`
};
const def$q = {
  keyword: Object.keys(KWDs),
  type: "number",
  schemaType: "number",
  $data: true,
  error: error$i,
  code(cxt) {
    const { keyword: keyword2, data, schemaCode } = cxt;
    cxt.fail$data((0, codegen_1$k._)`${data} ${KWDs[keyword2].fail} ${schemaCode} || isNaN(${data})`);
  }
};
limitNumber.default = def$q;
var multipleOf = {};
Object.defineProperty(multipleOf, "__esModule", { value: true });
const codegen_1$j = codegen;
const error$h = {
  message: ({ schemaCode }) => (0, codegen_1$j.str)`must be multiple of ${schemaCode}`,
  params: ({ schemaCode }) => (0, codegen_1$j._)`{multipleOf: ${schemaCode}}`
};
const def$p = {
  keyword: "multipleOf",
  type: "number",
  schemaType: "number",
  $data: true,
  error: error$h,
  code(cxt) {
    const { gen, data, schemaCode, it } = cxt;
    const prec = it.opts.multipleOfPrecision;
    const res = gen.let("res");
    const invalid = prec ? (0, codegen_1$j._)`Math.abs(Math.round(${res}) - ${res}) > 1e-${prec}` : (0, codegen_1$j._)`${res} !== parseInt(${res})`;
    cxt.fail$data((0, codegen_1$j._)`(${schemaCode} === 0 || (${res} = ${data}/${schemaCode}, ${invalid}))`);
  }
};
multipleOf.default = def$p;
var limitLength = {};
var ucs2length$1 = {};
Object.defineProperty(ucs2length$1, "__esModule", { value: true });
function ucs2length(str) {
  const len = str.length;
  let length = 0;
  let pos = 0;
  let value;
  while (pos < len) {
    length++;
    value = str.charCodeAt(pos++);
    if (value >= 55296 && value <= 56319 && pos < len) {
      value = str.charCodeAt(pos);
      if ((value & 64512) === 56320)
        pos++;
    }
  }
  return length;
}
ucs2length$1.default = ucs2length;
ucs2length.code = 'require("ajv/dist/runtime/ucs2length").default';
Object.defineProperty(limitLength, "__esModule", { value: true });
const codegen_1$i = codegen;
const util_1$j = util$1;
const ucs2length_1 = ucs2length$1;
const error$g = {
  message({ keyword: keyword2, schemaCode }) {
    const comp = keyword2 === "maxLength" ? "more" : "fewer";
    return (0, codegen_1$i.str)`must NOT have ${comp} than ${schemaCode} characters`;
  },
  params: ({ schemaCode }) => (0, codegen_1$i._)`{limit: ${schemaCode}}`
};
const def$o = {
  keyword: ["maxLength", "minLength"],
  type: "string",
  schemaType: "number",
  $data: true,
  error: error$g,
  code(cxt) {
    const { keyword: keyword2, data, schemaCode, it } = cxt;
    const op = keyword2 === "maxLength" ? codegen_1$i.operators.GT : codegen_1$i.operators.LT;
    const len = it.opts.unicode === false ? (0, codegen_1$i._)`${data}.length` : (0, codegen_1$i._)`${(0, util_1$j.useFunc)(cxt.gen, ucs2length_1.default)}(${data})`;
    cxt.fail$data((0, codegen_1$i._)`${len} ${op} ${schemaCode}`);
  }
};
limitLength.default = def$o;
var pattern = {};
Object.defineProperty(pattern, "__esModule", { value: true });
const code_1$7 = code;
const util_1$i = util$1;
const codegen_1$h = codegen;
const error$f = {
  message: ({ schemaCode }) => (0, codegen_1$h.str)`must match pattern "${schemaCode}"`,
  params: ({ schemaCode }) => (0, codegen_1$h._)`{pattern: ${schemaCode}}`
};
const def$n = {
  keyword: "pattern",
  type: "string",
  schemaType: "string",
  $data: true,
  error: error$f,
  code(cxt) {
    const { gen, data, $data, schema, schemaCode, it } = cxt;
    const u = it.opts.unicodeRegExp ? "u" : "";
    if ($data) {
      const { regExp } = it.opts.code;
      const regExpCode = regExp.code === "new RegExp" ? (0, codegen_1$h._)`new RegExp` : (0, util_1$i.useFunc)(gen, regExp);
      const valid2 = gen.let("valid");
      gen.try(() => gen.assign(valid2, (0, codegen_1$h._)`${regExpCode}(${schemaCode}, ${u}).test(${data})`), () => gen.assign(valid2, false));
      cxt.fail$data((0, codegen_1$h._)`!${valid2}`);
    } else {
      const regExp = (0, code_1$7.usePattern)(cxt, schema);
      cxt.fail$data((0, codegen_1$h._)`!${regExp}.test(${data})`);
    }
  }
};
pattern.default = def$n;
var limitProperties = {};
Object.defineProperty(limitProperties, "__esModule", { value: true });
const codegen_1$g = codegen;
const error$e = {
  message({ keyword: keyword2, schemaCode }) {
    const comp = keyword2 === "maxProperties" ? "more" : "fewer";
    return (0, codegen_1$g.str)`must NOT have ${comp} than ${schemaCode} properties`;
  },
  params: ({ schemaCode }) => (0, codegen_1$g._)`{limit: ${schemaCode}}`
};
const def$m = {
  keyword: ["maxProperties", "minProperties"],
  type: "object",
  schemaType: "number",
  $data: true,
  error: error$e,
  code(cxt) {
    const { keyword: keyword2, data, schemaCode } = cxt;
    const op = keyword2 === "maxProperties" ? codegen_1$g.operators.GT : codegen_1$g.operators.LT;
    cxt.fail$data((0, codegen_1$g._)`Object.keys(${data}).length ${op} ${schemaCode}`);
  }
};
limitProperties.default = def$m;
var required = {};
Object.defineProperty(required, "__esModule", { value: true });
const code_1$6 = code;
const codegen_1$f = codegen;
const util_1$h = util$1;
const error$d = {
  message: ({ params: { missingProperty } }) => (0, codegen_1$f.str)`must have required property '${missingProperty}'`,
  params: ({ params: { missingProperty } }) => (0, codegen_1$f._)`{missingProperty: ${missingProperty}}`
};
const def$l = {
  keyword: "required",
  type: "object",
  schemaType: "array",
  $data: true,
  error: error$d,
  code(cxt) {
    const { gen, schema, schemaCode, data, $data, it } = cxt;
    const { opts } = it;
    if (!$data && schema.length === 0)
      return;
    const useLoop = schema.length >= opts.loopRequired;
    if (it.allErrors)
      allErrorsMode();
    else
      exitOnErrorMode();
    if (opts.strictRequired) {
      const props = cxt.parentSchema.properties;
      const { definedProperties } = cxt.it;
      for (const requiredKey of schema) {
        if ((props === null || props === void 0 ? void 0 : props[requiredKey]) === void 0 && !definedProperties.has(requiredKey)) {
          const schemaPath = it.schemaEnv.baseId + it.errSchemaPath;
          const msg = `required property "${requiredKey}" is not defined at "${schemaPath}" (strictRequired)`;
          (0, util_1$h.checkStrictMode)(it, msg, it.opts.strictRequired);
        }
      }
    }
    function allErrorsMode() {
      if (useLoop || $data) {
        cxt.block$data(codegen_1$f.nil, loopAllRequired);
      } else {
        for (const prop of schema) {
          (0, code_1$6.checkReportMissingProp)(cxt, prop);
        }
      }
    }
    function exitOnErrorMode() {
      const missing = gen.let("missing");
      if (useLoop || $data) {
        const valid2 = gen.let("valid", true);
        cxt.block$data(valid2, () => loopUntilMissing(missing, valid2));
        cxt.ok(valid2);
      } else {
        gen.if((0, code_1$6.checkMissingProp)(cxt, schema, missing));
        (0, code_1$6.reportMissingProp)(cxt, missing);
        gen.else();
      }
    }
    function loopAllRequired() {
      gen.forOf("prop", schemaCode, (prop) => {
        cxt.setParams({ missingProperty: prop });
        gen.if((0, code_1$6.noPropertyInData)(gen, data, prop, opts.ownProperties), () => cxt.error());
      });
    }
    function loopUntilMissing(missing, valid2) {
      cxt.setParams({ missingProperty: missing });
      gen.forOf(missing, schemaCode, () => {
        gen.assign(valid2, (0, code_1$6.propertyInData)(gen, data, missing, opts.ownProperties));
        gen.if((0, codegen_1$f.not)(valid2), () => {
          cxt.error();
          gen.break();
        });
      }, codegen_1$f.nil);
    }
  }
};
required.default = def$l;
var limitItems = {};
Object.defineProperty(limitItems, "__esModule", { value: true });
const codegen_1$e = codegen;
const error$c = {
  message({ keyword: keyword2, schemaCode }) {
    const comp = keyword2 === "maxItems" ? "more" : "fewer";
    return (0, codegen_1$e.str)`must NOT have ${comp} than ${schemaCode} items`;
  },
  params: ({ schemaCode }) => (0, codegen_1$e._)`{limit: ${schemaCode}}`
};
const def$k = {
  keyword: ["maxItems", "minItems"],
  type: "array",
  schemaType: "number",
  $data: true,
  error: error$c,
  code(cxt) {
    const { keyword: keyword2, data, schemaCode } = cxt;
    const op = keyword2 === "maxItems" ? codegen_1$e.operators.GT : codegen_1$e.operators.LT;
    cxt.fail$data((0, codegen_1$e._)`${data}.length ${op} ${schemaCode}`);
  }
};
limitItems.default = def$k;
var uniqueItems = {};
var equal$1 = {};
Object.defineProperty(equal$1, "__esModule", { value: true });
const equal = fastDeepEqual;
equal.code = 'require("ajv/dist/runtime/equal").default';
equal$1.default = equal;
Object.defineProperty(uniqueItems, "__esModule", { value: true });
const dataType_1 = dataType;
const codegen_1$d = codegen;
const util_1$g = util$1;
const equal_1$2 = equal$1;
const error$b = {
  message: ({ params: { i: i2, j } }) => (0, codegen_1$d.str)`must NOT have duplicate items (items ## ${j} and ${i2} are identical)`,
  params: ({ params: { i: i2, j } }) => (0, codegen_1$d._)`{i: ${i2}, j: ${j}}`
};
const def$j = {
  keyword: "uniqueItems",
  type: "array",
  schemaType: "boolean",
  $data: true,
  error: error$b,
  code(cxt) {
    const { gen, data, $data, schema, parentSchema, schemaCode, it } = cxt;
    if (!$data && !schema)
      return;
    const valid2 = gen.let("valid");
    const itemTypes = parentSchema.items ? (0, dataType_1.getSchemaTypes)(parentSchema.items) : [];
    cxt.block$data(valid2, validateUniqueItems, (0, codegen_1$d._)`${schemaCode} === false`);
    cxt.ok(valid2);
    function validateUniqueItems() {
      const i2 = gen.let("i", (0, codegen_1$d._)`${data}.length`);
      const j = gen.let("j");
      cxt.setParams({ i: i2, j });
      gen.assign(valid2, true);
      gen.if((0, codegen_1$d._)`${i2} > 1`, () => (canOptimize() ? loopN : loopN2)(i2, j));
    }
    function canOptimize() {
      return itemTypes.length > 0 && !itemTypes.some((t2) => t2 === "object" || t2 === "array");
    }
    function loopN(i2, j) {
      const item = gen.name("item");
      const wrongType = (0, dataType_1.checkDataTypes)(itemTypes, item, it.opts.strictNumbers, dataType_1.DataType.Wrong);
      const indices = gen.const("indices", (0, codegen_1$d._)`{}`);
      gen.for((0, codegen_1$d._)`;${i2}--;`, () => {
        gen.let(item, (0, codegen_1$d._)`${data}[${i2}]`);
        gen.if(wrongType, (0, codegen_1$d._)`continue`);
        if (itemTypes.length > 1)
          gen.if((0, codegen_1$d._)`typeof ${item} == "string"`, (0, codegen_1$d._)`${item} += "_"`);
        gen.if((0, codegen_1$d._)`typeof ${indices}[${item}] == "number"`, () => {
          gen.assign(j, (0, codegen_1$d._)`${indices}[${item}]`);
          cxt.error();
          gen.assign(valid2, false).break();
        }).code((0, codegen_1$d._)`${indices}[${item}] = ${i2}`);
      });
    }
    function loopN2(i2, j) {
      const eql = (0, util_1$g.useFunc)(gen, equal_1$2.default);
      const outer = gen.name("outer");
      gen.label(outer).for((0, codegen_1$d._)`;${i2}--;`, () => gen.for((0, codegen_1$d._)`${j} = ${i2}; ${j}--;`, () => gen.if((0, codegen_1$d._)`${eql}(${data}[${i2}], ${data}[${j}])`, () => {
        cxt.error();
        gen.assign(valid2, false).break(outer);
      })));
    }
  }
};
uniqueItems.default = def$j;
var _const = {};
Object.defineProperty(_const, "__esModule", { value: true });
const codegen_1$c = codegen;
const util_1$f = util$1;
const equal_1$1 = equal$1;
const error$a = {
  message: "must be equal to constant",
  params: ({ schemaCode }) => (0, codegen_1$c._)`{allowedValue: ${schemaCode}}`
};
const def$i = {
  keyword: "const",
  $data: true,
  error: error$a,
  code(cxt) {
    const { gen, data, $data, schemaCode, schema } = cxt;
    if ($data || schema && typeof schema == "object") {
      cxt.fail$data((0, codegen_1$c._)`!${(0, util_1$f.useFunc)(gen, equal_1$1.default)}(${data}, ${schemaCode})`);
    } else {
      cxt.fail((0, codegen_1$c._)`${schema} !== ${data}`);
    }
  }
};
_const.default = def$i;
var _enum = {};
Object.defineProperty(_enum, "__esModule", { value: true });
const codegen_1$b = codegen;
const util_1$e = util$1;
const equal_1 = equal$1;
const error$9 = {
  message: "must be equal to one of the allowed values",
  params: ({ schemaCode }) => (0, codegen_1$b._)`{allowedValues: ${schemaCode}}`
};
const def$h = {
  keyword: "enum",
  schemaType: "array",
  $data: true,
  error: error$9,
  code(cxt) {
    const { gen, data, $data, schema, schemaCode, it } = cxt;
    if (!$data && schema.length === 0)
      throw new Error("enum must have non-empty array");
    const useLoop = schema.length >= it.opts.loopEnum;
    let eql;
    const getEql = () => eql !== null && eql !== void 0 ? eql : eql = (0, util_1$e.useFunc)(gen, equal_1.default);
    let valid2;
    if (useLoop || $data) {
      valid2 = gen.let("valid");
      cxt.block$data(valid2, loopEnum);
    } else {
      if (!Array.isArray(schema))
        throw new Error("ajv implementation error");
      const vSchema = gen.const("vSchema", schemaCode);
      valid2 = (0, codegen_1$b.or)(...schema.map((_x, i2) => equalCode(vSchema, i2)));
    }
    cxt.pass(valid2);
    function loopEnum() {
      gen.assign(valid2, false);
      gen.forOf("v", schemaCode, (v) => gen.if((0, codegen_1$b._)`${getEql()}(${data}, ${v})`, () => gen.assign(valid2, true).break()));
    }
    function equalCode(vSchema, i2) {
      const sch = schema[i2];
      return typeof sch === "object" && sch !== null ? (0, codegen_1$b._)`${getEql()}(${data}, ${vSchema}[${i2}])` : (0, codegen_1$b._)`${data} === ${sch}`;
    }
  }
};
_enum.default = def$h;
Object.defineProperty(validation$1, "__esModule", { value: true });
const limitNumber_1 = limitNumber;
const multipleOf_1 = multipleOf;
const limitLength_1 = limitLength;
const pattern_1 = pattern;
const limitProperties_1 = limitProperties;
const required_1 = required;
const limitItems_1 = limitItems;
const uniqueItems_1 = uniqueItems;
const const_1 = _const;
const enum_1 = _enum;
const validation = [
  // number
  limitNumber_1.default,
  multipleOf_1.default,
  // string
  limitLength_1.default,
  pattern_1.default,
  // object
  limitProperties_1.default,
  required_1.default,
  // array
  limitItems_1.default,
  uniqueItems_1.default,
  // any
  { keyword: "type", schemaType: ["string", "array"] },
  { keyword: "nullable", schemaType: "boolean" },
  const_1.default,
  enum_1.default
];
validation$1.default = validation;
var applicator = {};
var additionalItems = {};
Object.defineProperty(additionalItems, "__esModule", { value: true });
additionalItems.validateAdditionalItems = void 0;
const codegen_1$a = codegen;
const util_1$d = util$1;
const error$8 = {
  message: ({ params: { len } }) => (0, codegen_1$a.str)`must NOT have more than ${len} items`,
  params: ({ params: { len } }) => (0, codegen_1$a._)`{limit: ${len}}`
};
const def$g = {
  keyword: "additionalItems",
  type: "array",
  schemaType: ["boolean", "object"],
  before: "uniqueItems",
  error: error$8,
  code(cxt) {
    const { parentSchema, it } = cxt;
    const { items: items2 } = parentSchema;
    if (!Array.isArray(items2)) {
      (0, util_1$d.checkStrictMode)(it, '"additionalItems" is ignored when "items" is not an array of schemas');
      return;
    }
    validateAdditionalItems(cxt, items2);
  }
};
function validateAdditionalItems(cxt, items2) {
  const { gen, schema, data, keyword: keyword2, it } = cxt;
  it.items = true;
  const len = gen.const("len", (0, codegen_1$a._)`${data}.length`);
  if (schema === false) {
    cxt.setParams({ len: items2.length });
    cxt.pass((0, codegen_1$a._)`${len} <= ${items2.length}`);
  } else if (typeof schema == "object" && !(0, util_1$d.alwaysValidSchema)(it, schema)) {
    const valid2 = gen.var("valid", (0, codegen_1$a._)`${len} <= ${items2.length}`);
    gen.if((0, codegen_1$a.not)(valid2), () => validateItems(valid2));
    cxt.ok(valid2);
  }
  function validateItems(valid2) {
    gen.forRange("i", items2.length, len, (i2) => {
      cxt.subschema({ keyword: keyword2, dataProp: i2, dataPropType: util_1$d.Type.Num }, valid2);
      if (!it.allErrors)
        gen.if((0, codegen_1$a.not)(valid2), () => gen.break());
    });
  }
}
additionalItems.validateAdditionalItems = validateAdditionalItems;
additionalItems.default = def$g;
var prefixItems = {};
var items = {};
Object.defineProperty(items, "__esModule", { value: true });
items.validateTuple = void 0;
const codegen_1$9 = codegen;
const util_1$c = util$1;
const code_1$5 = code;
const def$f = {
  keyword: "items",
  type: "array",
  schemaType: ["object", "array", "boolean"],
  before: "uniqueItems",
  code(cxt) {
    const { schema, it } = cxt;
    if (Array.isArray(schema))
      return validateTuple(cxt, "additionalItems", schema);
    it.items = true;
    if ((0, util_1$c.alwaysValidSchema)(it, schema))
      return;
    cxt.ok((0, code_1$5.validateArray)(cxt));
  }
};
function validateTuple(cxt, extraItems, schArr = cxt.schema) {
  const { gen, parentSchema, data, keyword: keyword2, it } = cxt;
  checkStrictTuple(parentSchema);
  if (it.opts.unevaluated && schArr.length && it.items !== true) {
    it.items = util_1$c.mergeEvaluated.items(gen, schArr.length, it.items);
  }
  const valid2 = gen.name("valid");
  const len = gen.const("len", (0, codegen_1$9._)`${data}.length`);
  schArr.forEach((sch, i2) => {
    if ((0, util_1$c.alwaysValidSchema)(it, sch))
      return;
    gen.if((0, codegen_1$9._)`${len} > ${i2}`, () => cxt.subschema({
      keyword: keyword2,
      schemaProp: i2,
      dataProp: i2
    }, valid2));
    cxt.ok(valid2);
  });
  function checkStrictTuple(sch) {
    const { opts, errSchemaPath } = it;
    const l = schArr.length;
    const fullTuple = l === sch.minItems && (l === sch.maxItems || sch[extraItems] === false);
    if (opts.strictTuples && !fullTuple) {
      const msg = `"${keyword2}" is ${l}-tuple, but minItems or maxItems/${extraItems} are not specified or different at path "${errSchemaPath}"`;
      (0, util_1$c.checkStrictMode)(it, msg, opts.strictTuples);
    }
  }
}
items.validateTuple = validateTuple;
items.default = def$f;
Object.defineProperty(prefixItems, "__esModule", { value: true });
const items_1$1 = items;
const def$e = {
  keyword: "prefixItems",
  type: "array",
  schemaType: ["array"],
  before: "uniqueItems",
  code: (cxt) => (0, items_1$1.validateTuple)(cxt, "items")
};
prefixItems.default = def$e;
var items2020 = {};
Object.defineProperty(items2020, "__esModule", { value: true });
const codegen_1$8 = codegen;
const util_1$b = util$1;
const code_1$4 = code;
const additionalItems_1$1 = additionalItems;
const error$7 = {
  message: ({ params: { len } }) => (0, codegen_1$8.str)`must NOT have more than ${len} items`,
  params: ({ params: { len } }) => (0, codegen_1$8._)`{limit: ${len}}`
};
const def$d = {
  keyword: "items",
  type: "array",
  schemaType: ["object", "boolean"],
  before: "uniqueItems",
  error: error$7,
  code(cxt) {
    const { schema, parentSchema, it } = cxt;
    const { prefixItems: prefixItems2 } = parentSchema;
    it.items = true;
    if ((0, util_1$b.alwaysValidSchema)(it, schema))
      return;
    if (prefixItems2)
      (0, additionalItems_1$1.validateAdditionalItems)(cxt, prefixItems2);
    else
      cxt.ok((0, code_1$4.validateArray)(cxt));
  }
};
items2020.default = def$d;
var contains = {};
Object.defineProperty(contains, "__esModule", { value: true });
const codegen_1$7 = codegen;
const util_1$a = util$1;
const error$6 = {
  message: ({ params: { min: min2, max: max2 } }) => max2 === void 0 ? (0, codegen_1$7.str)`must contain at least ${min2} valid item(s)` : (0, codegen_1$7.str)`must contain at least ${min2} and no more than ${max2} valid item(s)`,
  params: ({ params: { min: min2, max: max2 } }) => max2 === void 0 ? (0, codegen_1$7._)`{minContains: ${min2}}` : (0, codegen_1$7._)`{minContains: ${min2}, maxContains: ${max2}}`
};
const def$c = {
  keyword: "contains",
  type: "array",
  schemaType: ["object", "boolean"],
  before: "uniqueItems",
  trackErrors: true,
  error: error$6,
  code(cxt) {
    const { gen, schema, parentSchema, data, it } = cxt;
    let min2;
    let max2;
    const { minContains, maxContains } = parentSchema;
    if (it.opts.next) {
      min2 = minContains === void 0 ? 1 : minContains;
      max2 = maxContains;
    } else {
      min2 = 1;
    }
    const len = gen.const("len", (0, codegen_1$7._)`${data}.length`);
    cxt.setParams({ min: min2, max: max2 });
    if (max2 === void 0 && min2 === 0) {
      (0, util_1$a.checkStrictMode)(it, `"minContains" == 0 without "maxContains": "contains" keyword ignored`);
      return;
    }
    if (max2 !== void 0 && min2 > max2) {
      (0, util_1$a.checkStrictMode)(it, `"minContains" > "maxContains" is always invalid`);
      cxt.fail();
      return;
    }
    if ((0, util_1$a.alwaysValidSchema)(it, schema)) {
      let cond = (0, codegen_1$7._)`${len} >= ${min2}`;
      if (max2 !== void 0)
        cond = (0, codegen_1$7._)`${cond} && ${len} <= ${max2}`;
      cxt.pass(cond);
      return;
    }
    it.items = true;
    const valid2 = gen.name("valid");
    if (max2 === void 0 && min2 === 1) {
      validateItems(valid2, () => gen.if(valid2, () => gen.break()));
    } else if (min2 === 0) {
      gen.let(valid2, true);
      if (max2 !== void 0)
        gen.if((0, codegen_1$7._)`${data}.length > 0`, validateItemsWithCount);
    } else {
      gen.let(valid2, false);
      validateItemsWithCount();
    }
    cxt.result(valid2, () => cxt.reset());
    function validateItemsWithCount() {
      const schValid = gen.name("_valid");
      const count = gen.let("count", 0);
      validateItems(schValid, () => gen.if(schValid, () => checkLimits(count)));
    }
    function validateItems(_valid, block2) {
      gen.forRange("i", 0, len, (i2) => {
        cxt.subschema({
          keyword: "contains",
          dataProp: i2,
          dataPropType: util_1$a.Type.Num,
          compositeRule: true
        }, _valid);
        block2();
      });
    }
    function checkLimits(count) {
      gen.code((0, codegen_1$7._)`${count}++`);
      if (max2 === void 0) {
        gen.if((0, codegen_1$7._)`${count} >= ${min2}`, () => gen.assign(valid2, true).break());
      } else {
        gen.if((0, codegen_1$7._)`${count} > ${max2}`, () => gen.assign(valid2, false).break());
        if (min2 === 1)
          gen.assign(valid2, true);
        else
          gen.if((0, codegen_1$7._)`${count} >= ${min2}`, () => gen.assign(valid2, true));
      }
    }
  }
};
contains.default = def$c;
var dependencies = {};
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.validateSchemaDeps = exports$12.validatePropertyDeps = exports$12.error = void 0;
  const codegen_12 = codegen;
  const util_12 = util$1;
  const code_12 = code;
  exports$12.error = {
    message: ({ params: { property, depsCount, deps } }) => {
      const property_ies = depsCount === 1 ? "property" : "properties";
      return (0, codegen_12.str)`must have ${property_ies} ${deps} when property ${property} is present`;
    },
    params: ({ params: { property, depsCount, deps, missingProperty } }) => (0, codegen_12._)`{property: ${property},
    missingProperty: ${missingProperty},
    depsCount: ${depsCount},
    deps: ${deps}}`
    // TODO change to reference
  };
  const def2 = {
    keyword: "dependencies",
    type: "object",
    schemaType: "object",
    error: exports$12.error,
    code(cxt) {
      const [propDeps, schDeps] = splitDependencies(cxt);
      validatePropertyDeps(cxt, propDeps);
      validateSchemaDeps(cxt, schDeps);
    }
  };
  function splitDependencies({ schema }) {
    const propertyDeps = {};
    const schemaDeps = {};
    for (const key in schema) {
      if (key === "__proto__")
        continue;
      const deps = Array.isArray(schema[key]) ? propertyDeps : schemaDeps;
      deps[key] = schema[key];
    }
    return [propertyDeps, schemaDeps];
  }
  function validatePropertyDeps(cxt, propertyDeps = cxt.schema) {
    const { gen, data, it } = cxt;
    if (Object.keys(propertyDeps).length === 0)
      return;
    const missing = gen.let("missing");
    for (const prop in propertyDeps) {
      const deps = propertyDeps[prop];
      if (deps.length === 0)
        continue;
      const hasProperty2 = (0, code_12.propertyInData)(gen, data, prop, it.opts.ownProperties);
      cxt.setParams({
        property: prop,
        depsCount: deps.length,
        deps: deps.join(", ")
      });
      if (it.allErrors) {
        gen.if(hasProperty2, () => {
          for (const depProp of deps) {
            (0, code_12.checkReportMissingProp)(cxt, depProp);
          }
        });
      } else {
        gen.if((0, codegen_12._)`${hasProperty2} && (${(0, code_12.checkMissingProp)(cxt, deps, missing)})`);
        (0, code_12.reportMissingProp)(cxt, missing);
        gen.else();
      }
    }
  }
  exports$12.validatePropertyDeps = validatePropertyDeps;
  function validateSchemaDeps(cxt, schemaDeps = cxt.schema) {
    const { gen, data, keyword: keyword2, it } = cxt;
    const valid2 = gen.name("valid");
    for (const prop in schemaDeps) {
      if ((0, util_12.alwaysValidSchema)(it, schemaDeps[prop]))
        continue;
      gen.if(
        (0, code_12.propertyInData)(gen, data, prop, it.opts.ownProperties),
        () => {
          const schCxt = cxt.subschema({ keyword: keyword2, schemaProp: prop }, valid2);
          cxt.mergeValidEvaluated(schCxt, valid2);
        },
        () => gen.var(valid2, true)
        // TODO var
      );
      cxt.ok(valid2);
    }
  }
  exports$12.validateSchemaDeps = validateSchemaDeps;
  exports$12.default = def2;
})(dependencies);
var propertyNames = {};
Object.defineProperty(propertyNames, "__esModule", { value: true });
const codegen_1$6 = codegen;
const util_1$9 = util$1;
const error$5 = {
  message: "property name must be valid",
  params: ({ params }) => (0, codegen_1$6._)`{propertyName: ${params.propertyName}}`
};
const def$b = {
  keyword: "propertyNames",
  type: "object",
  schemaType: ["object", "boolean"],
  error: error$5,
  code(cxt) {
    const { gen, schema, data, it } = cxt;
    if ((0, util_1$9.alwaysValidSchema)(it, schema))
      return;
    const valid2 = gen.name("valid");
    gen.forIn("key", data, (key) => {
      cxt.setParams({ propertyName: key });
      cxt.subschema({
        keyword: "propertyNames",
        data: key,
        dataTypes: ["string"],
        propertyName: key,
        compositeRule: true
      }, valid2);
      gen.if((0, codegen_1$6.not)(valid2), () => {
        cxt.error(true);
        if (!it.allErrors)
          gen.break();
      });
    });
    cxt.ok(valid2);
  }
};
propertyNames.default = def$b;
var additionalProperties = {};
Object.defineProperty(additionalProperties, "__esModule", { value: true });
const code_1$3 = code;
const codegen_1$5 = codegen;
const names_1 = names$1;
const util_1$8 = util$1;
const error$4 = {
  message: "must NOT have additional properties",
  params: ({ params }) => (0, codegen_1$5._)`{additionalProperty: ${params.additionalProperty}}`
};
const def$a = {
  keyword: "additionalProperties",
  type: ["object"],
  schemaType: ["boolean", "object"],
  allowUndefined: true,
  trackErrors: true,
  error: error$4,
  code(cxt) {
    const { gen, schema, parentSchema, data, errsCount, it } = cxt;
    if (!errsCount)
      throw new Error("ajv implementation error");
    const { allErrors, opts } = it;
    it.props = true;
    if (opts.removeAdditional !== "all" && (0, util_1$8.alwaysValidSchema)(it, schema))
      return;
    const props = (0, code_1$3.allSchemaProperties)(parentSchema.properties);
    const patProps = (0, code_1$3.allSchemaProperties)(parentSchema.patternProperties);
    checkAdditionalProperties();
    cxt.ok((0, codegen_1$5._)`${errsCount} === ${names_1.default.errors}`);
    function checkAdditionalProperties() {
      gen.forIn("key", data, (key) => {
        if (!props.length && !patProps.length)
          additionalPropertyCode(key);
        else
          gen.if(isAdditional(key), () => additionalPropertyCode(key));
      });
    }
    function isAdditional(key) {
      let definedProp;
      if (props.length > 8) {
        const propsSchema = (0, util_1$8.schemaRefOrVal)(it, parentSchema.properties, "properties");
        definedProp = (0, code_1$3.isOwnProperty)(gen, propsSchema, key);
      } else if (props.length) {
        definedProp = (0, codegen_1$5.or)(...props.map((p) => (0, codegen_1$5._)`${key} === ${p}`));
      } else {
        definedProp = codegen_1$5.nil;
      }
      if (patProps.length) {
        definedProp = (0, codegen_1$5.or)(definedProp, ...patProps.map((p) => (0, codegen_1$5._)`${(0, code_1$3.usePattern)(cxt, p)}.test(${key})`));
      }
      return (0, codegen_1$5.not)(definedProp);
    }
    function deleteAdditional(key) {
      gen.code((0, codegen_1$5._)`delete ${data}[${key}]`);
    }
    function additionalPropertyCode(key) {
      if (opts.removeAdditional === "all" || opts.removeAdditional && schema === false) {
        deleteAdditional(key);
        return;
      }
      if (schema === false) {
        cxt.setParams({ additionalProperty: key });
        cxt.error();
        if (!allErrors)
          gen.break();
        return;
      }
      if (typeof schema == "object" && !(0, util_1$8.alwaysValidSchema)(it, schema)) {
        const valid2 = gen.name("valid");
        if (opts.removeAdditional === "failing") {
          applyAdditionalSchema(key, valid2, false);
          gen.if((0, codegen_1$5.not)(valid2), () => {
            cxt.reset();
            deleteAdditional(key);
          });
        } else {
          applyAdditionalSchema(key, valid2);
          if (!allErrors)
            gen.if((0, codegen_1$5.not)(valid2), () => gen.break());
        }
      }
    }
    function applyAdditionalSchema(key, valid2, errors2) {
      const subschema2 = {
        keyword: "additionalProperties",
        dataProp: key,
        dataPropType: util_1$8.Type.Str
      };
      if (errors2 === false) {
        Object.assign(subschema2, {
          compositeRule: true,
          createErrors: false,
          allErrors: false
        });
      }
      cxt.subschema(subschema2, valid2);
    }
  }
};
additionalProperties.default = def$a;
var properties$1 = {};
Object.defineProperty(properties$1, "__esModule", { value: true });
const validate_1 = validate;
const code_1$2 = code;
const util_1$7 = util$1;
const additionalProperties_1$1 = additionalProperties;
const def$9 = {
  keyword: "properties",
  type: "object",
  schemaType: "object",
  code(cxt) {
    const { gen, schema, parentSchema, data, it } = cxt;
    if (it.opts.removeAdditional === "all" && parentSchema.additionalProperties === void 0) {
      additionalProperties_1$1.default.code(new validate_1.KeywordCxt(it, additionalProperties_1$1.default, "additionalProperties"));
    }
    const allProps = (0, code_1$2.allSchemaProperties)(schema);
    for (const prop of allProps) {
      it.definedProperties.add(prop);
    }
    if (it.opts.unevaluated && allProps.length && it.props !== true) {
      it.props = util_1$7.mergeEvaluated.props(gen, (0, util_1$7.toHash)(allProps), it.props);
    }
    const properties2 = allProps.filter((p) => !(0, util_1$7.alwaysValidSchema)(it, schema[p]));
    if (properties2.length === 0)
      return;
    const valid2 = gen.name("valid");
    for (const prop of properties2) {
      if (hasDefault(prop)) {
        applyPropertySchema(prop);
      } else {
        gen.if((0, code_1$2.propertyInData)(gen, data, prop, it.opts.ownProperties));
        applyPropertySchema(prop);
        if (!it.allErrors)
          gen.else().var(valid2, true);
        gen.endIf();
      }
      cxt.it.definedProperties.add(prop);
      cxt.ok(valid2);
    }
    function hasDefault(prop) {
      return it.opts.useDefaults && !it.compositeRule && schema[prop].default !== void 0;
    }
    function applyPropertySchema(prop) {
      cxt.subschema({
        keyword: "properties",
        schemaProp: prop,
        dataProp: prop
      }, valid2);
    }
  }
};
properties$1.default = def$9;
var patternProperties = {};
Object.defineProperty(patternProperties, "__esModule", { value: true });
const code_1$1 = code;
const codegen_1$4 = codegen;
const util_1$6 = util$1;
const util_2 = util$1;
const def$8 = {
  keyword: "patternProperties",
  type: "object",
  schemaType: "object",
  code(cxt) {
    const { gen, schema, data, parentSchema, it } = cxt;
    const { opts } = it;
    const patterns = (0, code_1$1.allSchemaProperties)(schema);
    const alwaysValidPatterns = patterns.filter((p) => (0, util_1$6.alwaysValidSchema)(it, schema[p]));
    if (patterns.length === 0 || alwaysValidPatterns.length === patterns.length && (!it.opts.unevaluated || it.props === true)) {
      return;
    }
    const checkProperties = opts.strictSchema && !opts.allowMatchingProperties && parentSchema.properties;
    const valid2 = gen.name("valid");
    if (it.props !== true && !(it.props instanceof codegen_1$4.Name)) {
      it.props = (0, util_2.evaluatedPropsToName)(gen, it.props);
    }
    const { props } = it;
    validatePatternProperties();
    function validatePatternProperties() {
      for (const pat of patterns) {
        if (checkProperties)
          checkMatchingProperties(pat);
        if (it.allErrors) {
          validateProperties(pat);
        } else {
          gen.var(valid2, true);
          validateProperties(pat);
          gen.if(valid2);
        }
      }
    }
    function checkMatchingProperties(pat) {
      for (const prop in checkProperties) {
        if (new RegExp(pat).test(prop)) {
          (0, util_1$6.checkStrictMode)(it, `property ${prop} matches pattern ${pat} (use allowMatchingProperties)`);
        }
      }
    }
    function validateProperties(pat) {
      gen.forIn("key", data, (key) => {
        gen.if((0, codegen_1$4._)`${(0, code_1$1.usePattern)(cxt, pat)}.test(${key})`, () => {
          const alwaysValid = alwaysValidPatterns.includes(pat);
          if (!alwaysValid) {
            cxt.subschema({
              keyword: "patternProperties",
              schemaProp: pat,
              dataProp: key,
              dataPropType: util_2.Type.Str
            }, valid2);
          }
          if (it.opts.unevaluated && props !== true) {
            gen.assign((0, codegen_1$4._)`${props}[${key}]`, true);
          } else if (!alwaysValid && !it.allErrors) {
            gen.if((0, codegen_1$4.not)(valid2), () => gen.break());
          }
        });
      });
    }
  }
};
patternProperties.default = def$8;
var not = {};
Object.defineProperty(not, "__esModule", { value: true });
const util_1$5 = util$1;
const def$7 = {
  keyword: "not",
  schemaType: ["object", "boolean"],
  trackErrors: true,
  code(cxt) {
    const { gen, schema, it } = cxt;
    if ((0, util_1$5.alwaysValidSchema)(it, schema)) {
      cxt.fail();
      return;
    }
    const valid2 = gen.name("valid");
    cxt.subschema({
      keyword: "not",
      compositeRule: true,
      createErrors: false,
      allErrors: false
    }, valid2);
    cxt.failResult(valid2, () => cxt.reset(), () => cxt.error());
  },
  error: { message: "must NOT be valid" }
};
not.default = def$7;
var anyOf = {};
Object.defineProperty(anyOf, "__esModule", { value: true });
const code_1 = code;
const def$6 = {
  keyword: "anyOf",
  schemaType: "array",
  trackErrors: true,
  code: code_1.validateUnion,
  error: { message: "must match a schema in anyOf" }
};
anyOf.default = def$6;
var oneOf = {};
Object.defineProperty(oneOf, "__esModule", { value: true });
const codegen_1$3 = codegen;
const util_1$4 = util$1;
const error$3 = {
  message: "must match exactly one schema in oneOf",
  params: ({ params }) => (0, codegen_1$3._)`{passingSchemas: ${params.passing}}`
};
const def$5 = {
  keyword: "oneOf",
  schemaType: "array",
  trackErrors: true,
  error: error$3,
  code(cxt) {
    const { gen, schema, parentSchema, it } = cxt;
    if (!Array.isArray(schema))
      throw new Error("ajv implementation error");
    if (it.opts.discriminator && parentSchema.discriminator)
      return;
    const schArr = schema;
    const valid2 = gen.let("valid", false);
    const passing = gen.let("passing", null);
    const schValid = gen.name("_valid");
    cxt.setParams({ passing });
    gen.block(validateOneOf);
    cxt.result(valid2, () => cxt.reset(), () => cxt.error(true));
    function validateOneOf() {
      schArr.forEach((sch, i2) => {
        let schCxt;
        if ((0, util_1$4.alwaysValidSchema)(it, sch)) {
          gen.var(schValid, true);
        } else {
          schCxt = cxt.subschema({
            keyword: "oneOf",
            schemaProp: i2,
            compositeRule: true
          }, schValid);
        }
        if (i2 > 0) {
          gen.if((0, codegen_1$3._)`${schValid} && ${valid2}`).assign(valid2, false).assign(passing, (0, codegen_1$3._)`[${passing}, ${i2}]`).else();
        }
        gen.if(schValid, () => {
          gen.assign(valid2, true);
          gen.assign(passing, i2);
          if (schCxt)
            cxt.mergeEvaluated(schCxt, codegen_1$3.Name);
        });
      });
    }
  }
};
oneOf.default = def$5;
var allOf = {};
Object.defineProperty(allOf, "__esModule", { value: true });
const util_1$3 = util$1;
const def$4 = {
  keyword: "allOf",
  schemaType: "array",
  code(cxt) {
    const { gen, schema, it } = cxt;
    if (!Array.isArray(schema))
      throw new Error("ajv implementation error");
    const valid2 = gen.name("valid");
    schema.forEach((sch, i2) => {
      if ((0, util_1$3.alwaysValidSchema)(it, sch))
        return;
      const schCxt = cxt.subschema({ keyword: "allOf", schemaProp: i2 }, valid2);
      cxt.ok(valid2);
      cxt.mergeEvaluated(schCxt);
    });
  }
};
allOf.default = def$4;
var _if = {};
Object.defineProperty(_if, "__esModule", { value: true });
const codegen_1$2 = codegen;
const util_1$2 = util$1;
const error$2 = {
  message: ({ params }) => (0, codegen_1$2.str)`must match "${params.ifClause}" schema`,
  params: ({ params }) => (0, codegen_1$2._)`{failingKeyword: ${params.ifClause}}`
};
const def$3 = {
  keyword: "if",
  schemaType: ["object", "boolean"],
  trackErrors: true,
  error: error$2,
  code(cxt) {
    const { gen, parentSchema, it } = cxt;
    if (parentSchema.then === void 0 && parentSchema.else === void 0) {
      (0, util_1$2.checkStrictMode)(it, '"if" without "then" and "else" is ignored');
    }
    const hasThen = hasSchema(it, "then");
    const hasElse = hasSchema(it, "else");
    if (!hasThen && !hasElse)
      return;
    const valid2 = gen.let("valid", true);
    const schValid = gen.name("_valid");
    validateIf();
    cxt.reset();
    if (hasThen && hasElse) {
      const ifClause = gen.let("ifClause");
      cxt.setParams({ ifClause });
      gen.if(schValid, validateClause("then", ifClause), validateClause("else", ifClause));
    } else if (hasThen) {
      gen.if(schValid, validateClause("then"));
    } else {
      gen.if((0, codegen_1$2.not)(schValid), validateClause("else"));
    }
    cxt.pass(valid2, () => cxt.error(true));
    function validateIf() {
      const schCxt = cxt.subschema({
        keyword: "if",
        compositeRule: true,
        createErrors: false,
        allErrors: false
      }, schValid);
      cxt.mergeEvaluated(schCxt);
    }
    function validateClause(keyword2, ifClause) {
      return () => {
        const schCxt = cxt.subschema({ keyword: keyword2 }, schValid);
        gen.assign(valid2, schValid);
        cxt.mergeValidEvaluated(schCxt, valid2);
        if (ifClause)
          gen.assign(ifClause, (0, codegen_1$2._)`${keyword2}`);
        else
          cxt.setParams({ ifClause: keyword2 });
      };
    }
  }
};
function hasSchema(it, keyword2) {
  const schema = it.schema[keyword2];
  return schema !== void 0 && !(0, util_1$2.alwaysValidSchema)(it, schema);
}
_if.default = def$3;
var thenElse = {};
Object.defineProperty(thenElse, "__esModule", { value: true });
const util_1$1 = util$1;
const def$2 = {
  keyword: ["then", "else"],
  schemaType: ["object", "boolean"],
  code({ keyword: keyword2, parentSchema, it }) {
    if (parentSchema.if === void 0)
      (0, util_1$1.checkStrictMode)(it, `"${keyword2}" without "if" is ignored`);
  }
};
thenElse.default = def$2;
Object.defineProperty(applicator, "__esModule", { value: true });
const additionalItems_1 = additionalItems;
const prefixItems_1 = prefixItems;
const items_1 = items;
const items2020_1 = items2020;
const contains_1 = contains;
const dependencies_1 = dependencies;
const propertyNames_1 = propertyNames;
const additionalProperties_1 = additionalProperties;
const properties_1 = properties$1;
const patternProperties_1 = patternProperties;
const not_1 = not;
const anyOf_1 = anyOf;
const oneOf_1 = oneOf;
const allOf_1 = allOf;
const if_1 = _if;
const thenElse_1 = thenElse;
function getApplicator(draft20202 = false) {
  const applicator2 = [
    // any
    not_1.default,
    anyOf_1.default,
    oneOf_1.default,
    allOf_1.default,
    if_1.default,
    thenElse_1.default,
    // object
    propertyNames_1.default,
    additionalProperties_1.default,
    dependencies_1.default,
    properties_1.default,
    patternProperties_1.default
  ];
  if (draft20202)
    applicator2.push(prefixItems_1.default, items2020_1.default);
  else
    applicator2.push(additionalItems_1.default, items_1.default);
  applicator2.push(contains_1.default);
  return applicator2;
}
applicator.default = getApplicator;
var format$3 = {};
var format$2 = {};
Object.defineProperty(format$2, "__esModule", { value: true });
const codegen_1$1 = codegen;
const error$1 = {
  message: ({ schemaCode }) => (0, codegen_1$1.str)`must match format "${schemaCode}"`,
  params: ({ schemaCode }) => (0, codegen_1$1._)`{format: ${schemaCode}}`
};
const def$1 = {
  keyword: "format",
  type: ["number", "string"],
  schemaType: "string",
  $data: true,
  error: error$1,
  code(cxt, ruleType) {
    const { gen, data, $data, schema, schemaCode, it } = cxt;
    const { opts, errSchemaPath, schemaEnv, self: self2 } = it;
    if (!opts.validateFormats)
      return;
    if ($data)
      validate$DataFormat();
    else
      validateFormat();
    function validate$DataFormat() {
      const fmts = gen.scopeValue("formats", {
        ref: self2.formats,
        code: opts.code.formats
      });
      const fDef = gen.const("fDef", (0, codegen_1$1._)`${fmts}[${schemaCode}]`);
      const fType = gen.let("fType");
      const format2 = gen.let("format");
      gen.if((0, codegen_1$1._)`typeof ${fDef} == "object" && !(${fDef} instanceof RegExp)`, () => gen.assign(fType, (0, codegen_1$1._)`${fDef}.type || "string"`).assign(format2, (0, codegen_1$1._)`${fDef}.validate`), () => gen.assign(fType, (0, codegen_1$1._)`"string"`).assign(format2, fDef));
      cxt.fail$data((0, codegen_1$1.or)(unknownFmt(), invalidFmt()));
      function unknownFmt() {
        if (opts.strictSchema === false)
          return codegen_1$1.nil;
        return (0, codegen_1$1._)`${schemaCode} && !${format2}`;
      }
      function invalidFmt() {
        const callFormat = schemaEnv.$async ? (0, codegen_1$1._)`(${fDef}.async ? await ${format2}(${data}) : ${format2}(${data}))` : (0, codegen_1$1._)`${format2}(${data})`;
        const validData = (0, codegen_1$1._)`(typeof ${format2} == "function" ? ${callFormat} : ${format2}.test(${data}))`;
        return (0, codegen_1$1._)`${format2} && ${format2} !== true && ${fType} === ${ruleType} && !${validData}`;
      }
    }
    function validateFormat() {
      const formatDef = self2.formats[schema];
      if (!formatDef) {
        unknownFormat();
        return;
      }
      if (formatDef === true)
        return;
      const [fmtType, format2, fmtRef] = getFormat(formatDef);
      if (fmtType === ruleType)
        cxt.pass(validCondition());
      function unknownFormat() {
        if (opts.strictSchema === false) {
          self2.logger.warn(unknownMsg());
          return;
        }
        throw new Error(unknownMsg());
        function unknownMsg() {
          return `unknown format "${schema}" ignored in schema at path "${errSchemaPath}"`;
        }
      }
      function getFormat(fmtDef) {
        const code2 = fmtDef instanceof RegExp ? (0, codegen_1$1.regexpCode)(fmtDef) : opts.code.formats ? (0, codegen_1$1._)`${opts.code.formats}${(0, codegen_1$1.getProperty)(schema)}` : void 0;
        const fmt = gen.scopeValue("formats", { key: schema, ref: fmtDef, code: code2 });
        if (typeof fmtDef == "object" && !(fmtDef instanceof RegExp)) {
          return [fmtDef.type || "string", fmtDef.validate, (0, codegen_1$1._)`${fmt}.validate`];
        }
        return ["string", fmtDef, fmt];
      }
      function validCondition() {
        if (typeof formatDef == "object" && !(formatDef instanceof RegExp) && formatDef.async) {
          if (!schemaEnv.$async)
            throw new Error("async format in sync schema");
          return (0, codegen_1$1._)`await ${fmtRef}(${data})`;
        }
        return typeof format2 == "function" ? (0, codegen_1$1._)`${fmtRef}(${data})` : (0, codegen_1$1._)`${fmtRef}.test(${data})`;
      }
    }
  }
};
format$2.default = def$1;
Object.defineProperty(format$3, "__esModule", { value: true });
const format_1$1 = format$2;
const format$1 = [format_1$1.default];
format$3.default = format$1;
var metadata$1 = {};
Object.defineProperty(metadata$1, "__esModule", { value: true });
metadata$1.contentVocabulary = metadata$1.metadataVocabulary = void 0;
metadata$1.metadataVocabulary = [
  "title",
  "description",
  "default",
  "deprecated",
  "readOnly",
  "writeOnly",
  "examples"
];
metadata$1.contentVocabulary = [
  "contentMediaType",
  "contentEncoding",
  "contentSchema"
];
Object.defineProperty(draft7, "__esModule", { value: true });
const core_1 = core$1;
const validation_1 = validation$1;
const applicator_1 = applicator;
const format_1 = format$3;
const metadata_1 = metadata$1;
const draft7Vocabularies = [
  core_1.default,
  validation_1.default,
  (0, applicator_1.default)(),
  format_1.default,
  metadata_1.metadataVocabulary,
  metadata_1.contentVocabulary
];
draft7.default = draft7Vocabularies;
var discriminator = {};
var types = {};
Object.defineProperty(types, "__esModule", { value: true });
types.DiscrError = void 0;
var DiscrError;
(function(DiscrError2) {
  DiscrError2["Tag"] = "tag";
  DiscrError2["Mapping"] = "mapping";
})(DiscrError || (types.DiscrError = DiscrError = {}));
Object.defineProperty(discriminator, "__esModule", { value: true });
const codegen_1 = codegen;
const types_1 = types;
const compile_1 = compile;
const ref_error_1 = ref_error;
const util_1 = util$1;
const error = {
  message: ({ params: { discrError, tagName } }) => discrError === types_1.DiscrError.Tag ? `tag "${tagName}" must be string` : `value of tag "${tagName}" must be in oneOf`,
  params: ({ params: { discrError, tag, tagName } }) => (0, codegen_1._)`{error: ${discrError}, tag: ${tagName}, tagValue: ${tag}}`
};
const def = {
  keyword: "discriminator",
  type: "object",
  schemaType: "object",
  error,
  code(cxt) {
    const { gen, data, schema, parentSchema, it } = cxt;
    const { oneOf: oneOf2 } = parentSchema;
    if (!it.opts.discriminator) {
      throw new Error("discriminator: requires discriminator option");
    }
    const tagName = schema.propertyName;
    if (typeof tagName != "string")
      throw new Error("discriminator: requires propertyName");
    if (schema.mapping)
      throw new Error("discriminator: mapping is not supported");
    if (!oneOf2)
      throw new Error("discriminator: requires oneOf keyword");
    const valid2 = gen.let("valid", false);
    const tag = gen.const("tag", (0, codegen_1._)`${data}${(0, codegen_1.getProperty)(tagName)}`);
    gen.if((0, codegen_1._)`typeof ${tag} == "string"`, () => validateMapping(), () => cxt.error(false, { discrError: types_1.DiscrError.Tag, tag, tagName }));
    cxt.ok(valid2);
    function validateMapping() {
      const mapping = getMapping();
      gen.if(false);
      for (const tagValue in mapping) {
        gen.elseIf((0, codegen_1._)`${tag} === ${tagValue}`);
        gen.assign(valid2, applyTagSchema(mapping[tagValue]));
      }
      gen.else();
      cxt.error(false, { discrError: types_1.DiscrError.Mapping, tag, tagName });
      gen.endIf();
    }
    function applyTagSchema(schemaProp) {
      const _valid = gen.name("valid");
      const schCxt = cxt.subschema({ keyword: "oneOf", schemaProp }, _valid);
      cxt.mergeEvaluated(schCxt, codegen_1.Name);
      return _valid;
    }
    function getMapping() {
      var _a2;
      const oneOfMapping = {};
      const topRequired = hasRequired(parentSchema);
      let tagRequired = true;
      for (let i2 = 0; i2 < oneOf2.length; i2++) {
        let sch = oneOf2[i2];
        if ((sch === null || sch === void 0 ? void 0 : sch.$ref) && !(0, util_1.schemaHasRulesButRef)(sch, it.self.RULES)) {
          const ref2 = sch.$ref;
          sch = compile_1.resolveRef.call(it.self, it.schemaEnv.root, it.baseId, ref2);
          if (sch instanceof compile_1.SchemaEnv)
            sch = sch.schema;
          if (sch === void 0)
            throw new ref_error_1.default(it.opts.uriResolver, it.baseId, ref2);
        }
        const propSch = (_a2 = sch === null || sch === void 0 ? void 0 : sch.properties) === null || _a2 === void 0 ? void 0 : _a2[tagName];
        if (typeof propSch != "object") {
          throw new Error(`discriminator: oneOf subschemas (or referenced schemas) must have "properties/${tagName}"`);
        }
        tagRequired = tagRequired && (topRequired || hasRequired(sch));
        addMappings(propSch, i2);
      }
      if (!tagRequired)
        throw new Error(`discriminator: "${tagName}" must be required`);
      return oneOfMapping;
      function hasRequired({ required: required2 }) {
        return Array.isArray(required2) && required2.includes(tagName);
      }
      function addMappings(sch, i2) {
        if (sch.const) {
          addMapping(sch.const, i2);
        } else if (sch.enum) {
          for (const tagValue of sch.enum) {
            addMapping(tagValue, i2);
          }
        } else {
          throw new Error(`discriminator: "properties/${tagName}" must have "const" or "enum"`);
        }
      }
      function addMapping(tagValue, i2) {
        if (typeof tagValue != "string" || tagValue in oneOfMapping) {
          throw new Error(`discriminator: "${tagName}" values must be unique strings`);
        }
        oneOfMapping[tagValue] = i2;
      }
    }
  }
};
discriminator.default = def;
const $schema = "http://json-schema.org/draft-07/schema#";
const $id = "http://json-schema.org/draft-07/schema#";
const title = "Core schema meta-schema";
const definitions = {
  schemaArray: {
    type: "array",
    minItems: 1,
    items: {
      $ref: "#"
    }
  },
  nonNegativeInteger: {
    type: "integer",
    minimum: 0
  },
  nonNegativeIntegerDefault0: {
    allOf: [
      {
        $ref: "#/definitions/nonNegativeInteger"
      },
      {
        "default": 0
      }
    ]
  },
  simpleTypes: {
    "enum": [
      "array",
      "boolean",
      "integer",
      "null",
      "number",
      "object",
      "string"
    ]
  },
  stringArray: {
    type: "array",
    items: {
      type: "string"
    },
    uniqueItems: true,
    "default": []
  }
};
const type = [
  "object",
  "boolean"
];
const properties = {
  $id: {
    type: "string",
    format: "uri-reference"
  },
  $schema: {
    type: "string",
    format: "uri"
  },
  $ref: {
    type: "string",
    format: "uri-reference"
  },
  $comment: {
    type: "string"
  },
  title: {
    type: "string"
  },
  description: {
    type: "string"
  },
  "default": true,
  readOnly: {
    type: "boolean",
    "default": false
  },
  examples: {
    type: "array",
    items: true
  },
  multipleOf: {
    type: "number",
    exclusiveMinimum: 0
  },
  maximum: {
    type: "number"
  },
  exclusiveMaximum: {
    type: "number"
  },
  minimum: {
    type: "number"
  },
  exclusiveMinimum: {
    type: "number"
  },
  maxLength: {
    $ref: "#/definitions/nonNegativeInteger"
  },
  minLength: {
    $ref: "#/definitions/nonNegativeIntegerDefault0"
  },
  pattern: {
    type: "string",
    format: "regex"
  },
  additionalItems: {
    $ref: "#"
  },
  items: {
    anyOf: [
      {
        $ref: "#"
      },
      {
        $ref: "#/definitions/schemaArray"
      }
    ],
    "default": true
  },
  maxItems: {
    $ref: "#/definitions/nonNegativeInteger"
  },
  minItems: {
    $ref: "#/definitions/nonNegativeIntegerDefault0"
  },
  uniqueItems: {
    type: "boolean",
    "default": false
  },
  contains: {
    $ref: "#"
  },
  maxProperties: {
    $ref: "#/definitions/nonNegativeInteger"
  },
  minProperties: {
    $ref: "#/definitions/nonNegativeIntegerDefault0"
  },
  required: {
    $ref: "#/definitions/stringArray"
  },
  additionalProperties: {
    $ref: "#"
  },
  definitions: {
    type: "object",
    additionalProperties: {
      $ref: "#"
    },
    "default": {}
  },
  properties: {
    type: "object",
    additionalProperties: {
      $ref: "#"
    },
    "default": {}
  },
  patternProperties: {
    type: "object",
    additionalProperties: {
      $ref: "#"
    },
    propertyNames: {
      format: "regex"
    },
    "default": {}
  },
  dependencies: {
    type: "object",
    additionalProperties: {
      anyOf: [
        {
          $ref: "#"
        },
        {
          $ref: "#/definitions/stringArray"
        }
      ]
    }
  },
  propertyNames: {
    $ref: "#"
  },
  "const": true,
  "enum": {
    type: "array",
    items: true,
    minItems: 1,
    uniqueItems: true
  },
  type: {
    anyOf: [
      {
        $ref: "#/definitions/simpleTypes"
      },
      {
        type: "array",
        items: {
          $ref: "#/definitions/simpleTypes"
        },
        minItems: 1,
        uniqueItems: true
      }
    ]
  },
  format: {
    type: "string"
  },
  contentMediaType: {
    type: "string"
  },
  contentEncoding: {
    type: "string"
  },
  "if": {
    $ref: "#"
  },
  then: {
    $ref: "#"
  },
  "else": {
    $ref: "#"
  },
  allOf: {
    $ref: "#/definitions/schemaArray"
  },
  anyOf: {
    $ref: "#/definitions/schemaArray"
  },
  oneOf: {
    $ref: "#/definitions/schemaArray"
  },
  not: {
    $ref: "#"
  }
};
const require$$3 = {
  $schema,
  $id,
  title,
  definitions,
  type,
  properties,
  "default": true
};
(function(module2, exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.MissingRefError = exports$12.ValidationError = exports$12.CodeGen = exports$12.Name = exports$12.nil = exports$12.stringify = exports$12.str = exports$12._ = exports$12.KeywordCxt = exports$12.Ajv = void 0;
  const core_12 = core$2;
  const draft7_1 = draft7;
  const discriminator_1 = discriminator;
  const draft7MetaSchema = require$$3;
  const META_SUPPORT_DATA2 = ["/properties"];
  const META_SCHEMA_ID = "http://json-schema.org/draft-07/schema";
  class Ajv extends core_12.default {
    _addVocabularies() {
      super._addVocabularies();
      draft7_1.default.forEach((v) => this.addVocabulary(v));
      if (this.opts.discriminator)
        this.addKeyword(discriminator_1.default);
    }
    _addDefaultMetaSchema() {
      super._addDefaultMetaSchema();
      if (!this.opts.meta)
        return;
      const metaSchema2 = this.opts.$data ? this.$dataMetaSchema(draft7MetaSchema, META_SUPPORT_DATA2) : draft7MetaSchema;
      this.addMetaSchema(metaSchema2, META_SCHEMA_ID, false);
      this.refs["http://json-schema.org/schema"] = META_SCHEMA_ID;
    }
    defaultMeta() {
      return this.opts.defaultMeta = super.defaultMeta() || (this.getSchema(META_SCHEMA_ID) ? META_SCHEMA_ID : void 0);
    }
  }
  exports$12.Ajv = Ajv;
  module2.exports = exports$12 = Ajv;
  module2.exports.Ajv = Ajv;
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.default = Ajv;
  var validate_12 = validate;
  Object.defineProperty(exports$12, "KeywordCxt", { enumerable: true, get: function() {
    return validate_12.KeywordCxt;
  } });
  var codegen_12 = codegen;
  Object.defineProperty(exports$12, "_", { enumerable: true, get: function() {
    return codegen_12._;
  } });
  Object.defineProperty(exports$12, "str", { enumerable: true, get: function() {
    return codegen_12.str;
  } });
  Object.defineProperty(exports$12, "stringify", { enumerable: true, get: function() {
    return codegen_12.stringify;
  } });
  Object.defineProperty(exports$12, "nil", { enumerable: true, get: function() {
    return codegen_12.nil;
  } });
  Object.defineProperty(exports$12, "Name", { enumerable: true, get: function() {
    return codegen_12.Name;
  } });
  Object.defineProperty(exports$12, "CodeGen", { enumerable: true, get: function() {
    return codegen_12.CodeGen;
  } });
  var validation_error_12 = validation_error;
  Object.defineProperty(exports$12, "ValidationError", { enumerable: true, get: function() {
    return validation_error_12.default;
  } });
  var ref_error_12 = ref_error;
  Object.defineProperty(exports$12, "MissingRefError", { enumerable: true, get: function() {
    return ref_error_12.default;
  } });
})(ajv, ajv.exports);
var ajvExports = ajv.exports;
(function(exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.formatLimitDefinition = void 0;
  const ajv_1 = ajvExports;
  const codegen_12 = codegen;
  const ops2 = codegen_12.operators;
  const KWDs2 = {
    formatMaximum: { okStr: "<=", ok: ops2.LTE, fail: ops2.GT },
    formatMinimum: { okStr: ">=", ok: ops2.GTE, fail: ops2.LT },
    formatExclusiveMaximum: { okStr: "<", ok: ops2.LT, fail: ops2.GTE },
    formatExclusiveMinimum: { okStr: ">", ok: ops2.GT, fail: ops2.LTE }
  };
  const error2 = {
    message: ({ keyword: keyword2, schemaCode }) => (0, codegen_12.str)`should be ${KWDs2[keyword2].okStr} ${schemaCode}`,
    params: ({ keyword: keyword2, schemaCode }) => (0, codegen_12._)`{comparison: ${KWDs2[keyword2].okStr}, limit: ${schemaCode}}`
  };
  exports$12.formatLimitDefinition = {
    keyword: Object.keys(KWDs2),
    type: "string",
    schemaType: "string",
    $data: true,
    error: error2,
    code(cxt) {
      const { gen, data, schemaCode, keyword: keyword2, it } = cxt;
      const { opts, self: self2 } = it;
      if (!opts.validateFormats)
        return;
      const fCxt = new ajv_1.KeywordCxt(it, self2.RULES.all.format.definition, "format");
      if (fCxt.$data)
        validate$DataFormat();
      else
        validateFormat();
      function validate$DataFormat() {
        const fmts = gen.scopeValue("formats", {
          ref: self2.formats,
          code: opts.code.formats
        });
        const fmt = gen.const("fmt", (0, codegen_12._)`${fmts}[${fCxt.schemaCode}]`);
        cxt.fail$data((0, codegen_12.or)((0, codegen_12._)`typeof ${fmt} != "object"`, (0, codegen_12._)`${fmt} instanceof RegExp`, (0, codegen_12._)`typeof ${fmt}.compare != "function"`, compareCode(fmt)));
      }
      function validateFormat() {
        const format2 = fCxt.schema;
        const fmtDef = self2.formats[format2];
        if (!fmtDef || fmtDef === true)
          return;
        if (typeof fmtDef != "object" || fmtDef instanceof RegExp || typeof fmtDef.compare != "function") {
          throw new Error(`"${keyword2}": format "${format2}" does not define "compare" function`);
        }
        const fmt = gen.scopeValue("formats", {
          key: format2,
          ref: fmtDef,
          code: opts.code.formats ? (0, codegen_12._)`${opts.code.formats}${(0, codegen_12.getProperty)(format2)}` : void 0
        });
        cxt.fail$data(compareCode(fmt));
      }
      function compareCode(fmt) {
        return (0, codegen_12._)`${fmt}.compare(${data}, ${schemaCode}) ${KWDs2[keyword2].fail} 0`;
      }
    },
    dependencies: ["format"]
  };
  const formatLimitPlugin = (ajv2) => {
    ajv2.addKeyword(exports$12.formatLimitDefinition);
    return ajv2;
  };
  exports$12.default = formatLimitPlugin;
})(limit);
(function(module2, exports$12) {
  Object.defineProperty(exports$12, "__esModule", { value: true });
  const formats_1 = formats$1;
  const limit_1 = limit;
  const codegen_12 = codegen;
  const fullName = new codegen_12.Name("fullFormats");
  const fastName = new codegen_12.Name("fastFormats");
  const formatsPlugin = (ajv2, opts = { keywords: true }) => {
    if (Array.isArray(opts)) {
      addFormats(ajv2, opts, formats_1.fullFormats, fullName);
      return ajv2;
    }
    const [formats2, exportName] = opts.mode === "fast" ? [formats_1.fastFormats, fastName] : [formats_1.fullFormats, fullName];
    const list = opts.formats || formats_1.formatNames;
    addFormats(ajv2, list, formats2, exportName);
    if (opts.keywords)
      (0, limit_1.default)(ajv2);
    return ajv2;
  };
  formatsPlugin.get = (name2, mode = "full") => {
    const formats2 = mode === "fast" ? formats_1.fastFormats : formats_1.fullFormats;
    const f = formats2[name2];
    if (!f)
      throw new Error(`Unknown format "${name2}"`);
    return f;
  };
  function addFormats(ajv2, list, fs2, exportName) {
    var _a2;
    var _b;
    (_a2 = (_b = ajv2.opts.code).formats) !== null && _a2 !== void 0 ? _a2 : _b.formats = (0, codegen_12._)`require("ajv-formats/dist/formats").${exportName}`;
    for (const f of list)
      ajv2.addFormat(f, fs2[f]);
  }
  module2.exports = exports$12 = formatsPlugin;
  Object.defineProperty(exports$12, "__esModule", { value: true });
  exports$12.default = formatsPlugin;
})(dist$1, dist$1.exports);
var distExports = dist$1.exports;
const ajvFormatsModule = /* @__PURE__ */ getDefaultExportFromCjs(distExports);
const copyProperty = (to, from, property, ignoreNonConfigurable) => {
  if (property === "length" || property === "prototype") {
    return;
  }
  if (property === "arguments" || property === "caller") {
    return;
  }
  const toDescriptor = Object.getOwnPropertyDescriptor(to, property);
  const fromDescriptor = Object.getOwnPropertyDescriptor(from, property);
  if (!canCopyProperty(toDescriptor, fromDescriptor) && ignoreNonConfigurable) {
    return;
  }
  Object.defineProperty(to, property, fromDescriptor);
};
const canCopyProperty = function(toDescriptor, fromDescriptor) {
  return toDescriptor === void 0 || toDescriptor.configurable || toDescriptor.writable === fromDescriptor.writable && toDescriptor.enumerable === fromDescriptor.enumerable && toDescriptor.configurable === fromDescriptor.configurable && (toDescriptor.writable || toDescriptor.value === fromDescriptor.value);
};
const changePrototype = (to, from) => {
  const fromPrototype = Object.getPrototypeOf(from);
  if (fromPrototype === Object.getPrototypeOf(to)) {
    return;
  }
  Object.setPrototypeOf(to, fromPrototype);
};
const wrappedToString = (withName, fromBody) => `/* Wrapped ${withName}*/
${fromBody}`;
const toStringDescriptor = Object.getOwnPropertyDescriptor(Function.prototype, "toString");
const toStringName = Object.getOwnPropertyDescriptor(Function.prototype.toString, "name");
const changeToString = (to, from, name2) => {
  const withName = name2 === "" ? "" : `with ${name2.trim()}() `;
  const newToString = wrappedToString.bind(null, withName, from.toString());
  Object.defineProperty(newToString, "name", toStringName);
  const { writable, enumerable, configurable } = toStringDescriptor;
  Object.defineProperty(to, "toString", { value: newToString, writable, enumerable, configurable });
};
function mimicFunction(to, from, { ignoreNonConfigurable = false } = {}) {
  const { name: name2 } = to;
  for (const property of Reflect.ownKeys(from)) {
    copyProperty(to, from, property, ignoreNonConfigurable);
  }
  changePrototype(to, from);
  changeToString(to, from, name2);
  return to;
}
const debounceFunction = (inputFunction, options = {}) => {
  if (typeof inputFunction !== "function") {
    throw new TypeError(`Expected the first argument to be a function, got \`${typeof inputFunction}\``);
  }
  const {
    wait = 0,
    maxWait = Number.POSITIVE_INFINITY,
    before = false,
    after = true
  } = options;
  if (wait < 0 || maxWait < 0) {
    throw new RangeError("`wait` and `maxWait` must not be negative.");
  }
  if (!before && !after) {
    throw new Error("Both `before` and `after` are false, function wouldn't be called.");
  }
  let timeout2;
  let maxTimeout;
  let result;
  const debouncedFunction = function(...arguments_) {
    const context = this;
    const later = () => {
      timeout2 = void 0;
      if (maxTimeout) {
        clearTimeout(maxTimeout);
        maxTimeout = void 0;
      }
      if (after) {
        result = inputFunction.apply(context, arguments_);
      }
    };
    const maxLater = () => {
      maxTimeout = void 0;
      if (timeout2) {
        clearTimeout(timeout2);
        timeout2 = void 0;
      }
      if (after) {
        result = inputFunction.apply(context, arguments_);
      }
    };
    const shouldCallNow = before && !timeout2;
    clearTimeout(timeout2);
    timeout2 = setTimeout(later, wait);
    if (maxWait > 0 && maxWait !== Number.POSITIVE_INFINITY && !maxTimeout) {
      maxTimeout = setTimeout(maxLater, maxWait);
    }
    if (shouldCallNow) {
      result = inputFunction.apply(context, arguments_);
    }
    return result;
  };
  mimicFunction(debouncedFunction, inputFunction);
  debouncedFunction.cancel = () => {
    if (timeout2) {
      clearTimeout(timeout2);
      timeout2 = void 0;
    }
    if (maxTimeout) {
      clearTimeout(maxTimeout);
      maxTimeout = void 0;
    }
  };
  return debouncedFunction;
};
var re$5 = { exports: {} };
const SEMVER_SPEC_VERSION = "2.0.0";
const MAX_LENGTH$4 = 256;
const MAX_SAFE_INTEGER$3 = Number.MAX_SAFE_INTEGER || /* istanbul ignore next */
9007199254740991;
const MAX_SAFE_COMPONENT_LENGTH$1 = 16;
const MAX_SAFE_BUILD_LENGTH$1 = MAX_LENGTH$4 - 6;
const RELEASE_TYPES = [
  "major",
  "premajor",
  "minor",
  "preminor",
  "patch",
  "prepatch",
  "prerelease"
];
var constants$2 = {
  MAX_LENGTH: MAX_LENGTH$4,
  MAX_SAFE_COMPONENT_LENGTH: MAX_SAFE_COMPONENT_LENGTH$1,
  MAX_SAFE_BUILD_LENGTH: MAX_SAFE_BUILD_LENGTH$1,
  MAX_SAFE_INTEGER: MAX_SAFE_INTEGER$3,
  RELEASE_TYPES,
  SEMVER_SPEC_VERSION,
  FLAG_INCLUDE_PRERELEASE: 1,
  FLAG_LOOSE: 2
};
const debug$3 = typeof process === "object" && process.env && process.env.NODE_DEBUG && /\bsemver\b/i.test(process.env.NODE_DEBUG) ? (...args) => console.error("SEMVER", ...args) : () => {
};
var debug_1$1 = debug$3;
(function(module2, exports$12) {
  const {
    MAX_SAFE_COMPONENT_LENGTH: MAX_SAFE_COMPONENT_LENGTH2,
    MAX_SAFE_BUILD_LENGTH: MAX_SAFE_BUILD_LENGTH2,
    MAX_LENGTH: MAX_LENGTH2
  } = constants$2;
  const debug2 = debug_1$1;
  exports$12 = module2.exports = {};
  const re2 = exports$12.re = [];
  const safeRe = exports$12.safeRe = [];
  const src = exports$12.src = [];
  const safeSrc = exports$12.safeSrc = [];
  const t2 = exports$12.t = {};
  let R = 0;
  const LETTERDASHNUMBER = "[a-zA-Z0-9-]";
  const safeRegexReplacements = [
    ["\\s", 1],
    ["\\d", MAX_LENGTH2],
    [LETTERDASHNUMBER, MAX_SAFE_BUILD_LENGTH2]
  ];
  const makeSafeRegex = (value) => {
    for (const [token, max2] of safeRegexReplacements) {
      value = value.split(`${token}*`).join(`${token}{0,${max2}}`).split(`${token}+`).join(`${token}{1,${max2}}`);
    }
    return value;
  };
  const createToken = (name2, value, isGlobal) => {
    const safe = makeSafeRegex(value);
    const index2 = R++;
    debug2(name2, index2, value);
    t2[name2] = index2;
    src[index2] = value;
    safeSrc[index2] = safe;
    re2[index2] = new RegExp(value, isGlobal ? "g" : void 0);
    safeRe[index2] = new RegExp(safe, isGlobal ? "g" : void 0);
  };
  createToken("NUMERICIDENTIFIER", "0|[1-9]\\d*");
  createToken("NUMERICIDENTIFIERLOOSE", "\\d+");
  createToken("NONNUMERICIDENTIFIER", `\\d*[a-zA-Z-]${LETTERDASHNUMBER}*`);
  createToken("MAINVERSION", `(${src[t2.NUMERICIDENTIFIER]})\\.(${src[t2.NUMERICIDENTIFIER]})\\.(${src[t2.NUMERICIDENTIFIER]})`);
  createToken("MAINVERSIONLOOSE", `(${src[t2.NUMERICIDENTIFIERLOOSE]})\\.(${src[t2.NUMERICIDENTIFIERLOOSE]})\\.(${src[t2.NUMERICIDENTIFIERLOOSE]})`);
  createToken("PRERELEASEIDENTIFIER", `(?:${src[t2.NONNUMERICIDENTIFIER]}|${src[t2.NUMERICIDENTIFIER]})`);
  createToken("PRERELEASEIDENTIFIERLOOSE", `(?:${src[t2.NONNUMERICIDENTIFIER]}|${src[t2.NUMERICIDENTIFIERLOOSE]})`);
  createToken("PRERELEASE", `(?:-(${src[t2.PRERELEASEIDENTIFIER]}(?:\\.${src[t2.PRERELEASEIDENTIFIER]})*))`);
  createToken("PRERELEASELOOSE", `(?:-?(${src[t2.PRERELEASEIDENTIFIERLOOSE]}(?:\\.${src[t2.PRERELEASEIDENTIFIERLOOSE]})*))`);
  createToken("BUILDIDENTIFIER", `${LETTERDASHNUMBER}+`);
  createToken("BUILD", `(?:\\+(${src[t2.BUILDIDENTIFIER]}(?:\\.${src[t2.BUILDIDENTIFIER]})*))`);
  createToken("FULLPLAIN", `v?${src[t2.MAINVERSION]}${src[t2.PRERELEASE]}?${src[t2.BUILD]}?`);
  createToken("FULL", `^${src[t2.FULLPLAIN]}$`);
  createToken("LOOSEPLAIN", `[v=\\s]*${src[t2.MAINVERSIONLOOSE]}${src[t2.PRERELEASELOOSE]}?${src[t2.BUILD]}?`);
  createToken("LOOSE", `^${src[t2.LOOSEPLAIN]}$`);
  createToken("GTLT", "((?:<|>)?=?)");
  createToken("XRANGEIDENTIFIERLOOSE", `${src[t2.NUMERICIDENTIFIERLOOSE]}|x|X|\\*`);
  createToken("XRANGEIDENTIFIER", `${src[t2.NUMERICIDENTIFIER]}|x|X|\\*`);
  createToken("XRANGEPLAIN", `[v=\\s]*(${src[t2.XRANGEIDENTIFIER]})(?:\\.(${src[t2.XRANGEIDENTIFIER]})(?:\\.(${src[t2.XRANGEIDENTIFIER]})(?:${src[t2.PRERELEASE]})?${src[t2.BUILD]}?)?)?`);
  createToken("XRANGEPLAINLOOSE", `[v=\\s]*(${src[t2.XRANGEIDENTIFIERLOOSE]})(?:\\.(${src[t2.XRANGEIDENTIFIERLOOSE]})(?:\\.(${src[t2.XRANGEIDENTIFIERLOOSE]})(?:${src[t2.PRERELEASELOOSE]})?${src[t2.BUILD]}?)?)?`);
  createToken("XRANGE", `^${src[t2.GTLT]}\\s*${src[t2.XRANGEPLAIN]}$`);
  createToken("XRANGELOOSE", `^${src[t2.GTLT]}\\s*${src[t2.XRANGEPLAINLOOSE]}$`);
  createToken("COERCEPLAIN", `${"(^|[^\\d])(\\d{1,"}${MAX_SAFE_COMPONENT_LENGTH2}})(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH2}}))?(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH2}}))?`);
  createToken("COERCE", `${src[t2.COERCEPLAIN]}(?:$|[^\\d])`);
  createToken("COERCEFULL", src[t2.COERCEPLAIN] + `(?:${src[t2.PRERELEASE]})?(?:${src[t2.BUILD]})?(?:$|[^\\d])`);
  createToken("COERCERTL", src[t2.COERCE], true);
  createToken("COERCERTLFULL", src[t2.COERCEFULL], true);
  createToken("LONETILDE", "(?:~>?)");
  createToken("TILDETRIM", `(\\s*)${src[t2.LONETILDE]}\\s+`, true);
  exports$12.tildeTrimReplace = "$1~";
  createToken("TILDE", `^${src[t2.LONETILDE]}${src[t2.XRANGEPLAIN]}$`);
  createToken("TILDELOOSE", `^${src[t2.LONETILDE]}${src[t2.XRANGEPLAINLOOSE]}$`);
  createToken("LONECARET", "(?:\\^)");
  createToken("CARETTRIM", `(\\s*)${src[t2.LONECARET]}\\s+`, true);
  exports$12.caretTrimReplace = "$1^";
  createToken("CARET", `^${src[t2.LONECARET]}${src[t2.XRANGEPLAIN]}$`);
  createToken("CARETLOOSE", `^${src[t2.LONECARET]}${src[t2.XRANGEPLAINLOOSE]}$`);
  createToken("COMPARATORLOOSE", `^${src[t2.GTLT]}\\s*(${src[t2.LOOSEPLAIN]})$|^$`);
  createToken("COMPARATOR", `^${src[t2.GTLT]}\\s*(${src[t2.FULLPLAIN]})$|^$`);
  createToken("COMPARATORTRIM", `(\\s*)${src[t2.GTLT]}\\s*(${src[t2.LOOSEPLAIN]}|${src[t2.XRANGEPLAIN]})`, true);
  exports$12.comparatorTrimReplace = "$1$2$3";
  createToken("HYPHENRANGE", `^\\s*(${src[t2.XRANGEPLAIN]})\\s+-\\s+(${src[t2.XRANGEPLAIN]})\\s*$`);
  createToken("HYPHENRANGELOOSE", `^\\s*(${src[t2.XRANGEPLAINLOOSE]})\\s+-\\s+(${src[t2.XRANGEPLAINLOOSE]})\\s*$`);
  createToken("STAR", "(<|>)?=?\\s*\\*");
  createToken("GTE0", "^\\s*>=\\s*0\\.0\\.0\\s*$");
  createToken("GTE0PRE", "^\\s*>=\\s*0\\.0\\.0-0\\s*$");
})(re$5, re$5.exports);
var reExports$1 = re$5.exports;
const looseOption$1 = Object.freeze({ loose: true });
const emptyOpts$1 = Object.freeze({});
const parseOptions$3 = (options) => {
  if (!options) {
    return emptyOpts$1;
  }
  if (typeof options !== "object") {
    return looseOption$1;
  }
  return options;
};
var parseOptions_1$1 = parseOptions$3;
const numeric$1 = /^[0-9]+$/;
const compareIdentifiers$3 = (a, b) => {
  if (typeof a === "number" && typeof b === "number") {
    return a === b ? 0 : a < b ? -1 : 1;
  }
  const anum = numeric$1.test(a);
  const bnum = numeric$1.test(b);
  if (anum && bnum) {
    a = +a;
    b = +b;
  }
  return a === b ? 0 : anum && !bnum ? -1 : bnum && !anum ? 1 : a < b ? -1 : 1;
};
const rcompareIdentifiers = (a, b) => compareIdentifiers$3(b, a);
var identifiers$2 = {
  compareIdentifiers: compareIdentifiers$3,
  rcompareIdentifiers
};
const debug$2 = debug_1$1;
const { MAX_LENGTH: MAX_LENGTH$3, MAX_SAFE_INTEGER: MAX_SAFE_INTEGER$2 } = constants$2;
const { safeRe: re$4, t: t$3 } = reExports$1;
const parseOptions$2 = parseOptions_1$1;
const { compareIdentifiers: compareIdentifiers$2 } = identifiers$2;
let SemVer$h = class SemVer2 {
  constructor(version2, options) {
    options = parseOptions$2(options);
    if (version2 instanceof SemVer2) {
      if (version2.loose === !!options.loose && version2.includePrerelease === !!options.includePrerelease) {
        return version2;
      } else {
        version2 = version2.version;
      }
    } else if (typeof version2 !== "string") {
      throw new TypeError(`Invalid version. Must be a string. Got type "${typeof version2}".`);
    }
    if (version2.length > MAX_LENGTH$3) {
      throw new TypeError(
        `version is longer than ${MAX_LENGTH$3} characters`
      );
    }
    debug$2("SemVer", version2, options);
    this.options = options;
    this.loose = !!options.loose;
    this.includePrerelease = !!options.includePrerelease;
    const m = version2.trim().match(options.loose ? re$4[t$3.LOOSE] : re$4[t$3.FULL]);
    if (!m) {
      throw new TypeError(`Invalid Version: ${version2}`);
    }
    this.raw = version2;
    this.major = +m[1];
    this.minor = +m[2];
    this.patch = +m[3];
    if (this.major > MAX_SAFE_INTEGER$2 || this.major < 0) {
      throw new TypeError("Invalid major version");
    }
    if (this.minor > MAX_SAFE_INTEGER$2 || this.minor < 0) {
      throw new TypeError("Invalid minor version");
    }
    if (this.patch > MAX_SAFE_INTEGER$2 || this.patch < 0) {
      throw new TypeError("Invalid patch version");
    }
    if (!m[4]) {
      this.prerelease = [];
    } else {
      this.prerelease = m[4].split(".").map((id2) => {
        if (/^[0-9]+$/.test(id2)) {
          const num = +id2;
          if (num >= 0 && num < MAX_SAFE_INTEGER$2) {
            return num;
          }
        }
        return id2;
      });
    }
    this.build = m[5] ? m[5].split(".") : [];
    this.format();
  }
  format() {
    this.version = `${this.major}.${this.minor}.${this.patch}`;
    if (this.prerelease.length) {
      this.version += `-${this.prerelease.join(".")}`;
    }
    return this.version;
  }
  toString() {
    return this.version;
  }
  compare(other) {
    debug$2("SemVer.compare", this.version, this.options, other);
    if (!(other instanceof SemVer2)) {
      if (typeof other === "string" && other === this.version) {
        return 0;
      }
      other = new SemVer2(other, this.options);
    }
    if (other.version === this.version) {
      return 0;
    }
    return this.compareMain(other) || this.comparePre(other);
  }
  compareMain(other) {
    if (!(other instanceof SemVer2)) {
      other = new SemVer2(other, this.options);
    }
    if (this.major < other.major) {
      return -1;
    }
    if (this.major > other.major) {
      return 1;
    }
    if (this.minor < other.minor) {
      return -1;
    }
    if (this.minor > other.minor) {
      return 1;
    }
    if (this.patch < other.patch) {
      return -1;
    }
    if (this.patch > other.patch) {
      return 1;
    }
    return 0;
  }
  comparePre(other) {
    if (!(other instanceof SemVer2)) {
      other = new SemVer2(other, this.options);
    }
    if (this.prerelease.length && !other.prerelease.length) {
      return -1;
    } else if (!this.prerelease.length && other.prerelease.length) {
      return 1;
    } else if (!this.prerelease.length && !other.prerelease.length) {
      return 0;
    }
    let i2 = 0;
    do {
      const a = this.prerelease[i2];
      const b = other.prerelease[i2];
      debug$2("prerelease compare", i2, a, b);
      if (a === void 0 && b === void 0) {
        return 0;
      } else if (b === void 0) {
        return 1;
      } else if (a === void 0) {
        return -1;
      } else if (a === b) {
        continue;
      } else {
        return compareIdentifiers$2(a, b);
      }
    } while (++i2);
  }
  compareBuild(other) {
    if (!(other instanceof SemVer2)) {
      other = new SemVer2(other, this.options);
    }
    let i2 = 0;
    do {
      const a = this.build[i2];
      const b = other.build[i2];
      debug$2("build compare", i2, a, b);
      if (a === void 0 && b === void 0) {
        return 0;
      } else if (b === void 0) {
        return 1;
      } else if (a === void 0) {
        return -1;
      } else if (a === b) {
        continue;
      } else {
        return compareIdentifiers$2(a, b);
      }
    } while (++i2);
  }
  // preminor will bump the version up to the next minor release, and immediately
  // down to pre-release. premajor and prepatch work the same way.
  inc(release, identifier, identifierBase) {
    if (release.startsWith("pre")) {
      if (!identifier && identifierBase === false) {
        throw new Error("invalid increment argument: identifier is empty");
      }
      if (identifier) {
        const match = `-${identifier}`.match(this.options.loose ? re$4[t$3.PRERELEASELOOSE] : re$4[t$3.PRERELEASE]);
        if (!match || match[1] !== identifier) {
          throw new Error(`invalid identifier: ${identifier}`);
        }
      }
    }
    switch (release) {
      case "premajor":
        this.prerelease.length = 0;
        this.patch = 0;
        this.minor = 0;
        this.major++;
        this.inc("pre", identifier, identifierBase);
        break;
      case "preminor":
        this.prerelease.length = 0;
        this.patch = 0;
        this.minor++;
        this.inc("pre", identifier, identifierBase);
        break;
      case "prepatch":
        this.prerelease.length = 0;
        this.inc("patch", identifier, identifierBase);
        this.inc("pre", identifier, identifierBase);
        break;
      case "prerelease":
        if (this.prerelease.length === 0) {
          this.inc("patch", identifier, identifierBase);
        }
        this.inc("pre", identifier, identifierBase);
        break;
      case "release":
        if (this.prerelease.length === 0) {
          throw new Error(`version ${this.raw} is not a prerelease`);
        }
        this.prerelease.length = 0;
        break;
      case "major":
        if (this.minor !== 0 || this.patch !== 0 || this.prerelease.length === 0) {
          this.major++;
        }
        this.minor = 0;
        this.patch = 0;
        this.prerelease = [];
        break;
      case "minor":
        if (this.patch !== 0 || this.prerelease.length === 0) {
          this.minor++;
        }
        this.patch = 0;
        this.prerelease = [];
        break;
      case "patch":
        if (this.prerelease.length === 0) {
          this.patch++;
        }
        this.prerelease = [];
        break;
      case "pre": {
        const base = Number(identifierBase) ? 1 : 0;
        if (this.prerelease.length === 0) {
          this.prerelease = [base];
        } else {
          let i2 = this.prerelease.length;
          while (--i2 >= 0) {
            if (typeof this.prerelease[i2] === "number") {
              this.prerelease[i2]++;
              i2 = -2;
            }
          }
          if (i2 === -1) {
            if (identifier === this.prerelease.join(".") && identifierBase === false) {
              throw new Error("invalid increment argument: identifier already exists");
            }
            this.prerelease.push(base);
          }
        }
        if (identifier) {
          let prerelease2 = [identifier, base];
          if (identifierBase === false) {
            prerelease2 = [identifier];
          }
          if (compareIdentifiers$2(this.prerelease[0], identifier) === 0) {
            if (isNaN(this.prerelease[1])) {
              this.prerelease = prerelease2;
            }
          } else {
            this.prerelease = prerelease2;
          }
        }
        break;
      }
      default:
        throw new Error(`invalid increment argument: ${release}`);
    }
    this.raw = this.format();
    if (this.build.length) {
      this.raw += `+${this.build.join(".")}`;
    }
    return this;
  }
};
var semver$3 = SemVer$h;
const SemVer$g = semver$3;
const parse$9 = (version2, options, throwErrors = false) => {
  if (version2 instanceof SemVer$g) {
    return version2;
  }
  try {
    return new SemVer$g(version2, options);
  } catch (er) {
    if (!throwErrors) {
      return null;
    }
    throw er;
  }
};
var parse_1$1 = parse$9;
const parse$8 = parse_1$1;
const valid$2 = (version2, options) => {
  const v = parse$8(version2, options);
  return v ? v.version : null;
};
var valid_1 = valid$2;
const parse$7 = parse_1$1;
const clean$1 = (version2, options) => {
  const s = parse$7(version2.trim().replace(/^[=v]+/, ""), options);
  return s ? s.version : null;
};
var clean_1 = clean$1;
const SemVer$f = semver$3;
const inc$1 = (version2, release, options, identifier, identifierBase) => {
  if (typeof options === "string") {
    identifierBase = identifier;
    identifier = options;
    options = void 0;
  }
  try {
    return new SemVer$f(
      version2 instanceof SemVer$f ? version2.version : version2,
      options
    ).inc(release, identifier, identifierBase).version;
  } catch (er) {
    return null;
  }
};
var inc_1 = inc$1;
const parse$6 = parse_1$1;
const diff$1 = (version1, version2) => {
  const v1 = parse$6(version1, null, true);
  const v2 = parse$6(version2, null, true);
  const comparison = v1.compare(v2);
  if (comparison === 0) {
    return null;
  }
  const v1Higher = comparison > 0;
  const highVersion = v1Higher ? v1 : v2;
  const lowVersion = v1Higher ? v2 : v1;
  const highHasPre = !!highVersion.prerelease.length;
  const lowHasPre = !!lowVersion.prerelease.length;
  if (lowHasPre && !highHasPre) {
    if (!lowVersion.patch && !lowVersion.minor) {
      return "major";
    }
    if (lowVersion.compareMain(highVersion) === 0) {
      if (lowVersion.minor && !lowVersion.patch) {
        return "minor";
      }
      return "patch";
    }
  }
  const prefix = highHasPre ? "pre" : "";
  if (v1.major !== v2.major) {
    return prefix + "major";
  }
  if (v1.minor !== v2.minor) {
    return prefix + "minor";
  }
  if (v1.patch !== v2.patch) {
    return prefix + "patch";
  }
  return "prerelease";
};
var diff_1 = diff$1;
const SemVer$e = semver$3;
const major$1 = (a, loose) => new SemVer$e(a, loose).major;
var major_1 = major$1;
const SemVer$d = semver$3;
const minor$1 = (a, loose) => new SemVer$d(a, loose).minor;
var minor_1 = minor$1;
const SemVer$c = semver$3;
const patch$1 = (a, loose) => new SemVer$c(a, loose).patch;
var patch_1 = patch$1;
const parse$5 = parse_1$1;
const prerelease$1 = (version2, options) => {
  const parsed = parse$5(version2, options);
  return parsed && parsed.prerelease.length ? parsed.prerelease : null;
};
var prerelease_1 = prerelease$1;
const SemVer$b = semver$3;
const compare$d = (a, b, loose) => new SemVer$b(a, loose).compare(new SemVer$b(b, loose));
var compare_1$1 = compare$d;
const compare$c = compare_1$1;
const rcompare$1 = (a, b, loose) => compare$c(b, a, loose);
var rcompare_1 = rcompare$1;
const compare$b = compare_1$1;
const compareLoose$1 = (a, b) => compare$b(a, b, true);
var compareLoose_1 = compareLoose$1;
const SemVer$a = semver$3;
const compareBuild$3 = (a, b, loose) => {
  const versionA = new SemVer$a(a, loose);
  const versionB = new SemVer$a(b, loose);
  return versionA.compare(versionB) || versionA.compareBuild(versionB);
};
var compareBuild_1 = compareBuild$3;
const compareBuild$2 = compareBuild_1;
const sort$1 = (list, loose) => list.sort((a, b) => compareBuild$2(a, b, loose));
var sort_1 = sort$1;
const compareBuild$1 = compareBuild_1;
const rsort$1 = (list, loose) => list.sort((a, b) => compareBuild$1(b, a, loose));
var rsort_1 = rsort$1;
const compare$a = compare_1$1;
const gt$4 = (a, b, loose) => compare$a(a, b, loose) > 0;
var gt_1 = gt$4;
const compare$9 = compare_1$1;
const lt$3 = (a, b, loose) => compare$9(a, b, loose) < 0;
var lt_1 = lt$3;
const compare$8 = compare_1$1;
const eq$2 = (a, b, loose) => compare$8(a, b, loose) === 0;
var eq_1 = eq$2;
const compare$7 = compare_1$1;
const neq$2 = (a, b, loose) => compare$7(a, b, loose) !== 0;
var neq_1 = neq$2;
const compare$6 = compare_1$1;
const gte$4 = (a, b, loose) => compare$6(a, b, loose) >= 0;
var gte_1$1 = gte$4;
const compare$5 = compare_1$1;
const lte$3 = (a, b, loose) => compare$5(a, b, loose) <= 0;
var lte_1 = lte$3;
const eq$1 = eq_1;
const neq$1 = neq_1;
const gt$3 = gt_1;
const gte$3 = gte_1$1;
const lt$2 = lt_1;
const lte$2 = lte_1;
const cmp$1 = (a, op, b, loose) => {
  switch (op) {
    case "===":
      if (typeof a === "object") {
        a = a.version;
      }
      if (typeof b === "object") {
        b = b.version;
      }
      return a === b;
    case "!==":
      if (typeof a === "object") {
        a = a.version;
      }
      if (typeof b === "object") {
        b = b.version;
      }
      return a !== b;
    case "":
    case "=":
    case "==":
      return eq$1(a, b, loose);
    case "!=":
      return neq$1(a, b, loose);
    case ">":
      return gt$3(a, b, loose);
    case ">=":
      return gte$3(a, b, loose);
    case "<":
      return lt$2(a, b, loose);
    case "<=":
      return lte$2(a, b, loose);
    default:
      throw new TypeError(`Invalid operator: ${op}`);
  }
};
var cmp_1 = cmp$1;
const SemVer$9 = semver$3;
const parse$4 = parse_1$1;
const { safeRe: re$3, t: t$2 } = reExports$1;
const coerce$2 = (version2, options) => {
  if (version2 instanceof SemVer$9) {
    return version2;
  }
  if (typeof version2 === "number") {
    version2 = String(version2);
  }
  if (typeof version2 !== "string") {
    return null;
  }
  options = options || {};
  let match = null;
  if (!options.rtl) {
    match = version2.match(options.includePrerelease ? re$3[t$2.COERCEFULL] : re$3[t$2.COERCE]);
  } else {
    const coerceRtlRegex = options.includePrerelease ? re$3[t$2.COERCERTLFULL] : re$3[t$2.COERCERTL];
    let next2;
    while ((next2 = coerceRtlRegex.exec(version2)) && (!match || match.index + match[0].length !== version2.length)) {
      if (!match || next2.index + next2[0].length !== match.index + match[0].length) {
        match = next2;
      }
      coerceRtlRegex.lastIndex = next2.index + next2[1].length + next2[2].length;
    }
    coerceRtlRegex.lastIndex = -1;
  }
  if (match === null) {
    return null;
  }
  const major2 = match[2];
  const minor2 = match[3] || "0";
  const patch2 = match[4] || "0";
  const prerelease2 = options.includePrerelease && match[5] ? `-${match[5]}` : "";
  const build = options.includePrerelease && match[6] ? `+${match[6]}` : "";
  return parse$4(`${major2}.${minor2}.${patch2}${prerelease2}${build}`, options);
};
var coerce_1$1 = coerce$2;
class LRUCache {
  constructor() {
    this.max = 1e3;
    this.map = /* @__PURE__ */ new Map();
  }
  get(key) {
    const value = this.map.get(key);
    if (value === void 0) {
      return void 0;
    } else {
      this.map.delete(key);
      this.map.set(key, value);
      return value;
    }
  }
  delete(key) {
    return this.map.delete(key);
  }
  set(key, value) {
    const deleted = this.delete(key);
    if (!deleted && value !== void 0) {
      if (this.map.size >= this.max) {
        const firstKey = this.map.keys().next().value;
        this.delete(firstKey);
      }
      this.map.set(key, value);
    }
    return this;
  }
}
var lrucache = LRUCache;
var range$1;
var hasRequiredRange;
function requireRange() {
  if (hasRequiredRange) return range$1;
  hasRequiredRange = 1;
  const SPACE_CHARACTERS = /\s+/g;
  class Range2 {
    constructor(range2, options) {
      options = parseOptions2(options);
      if (range2 instanceof Range2) {
        if (range2.loose === !!options.loose && range2.includePrerelease === !!options.includePrerelease) {
          return range2;
        } else {
          return new Range2(range2.raw, options);
        }
      }
      if (range2 instanceof Comparator2) {
        this.raw = range2.value;
        this.set = [[range2]];
        this.formatted = void 0;
        return this;
      }
      this.options = options;
      this.loose = !!options.loose;
      this.includePrerelease = !!options.includePrerelease;
      this.raw = range2.trim().replace(SPACE_CHARACTERS, " ");
      this.set = this.raw.split("||").map((r) => this.parseRange(r.trim())).filter((c) => c.length);
      if (!this.set.length) {
        throw new TypeError(`Invalid SemVer Range: ${this.raw}`);
      }
      if (this.set.length > 1) {
        const first = this.set[0];
        this.set = this.set.filter((c) => !isNullSet(c[0]));
        if (this.set.length === 0) {
          this.set = [first];
        } else if (this.set.length > 1) {
          for (const c of this.set) {
            if (c.length === 1 && isAny(c[0])) {
              this.set = [c];
              break;
            }
          }
        }
      }
      this.formatted = void 0;
    }
    get range() {
      if (this.formatted === void 0) {
        this.formatted = "";
        for (let i2 = 0; i2 < this.set.length; i2++) {
          if (i2 > 0) {
            this.formatted += "||";
          }
          const comps = this.set[i2];
          for (let k = 0; k < comps.length; k++) {
            if (k > 0) {
              this.formatted += " ";
            }
            this.formatted += comps[k].toString().trim();
          }
        }
      }
      return this.formatted;
    }
    format() {
      return this.range;
    }
    toString() {
      return this.range;
    }
    parseRange(range2) {
      const memoOpts = (this.options.includePrerelease && FLAG_INCLUDE_PRERELEASE) | (this.options.loose && FLAG_LOOSE);
      const memoKey = memoOpts + ":" + range2;
      const cached = cache2.get(memoKey);
      if (cached) {
        return cached;
      }
      const loose = this.options.loose;
      const hr = loose ? re2[t2.HYPHENRANGELOOSE] : re2[t2.HYPHENRANGE];
      range2 = range2.replace(hr, hyphenReplace(this.options.includePrerelease));
      debug2("hyphen replace", range2);
      range2 = range2.replace(re2[t2.COMPARATORTRIM], comparatorTrimReplace);
      debug2("comparator trim", range2);
      range2 = range2.replace(re2[t2.TILDETRIM], tildeTrimReplace);
      debug2("tilde trim", range2);
      range2 = range2.replace(re2[t2.CARETTRIM], caretTrimReplace);
      debug2("caret trim", range2);
      let rangeList = range2.split(" ").map((comp) => parseComparator(comp, this.options)).join(" ").split(/\s+/).map((comp) => replaceGTE0(comp, this.options));
      if (loose) {
        rangeList = rangeList.filter((comp) => {
          debug2("loose invalid filter", comp, this.options);
          return !!comp.match(re2[t2.COMPARATORLOOSE]);
        });
      }
      debug2("range list", rangeList);
      const rangeMap = /* @__PURE__ */ new Map();
      const comparators = rangeList.map((comp) => new Comparator2(comp, this.options));
      for (const comp of comparators) {
        if (isNullSet(comp)) {
          return [comp];
        }
        rangeMap.set(comp.value, comp);
      }
      if (rangeMap.size > 1 && rangeMap.has("")) {
        rangeMap.delete("");
      }
      const result = [...rangeMap.values()];
      cache2.set(memoKey, result);
      return result;
    }
    intersects(range2, options) {
      if (!(range2 instanceof Range2)) {
        throw new TypeError("a Range is required");
      }
      return this.set.some((thisComparators) => {
        return isSatisfiable(thisComparators, options) && range2.set.some((rangeComparators) => {
          return isSatisfiable(rangeComparators, options) && thisComparators.every((thisComparator) => {
            return rangeComparators.every((rangeComparator) => {
              return thisComparator.intersects(rangeComparator, options);
            });
          });
        });
      });
    }
    // if ANY of the sets match ALL of its comparators, then pass
    test(version2) {
      if (!version2) {
        return false;
      }
      if (typeof version2 === "string") {
        try {
          version2 = new SemVer4(version2, this.options);
        } catch (er) {
          return false;
        }
      }
      for (let i2 = 0; i2 < this.set.length; i2++) {
        if (testSet(this.set[i2], version2, this.options)) {
          return true;
        }
      }
      return false;
    }
  }
  range$1 = Range2;
  const LRU = lrucache;
  const cache2 = new LRU();
  const parseOptions2 = parseOptions_1$1;
  const Comparator2 = requireComparator();
  const debug2 = debug_1$1;
  const SemVer4 = semver$3;
  const {
    safeRe: re2,
    t: t2,
    comparatorTrimReplace,
    tildeTrimReplace,
    caretTrimReplace
  } = reExports$1;
  const { FLAG_INCLUDE_PRERELEASE, FLAG_LOOSE } = constants$2;
  const isNullSet = (c) => c.value === "<0.0.0-0";
  const isAny = (c) => c.value === "";
  const isSatisfiable = (comparators, options) => {
    let result = true;
    const remainingComparators = comparators.slice();
    let testComparator = remainingComparators.pop();
    while (result && remainingComparators.length) {
      result = remainingComparators.every((otherComparator) => {
        return testComparator.intersects(otherComparator, options);
      });
      testComparator = remainingComparators.pop();
    }
    return result;
  };
  const parseComparator = (comp, options) => {
    comp = comp.replace(re2[t2.BUILD], "");
    debug2("comp", comp, options);
    comp = replaceCarets(comp, options);
    debug2("caret", comp);
    comp = replaceTildes(comp, options);
    debug2("tildes", comp);
    comp = replaceXRanges(comp, options);
    debug2("xrange", comp);
    comp = replaceStars(comp, options);
    debug2("stars", comp);
    return comp;
  };
  const isX = (id2) => !id2 || id2.toLowerCase() === "x" || id2 === "*";
  const replaceTildes = (comp, options) => {
    return comp.trim().split(/\s+/).map((c) => replaceTilde(c, options)).join(" ");
  };
  const replaceTilde = (comp, options) => {
    const r = options.loose ? re2[t2.TILDELOOSE] : re2[t2.TILDE];
    return comp.replace(r, (_, M, m, p, pr) => {
      debug2("tilde", comp, _, M, m, p, pr);
      let ret;
      if (isX(M)) {
        ret = "";
      } else if (isX(m)) {
        ret = `>=${M}.0.0 <${+M + 1}.0.0-0`;
      } else if (isX(p)) {
        ret = `>=${M}.${m}.0 <${M}.${+m + 1}.0-0`;
      } else if (pr) {
        debug2("replaceTilde pr", pr);
        ret = `>=${M}.${m}.${p}-${pr} <${M}.${+m + 1}.0-0`;
      } else {
        ret = `>=${M}.${m}.${p} <${M}.${+m + 1}.0-0`;
      }
      debug2("tilde return", ret);
      return ret;
    });
  };
  const replaceCarets = (comp, options) => {
    return comp.trim().split(/\s+/).map((c) => replaceCaret(c, options)).join(" ");
  };
  const replaceCaret = (comp, options) => {
    debug2("caret", comp, options);
    const r = options.loose ? re2[t2.CARETLOOSE] : re2[t2.CARET];
    const z = options.includePrerelease ? "-0" : "";
    return comp.replace(r, (_, M, m, p, pr) => {
      debug2("caret", comp, _, M, m, p, pr);
      let ret;
      if (isX(M)) {
        ret = "";
      } else if (isX(m)) {
        ret = `>=${M}.0.0${z} <${+M + 1}.0.0-0`;
      } else if (isX(p)) {
        if (M === "0") {
          ret = `>=${M}.${m}.0${z} <${M}.${+m + 1}.0-0`;
        } else {
          ret = `>=${M}.${m}.0${z} <${+M + 1}.0.0-0`;
        }
      } else if (pr) {
        debug2("replaceCaret pr", pr);
        if (M === "0") {
          if (m === "0") {
            ret = `>=${M}.${m}.${p}-${pr} <${M}.${m}.${+p + 1}-0`;
          } else {
            ret = `>=${M}.${m}.${p}-${pr} <${M}.${+m + 1}.0-0`;
          }
        } else {
          ret = `>=${M}.${m}.${p}-${pr} <${+M + 1}.0.0-0`;
        }
      } else {
        debug2("no pr");
        if (M === "0") {
          if (m === "0") {
            ret = `>=${M}.${m}.${p}${z} <${M}.${m}.${+p + 1}-0`;
          } else {
            ret = `>=${M}.${m}.${p}${z} <${M}.${+m + 1}.0-0`;
          }
        } else {
          ret = `>=${M}.${m}.${p} <${+M + 1}.0.0-0`;
        }
      }
      debug2("caret return", ret);
      return ret;
    });
  };
  const replaceXRanges = (comp, options) => {
    debug2("replaceXRanges", comp, options);
    return comp.split(/\s+/).map((c) => replaceXRange(c, options)).join(" ");
  };
  const replaceXRange = (comp, options) => {
    comp = comp.trim();
    const r = options.loose ? re2[t2.XRANGELOOSE] : re2[t2.XRANGE];
    return comp.replace(r, (ret, gtlt, M, m, p, pr) => {
      debug2("xRange", comp, ret, gtlt, M, m, p, pr);
      const xM = isX(M);
      const xm = xM || isX(m);
      const xp = xm || isX(p);
      const anyX = xp;
      if (gtlt === "=" && anyX) {
        gtlt = "";
      }
      pr = options.includePrerelease ? "-0" : "";
      if (xM) {
        if (gtlt === ">" || gtlt === "<") {
          ret = "<0.0.0-0";
        } else {
          ret = "*";
        }
      } else if (gtlt && anyX) {
        if (xm) {
          m = 0;
        }
        p = 0;
        if (gtlt === ">") {
          gtlt = ">=";
          if (xm) {
            M = +M + 1;
            m = 0;
            p = 0;
          } else {
            m = +m + 1;
            p = 0;
          }
        } else if (gtlt === "<=") {
          gtlt = "<";
          if (xm) {
            M = +M + 1;
          } else {
            m = +m + 1;
          }
        }
        if (gtlt === "<") {
          pr = "-0";
        }
        ret = `${gtlt + M}.${m}.${p}${pr}`;
      } else if (xm) {
        ret = `>=${M}.0.0${pr} <${+M + 1}.0.0-0`;
      } else if (xp) {
        ret = `>=${M}.${m}.0${pr} <${M}.${+m + 1}.0-0`;
      }
      debug2("xRange return", ret);
      return ret;
    });
  };
  const replaceStars = (comp, options) => {
    debug2("replaceStars", comp, options);
    return comp.trim().replace(re2[t2.STAR], "");
  };
  const replaceGTE0 = (comp, options) => {
    debug2("replaceGTE0", comp, options);
    return comp.trim().replace(re2[options.includePrerelease ? t2.GTE0PRE : t2.GTE0], "");
  };
  const hyphenReplace = (incPr) => ($0, from, fM, fm, fp, fpr, fb, to, tM, tm, tp, tpr) => {
    if (isX(fM)) {
      from = "";
    } else if (isX(fm)) {
      from = `>=${fM}.0.0${incPr ? "-0" : ""}`;
    } else if (isX(fp)) {
      from = `>=${fM}.${fm}.0${incPr ? "-0" : ""}`;
    } else if (fpr) {
      from = `>=${from}`;
    } else {
      from = `>=${from}${incPr ? "-0" : ""}`;
    }
    if (isX(tM)) {
      to = "";
    } else if (isX(tm)) {
      to = `<${+tM + 1}.0.0-0`;
    } else if (isX(tp)) {
      to = `<${tM}.${+tm + 1}.0-0`;
    } else if (tpr) {
      to = `<=${tM}.${tm}.${tp}-${tpr}`;
    } else if (incPr) {
      to = `<${tM}.${tm}.${+tp + 1}-0`;
    } else {
      to = `<=${to}`;
    }
    return `${from} ${to}`.trim();
  };
  const testSet = (set, version2, options) => {
    for (let i2 = 0; i2 < set.length; i2++) {
      if (!set[i2].test(version2)) {
        return false;
      }
    }
    if (version2.prerelease.length && !options.includePrerelease) {
      for (let i2 = 0; i2 < set.length; i2++) {
        debug2(set[i2].semver);
        if (set[i2].semver === Comparator2.ANY) {
          continue;
        }
        if (set[i2].semver.prerelease.length > 0) {
          const allowed = set[i2].semver;
          if (allowed.major === version2.major && allowed.minor === version2.minor && allowed.patch === version2.patch) {
            return true;
          }
        }
      }
      return false;
    }
    return true;
  };
  return range$1;
}
var comparator;
var hasRequiredComparator;
function requireComparator() {
  if (hasRequiredComparator) return comparator;
  hasRequiredComparator = 1;
  const ANY2 = Symbol("SemVer ANY");
  class Comparator2 {
    static get ANY() {
      return ANY2;
    }
    constructor(comp, options) {
      options = parseOptions2(options);
      if (comp instanceof Comparator2) {
        if (comp.loose === !!options.loose) {
          return comp;
        } else {
          comp = comp.value;
        }
      }
      comp = comp.trim().split(/\s+/).join(" ");
      debug2("comparator", comp, options);
      this.options = options;
      this.loose = !!options.loose;
      this.parse(comp);
      if (this.semver === ANY2) {
        this.value = "";
      } else {
        this.value = this.operator + this.semver.version;
      }
      debug2("comp", this);
    }
    parse(comp) {
      const r = this.options.loose ? re2[t2.COMPARATORLOOSE] : re2[t2.COMPARATOR];
      const m = comp.match(r);
      if (!m) {
        throw new TypeError(`Invalid comparator: ${comp}`);
      }
      this.operator = m[1] !== void 0 ? m[1] : "";
      if (this.operator === "=") {
        this.operator = "";
      }
      if (!m[2]) {
        this.semver = ANY2;
      } else {
        this.semver = new SemVer4(m[2], this.options.loose);
      }
    }
    toString() {
      return this.value;
    }
    test(version2) {
      debug2("Comparator.test", version2, this.options.loose);
      if (this.semver === ANY2 || version2 === ANY2) {
        return true;
      }
      if (typeof version2 === "string") {
        try {
          version2 = new SemVer4(version2, this.options);
        } catch (er) {
          return false;
        }
      }
      return cmp2(version2, this.operator, this.semver, this.options);
    }
    intersects(comp, options) {
      if (!(comp instanceof Comparator2)) {
        throw new TypeError("a Comparator is required");
      }
      if (this.operator === "") {
        if (this.value === "") {
          return true;
        }
        return new Range2(comp.value, options).test(this.value);
      } else if (comp.operator === "") {
        if (comp.value === "") {
          return true;
        }
        return new Range2(this.value, options).test(comp.semver);
      }
      options = parseOptions2(options);
      if (options.includePrerelease && (this.value === "<0.0.0-0" || comp.value === "<0.0.0-0")) {
        return false;
      }
      if (!options.includePrerelease && (this.value.startsWith("<0.0.0") || comp.value.startsWith("<0.0.0"))) {
        return false;
      }
      if (this.operator.startsWith(">") && comp.operator.startsWith(">")) {
        return true;
      }
      if (this.operator.startsWith("<") && comp.operator.startsWith("<")) {
        return true;
      }
      if (this.semver.version === comp.semver.version && this.operator.includes("=") && comp.operator.includes("=")) {
        return true;
      }
      if (cmp2(this.semver, "<", comp.semver, options) && this.operator.startsWith(">") && comp.operator.startsWith("<")) {
        return true;
      }
      if (cmp2(this.semver, ">", comp.semver, options) && this.operator.startsWith("<") && comp.operator.startsWith(">")) {
        return true;
      }
      return false;
    }
  }
  comparator = Comparator2;
  const parseOptions2 = parseOptions_1$1;
  const { safeRe: re2, t: t2 } = reExports$1;
  const cmp2 = cmp_1;
  const debug2 = debug_1$1;
  const SemVer4 = semver$3;
  const Range2 = requireRange();
  return comparator;
}
const Range$9 = requireRange();
const satisfies$4 = (version2, range2, options) => {
  try {
    range2 = new Range$9(range2, options);
  } catch (er) {
    return false;
  }
  return range2.test(version2);
};
var satisfies_1 = satisfies$4;
const Range$8 = requireRange();
const toComparators$1 = (range2, options) => new Range$8(range2, options).set.map((comp) => comp.map((c) => c.value).join(" ").trim().split(" "));
var toComparators_1 = toComparators$1;
const SemVer$8 = semver$3;
const Range$7 = requireRange();
const maxSatisfying$1 = (versions2, range2, options) => {
  let max2 = null;
  let maxSV = null;
  let rangeObj = null;
  try {
    rangeObj = new Range$7(range2, options);
  } catch (er) {
    return null;
  }
  versions2.forEach((v) => {
    if (rangeObj.test(v)) {
      if (!max2 || maxSV.compare(v) === -1) {
        max2 = v;
        maxSV = new SemVer$8(max2, options);
      }
    }
  });
  return max2;
};
var maxSatisfying_1 = maxSatisfying$1;
const SemVer$7 = semver$3;
const Range$6 = requireRange();
const minSatisfying$1 = (versions2, range2, options) => {
  let min2 = null;
  let minSV = null;
  let rangeObj = null;
  try {
    rangeObj = new Range$6(range2, options);
  } catch (er) {
    return null;
  }
  versions2.forEach((v) => {
    if (rangeObj.test(v)) {
      if (!min2 || minSV.compare(v) === 1) {
        min2 = v;
        minSV = new SemVer$7(min2, options);
      }
    }
  });
  return min2;
};
var minSatisfying_1 = minSatisfying$1;
const SemVer$6 = semver$3;
const Range$5 = requireRange();
const gt$2 = gt_1;
const minVersion$1 = (range2, loose) => {
  range2 = new Range$5(range2, loose);
  let minver = new SemVer$6("0.0.0");
  if (range2.test(minver)) {
    return minver;
  }
  minver = new SemVer$6("0.0.0-0");
  if (range2.test(minver)) {
    return minver;
  }
  minver = null;
  for (let i2 = 0; i2 < range2.set.length; ++i2) {
    const comparators = range2.set[i2];
    let setMin = null;
    comparators.forEach((comparator2) => {
      const compver = new SemVer$6(comparator2.semver.version);
      switch (comparator2.operator) {
        case ">":
          if (compver.prerelease.length === 0) {
            compver.patch++;
          } else {
            compver.prerelease.push(0);
          }
          compver.raw = compver.format();
        case "":
        case ">=":
          if (!setMin || gt$2(compver, setMin)) {
            setMin = compver;
          }
          break;
        case "<":
        case "<=":
          break;
        default:
          throw new Error(`Unexpected operation: ${comparator2.operator}`);
      }
    });
    if (setMin && (!minver || gt$2(minver, setMin))) {
      minver = setMin;
    }
  }
  if (minver && range2.test(minver)) {
    return minver;
  }
  return null;
};
var minVersion_1 = minVersion$1;
const Range$4 = requireRange();
const validRange$1 = (range2, options) => {
  try {
    return new Range$4(range2, options).range || "*";
  } catch (er) {
    return null;
  }
};
var valid$1 = validRange$1;
const SemVer$5 = semver$3;
const Comparator$2 = requireComparator();
const { ANY: ANY$1 } = Comparator$2;
const Range$3 = requireRange();
const satisfies$3 = satisfies_1;
const gt$1 = gt_1;
const lt$1 = lt_1;
const lte$1 = lte_1;
const gte$2 = gte_1$1;
const outside$3 = (version2, range2, hilo, options) => {
  version2 = new SemVer$5(version2, options);
  range2 = new Range$3(range2, options);
  let gtfn, ltefn, ltfn, comp, ecomp;
  switch (hilo) {
    case ">":
      gtfn = gt$1;
      ltefn = lte$1;
      ltfn = lt$1;
      comp = ">";
      ecomp = ">=";
      break;
    case "<":
      gtfn = lt$1;
      ltefn = gte$2;
      ltfn = gt$1;
      comp = "<";
      ecomp = "<=";
      break;
    default:
      throw new TypeError('Must provide a hilo val of "<" or ">"');
  }
  if (satisfies$3(version2, range2, options)) {
    return false;
  }
  for (let i2 = 0; i2 < range2.set.length; ++i2) {
    const comparators = range2.set[i2];
    let high = null;
    let low = null;
    comparators.forEach((comparator2) => {
      if (comparator2.semver === ANY$1) {
        comparator2 = new Comparator$2(">=0.0.0");
      }
      high = high || comparator2;
      low = low || comparator2;
      if (gtfn(comparator2.semver, high.semver, options)) {
        high = comparator2;
      } else if (ltfn(comparator2.semver, low.semver, options)) {
        low = comparator2;
      }
    });
    if (high.operator === comp || high.operator === ecomp) {
      return false;
    }
    if ((!low.operator || low.operator === comp) && ltefn(version2, low.semver)) {
      return false;
    } else if (low.operator === ecomp && ltfn(version2, low.semver)) {
      return false;
    }
  }
  return true;
};
var outside_1 = outside$3;
const outside$2 = outside_1;
const gtr$1 = (version2, range2, options) => outside$2(version2, range2, ">", options);
var gtr_1 = gtr$1;
const outside$1 = outside_1;
const ltr$1 = (version2, range2, options) => outside$1(version2, range2, "<", options);
var ltr_1 = ltr$1;
const Range$2 = requireRange();
const intersects$1 = (r1, r2, options) => {
  r1 = new Range$2(r1, options);
  r2 = new Range$2(r2, options);
  return r1.intersects(r2, options);
};
var intersects_1 = intersects$1;
const satisfies$2 = satisfies_1;
const compare$4 = compare_1$1;
var simplify = (versions2, range2, options) => {
  const set = [];
  let first = null;
  let prev = null;
  const v = versions2.sort((a, b) => compare$4(a, b, options));
  for (const version2 of v) {
    const included = satisfies$2(version2, range2, options);
    if (included) {
      prev = version2;
      if (!first) {
        first = version2;
      }
    } else {
      if (prev) {
        set.push([first, prev]);
      }
      prev = null;
      first = null;
    }
  }
  if (first) {
    set.push([first, null]);
  }
  const ranges = [];
  for (const [min2, max2] of set) {
    if (min2 === max2) {
      ranges.push(min2);
    } else if (!max2 && min2 === v[0]) {
      ranges.push("*");
    } else if (!max2) {
      ranges.push(`>=${min2}`);
    } else if (min2 === v[0]) {
      ranges.push(`<=${max2}`);
    } else {
      ranges.push(`${min2} - ${max2}`);
    }
  }
  const simplified = ranges.join(" || ");
  const original = typeof range2.raw === "string" ? range2.raw : String(range2);
  return simplified.length < original.length ? simplified : range2;
};
const Range$1 = requireRange();
const Comparator$1 = requireComparator();
const { ANY } = Comparator$1;
const satisfies$1 = satisfies_1;
const compare$3 = compare_1$1;
const subset$1 = (sub, dom, options = {}) => {
  if (sub === dom) {
    return true;
  }
  sub = new Range$1(sub, options);
  dom = new Range$1(dom, options);
  let sawNonNull = false;
  OUTER: for (const simpleSub of sub.set) {
    for (const simpleDom of dom.set) {
      const isSub = simpleSubset(simpleSub, simpleDom, options);
      sawNonNull = sawNonNull || isSub !== null;
      if (isSub) {
        continue OUTER;
      }
    }
    if (sawNonNull) {
      return false;
    }
  }
  return true;
};
const minimumVersionWithPreRelease = [new Comparator$1(">=0.0.0-0")];
const minimumVersion = [new Comparator$1(">=0.0.0")];
const simpleSubset = (sub, dom, options) => {
  if (sub === dom) {
    return true;
  }
  if (sub.length === 1 && sub[0].semver === ANY) {
    if (dom.length === 1 && dom[0].semver === ANY) {
      return true;
    } else if (options.includePrerelease) {
      sub = minimumVersionWithPreRelease;
    } else {
      sub = minimumVersion;
    }
  }
  if (dom.length === 1 && dom[0].semver === ANY) {
    if (options.includePrerelease) {
      return true;
    } else {
      dom = minimumVersion;
    }
  }
  const eqSet = /* @__PURE__ */ new Set();
  let gt2, lt2;
  for (const c of sub) {
    if (c.operator === ">" || c.operator === ">=") {
      gt2 = higherGT(gt2, c, options);
    } else if (c.operator === "<" || c.operator === "<=") {
      lt2 = lowerLT(lt2, c, options);
    } else {
      eqSet.add(c.semver);
    }
  }
  if (eqSet.size > 1) {
    return null;
  }
  let gtltComp;
  if (gt2 && lt2) {
    gtltComp = compare$3(gt2.semver, lt2.semver, options);
    if (gtltComp > 0) {
      return null;
    } else if (gtltComp === 0 && (gt2.operator !== ">=" || lt2.operator !== "<=")) {
      return null;
    }
  }
  for (const eq2 of eqSet) {
    if (gt2 && !satisfies$1(eq2, String(gt2), options)) {
      return null;
    }
    if (lt2 && !satisfies$1(eq2, String(lt2), options)) {
      return null;
    }
    for (const c of dom) {
      if (!satisfies$1(eq2, String(c), options)) {
        return false;
      }
    }
    return true;
  }
  let higher, lower;
  let hasDomLT, hasDomGT;
  let needDomLTPre = lt2 && !options.includePrerelease && lt2.semver.prerelease.length ? lt2.semver : false;
  let needDomGTPre = gt2 && !options.includePrerelease && gt2.semver.prerelease.length ? gt2.semver : false;
  if (needDomLTPre && needDomLTPre.prerelease.length === 1 && lt2.operator === "<" && needDomLTPre.prerelease[0] === 0) {
    needDomLTPre = false;
  }
  for (const c of dom) {
    hasDomGT = hasDomGT || c.operator === ">" || c.operator === ">=";
    hasDomLT = hasDomLT || c.operator === "<" || c.operator === "<=";
    if (gt2) {
      if (needDomGTPre) {
        if (c.semver.prerelease && c.semver.prerelease.length && c.semver.major === needDomGTPre.major && c.semver.minor === needDomGTPre.minor && c.semver.patch === needDomGTPre.patch) {
          needDomGTPre = false;
        }
      }
      if (c.operator === ">" || c.operator === ">=") {
        higher = higherGT(gt2, c, options);
        if (higher === c && higher !== gt2) {
          return false;
        }
      } else if (gt2.operator === ">=" && !satisfies$1(gt2.semver, String(c), options)) {
        return false;
      }
    }
    if (lt2) {
      if (needDomLTPre) {
        if (c.semver.prerelease && c.semver.prerelease.length && c.semver.major === needDomLTPre.major && c.semver.minor === needDomLTPre.minor && c.semver.patch === needDomLTPre.patch) {
          needDomLTPre = false;
        }
      }
      if (c.operator === "<" || c.operator === "<=") {
        lower = lowerLT(lt2, c, options);
        if (lower === c && lower !== lt2) {
          return false;
        }
      } else if (lt2.operator === "<=" && !satisfies$1(lt2.semver, String(c), options)) {
        return false;
      }
    }
    if (!c.operator && (lt2 || gt2) && gtltComp !== 0) {
      return false;
    }
  }
  if (gt2 && hasDomLT && !lt2 && gtltComp !== 0) {
    return false;
  }
  if (lt2 && hasDomGT && !gt2 && gtltComp !== 0) {
    return false;
  }
  if (needDomGTPre || needDomLTPre) {
    return false;
  }
  return true;
};
const higherGT = (a, b, options) => {
  if (!a) {
    return b;
  }
  const comp = compare$3(a.semver, b.semver, options);
  return comp > 0 ? a : comp < 0 ? b : b.operator === ">" && a.operator === ">=" ? b : a;
};
const lowerLT = (a, b, options) => {
  if (!a) {
    return b;
  }
  const comp = compare$3(a.semver, b.semver, options);
  return comp < 0 ? a : comp > 0 ? b : b.operator === "<" && a.operator === "<=" ? b : a;
};
var subset_1 = subset$1;
const internalRe = reExports$1;
const constants$1 = constants$2;
const SemVer$4 = semver$3;
const identifiers$1 = identifiers$2;
const parse$3 = parse_1$1;
const valid = valid_1;
const clean = clean_1;
const inc = inc_1;
const diff = diff_1;
const major = major_1;
const minor = minor_1;
const patch = patch_1;
const prerelease = prerelease_1;
const compare$2 = compare_1$1;
const rcompare = rcompare_1;
const compareLoose = compareLoose_1;
const compareBuild = compareBuild_1;
const sort = sort_1;
const rsort = rsort_1;
const gt = gt_1;
const lt = lt_1;
const eq = eq_1;
const neq = neq_1;
const gte$1 = gte_1$1;
const lte = lte_1;
const cmp = cmp_1;
const coerce$1 = coerce_1$1;
const Comparator = requireComparator();
const Range = requireRange();
const satisfies = satisfies_1;
const toComparators = toComparators_1;
const maxSatisfying = maxSatisfying_1;
const minSatisfying = minSatisfying_1;
const minVersion = minVersion_1;
const validRange = valid$1;
const outside = outside_1;
const gtr = gtr_1;
const ltr = ltr_1;
const intersects = intersects_1;
const simplifyRange = simplify;
const subset = subset_1;
var semver$1 = {
  parse: parse$3,
  valid,
  clean,
  inc,
  diff,
  major,
  minor,
  patch,
  prerelease,
  compare: compare$2,
  rcompare,
  compareLoose,
  compareBuild,
  sort,
  rsort,
  gt,
  lt,
  eq,
  neq,
  gte: gte$1,
  lte,
  cmp,
  coerce: coerce$1,
  Comparator,
  Range,
  satisfies,
  toComparators,
  maxSatisfying,
  minSatisfying,
  minVersion,
  validRange,
  outside,
  gtr,
  ltr,
  intersects,
  simplifyRange,
  subset,
  SemVer: SemVer$4,
  re: internalRe.re,
  src: internalRe.src,
  tokens: internalRe.t,
  SEMVER_SPEC_VERSION: constants$1.SEMVER_SPEC_VERSION,
  RELEASE_TYPES: constants$1.RELEASE_TYPES,
  compareIdentifiers: identifiers$1.compareIdentifiers,
  rcompareIdentifiers: identifiers$1.rcompareIdentifiers
};
const semver$2 = /* @__PURE__ */ getDefaultExportFromCjs(semver$1);
const objectToString = Object.prototype.toString;
const uint8ArrayStringified = "[object Uint8Array]";
const arrayBufferStringified = "[object ArrayBuffer]";
function isType(value, typeConstructor, typeStringified) {
  if (!value) {
    return false;
  }
  if (value.constructor === typeConstructor) {
    return true;
  }
  return objectToString.call(value) === typeStringified;
}
function isUint8Array(value) {
  return isType(value, Uint8Array, uint8ArrayStringified);
}
function isArrayBuffer(value) {
  return isType(value, ArrayBuffer, arrayBufferStringified);
}
function isUint8ArrayOrArrayBuffer(value) {
  return isUint8Array(value) || isArrayBuffer(value);
}
function assertUint8Array(value) {
  if (!isUint8Array(value)) {
    throw new TypeError(`Expected \`Uint8Array\`, got \`${typeof value}\``);
  }
}
function assertUint8ArrayOrArrayBuffer(value) {
  if (!isUint8ArrayOrArrayBuffer(value)) {
    throw new TypeError(`Expected \`Uint8Array\` or \`ArrayBuffer\`, got \`${typeof value}\``);
  }
}
function concatUint8Arrays(arrays, totalLength) {
  if (arrays.length === 0) {
    return new Uint8Array(0);
  }
  totalLength ?? (totalLength = arrays.reduce((accumulator, currentValue) => accumulator + currentValue.length, 0));
  const returnValue = new Uint8Array(totalLength);
  let offset = 0;
  for (const array of arrays) {
    assertUint8Array(array);
    returnValue.set(array, offset);
    offset += array.length;
  }
  return returnValue;
}
const cachedDecoders = {
  utf8: new globalThis.TextDecoder("utf8")
};
function uint8ArrayToString(array, encoding = "utf8") {
  assertUint8ArrayOrArrayBuffer(array);
  cachedDecoders[encoding] ?? (cachedDecoders[encoding] = new globalThis.TextDecoder(encoding));
  return cachedDecoders[encoding].decode(array);
}
function assertString(value) {
  if (typeof value !== "string") {
    throw new TypeError(`Expected \`string\`, got \`${typeof value}\``);
  }
}
const cachedEncoder = new globalThis.TextEncoder();
function stringToUint8Array(string2) {
  assertString(string2);
  return cachedEncoder.encode(string2);
}
Array.from({ length: 256 }, (_, index2) => index2.toString(16).padStart(2, "0"));
const defaultEncryptionAlgorithm = "aes-256-cbc";
const supportedEncryptionAlgorithms = /* @__PURE__ */ new Set([
  "aes-256-cbc",
  "aes-256-gcm",
  "aes-256-ctr"
]);
const isSupportedEncryptionAlgorithm = (value) => typeof value === "string" && supportedEncryptionAlgorithms.has(value);
const createPlainObject = () => /* @__PURE__ */ Object.create(null);
const isExist = (data) => data !== void 0;
const checkValueType = (key, value) => {
  const nonJsonTypes = /* @__PURE__ */ new Set([
    "undefined",
    "symbol",
    "function"
  ]);
  const type2 = typeof value;
  if (nonJsonTypes.has(type2)) {
    throw new TypeError(`Setting a value of type \`${type2}\` for key \`${key}\` is not allowed as it's not supported by JSON`);
  }
};
const INTERNAL_KEY = "__internal__";
const MIGRATION_KEY = `${INTERNAL_KEY}.migrations.version`;
class Conf {
  constructor(partialOptions = {}) {
    __privateAdd(this, _Conf_instances);
    __publicField(this, "path");
    __publicField(this, "events");
    __privateAdd(this, _validator);
    __privateAdd(this, _encryptionKey);
    __privateAdd(this, _encryptionAlgorithm);
    __privateAdd(this, _options);
    __privateAdd(this, _defaultValues, {});
    __privateAdd(this, _isInMigration, false);
    __privateAdd(this, _watcher);
    __privateAdd(this, _watchFile);
    __privateAdd(this, _debouncedChangeHandler);
    __publicField(this, "_deserialize", (value) => JSON.parse(value));
    __publicField(this, "_serialize", (value) => JSON.stringify(value, void 0, "	"));
    const options = __privateMethod(this, _Conf_instances, prepareOptions_fn).call(this, partialOptions);
    __privateSet(this, _options, options);
    __privateMethod(this, _Conf_instances, setupValidator_fn).call(this, options);
    __privateMethod(this, _Conf_instances, applyDefaultValues_fn).call(this, options);
    __privateMethod(this, _Conf_instances, configureSerialization_fn).call(this, options);
    this.events = new EventTarget();
    __privateSet(this, _encryptionKey, options.encryptionKey);
    __privateSet(this, _encryptionAlgorithm, options.encryptionAlgorithm ?? defaultEncryptionAlgorithm);
    this.path = __privateMethod(this, _Conf_instances, resolvePath_fn).call(this, options);
    __privateMethod(this, _Conf_instances, initializeStore_fn).call(this, options);
    if (options.watch) {
      this._watch();
    }
  }
  get(key, defaultValue) {
    if (__privateGet(this, _options).accessPropertiesByDotNotation) {
      return this._get(key, defaultValue);
    }
    const { store: store2 } = this;
    return key in store2 ? store2[key] : defaultValue;
  }
  set(key, value) {
    if (typeof key !== "string" && typeof key !== "object") {
      throw new TypeError(`Expected \`key\` to be of type \`string\` or \`object\`, got ${typeof key}`);
    }
    if (typeof key !== "object" && value === void 0) {
      throw new TypeError("Use `delete()` to clear values");
    }
    if (this._containsReservedKey(key)) {
      throw new TypeError(`Please don't use the ${INTERNAL_KEY} key, as it's used to manage this module internal operations.`);
    }
    const { store: store2 } = this;
    const set = (key2, value2) => {
      checkValueType(key2, value2);
      if (__privateGet(this, _options).accessPropertiesByDotNotation) {
        setProperty(store2, key2, value2);
      } else {
        if (key2 === "__proto__" || key2 === "constructor" || key2 === "prototype") {
          return;
        }
        store2[key2] = value2;
      }
    };
    if (typeof key === "object") {
      const object2 = key;
      for (const [key2, value2] of Object.entries(object2)) {
        set(key2, value2);
      }
    } else {
      set(key, value);
    }
    this.store = store2;
  }
  has(key) {
    if (__privateGet(this, _options).accessPropertiesByDotNotation) {
      return hasProperty(this.store, key);
    }
    return key in this.store;
  }
  appendToArray(key, value) {
    checkValueType(key, value);
    const array = __privateGet(this, _options).accessPropertiesByDotNotation ? this._get(key, []) : key in this.store ? this.store[key] : [];
    if (!Array.isArray(array)) {
      throw new TypeError(`The key \`${key}\` is already set to a non-array value`);
    }
    this.set(key, [...array, value]);
  }
  /**
      Reset items to their default values, as defined by the `defaults` or `schema` option.
  
      @see `clear()` to reset all items.
  
      @param keys - The keys of the items to reset.
      */
  reset(...keys) {
    for (const key of keys) {
      if (isExist(__privateGet(this, _defaultValues)[key])) {
        this.set(key, __privateGet(this, _defaultValues)[key]);
      }
    }
  }
  delete(key) {
    const { store: store2 } = this;
    if (__privateGet(this, _options).accessPropertiesByDotNotation) {
      deleteProperty(store2, key);
    } else {
      delete store2[key];
    }
    this.store = store2;
  }
  /**
      Delete all items.
  
      This resets known items to their default values, if defined by the `defaults` or `schema` option.
      */
  clear() {
    const newStore = createPlainObject();
    for (const key of Object.keys(__privateGet(this, _defaultValues))) {
      if (isExist(__privateGet(this, _defaultValues)[key])) {
        checkValueType(key, __privateGet(this, _defaultValues)[key]);
        if (__privateGet(this, _options).accessPropertiesByDotNotation) {
          setProperty(newStore, key, __privateGet(this, _defaultValues)[key]);
        } else {
          newStore[key] = __privateGet(this, _defaultValues)[key];
        }
      }
    }
    this.store = newStore;
  }
  onDidChange(key, callback) {
    if (typeof key !== "string") {
      throw new TypeError(`Expected \`key\` to be of type \`string\`, got ${typeof key}`);
    }
    if (typeof callback !== "function") {
      throw new TypeError(`Expected \`callback\` to be of type \`function\`, got ${typeof callback}`);
    }
    return this._handleValueChange(() => this.get(key), callback);
  }
  /**
      Watches the whole config object, calling `callback` on any changes.
  
      @param callback - A callback function that is called on any changes. When a `key` is first set `oldValue` will be `undefined`, and when a key is deleted `newValue` will be `undefined`.
      @returns A function, that when called, will unsubscribe.
      */
  onDidAnyChange(callback) {
    if (typeof callback !== "function") {
      throw new TypeError(`Expected \`callback\` to be of type \`function\`, got ${typeof callback}`);
    }
    return this._handleStoreChange(callback);
  }
  get size() {
    const entries = Object.keys(this.store);
    return entries.filter((key) => !this._isReservedKeyPath(key)).length;
  }
  /**
      Get all the config as an object or replace the current config with an object.
  
      @example
      ```
      console.log(config.store);
      //=> {name: 'John', age: 30}
      ```
  
      @example
      ```
      config.store = {
          hello: 'world'
      };
      ```
      */
  get store() {
    var _a2;
    try {
      const data = fs$3.readFileSync(this.path, __privateGet(this, _encryptionKey) ? null : "utf8");
      const dataString = this._decryptData(data);
      const parseStore = (value) => {
        const deserializedData = this._deserialize(value);
        if (!__privateGet(this, _isInMigration)) {
          this._validate(deserializedData);
        }
        return Object.assign(createPlainObject(), deserializedData);
      };
      return parseStore(dataString);
    } catch (error2) {
      if ((error2 == null ? void 0 : error2.code) === "ENOENT") {
        this._ensureDirectory();
        return createPlainObject();
      }
      if (__privateGet(this, _options).clearInvalidConfig) {
        const errorInstance = error2;
        if (errorInstance.name === "SyntaxError") {
          return createPlainObject();
        }
        if ((_a2 = errorInstance.message) == null ? void 0 : _a2.startsWith("Config schema violation:")) {
          return createPlainObject();
        }
        if (errorInstance.message === "Failed to decrypt config data.") {
          return createPlainObject();
        }
      }
      throw error2;
    }
  }
  set store(value) {
    this._ensureDirectory();
    if (!hasProperty(value, INTERNAL_KEY)) {
      try {
        const data = fs$3.readFileSync(this.path, __privateGet(this, _encryptionKey) ? null : "utf8");
        const dataString = this._decryptData(data);
        const currentStore = this._deserialize(dataString);
        if (hasProperty(currentStore, INTERNAL_KEY)) {
          setProperty(value, INTERNAL_KEY, getProperty(currentStore, INTERNAL_KEY));
        }
      } catch {
      }
    }
    if (!__privateGet(this, _isInMigration)) {
      this._validate(value);
    }
    this._write(value);
    this.events.dispatchEvent(new Event("change"));
  }
  *[Symbol.iterator]() {
    for (const [key, value] of Object.entries(this.store)) {
      if (!this._isReservedKeyPath(key)) {
        yield [key, value];
      }
    }
  }
  /**
  Close the file watcher if one exists. This is useful in tests to prevent the process from hanging.
  */
  _closeWatcher() {
    if (__privateGet(this, _watcher)) {
      __privateGet(this, _watcher).close();
      __privateSet(this, _watcher, void 0);
    }
    if (__privateGet(this, _watchFile)) {
      fs$3.unwatchFile(this.path);
      __privateSet(this, _watchFile, false);
    }
    __privateSet(this, _debouncedChangeHandler, void 0);
  }
  _decryptData(data) {
    const encryptionKey = __privateGet(this, _encryptionKey);
    if (!encryptionKey) {
      return typeof data === "string" ? data : uint8ArrayToString(data);
    }
    const encryptionAlgorithm = __privateGet(this, _encryptionAlgorithm);
    const authenticationTagLength = encryptionAlgorithm === "aes-256-gcm" ? 16 : 0;
    const separatorCodePoint = ":".codePointAt(0);
    const separatorByte = typeof data === "string" ? data.codePointAt(16) : data[16];
    const hasSeparator = separatorCodePoint !== void 0 && separatorByte === separatorCodePoint;
    if (!hasSeparator) {
      if (encryptionAlgorithm === "aes-256-cbc") {
        return typeof data === "string" ? data : uint8ArrayToString(data);
      }
      throw new Error("Failed to decrypt config data.");
    }
    const getEncryptedPayload = (dataUpdate2) => {
      if (authenticationTagLength === 0) {
        return { ciphertext: dataUpdate2 };
      }
      const authenticationTagStart = dataUpdate2.length - authenticationTagLength;
      if (authenticationTagStart < 0) {
        throw new Error("Invalid authentication tag length.");
      }
      return {
        ciphertext: dataUpdate2.slice(0, authenticationTagStart),
        authenticationTag: dataUpdate2.slice(authenticationTagStart)
      };
    };
    const initializationVector = data.slice(0, 16);
    const slice2 = data.slice(17);
    const dataUpdate = typeof slice2 === "string" ? stringToUint8Array(slice2) : slice2;
    const decrypt = (salt) => {
      const { ciphertext, authenticationTag } = getEncryptedPayload(dataUpdate);
      const password = crypto$1.pbkdf2Sync(encryptionKey, salt, 1e4, 32, "sha512");
      const decipher = crypto$1.createDecipheriv(encryptionAlgorithm, password, initializationVector);
      if (authenticationTag) {
        decipher.setAuthTag(authenticationTag);
      }
      return uint8ArrayToString(concatUint8Arrays([decipher.update(ciphertext), decipher.final()]));
    };
    try {
      return decrypt(initializationVector);
    } catch {
      try {
        return decrypt(initializationVector.toString());
      } catch {
      }
    }
    if (encryptionAlgorithm === "aes-256-cbc") {
      return typeof data === "string" ? data : uint8ArrayToString(data);
    }
    throw new Error("Failed to decrypt config data.");
  }
  _handleStoreChange(callback) {
    let currentValue = this.store;
    const onChange = () => {
      const oldValue = currentValue;
      const newValue = this.store;
      if (isDeepStrictEqual(newValue, oldValue)) {
        return;
      }
      currentValue = newValue;
      callback.call(this, newValue, oldValue);
    };
    this.events.addEventListener("change", onChange);
    return () => {
      this.events.removeEventListener("change", onChange);
    };
  }
  _handleValueChange(getter, callback) {
    let currentValue = getter();
    const onChange = () => {
      const oldValue = currentValue;
      const newValue = getter();
      if (isDeepStrictEqual(newValue, oldValue)) {
        return;
      }
      currentValue = newValue;
      callback.call(this, newValue, oldValue);
    };
    this.events.addEventListener("change", onChange);
    return () => {
      this.events.removeEventListener("change", onChange);
    };
  }
  _validate(data) {
    if (!__privateGet(this, _validator)) {
      return;
    }
    const valid2 = __privateGet(this, _validator).call(this, data);
    if (valid2 || !__privateGet(this, _validator).errors) {
      return;
    }
    const errors2 = __privateGet(this, _validator).errors.map(({ instancePath, message = "" }) => `\`${instancePath.slice(1)}\` ${message}`);
    throw new Error("Config schema violation: " + errors2.join("; "));
  }
  _ensureDirectory() {
    fs$3.mkdirSync(path$3.dirname(this.path), { recursive: true });
  }
  _write(value) {
    let data = this._serialize(value);
    const encryptionKey = __privateGet(this, _encryptionKey);
    if (encryptionKey) {
      const initializationVector = crypto$1.randomBytes(16);
      const password = crypto$1.pbkdf2Sync(encryptionKey, initializationVector, 1e4, 32, "sha512");
      const cipher = crypto$1.createCipheriv(__privateGet(this, _encryptionAlgorithm), password, initializationVector);
      const encryptedData = concatUint8Arrays([cipher.update(stringToUint8Array(data)), cipher.final()]);
      const encryptedParts = [initializationVector, stringToUint8Array(":"), encryptedData];
      if (__privateGet(this, _encryptionAlgorithm) === "aes-256-gcm") {
        encryptedParts.push(cipher.getAuthTag());
      }
      data = concatUint8Arrays(encryptedParts);
    }
    if (process$1.env.SNAP) {
      fs$3.writeFileSync(this.path, data, { mode: __privateGet(this, _options).configFileMode });
    } else {
      try {
        writeFileSync(this.path, data, { mode: __privateGet(this, _options).configFileMode });
      } catch (error2) {
        if ((error2 == null ? void 0 : error2.code) === "EXDEV") {
          fs$3.writeFileSync(this.path, data, { mode: __privateGet(this, _options).configFileMode });
          return;
        }
        throw error2;
      }
    }
  }
  _watch() {
    this._ensureDirectory();
    if (!fs$3.existsSync(this.path)) {
      this._write(createPlainObject());
    }
    if (process$1.platform === "win32" || process$1.platform === "darwin") {
      __privateGet(this, _debouncedChangeHandler) ?? __privateSet(this, _debouncedChangeHandler, debounceFunction(() => {
        this.events.dispatchEvent(new Event("change"));
      }, { wait: 100 }));
      const directory = path$3.dirname(this.path);
      const basename = path$3.basename(this.path);
      __privateSet(this, _watcher, fs$3.watch(directory, { persistent: false, encoding: "utf8" }, (_eventType, filename) => {
        if (filename && filename !== basename) {
          return;
        }
        if (typeof __privateGet(this, _debouncedChangeHandler) === "function") {
          __privateGet(this, _debouncedChangeHandler).call(this);
        }
      }));
    } else {
      __privateGet(this, _debouncedChangeHandler) ?? __privateSet(this, _debouncedChangeHandler, debounceFunction(() => {
        this.events.dispatchEvent(new Event("change"));
      }, { wait: 1e3 }));
      fs$3.watchFile(this.path, { persistent: false }, (_current, _previous) => {
        if (typeof __privateGet(this, _debouncedChangeHandler) === "function") {
          __privateGet(this, _debouncedChangeHandler).call(this);
        }
      });
      __privateSet(this, _watchFile, true);
    }
  }
  _migrate(migrations, versionToMigrate, beforeEachMigration) {
    let previousMigratedVersion = this._get(MIGRATION_KEY, "0.0.0");
    const newerVersions = Object.keys(migrations).filter((candidateVersion) => this._shouldPerformMigration(candidateVersion, previousMigratedVersion, versionToMigrate));
    let storeBackup = structuredClone(this.store);
    for (const version2 of newerVersions) {
      try {
        if (beforeEachMigration) {
          beforeEachMigration(this, {
            fromVersion: previousMigratedVersion,
            toVersion: version2,
            finalVersion: versionToMigrate,
            versions: newerVersions
          });
        }
        const migration = migrations[version2];
        migration == null ? void 0 : migration(this);
        this._set(MIGRATION_KEY, version2);
        previousMigratedVersion = version2;
        storeBackup = structuredClone(this.store);
      } catch (error2) {
        this.store = storeBackup;
        const errorMessage = error2 instanceof Error ? error2.message : String(error2);
        throw new Error(`Something went wrong during the migration! Changes applied to the store until this failed migration will be restored. ${errorMessage}`);
      }
    }
    if (this._isVersionInRangeFormat(previousMigratedVersion) || !semver$2.eq(previousMigratedVersion, versionToMigrate)) {
      this._set(MIGRATION_KEY, versionToMigrate);
    }
  }
  _containsReservedKey(key) {
    if (typeof key === "string") {
      return this._isReservedKeyPath(key);
    }
    if (!key || typeof key !== "object") {
      return false;
    }
    return this._objectContainsReservedKey(key);
  }
  _objectContainsReservedKey(value) {
    if (!value || typeof value !== "object") {
      return false;
    }
    for (const [candidateKey, candidateValue] of Object.entries(value)) {
      if (this._isReservedKeyPath(candidateKey)) {
        return true;
      }
      if (this._objectContainsReservedKey(candidateValue)) {
        return true;
      }
    }
    return false;
  }
  _isReservedKeyPath(candidate) {
    return candidate === INTERNAL_KEY || candidate.startsWith(`${INTERNAL_KEY}.`);
  }
  _isVersionInRangeFormat(version2) {
    return semver$2.clean(version2) === null;
  }
  _shouldPerformMigration(candidateVersion, previousMigratedVersion, versionToMigrate) {
    if (this._isVersionInRangeFormat(candidateVersion)) {
      if (previousMigratedVersion !== "0.0.0" && semver$2.satisfies(previousMigratedVersion, candidateVersion)) {
        return false;
      }
      return semver$2.satisfies(versionToMigrate, candidateVersion);
    }
    if (semver$2.lte(candidateVersion, previousMigratedVersion)) {
      return false;
    }
    if (semver$2.gt(candidateVersion, versionToMigrate)) {
      return false;
    }
    return true;
  }
  _get(key, defaultValue) {
    return getProperty(this.store, key, defaultValue);
  }
  _set(key, value) {
    const { store: store2 } = this;
    setProperty(store2, key, value);
    this.store = store2;
  }
}
_validator = new WeakMap();
_encryptionKey = new WeakMap();
_encryptionAlgorithm = new WeakMap();
_options = new WeakMap();
_defaultValues = new WeakMap();
_isInMigration = new WeakMap();
_watcher = new WeakMap();
_watchFile = new WeakMap();
_debouncedChangeHandler = new WeakMap();
_Conf_instances = new WeakSet();
prepareOptions_fn = function(partialOptions) {
  const options = {
    configName: "config",
    fileExtension: "json",
    projectSuffix: "nodejs",
    clearInvalidConfig: false,
    accessPropertiesByDotNotation: true,
    configFileMode: 438,
    ...partialOptions
  };
  options.encryptionAlgorithm ?? (options.encryptionAlgorithm = defaultEncryptionAlgorithm);
  if (!isSupportedEncryptionAlgorithm(options.encryptionAlgorithm)) {
    throw new TypeError(`The \`encryptionAlgorithm\` option must be one of: ${[...supportedEncryptionAlgorithms].join(", ")}`);
  }
  if (!options.cwd) {
    if (!options.projectName) {
      throw new Error("Please specify the `projectName` option.");
    }
    options.cwd = envPaths(options.projectName, { suffix: options.projectSuffix }).config;
  }
  if (typeof options.fileExtension === "string") {
    options.fileExtension = options.fileExtension.replace(/^\.+/, "");
  }
  return options;
};
setupValidator_fn = function(options) {
  if (!(options.schema ?? options.ajvOptions ?? options.rootSchema)) {
    return;
  }
  if (options.schema && typeof options.schema !== "object") {
    throw new TypeError("The `schema` option must be an object.");
  }
  const ajvFormats = ajvFormatsModule.default;
  const ajv2 = new _2020Exports.Ajv2020({
    allErrors: true,
    useDefaults: true,
    ...options.ajvOptions
  });
  ajvFormats(ajv2);
  const schema = {
    ...options.rootSchema,
    type: "object",
    properties: options.schema
  };
  __privateSet(this, _validator, ajv2.compile(schema));
  __privateMethod(this, _Conf_instances, captureSchemaDefaults_fn).call(this, options.schema);
};
captureSchemaDefaults_fn = function(schemaConfig) {
  const schemaEntries = Object.entries(schemaConfig ?? {});
  for (const [key, schemaDefinition] of schemaEntries) {
    if (!schemaDefinition || typeof schemaDefinition !== "object") {
      continue;
    }
    if (!Object.hasOwn(schemaDefinition, "default")) {
      continue;
    }
    const { default: defaultValue } = schemaDefinition;
    if (defaultValue === void 0) {
      continue;
    }
    __privateGet(this, _defaultValues)[key] = defaultValue;
  }
};
applyDefaultValues_fn = function(options) {
  if (options.defaults) {
    Object.assign(__privateGet(this, _defaultValues), options.defaults);
  }
};
configureSerialization_fn = function(options) {
  if (options.serialize) {
    this._serialize = options.serialize;
  }
  if (options.deserialize) {
    this._deserialize = options.deserialize;
  }
};
resolvePath_fn = function(options) {
  const normalizedFileExtension = typeof options.fileExtension === "string" ? options.fileExtension : void 0;
  const fileExtension = normalizedFileExtension ? `.${normalizedFileExtension}` : "";
  return path$3.resolve(options.cwd, `${options.configName ?? "config"}${fileExtension}`);
};
initializeStore_fn = function(options) {
  if (options.migrations) {
    __privateMethod(this, _Conf_instances, runMigrations_fn).call(this, options);
    this._validate(this.store);
    return;
  }
  const fileStore = this.store;
  const storeWithDefaults = Object.assign(createPlainObject(), options.defaults ?? {}, fileStore);
  this._validate(storeWithDefaults);
  try {
    assert.deepEqual(fileStore, storeWithDefaults);
  } catch {
    this.store = storeWithDefaults;
  }
};
runMigrations_fn = function(options) {
  const { migrations, projectVersion } = options;
  if (!migrations) {
    return;
  }
  if (!projectVersion) {
    throw new Error("Please specify the `projectVersion` option.");
  }
  __privateSet(this, _isInMigration, true);
  try {
    const fileStore = this.store;
    const storeWithDefaults = Object.assign(createPlainObject(), options.defaults ?? {}, fileStore);
    try {
      assert.deepEqual(fileStore, storeWithDefaults);
    } catch {
      this._write(storeWithDefaults);
    }
    this._migrate(migrations, projectVersion, options.beforeEachMigration);
  } finally {
    __privateSet(this, _isInMigration, false);
  }
};
const { app, ipcMain, shell } = electron;
let isInitialized = false;
const initDataListener = () => {
  if (!ipcMain || !app) {
    throw new Error("Electron Store: You need to call `.initRenderer()` from the main process.");
  }
  const appData = {
    defaultCwd: app.getPath("userData"),
    appVersion: app.getVersion()
  };
  if (isInitialized) {
    return appData;
  }
  ipcMain.on("electron-store-get-data", (event) => {
    event.returnValue = appData;
  });
  isInitialized = true;
  return appData;
};
class ElectronStore extends Conf {
  constructor(options) {
    let defaultCwd;
    let appVersion;
    if (process$1.type === "renderer") {
      const appData = electron.ipcRenderer.sendSync("electron-store-get-data");
      if (!appData) {
        throw new Error("Electron Store: You need to call `.initRenderer()` from the main process.");
      }
      ({ defaultCwd, appVersion } = appData);
    } else if (ipcMain && app) {
      ({ defaultCwd, appVersion } = initDataListener());
    }
    options = {
      name: "config",
      ...options
    };
    options.projectVersion || (options.projectVersion = appVersion);
    if (options.cwd) {
      options.cwd = path$3.isAbsolute(options.cwd) ? options.cwd : path$3.join(defaultCwd, options.cwd);
    } else {
      options.cwd = defaultCwd;
    }
    options.configName = options.name;
    delete options.name;
    super(options);
  }
  static initRenderer() {
    initDataListener();
  }
  async openInEditor() {
    const error2 = await shell.openPath(this.path);
    if (error2) {
      throw new Error(error2);
    }
  }
}
class PlaywrightBrowser {
  constructor(downloadPath = "./downloads") {
    __publicField(this, "browser", null);
    __publicField(this, "context", null);
    __publicField(this, "page", null);
    __publicField(this, "downloadPath");
    this.downloadPath = downloadPath;
  }
  async initialize() {
    if (this.browser) return;
    if (!fs$4.existsSync(this.downloadPath)) {
      fs$4.mkdirSync(this.downloadPath, { recursive: true });
    }
    this.browser = await chromium.launch({
      headless: true,
      args: ["--no-sandbox", "--disable-setuid-sandbox"]
    });
    this.context = await this.browser.newContext({
      viewport: { width: 1280, height: 720 },
      userAgent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    });
    this.page = await this.context.newPage();
    this.page.on("download", async (download) => {
      const downloadPath = path$4.join(this.downloadPath, download.suggestedFilename());
      await download.saveAs(downloadPath);
      console.log(`Downloaded: ${downloadPath}`);
    });
  }
  async navigate(url2) {
    await this.initialize();
    if (!this.page) throw new Error("Page not initialized");
    await this.page.goto(url2, {
      waitUntil: "networkidle",
      timeout: 3e4
    });
  }
  async click(selector) {
    if (!this.page) throw new Error("Page not initialized");
    await this.page.waitForSelector(selector, { state: "visible", timeout: 1e4 });
    await this.page.click(selector);
  }
  async type(selector, text) {
    if (!this.page) throw new Error("Page not initialized");
    await this.page.waitForSelector(selector, { state: "visible", timeout: 1e4 });
    await this.page.fill(selector, text);
  }
  async getText(selector) {
    if (!this.page) throw new Error("Page not initialized");
    if (selector) {
      await this.page.waitForSelector(selector, { state: "visible", timeout: 1e4 });
      return await this.page.textContent(selector) || "";
    }
    return await this.page.evaluate(() => document.body.innerText);
  }
  async getHtml() {
    if (!this.page) throw new Error("Page not initialized");
    return await this.page.content();
  }
  async screenshot(options) {
    if (!this.page) throw new Error("Page not initialized");
    const screenshotPath = (options == null ? void 0 : options.path) || path$4.join(this.downloadPath, `screenshot-${Date.now()}.png`);
    await this.page.screenshot({
      path: screenshotPath,
      fullPage: (options == null ? void 0 : options.fullPage) ?? false
    });
    return screenshotPath;
  }
  async scroll(direction) {
    if (!this.page) throw new Error("Page not initialized");
    switch (direction) {
      case "up":
        await this.page.evaluate(() => window.scrollBy(0, -500));
        break;
      case "down":
        await this.page.evaluate(() => window.scrollBy(0, 500));
        break;
      case "top":
        await this.page.evaluate(() => window.scrollTo(0, 0));
        break;
      case "bottom":
        await this.page.evaluate(() => window.scrollTo(0, document.body.scrollHeight));
        break;
    }
  }
  async findElements(selector) {
    if (!this.page) throw new Error("Page not initialized");
    const elements = await this.page.$$(selector);
    const results = [];
    for (const element of elements) {
      const tag = await element.evaluate((el) => el.tagName.toLowerCase());
      const text = await element.textContent() || "";
      const attributes = await element.evaluate((el) => {
        const attrs = {};
        for (const attr of el.attributes) {
          attrs[attr.name] = attr.value;
        }
        return attrs;
      });
      results.push({ tag, text: text.trim(), attributes });
    }
    return results;
  }
  async evaluate(script) {
    if (!this.page) throw new Error("Page not initialized");
    return await this.page.evaluate(script);
  }
  async waitForSelector(selector, timeout2) {
    if (!this.page) throw new Error("Page not initialized");
    await this.page.waitForSelector(selector, { timeout: timeout2 || 1e4 });
  }
  async waitForNavigation(timeout2) {
    if (!this.page) throw new Error("Page not initialized");
    await this.page.waitForLoadState("networkidle", { timeout: timeout2 || 3e4 });
  }
  async getUrl() {
    if (!this.page) throw new Error("Page not initialized");
    return this.page.url();
  }
  async goBack() {
    if (!this.page) throw new Error("Page not initialized");
    await this.page.goBack();
  }
  async goForward() {
    if (!this.page) throw new Error("Page not initialized");
    await this.page.goForward();
  }
  async reload() {
    if (!this.page) throw new Error("Page not initialized");
    await this.page.reload();
  }
  async close() {
    if (this.browser) {
      await this.browser.close();
      this.browser = null;
      this.context = null;
      this.page = null;
    }
  }
}
function dispatchCallback(progress_callback, data) {
  if (progress_callback) progress_callback(data);
}
function reverseDictionary(data) {
  return Object.fromEntries(Object.entries(data).map(([key, value]) => [value, key]));
}
function escapeRegExp(string2) {
  return string2.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
}
const Callable = (
  /** @type {any} */
  class {
    /**
    * Creates a new instance of the Callable class.
    */
    constructor() {
      let closure = function(...args) {
        return closure._call(...args);
      };
      return Object.setPrototypeOf(closure, new.target.prototype);
    }
    /**
     * This method should be implemented in subclasses to provide the
     * functionality of the callable object.
     *
     * @param {any[]} args
     * @throws {Error} If the subclass does not implement the `_call` method.
     */
    _call(...args) {
      throw Error("Must implement _call method in subclass");
    }
  }
);
function isTypedArray(val) {
  var _a2, _b, _c;
  return ((_c = (_b = (_a2 = val == null ? void 0 : val.prototype) == null ? void 0 : _a2.__proto__) == null ? void 0 : _b.constructor) == null ? void 0 : _c.name) === "TypedArray";
}
function isIntegralNumber(x) {
  return Number.isInteger(x) || typeof x === "bigint";
}
function exists(x) {
  return x !== void 0 && x !== null;
}
function calculateDimensions(arr) {
  const dimensions = [];
  let current = arr;
  while (Array.isArray(current)) {
    dimensions.push(current.length);
    current = current[0];
  }
  return dimensions;
}
function pop(obj, key, defaultValue = void 0) {
  const value = obj[key];
  if (value !== void 0) {
    delete obj[key];
    return value;
  }
  if (defaultValue === void 0) {
    throw Error(`Key ${key} does not exist in object.`);
  }
  return defaultValue;
}
function mergeArrays(...arrs) {
  return Array.prototype.concat.apply([], arrs);
}
function product(...a) {
  return a.reduce((a2, b) => a2.flatMap((d) => b.map((e) => [d, e])));
}
function calculateReflectOffset(i2, w) {
  return Math.abs((i2 + w) % (2 * w) - w);
}
var dist = {};
const backends = {};
const backendsSortedByPriority = [];
const registerBackend = (name2, backend2, priority) => {
  if (backend2 && typeof backend2.init === "function" && typeof backend2.createSessionHandler === "function") {
    const currentBackend = backends[name2];
    if (currentBackend === void 0) {
      backends[name2] = { backend: backend2, priority };
    } else if (currentBackend.priority > priority) {
      return;
    } else if (currentBackend.priority === priority) {
      if (currentBackend.backend !== backend2) {
        throw new Error(`cannot register backend "${name2}" using priority ${priority}`);
      }
    }
    if (priority >= 0) {
      const i2 = backendsSortedByPriority.indexOf(name2);
      if (i2 !== -1) {
        backendsSortedByPriority.splice(i2, 1);
      }
      for (let i3 = 0; i3 < backendsSortedByPriority.length; i3++) {
        if (backends[backendsSortedByPriority[i3]].priority <= priority) {
          backendsSortedByPriority.splice(i3, 0, name2);
          return;
        }
      }
      backendsSortedByPriority.push(name2);
    }
    return;
  }
  throw new TypeError("not a valid backend");
};
const resolveBackend = async (backendHints) => {
  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;
  const errors2 = [];
  for (const backendName of backendNames) {
    const backendInfo = backends[backendName];
    if (backendInfo) {
      if (backendInfo.initialized) {
        return backendInfo.backend;
      } else if (backendInfo.aborted) {
        continue;
      }
      const isInitializing = !!backendInfo.initPromise;
      try {
        if (!isInitializing) {
          backendInfo.initPromise = backendInfo.backend.init();
        }
        await backendInfo.initPromise;
        backendInfo.initialized = true;
        return backendInfo.backend;
      } catch (e) {
        if (!isInitializing) {
          errors2.push({ name: backendName, err: e });
        }
        backendInfo.aborted = true;
      } finally {
        delete backendInfo.initPromise;
      }
    }
  }
  throw new Error(`no available backend found. ERR: ${errors2.map((e) => `[${e.name}] ${e.err}`).join(", ")}`);
};
class EnvImpl {
  constructor() {
    this.wasm = {};
    this.webgl = {};
    this.logLevelInternal = "warning";
  }
  // TODO standadize the getter and setter convention in env for other fields.
  set logLevel(value) {
    if (value === void 0) {
      return;
    }
    if (typeof value !== "string" || ["verbose", "info", "warning", "error", "fatal"].indexOf(value) === -1) {
      throw new Error(`Unsupported logging level: ${value}`);
    }
    this.logLevelInternal = value;
  }
  get logLevel() {
    return this.logLevelInternal;
  }
}
const env$4 = new EnvImpl();
const isBigInt64ArrayAvailable = typeof BigInt64Array !== "undefined" && typeof BigInt64Array.from === "function";
const isBigUint64ArrayAvailable = typeof BigUint64Array !== "undefined" && typeof BigUint64Array.from === "function";
const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = /* @__PURE__ */ new Map([
  ["float32", Float32Array],
  ["uint8", Uint8Array],
  ["int8", Int8Array],
  ["uint16", Uint16Array],
  ["int16", Int16Array],
  ["int32", Int32Array],
  ["bool", Uint8Array],
  ["float64", Float64Array],
  ["uint32", Uint32Array]
]);
const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = /* @__PURE__ */ new Map([
  [Float32Array, "float32"],
  [Uint8Array, "uint8"],
  [Int8Array, "int8"],
  [Uint16Array, "uint16"],
  [Int16Array, "int16"],
  [Int32Array, "int32"],
  [Float64Array, "float64"],
  [Uint32Array, "uint32"]
]);
if (isBigInt64ArrayAvailable) {
  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set("int64", BigInt64Array);
  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, "int64");
}
if (isBigUint64ArrayAvailable) {
  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set("uint64", BigUint64Array);
  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, "uint64");
}
const calculateSize = (dims) => {
  let size = 1;
  for (let i2 = 0; i2 < dims.length; i2++) {
    const dim = dims[i2];
    if (typeof dim !== "number" || !Number.isSafeInteger(dim)) {
      throw new TypeError(`dims[${i2}] must be an integer, got: ${dim}`);
    }
    if (dim < 0) {
      throw new RangeError(`dims[${i2}] must be a non-negative integer, got: ${dim}`);
    }
    size *= dim;
  }
  return size;
};
let Tensor$2 = class Tensor2 {
  constructor(arg0, arg1, arg2) {
    let type2;
    let data;
    let dims;
    if (typeof arg0 === "string") {
      type2 = arg0;
      dims = arg2;
      if (arg0 === "string") {
        if (!Array.isArray(arg1)) {
          throw new TypeError("A string tensor's data must be a string array.");
        }
        data = arg1;
      } else {
        const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);
        if (typedArrayConstructor === void 0) {
          throw new TypeError(`Unsupported tensor type: ${arg0}.`);
        }
        if (Array.isArray(arg1)) {
          data = typedArrayConstructor.from(arg1);
        } else if (arg1 instanceof typedArrayConstructor) {
          data = arg1;
        } else {
          throw new TypeError(`A ${type2} tensor's data must be type of ${typedArrayConstructor}`);
        }
      }
    } else {
      dims = arg1;
      if (Array.isArray(arg0)) {
        if (arg0.length === 0) {
          throw new TypeError("Tensor type cannot be inferred from an empty array.");
        }
        const firstElementType = typeof arg0[0];
        if (firstElementType === "string") {
          type2 = "string";
          data = arg0;
        } else if (firstElementType === "boolean") {
          type2 = "bool";
          data = Uint8Array.from(arg0);
        } else {
          throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);
        }
      } else {
        const mappedType = NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor);
        if (mappedType === void 0) {
          throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);
        }
        type2 = mappedType;
        data = arg0;
      }
    }
    if (dims === void 0) {
      dims = [data.length];
    } else if (!Array.isArray(dims)) {
      throw new TypeError("A tensor's dims must be a number array");
    }
    const size = calculateSize(dims);
    if (size !== data.length) {
      throw new Error(`Tensor's size(${size}) does not match data length(${data.length}).`);
    }
    this.dims = dims;
    this.type = type2;
    this.data = data;
    this.size = size;
  }
  // #endregion
  /**
   * Create a new tensor object from image object
   *
   * @param buffer - Extracted image buffer data - assuming RGBA format
   * @param imageFormat - input image configuration - required configurations height, width, format
   * @param tensorFormat - output tensor configuration - Default is RGB format
   */
  static bufferToTensor(buffer2, options) {
    if (buffer2 === void 0) {
      throw new Error("Image buffer must be defined");
    }
    if (options.height === void 0 || options.width === void 0) {
      throw new Error("Image height and width must be defined");
    }
    const { height, width } = options;
    const norm = options.norm;
    let normMean;
    let normBias;
    if (norm === void 0 || norm.mean === void 0) {
      normMean = 255;
    } else {
      normMean = norm.mean;
    }
    if (norm === void 0 || norm.bias === void 0) {
      normBias = 0;
    } else {
      normBias = norm.bias;
    }
    const inputformat = options.bitmapFormat !== void 0 ? options.bitmapFormat : "RGBA";
    const outputformat = options.tensorFormat !== void 0 ? options.tensorFormat !== void 0 ? options.tensorFormat : "RGB" : "RGB";
    const offset = height * width;
    const float32Data = outputformat === "RGBA" ? new Float32Array(offset * 4) : new Float32Array(offset * 3);
    let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;
    let rTensorPointer = 0, gTensorPointer = offset, bTensorPointer = offset * 2, aTensorPointer = -1;
    if (inputformat === "RGB") {
      step = 3;
      rImagePointer = 0;
      gImagePointer = 1;
      bImagePointer = 2;
      aImagePointer = -1;
    }
    if (outputformat === "RGBA") {
      aTensorPointer = offset * 3;
    } else if (outputformat === "RBG") {
      rTensorPointer = 0;
      bTensorPointer = offset;
      gTensorPointer = offset * 2;
    } else if (outputformat === "BGR") {
      bTensorPointer = 0;
      gTensorPointer = offset;
      rTensorPointer = offset * 2;
    }
    for (let i2 = 0; i2 < offset; i2++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {
      float32Data[rTensorPointer++] = (buffer2[rImagePointer] + normBias) / normMean;
      float32Data[gTensorPointer++] = (buffer2[gImagePointer] + normBias) / normMean;
      float32Data[bTensorPointer++] = (buffer2[bImagePointer] + normBias) / normMean;
      if (aTensorPointer !== -1 && aImagePointer !== -1) {
        float32Data[aTensorPointer++] = (buffer2[aImagePointer] + normBias) / normMean;
      }
    }
    const outputTensor = outputformat === "RGBA" ? new Tensor2("float32", float32Data, [1, 4, height, width]) : new Tensor2("float32", float32Data, [1, 3, height, width]);
    return outputTensor;
  }
  static async fromImage(image, options) {
    const isHTMLImageEle = typeof HTMLImageElement !== "undefined" && image instanceof HTMLImageElement;
    const isImageDataEle = typeof ImageData !== "undefined" && image instanceof ImageData;
    const isImageBitmap = typeof ImageBitmap !== "undefined" && image instanceof ImageBitmap;
    const isURL = typeof String !== "undefined" && (image instanceof String || typeof image === "string");
    let data;
    let tensorConfig = {};
    if (isHTMLImageEle) {
      const canvas = document.createElement("canvas");
      const pixels2DContext = canvas.getContext("2d");
      if (pixels2DContext != null) {
        let height = image.naturalHeight;
        let width = image.naturalWidth;
        if (options !== void 0 && options.resizedHeight !== void 0 && options.resizedWidth !== void 0) {
          height = options.resizedHeight;
          width = options.resizedWidth;
        }
        if (options !== void 0) {
          tensorConfig = options;
          if (options.tensorFormat !== void 0) {
            throw new Error("Image input config format must be RGBA for HTMLImageElement");
          } else {
            tensorConfig.tensorFormat = "RGBA";
          }
          if (options.height !== void 0 && options.height !== height) {
            throw new Error("Image input config height doesn't match HTMLImageElement height");
          } else {
            tensorConfig.height = height;
          }
          if (options.width !== void 0 && options.width !== width) {
            throw new Error("Image input config width doesn't match HTMLImageElement width");
          } else {
            tensorConfig.width = width;
          }
        } else {
          tensorConfig.tensorFormat = "RGBA";
          tensorConfig.height = height;
          tensorConfig.width = width;
        }
        canvas.width = width;
        canvas.height = height;
        pixels2DContext.drawImage(image, 0, 0, width, height);
        data = pixels2DContext.getImageData(0, 0, width, height).data;
      } else {
        throw new Error("Can not access image data");
      }
    } else if (isImageDataEle) {
      const format2 = "RGBA";
      let height;
      let width;
      if (options !== void 0 && options.resizedWidth !== void 0 && options.resizedHeight !== void 0) {
        height = options.resizedHeight;
        width = options.resizedWidth;
      } else {
        height = image.height;
        width = image.width;
      }
      if (options !== void 0) {
        tensorConfig = options;
        if (options.bitmapFormat !== void 0 && options.bitmapFormat !== format2) {
          throw new Error("Image input config format must be RGBA for ImageData");
        } else {
          tensorConfig.bitmapFormat = "RGBA";
        }
      } else {
        tensorConfig.bitmapFormat = "RGBA";
      }
      tensorConfig.height = height;
      tensorConfig.width = width;
      if (options !== void 0) {
        const tempCanvas = document.createElement("canvas");
        tempCanvas.width = width;
        tempCanvas.height = height;
        const pixels2DContext = tempCanvas.getContext("2d");
        if (pixels2DContext != null) {
          pixels2DContext.putImageData(image, 0, 0);
          data = pixels2DContext.getImageData(0, 0, width, height).data;
        } else {
          throw new Error("Can not access image data");
        }
      } else {
        data = image.data;
      }
    } else if (isImageBitmap) {
      if (options === void 0) {
        throw new Error("Please provide image config with format for Imagebitmap");
      }
      if (options.bitmapFormat !== void 0) {
        throw new Error("Image input config format must be defined for ImageBitmap");
      }
      const pixels2DContext = document.createElement("canvas").getContext("2d");
      if (pixels2DContext != null) {
        const height = image.height;
        const width = image.width;
        pixels2DContext.drawImage(image, 0, 0, width, height);
        data = pixels2DContext.getImageData(0, 0, width, height).data;
        if (options !== void 0) {
          if (options.height !== void 0 && options.height !== height) {
            throw new Error("Image input config height doesn't match ImageBitmap height");
          } else {
            tensorConfig.height = height;
          }
          if (options.width !== void 0 && options.width !== width) {
            throw new Error("Image input config width doesn't match ImageBitmap width");
          } else {
            tensorConfig.width = width;
          }
        } else {
          tensorConfig.height = height;
          tensorConfig.width = width;
        }
        return Tensor2.bufferToTensor(data, tensorConfig);
      } else {
        throw new Error("Can not access image data");
      }
    } else if (isURL) {
      return new Promise((resolve2, reject) => {
        const canvas = document.createElement("canvas");
        const context = canvas.getContext("2d");
        if (!image || !context) {
          return reject();
        }
        const newImage = new Image();
        newImage.crossOrigin = "Anonymous";
        newImage.src = image;
        newImage.onload = () => {
          canvas.width = newImage.width;
          canvas.height = newImage.height;
          context.drawImage(newImage, 0, 0, canvas.width, canvas.height);
          const img = context.getImageData(0, 0, canvas.width, canvas.height);
          if (options !== void 0) {
            if (options.height !== void 0 && options.height !== canvas.height) {
              throw new Error("Image input config height doesn't match ImageBitmap height");
            } else {
              tensorConfig.height = canvas.height;
            }
            if (options.width !== void 0 && options.width !== canvas.width) {
              throw new Error("Image input config width doesn't match ImageBitmap width");
            } else {
              tensorConfig.width = canvas.width;
            }
          } else {
            tensorConfig.height = canvas.height;
            tensorConfig.width = canvas.width;
          }
          resolve2(Tensor2.bufferToTensor(img.data, tensorConfig));
        };
      });
    } else {
      throw new Error("Input data provided is not supported - aborted tensor creation");
    }
    if (data !== void 0) {
      return Tensor2.bufferToTensor(data, tensorConfig);
    } else {
      throw new Error("Input data provided is not supported - aborted tensor creation");
    }
  }
  toImageData(options) {
    var _a2, _b;
    const pixels2DContext = document.createElement("canvas").getContext("2d");
    let image;
    if (pixels2DContext != null) {
      const width = this.dims[3];
      const height = this.dims[2];
      const channels = this.dims[1];
      const inputformat = options !== void 0 ? options.format !== void 0 ? options.format : "RGB" : "RGB";
      const normMean = options !== void 0 ? ((_a2 = options.norm) === null || _a2 === void 0 ? void 0 : _a2.mean) !== void 0 ? options.norm.mean : 255 : 255;
      const normBias = options !== void 0 ? ((_b = options.norm) === null || _b === void 0 ? void 0 : _b.bias) !== void 0 ? options.norm.bias : 0 : 0;
      const offset = height * width;
      if (options !== void 0) {
        if (options.height !== void 0 && options.height !== height) {
          throw new Error("Image output config height doesn't match tensor height");
        }
        if (options.width !== void 0 && options.width !== width) {
          throw new Error("Image output config width doesn't match tensor width");
        }
        if (options.format !== void 0 && (channels === 4 && options.format !== "RGBA") || channels === 3 && (options.format !== "RGB" && options.format !== "BGR")) {
          throw new Error("Tensor format doesn't match input tensor dims");
        }
      }
      const step = 4;
      let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;
      let rTensorPointer = 0, gTensorPointer = offset, bTensorPointer = offset * 2, aTensorPointer = -1;
      if (inputformat === "RGBA") {
        rTensorPointer = 0;
        gTensorPointer = offset;
        bTensorPointer = offset * 2;
        aTensorPointer = offset * 3;
      } else if (inputformat === "RGB") {
        rTensorPointer = 0;
        gTensorPointer = offset;
        bTensorPointer = offset * 2;
      } else if (inputformat === "RBG") {
        rTensorPointer = 0;
        bTensorPointer = offset;
        gTensorPointer = offset * 2;
      }
      image = pixels2DContext.createImageData(width, height);
      for (let i2 = 0; i2 < height * width; rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i2++) {
        image.data[rImagePointer] = (this.data[rTensorPointer++] - normBias) * normMean;
        image.data[gImagePointer] = (this.data[gTensorPointer++] - normBias) * normMean;
        image.data[bImagePointer] = (this.data[bTensorPointer++] - normBias) * normMean;
        image.data[aImagePointer] = aTensorPointer === -1 ? 255 : (this.data[aTensorPointer++] - normBias) * normMean;
      }
    } else {
      throw new Error("Can not access image data");
    }
    return image;
  }
  // #endregion
  // #region tensor utilities
  reshape(dims) {
    return new Tensor2(this.type, this.data, dims);
  }
};
const Tensor$1 = Tensor$2;
let InferenceSession$2 = class InferenceSession2 {
  constructor(handler) {
    this.handler = handler;
  }
  async run(feeds, arg1, arg2) {
    const fetches = {};
    let options = {};
    if (typeof feeds !== "object" || feeds === null || feeds instanceof Tensor$1 || Array.isArray(feeds)) {
      throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");
    }
    let isFetchesEmpty = true;
    if (typeof arg1 === "object") {
      if (arg1 === null) {
        throw new TypeError("Unexpected argument[1]: cannot be null.");
      }
      if (arg1 instanceof Tensor$1) {
        throw new TypeError("'fetches' cannot be a Tensor");
      }
      if (Array.isArray(arg1)) {
        if (arg1.length === 0) {
          throw new TypeError("'fetches' cannot be an empty array.");
        }
        isFetchesEmpty = false;
        for (const name2 of arg1) {
          if (typeof name2 !== "string") {
            throw new TypeError("'fetches' must be a string array or an object.");
          }
          if (this.outputNames.indexOf(name2) === -1) {
            throw new RangeError(`'fetches' contains invalid output name: ${name2}.`);
          }
          fetches[name2] = null;
        }
        if (typeof arg2 === "object" && arg2 !== null) {
          options = arg2;
        } else if (typeof arg2 !== "undefined") {
          throw new TypeError("'options' must be an object.");
        }
      } else {
        let isFetches = false;
        const arg1Keys = Object.getOwnPropertyNames(arg1);
        for (const name2 of this.outputNames) {
          if (arg1Keys.indexOf(name2) !== -1) {
            const v = arg1[name2];
            if (v === null || v instanceof Tensor$1) {
              isFetches = true;
              isFetchesEmpty = false;
              fetches[name2] = v;
            }
          }
        }
        if (isFetches) {
          if (typeof arg2 === "object" && arg2 !== null) {
            options = arg2;
          } else if (typeof arg2 !== "undefined") {
            throw new TypeError("'options' must be an object.");
          }
        } else {
          options = arg1;
        }
      }
    } else if (typeof arg1 !== "undefined") {
      throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");
    }
    for (const name2 of this.inputNames) {
      if (typeof feeds[name2] === "undefined") {
        throw new Error(`input '${name2}' is missing in 'feeds'.`);
      }
    }
    if (isFetchesEmpty) {
      for (const name2 of this.outputNames) {
        fetches[name2] = null;
      }
    }
    const results = await this.handler.run(feeds, fetches, options);
    const returnValue = {};
    for (const key in results) {
      if (Object.hasOwnProperty.call(results, key)) {
        returnValue[key] = new Tensor$1(results[key].type, results[key].data, results[key].dims);
      }
    }
    return returnValue;
  }
  static async create(arg0, arg1, arg2, arg3) {
    let filePathOrUint8Array;
    let options = {};
    if (typeof arg0 === "string") {
      filePathOrUint8Array = arg0;
      if (typeof arg1 === "object" && arg1 !== null) {
        options = arg1;
      } else if (typeof arg1 !== "undefined") {
        throw new TypeError("'options' must be an object.");
      }
    } else if (arg0 instanceof Uint8Array) {
      filePathOrUint8Array = arg0;
      if (typeof arg1 === "object" && arg1 !== null) {
        options = arg1;
      } else if (typeof arg1 !== "undefined") {
        throw new TypeError("'options' must be an object.");
      }
    } else if (arg0 instanceof ArrayBuffer || typeof SharedArrayBuffer !== "undefined" && arg0 instanceof SharedArrayBuffer) {
      const buffer2 = arg0;
      let byteOffset = 0;
      let byteLength = arg0.byteLength;
      if (typeof arg1 === "object" && arg1 !== null) {
        options = arg1;
      } else if (typeof arg1 === "number") {
        byteOffset = arg1;
        if (!Number.isSafeInteger(byteOffset)) {
          throw new RangeError("'byteOffset' must be an integer.");
        }
        if (byteOffset < 0 || byteOffset >= buffer2.byteLength) {
          throw new RangeError(`'byteOffset' is out of range [0, ${buffer2.byteLength}).`);
        }
        byteLength = arg0.byteLength - byteOffset;
        if (typeof arg2 === "number") {
          byteLength = arg2;
          if (!Number.isSafeInteger(byteLength)) {
            throw new RangeError("'byteLength' must be an integer.");
          }
          if (byteLength <= 0 || byteOffset + byteLength > buffer2.byteLength) {
            throw new RangeError(`'byteLength' is out of range (0, ${buffer2.byteLength - byteOffset}].`);
          }
          if (typeof arg3 === "object" && arg3 !== null) {
            options = arg3;
          } else if (typeof arg3 !== "undefined") {
            throw new TypeError("'options' must be an object.");
          }
        } else if (typeof arg2 !== "undefined") {
          throw new TypeError("'byteLength' must be a number.");
        }
      } else if (typeof arg1 !== "undefined") {
        throw new TypeError("'options' must be an object.");
      }
      filePathOrUint8Array = new Uint8Array(buffer2, byteOffset, byteLength);
    } else {
      throw new TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");
    }
    const eps = options.executionProviders || [];
    const backendHints = eps.map((i2) => typeof i2 === "string" ? i2 : i2.name);
    const backend2 = await resolveBackend(backendHints);
    const handler = await backend2.createSessionHandler(filePathOrUint8Array, options);
    return new InferenceSession2(handler);
  }
  startProfiling() {
    this.handler.startProfiling();
  }
  endProfiling() {
    this.handler.endProfiling();
  }
  get inputNames() {
    return this.handler.inputNames;
  }
  get outputNames() {
    return this.handler.outputNames;
  }
};
const InferenceSession$1 = InferenceSession$2;
const lib$1 = /* @__PURE__ */ Object.freeze(/* @__PURE__ */ Object.defineProperty({
  __proto__: null,
  InferenceSession: InferenceSession$1,
  Tensor: Tensor$1,
  env: env$4,
  registerBackend
}, Symbol.toStringTag, { value: "Module" }));
const require$$6 = /* @__PURE__ */ getAugmentedNamespace(lib$1);
var backend = {};
function commonjsRequire(path2) {
  throw new Error('Could not dynamically require "' + path2 + '". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');
}
var binding = {};
Object.defineProperty(binding, "__esModule", { value: true });
binding.binding = void 0;
binding.binding = // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires
commonjsRequire(`../bin/napi-v3/${process.platform}/${process.arch}/onnxruntime_binding.node`);
var __classPrivateFieldSet = commonjsGlobal && commonjsGlobal.__classPrivateFieldSet || function(receiver, state, value, kind, f) {
  if (kind === "m") throw new TypeError("Private method is not writable");
  if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
  if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
  return kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;
};
var __classPrivateFieldGet = commonjsGlobal && commonjsGlobal.__classPrivateFieldGet || function(receiver, state, kind, f) {
  if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
  if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
  return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var _OnnxruntimeSessionHandler_inferenceSession;
Object.defineProperty(backend, "__esModule", { value: true });
backend.onnxruntimeBackend = void 0;
const binding_1 = binding;
class OnnxruntimeSessionHandler {
  constructor(pathOrBuffer, options) {
    _OnnxruntimeSessionHandler_inferenceSession.set(this, void 0);
    __classPrivateFieldSet(this, _OnnxruntimeSessionHandler_inferenceSession, new binding_1.binding.InferenceSession(), "f");
    if (typeof pathOrBuffer === "string") {
      __classPrivateFieldGet(this, _OnnxruntimeSessionHandler_inferenceSession, "f").loadModel(pathOrBuffer, options);
    } else {
      __classPrivateFieldGet(this, _OnnxruntimeSessionHandler_inferenceSession, "f").loadModel(pathOrBuffer.buffer, pathOrBuffer.byteOffset, pathOrBuffer.byteLength, options);
    }
    this.inputNames = __classPrivateFieldGet(this, _OnnxruntimeSessionHandler_inferenceSession, "f").inputNames;
    this.outputNames = __classPrivateFieldGet(this, _OnnxruntimeSessionHandler_inferenceSession, "f").outputNames;
  }
  async dispose() {
    return Promise.resolve();
  }
  startProfiling() {
  }
  endProfiling() {
  }
  async run(feeds, fetches, options) {
    return new Promise((resolve2, reject) => {
      process.nextTick(() => {
        try {
          resolve2(__classPrivateFieldGet(this, _OnnxruntimeSessionHandler_inferenceSession, "f").run(feeds, fetches, options));
        } catch (e) {
          reject(e);
        }
      });
    });
  }
}
_OnnxruntimeSessionHandler_inferenceSession = /* @__PURE__ */ new WeakMap();
class OnnxruntimeBackend {
  async init() {
    return Promise.resolve();
  }
  async createSessionHandler(pathOrBuffer, options) {
    return new Promise((resolve2, reject) => {
      process.nextTick(() => {
        try {
          resolve2(new OnnxruntimeSessionHandler(pathOrBuffer, options || {}));
        } catch (e) {
          reject(e);
        }
      });
    });
  }
}
backend.onnxruntimeBackend = new OnnxruntimeBackend();
(function(exports$12) {
  var __createBinding = commonjsGlobal && commonjsGlobal.__createBinding || (Object.create ? function(o, m, k, k2) {
    if (k2 === void 0) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() {
        return m[k];
      } };
    }
    Object.defineProperty(o, k2, desc);
  } : function(o, m, k, k2) {
    if (k2 === void 0) k2 = k;
    o[k2] = m[k];
  });
  var __exportStar = commonjsGlobal && commonjsGlobal.__exportStar || function(m, exports$13) {
    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports$13, p)) __createBinding(exports$13, m, p);
  };
  Object.defineProperty(exports$12, "__esModule", { value: true });
  __exportStar(require$$6, exports$12);
  const onnxruntime_common_1 = require$$6;
  const backend_1 = backend;
  (0, onnxruntime_common_1.registerBackend)("cpu", backend_1.onnxruntimeBackend, 100);
})(dist);
const index = /* @__PURE__ */ getDefaultExportFromCjs(dist);
const ONNX_NODE = /* @__PURE__ */ _mergeNamespaces({
  __proto__: null,
  default: index
}, [dist]);
var ortWeb_node$1 = {};
/*!
* ONNX Runtime Web v1.14.0
* Copyright (c) Microsoft Corporation. All rights reserved.
* Licensed under the MIT License.
*/
(function(exports$1) {
  (() => {
    var __webpack_modules__ = { 3474: (t2, e, n) => {
      var _scriptDir, r = (_scriptDir = (_scriptDir = "undefined" != typeof document && document.currentScript ? document.currentScript.src : void 0) || __filename, function(t3) {
        function e2() {
          return $.buffer != C && H($.buffer), F;
        }
        function r2() {
          return $.buffer != C && H($.buffer), N;
        }
        function i2() {
          return $.buffer != C && H($.buffer), R;
        }
        function o() {
          return $.buffer != C && H($.buffer), L;
        }
        function a() {
          return $.buffer != C && H($.buffer), M;
        }
        var s, u, c;
        t3 = t3 || {}, s || (s = void 0 !== t3 ? t3 : {}), s.ready = new Promise(function(t4, e3) {
          u = t4, c = e3;
        });
        var l, p, f, d, h, g, b = Object.assign({}, s), m = "./this.program", y = (t4, e3) => {
          throw e3;
        }, _ = "object" == typeof window, v = "function" == typeof importScripts, w = "object" == typeof process && "object" == typeof process.versions && "string" == typeof process.versions.node, x = s.ENVIRONMENT_IS_PTHREAD || false, T = "";
        function S(t4) {
          return s.locateFile ? s.locateFile(t4, T) : T + t4;
        }
        if (w) {
          let e3;
          T = v ? n(1423).dirname(T) + "/" : __dirname + "/", g = () => {
            h || (d = n(6231), h = n(1423));
          }, l = function(t4, e4) {
            return g(), t4 = h.normalize(t4), d.readFileSync(t4, e4 ? void 0 : "utf8");
          }, f = (t4) => ((t4 = l(t4, true)).buffer || (t4 = new Uint8Array(t4)), t4), p = (t4, e4, n2) => {
            g(), t4 = h.normalize(t4), d.readFile(t4, function(t5, r3) {
              t5 ? n2(t5) : e4(r3.buffer);
            });
          }, 1 < process.argv.length && (m = process.argv[1].replace(/\\/g, "/")), process.argv.slice(2), process.on("uncaughtException", function(t4) {
            if (!(t4 instanceof ut)) throw t4;
          }), process.on("unhandledRejection", function(t4) {
            throw t4;
          }), y = (t4, e4) => {
            if (J()) throw process.exitCode = t4, e4;
            e4 instanceof ut || P("exiting due to exception: " + e4), process.exit(t4);
          }, s.inspect = function() {
            return "[Emscripten Module object]";
          };
          try {
            e3 = n(4564);
          } catch (t4) {
            throw console.error('The "worker_threads" module is not supported in this node.js build - perhaps a newer version is needed?'), t4;
          }
          commonjsGlobal.Worker = e3.Worker;
        } else (_ || v) && (v ? T = self.location.href : "undefined" != typeof document && document.currentScript && (T = document.currentScript.src), _scriptDir && (T = _scriptDir), T = 0 !== T.indexOf("blob:") ? T.substr(0, T.replace(/[?#].*/, "").lastIndexOf("/") + 1) : "", w || (l = (t4) => {
          var e3 = new XMLHttpRequest();
          return e3.open("GET", t4, false), e3.send(null), e3.responseText;
        }, v && (f = (t4) => {
          var e3 = new XMLHttpRequest();
          return e3.open("GET", t4, false), e3.responseType = "arraybuffer", e3.send(null), new Uint8Array(e3.response);
        }), p = (t4, e3, n2) => {
          var r3 = new XMLHttpRequest();
          r3.open("GET", t4, true), r3.responseType = "arraybuffer", r3.onload = () => {
            200 == r3.status || 0 == r3.status && r3.response ? e3(r3.response) : n2();
          }, r3.onerror = n2, r3.send(null);
        }));
        w && "undefined" == typeof performance && (commonjsGlobal.performance = n(498).performance);
        var O = console.log.bind(console), A = console.warn.bind(console);
        w && (g(), O = (t4) => d.writeSync(1, t4 + "\n"), A = (t4) => d.writeSync(2, t4 + "\n"));
        var E, I = s.print || O, P = s.printErr || A;
        Object.assign(s, b), b = null, s.thisProgram && (m = s.thisProgram), s.quit && (y = s.quit), s.wasmBinary && (E = s.wasmBinary);
        var D = s.noExitRuntime || false;
        "object" != typeof WebAssembly && it("no native wasm support detected");
        var $, k, C, F, N, R, L, M, j = false, U = "undefined" != typeof TextDecoder ? new TextDecoder("utf8") : void 0;
        function V(t4, e3, n2) {
          var r3 = (e3 >>>= 0) + n2;
          for (n2 = e3; t4[n2] && !(n2 >= r3); ) ++n2;
          if (16 < n2 - e3 && t4.buffer && U) return U.decode(t4.buffer instanceof SharedArrayBuffer ? t4.slice(e3, n2) : t4.subarray(e3, n2));
          for (r3 = ""; e3 < n2; ) {
            var i3 = t4[e3++];
            if (128 & i3) {
              var o2 = 63 & t4[e3++];
              if (192 == (224 & i3)) r3 += String.fromCharCode((31 & i3) << 6 | o2);
              else {
                var a2 = 63 & t4[e3++];
                65536 > (i3 = 224 == (240 & i3) ? (15 & i3) << 12 | o2 << 6 | a2 : (7 & i3) << 18 | o2 << 12 | a2 << 6 | 63 & t4[e3++]) ? r3 += String.fromCharCode(i3) : (i3 -= 65536, r3 += String.fromCharCode(55296 | i3 >> 10, 56320 | 1023 & i3));
              }
            } else r3 += String.fromCharCode(i3);
          }
          return r3;
        }
        function B(t4, e3) {
          return (t4 >>>= 0) ? V(r2(), t4, e3) : "";
        }
        function z(t4, e3, n2, r3) {
          if (!(0 < r3)) return 0;
          var i3 = n2 >>>= 0;
          r3 = n2 + r3 - 1;
          for (var o2 = 0; o2 < t4.length; ++o2) {
            var a2 = t4.charCodeAt(o2);
            if (55296 <= a2 && 57343 >= a2 && (a2 = 65536 + ((1023 & a2) << 10) | 1023 & t4.charCodeAt(++o2)), 127 >= a2) {
              if (n2 >= r3) break;
              e3[n2++ >>> 0] = a2;
            } else {
              if (2047 >= a2) {
                if (n2 + 1 >= r3) break;
                e3[n2++ >>> 0] = 192 | a2 >> 6;
              } else {
                if (65535 >= a2) {
                  if (n2 + 2 >= r3) break;
                  e3[n2++ >>> 0] = 224 | a2 >> 12;
                } else {
                  if (n2 + 3 >= r3) break;
                  e3[n2++ >>> 0] = 240 | a2 >> 18, e3[n2++ >>> 0] = 128 | a2 >> 12 & 63;
                }
                e3[n2++ >>> 0] = 128 | a2 >> 6 & 63;
              }
              e3[n2++ >>> 0] = 128 | 63 & a2;
            }
          }
          return e3[n2 >>> 0] = 0, n2 - i3;
        }
        function G(t4) {
          for (var e3 = 0, n2 = 0; n2 < t4.length; ++n2) {
            var r3 = t4.charCodeAt(n2);
            127 >= r3 ? e3++ : 2047 >= r3 ? e3 += 2 : 55296 <= r3 && 57343 >= r3 ? (e3 += 4, ++n2) : e3 += 3;
          }
          return e3;
        }
        function H(t4) {
          C = t4, s.HEAP8 = F = new Int8Array(t4), s.HEAP16 = new Int16Array(t4), s.HEAP32 = R = new Int32Array(t4), s.HEAPU8 = N = new Uint8Array(t4), s.HEAPU16 = new Uint16Array(t4), s.HEAPU32 = L = new Uint32Array(t4), s.HEAPF32 = new Float32Array(t4), s.HEAPF64 = M = new Float64Array(t4);
        }
        x && (C = s.buffer);
        var q = s.INITIAL_MEMORY || 16777216;
        if (x) $ = s.wasmMemory, C = s.buffer;
        else if (s.wasmMemory) $ = s.wasmMemory;
        else if (!(($ = new WebAssembly.Memory({ initial: q / 65536, maximum: 65536, shared: true })).buffer instanceof SharedArrayBuffer)) throw P("requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag"), w && console.log("(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and also use a recent version)"), Error("bad memory");
        $ && (C = $.buffer), q = C.byteLength, H(C);
        var W, X = [], Y = [], K = [], Z = [];
        function J() {
          return D || false;
        }
        function Q() {
          var t4 = s.preRun.shift();
          X.unshift(t4);
        }
        var tt, et = 0, rt = null;
        function it(t4) {
          throw x ? postMessage({ cmd: "onAbort", arg: t4 }) : s.onAbort && s.onAbort(t4), P(t4 = "Aborted(" + t4 + ")"), j = true, t4 = new WebAssembly.RuntimeError(t4 + ". Build with -sASSERTIONS for more info."), c(t4), t4;
        }
        function ot() {
          return tt.startsWith("data:application/octet-stream;base64,");
        }
        function at() {
          var t4 = tt;
          try {
            if (t4 == tt && E) return new Uint8Array(E);
            if (f) return f(t4);
            throw "both async and sync fetching of the wasm failed";
          } catch (t5) {
            it(t5);
          }
        }
        tt = "ort-wasm-threaded.wasm", ot() || (tt = S(tt));
        var st = {};
        function ut(t4) {
          this.name = "ExitStatus", this.message = "Program terminated with exit(" + t4 + ")", this.status = t4;
        }
        function ct(t4) {
          (t4 = dt.Vb[t4]) || it(), dt.mc(t4);
        }
        function lt2(t4) {
          var e3 = dt.Cc();
          if (!e3) return 6;
          dt.ac.push(e3), dt.Vb[t4.Ub] = e3, e3.Ub = t4.Ub;
          var n2 = { cmd: "run", start_routine: t4.Ic, arg: t4.zc, pthread_ptr: t4.Ub };
          return e3.$b = () => {
            n2.time = performance.now(), e3.postMessage(n2, t4.Nc);
          }, e3.loaded && (e3.$b(), delete e3.$b), 0;
        }
        function pt(t4) {
          if (x) return Wt(1, 1, t4);
          J() || (dt.oc(), s.onExit && s.onExit(t4), j = true), y(t4, new ut(t4));
        }
        function ft(t4, e3) {
          if (!e3 && x) throw bt(t4), "unwind";
          J() || x || (me(), ht(K), be(0), re2[1].length && ie(1, 10), re2[2].length && ie(2, 10), dt.oc()), pt(t4);
        }
        var dt = { Yb: [], ac: [], qc: [], Vb: {}, fc: function() {
          x && dt.Ec();
        }, Pc: function() {
        }, Ec: function() {
          dt.receiveObjectTransfer = dt.Gc, dt.threadInitTLS = dt.pc, dt.setExitStatus = dt.nc, D = false;
        }, nc: function() {
        }, oc: function() {
          for (var t4 of Object.values(dt.Vb)) dt.mc(t4);
          for (t4 of dt.Yb) t4.terminate();
          dt.Yb = [];
        }, mc: function(t4) {
          var e3 = t4.Ub;
          delete dt.Vb[e3], dt.Yb.push(t4), dt.ac.splice(dt.ac.indexOf(t4), 1), t4.Ub = 0, xe(e3);
        }, Gc: function() {
        }, pc: function() {
          dt.qc.forEach((t4) => t4());
        }, Fc: function(t4, e3) {
          t4.onmessage = (n2) => {
            var r3 = (n2 = n2.data).cmd;
            if (t4.Ub && (dt.Bc = t4.Ub), n2.targetThread && n2.targetThread != de()) {
              var i3 = dt.Vb[n2.Qc];
              i3 ? i3.postMessage(n2, n2.transferList) : P('Internal error! Worker sent a message "' + r3 + '" to target pthread ' + n2.targetThread + ", but that thread no longer exists!");
            } else "processProxyingQueue" === r3 ? Vt(n2.queue) : "spawnThread" === r3 ? lt2(n2) : "cleanupThread" === r3 ? ct(n2.thread) : "killThread" === r3 ? (n2 = n2.thread, r3 = dt.Vb[n2], delete dt.Vb[n2], r3.terminate(), xe(n2), dt.ac.splice(dt.ac.indexOf(r3), 1), r3.Ub = 0) : "cancelThread" === r3 ? dt.Vb[n2.thread].postMessage({ cmd: "cancel" }) : "loaded" === r3 ? (t4.loaded = true, e3 && e3(t4), t4.$b && (t4.$b(), delete t4.$b)) : "print" === r3 ? I("Thread " + n2.threadId + ": " + n2.text) : "printErr" === r3 ? P("Thread " + n2.threadId + ": " + n2.text) : "alert" === r3 ? alert("Thread " + n2.threadId + ": " + n2.text) : "setimmediate" === n2.target ? t4.postMessage(n2) : "onAbort" === r3 ? s.onAbort && s.onAbort(n2.arg) : r3 && P("worker sent an unknown command " + r3);
            dt.Bc = void 0;
          }, t4.onerror = (t5) => {
            throw P("worker sent an error! " + t5.filename + ":" + t5.lineno + ": " + t5.message), t5;
          }, w && (t4.on("message", function(e4) {
            t4.onmessage({ data: e4 });
          }), t4.on("error", function(e4) {
            t4.onerror(e4);
          }), t4.on("detachedExit", function() {
          })), t4.postMessage({ cmd: "load", urlOrBlob: s.mainScriptUrlOrBlob || _scriptDir, wasmMemory: $, wasmModule: k });
        }, yc: function() {
          var t4 = S("ort-wasm-threaded.worker.js");
          dt.Yb.push(new Worker(t4));
        }, Cc: function() {
          return 0 == dt.Yb.length && (dt.yc(), dt.Fc(dt.Yb[0])), dt.Yb.pop();
        } };
        function ht(t4) {
          for (; 0 < t4.length; ) t4.shift()(s);
        }
        function gt2(t4) {
          var e3 = Ae();
          return t4 = t4(), Ee(e3), t4;
        }
        function bt(t4) {
          if (x) return Wt(2, 0, t4);
          try {
            ft(t4);
          } catch (t5) {
            t5 instanceof ut || "unwind" == t5 || y(1, t5);
          }
        }
        s.PThread = dt, s.establishStackSpace = function() {
          var t4 = de(), e3 = i2()[t4 + 44 >> 2 >>> 0];
          t4 = i2()[t4 + 48 >> 2 >>> 0], Oe(e3, e3 - t4), Ee(e3);
        };
        var mt = [];
        function yt(t4) {
          var e3 = mt[t4];
          return e3 || (t4 >= mt.length && (mt.length = t4 + 1), mt[t4] = e3 = W.get(t4)), e3;
        }
        s.invokeEntryPoint = function(t4, e3) {
          t4 = yt(t4)(e3), J() ? dt.nc(t4) : Te(t4);
        };
        var _t, vt, wt = [], xt = 0, Tt = 0;
        function St(t4) {
          this.Zb = t4, this.Sb = t4 - 24, this.xc = function(t5) {
            o()[this.Sb + 4 >> 2 >>> 0] = t5;
          }, this.bc = function() {
            return o()[this.Sb + 4 >> 2 >>> 0];
          }, this.wc = function(t5) {
            o()[this.Sb + 8 >> 2 >>> 0] = t5;
          }, this.Dc = function() {
            return o()[this.Sb + 8 >> 2 >>> 0];
          }, this.rc = function() {
            i2()[this.Sb >> 2 >>> 0] = 0;
          }, this.hc = function(t5) {
            t5 = t5 ? 1 : 0, e2()[this.Sb + 12 >> 0 >>> 0] = t5;
          }, this.uc = function() {
            return 0 != e2()[this.Sb + 12 >> 0 >>> 0];
          }, this.ic = function(t5) {
            t5 = t5 ? 1 : 0, e2()[this.Sb + 13 >> 0 >>> 0] = t5;
          }, this.kc = function() {
            return 0 != e2()[this.Sb + 13 >> 0 >>> 0];
          }, this.fc = function(t5, e3) {
            this.cc(0), this.xc(t5), this.wc(e3), this.rc(), this.hc(false), this.ic(false);
          }, this.sc = function() {
            Atomics.add(i2(), this.Sb >> 2, 1);
          }, this.Hc = function() {
            return 1 === Atomics.sub(i2(), this.Sb >> 2, 1);
          }, this.cc = function(t5) {
            o()[this.Sb + 16 >> 2 >>> 0] = t5;
          }, this.tc = function() {
            return o()[this.Sb + 16 >> 2 >>> 0];
          }, this.vc = function() {
            if (De(this.bc())) return o()[this.Zb >> 2 >>> 0];
            var t5 = this.tc();
            return 0 !== t5 ? t5 : this.Zb;
          };
        }
        function Ot(t4) {
          return ge(new St(t4).Sb);
        }
        function At(t4, e3, n2, r3) {
          return x ? Wt(3, 1, t4, e3, n2, r3) : Et(t4, e3, n2, r3);
        }
        function Et(t4, e3, n2, r3) {
          if ("undefined" == typeof SharedArrayBuffer) return P("Current environment does not support SharedArrayBuffer, pthreads are not available!"), 6;
          var i3 = [];
          return x && 0 === i3.length ? At(t4, e3, n2, r3) : (t4 = { Ic: n2, Ub: t4, zc: r3, Nc: i3 }, x ? (t4.Oc = "spawnThread", postMessage(t4, i3), 0) : lt2(t4));
        }
        function It(t4, e3, n2) {
          return x ? Wt(4, 1, t4, e3, n2) : 0;
        }
        function Pt(t4, e3) {
          if (x) return Wt(5, 1, t4, e3);
        }
        function Dt(t4, e3) {
          if (x) return Wt(6, 1, t4, e3);
        }
        function $t(t4, e3, n2) {
          if (x) return Wt(7, 1, t4, e3, n2);
        }
        function kt(t4, e3, n2) {
          return x ? Wt(8, 1, t4, e3, n2) : 0;
        }
        function Ct(t4, e3) {
          if (x) return Wt(9, 1, t4, e3);
        }
        function Ft(t4, e3, n2) {
          if (x) return Wt(10, 1, t4, e3, n2);
        }
        function Nt(t4, e3, n2, r3) {
          if (x) return Wt(11, 1, t4, e3, n2, r3);
        }
        function Rt(t4, e3, n2, r3) {
          if (x) return Wt(12, 1, t4, e3, n2, r3);
        }
        function Lt(t4, e3, n2, r3) {
          if (x) return Wt(13, 1, t4, e3, n2, r3);
        }
        function Mt(t4) {
          if (x) return Wt(14, 1, t4);
        }
        function jt(t4, e3) {
          if (x) return Wt(15, 1, t4, e3);
        }
        function Ut(t4, e3, n2) {
          if (x) return Wt(16, 1, t4, e3, n2);
        }
        function Vt(t4) {
          Atomics.store(i2(), t4 >> 2, 1), de() && we(t4), Atomics.compareExchange(i2(), t4 >> 2, 1, 0);
        }
        function Bt(t4) {
          return o()[t4 >>> 2] + 4294967296 * i2()[t4 + 4 >>> 2];
        }
        function zt(t4, e3, n2, r3, i3, o2) {
          return x ? Wt(17, 1, t4, e3, n2, r3, i3, o2) : -52;
        }
        function Gt(t4, e3, n2, r3, i3, o2) {
          if (x) return Wt(18, 1, t4, e3, n2, r3, i3, o2);
        }
        function Ht(t4) {
          var n2 = G(t4) + 1, r3 = he(n2);
          return r3 && z(t4, e2(), r3, n2), r3;
        }
        function qt(t4, e3, n2) {
          function r3(t5) {
            return (t5 = t5.toTimeString().match(/\(([A-Za-z ]+)\)$/)) ? t5[1] : "GMT";
          }
          if (x) return Wt(19, 1, t4, e3, n2);
          var a2 = (/* @__PURE__ */ new Date()).getFullYear(), s2 = new Date(a2, 0, 1), u2 = new Date(a2, 6, 1);
          a2 = s2.getTimezoneOffset();
          var c2 = u2.getTimezoneOffset(), l2 = Math.max(a2, c2);
          i2()[t4 >> 2 >>> 0] = 60 * l2, i2()[e3 >> 2 >>> 0] = Number(a2 != c2), t4 = r3(s2), e3 = r3(u2), t4 = Ht(t4), e3 = Ht(e3), c2 < a2 ? (o()[n2 >> 2 >>> 0] = t4, o()[n2 + 4 >> 2 >>> 0] = e3) : (o()[n2 >> 2 >>> 0] = e3, o()[n2 + 4 >> 2 >>> 0] = t4);
        }
        function Wt(t4, e3) {
          var n2 = arguments.length - 2, r3 = arguments;
          return gt2(() => {
            for (var i3 = Ie(8 * n2), o2 = i3 >> 3, s2 = 0; s2 < n2; s2++) {
              var u2 = r3[2 + s2];
              a()[o2 + s2 >>> 0] = u2;
            }
            return ve(t4, n2, i3, e3);
          });
        }
        s.executeNotifiedProxyingQueue = Vt, vt = w ? () => {
          var t4 = process.hrtime();
          return 1e3 * t4[0] + t4[1] / 1e6;
        } : x ? () => performance.now() - s.__performance_now_clock_drift : () => performance.now();
        var Xt, Yt = [], Kt = {};
        function Zt() {
          if (!Xt) {
            var t4, e3 = { USER: "web_user", LOGNAME: "web_user", PATH: "/", PWD: "/", HOME: "/home/web_user", LANG: ("object" == typeof navigator && navigator.languages && navigator.languages[0] || "C").replace("-", "_") + ".UTF-8", _: m || "./this.program" };
            for (t4 in Kt) void 0 === Kt[t4] ? delete e3[t4] : e3[t4] = Kt[t4];
            var n2 = [];
            for (t4 in e3) n2.push(t4 + "=" + e3[t4]);
            Xt = n2;
          }
          return Xt;
        }
        function Jt(t4, n2) {
          if (x) return Wt(20, 1, t4, n2);
          var r3 = 0;
          return Zt().forEach(function(i3, a2) {
            var s2 = n2 + r3;
            for (a2 = o()[t4 + 4 * a2 >> 2 >>> 0] = s2, s2 = 0; s2 < i3.length; ++s2) e2()[a2++ >> 0 >>> 0] = i3.charCodeAt(s2);
            e2()[a2 >> 0 >>> 0] = 0, r3 += i3.length + 1;
          }), 0;
        }
        function Qt(t4, e3) {
          if (x) return Wt(21, 1, t4, e3);
          var n2 = Zt();
          o()[t4 >> 2 >>> 0] = n2.length;
          var r3 = 0;
          return n2.forEach(function(t5) {
            r3 += t5.length + 1;
          }), o()[e3 >> 2 >>> 0] = r3, 0;
        }
        function te(t4) {
          return x ? Wt(22, 1, t4) : 52;
        }
        function ee(t4, e3, n2, r3) {
          return x ? Wt(23, 1, t4, e3, n2, r3) : 52;
        }
        function ne(t4, e3, n2, r3, i3) {
          return x ? Wt(24, 1, t4, e3, n2, r3, i3) : 70;
        }
        var re2 = [null, [], []];
        function ie(t4, e3) {
          var n2 = re2[t4];
          0 === e3 || 10 === e3 ? ((1 === t4 ? I : P)(V(n2, 0)), n2.length = 0) : n2.push(e3);
        }
        function oe(t4, e3, n2, i3) {
          if (x) return Wt(25, 1, t4, e3, n2, i3);
          for (var a2 = 0, s2 = 0; s2 < n2; s2++) {
            var u2 = o()[e3 >> 2 >>> 0], c2 = o()[e3 + 4 >> 2 >>> 0];
            e3 += 8;
            for (var l2 = 0; l2 < c2; l2++) ie(t4, r2()[u2 + l2 >>> 0]);
            a2 += c2;
          }
          return o()[i3 >> 2 >>> 0] = a2, 0;
        }
        var ae = 0;
        function se(t4) {
          return 0 == t4 % 4 && (0 != t4 % 100 || 0 == t4 % 400);
        }
        var ue = [31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31], ce = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];
        function le(t4, n2, r3, o2) {
          function a2(t5, e3, n3) {
            for (t5 = "number" == typeof t5 ? t5.toString() : t5 || ""; t5.length < e3; ) t5 = n3[0] + t5;
            return t5;
          }
          function s2(t5, e3) {
            return a2(t5, e3, "0");
          }
          function u2(t5, e3) {
            function n3(t6) {
              return 0 > t6 ? -1 : 0 < t6 ? 1 : 0;
            }
            var r4;
            return 0 === (r4 = n3(t5.getFullYear() - e3.getFullYear())) && 0 === (r4 = n3(t5.getMonth() - e3.getMonth())) && (r4 = n3(t5.getDate() - e3.getDate())), r4;
          }
          function c2(t5) {
            switch (t5.getDay()) {
              case 0:
                return new Date(t5.getFullYear() - 1, 11, 29);
              case 1:
                return t5;
              case 2:
                return new Date(t5.getFullYear(), 0, 3);
              case 3:
                return new Date(t5.getFullYear(), 0, 2);
              case 4:
                return new Date(t5.getFullYear(), 0, 1);
              case 5:
                return new Date(t5.getFullYear() - 1, 11, 31);
              case 6:
                return new Date(t5.getFullYear() - 1, 11, 30);
            }
          }
          function l2(t5) {
            var e3 = t5.Wb;
            for (t5 = new Date(new Date(t5.Xb + 1900, 0, 1).getTime()); 0 < e3; ) {
              var n3 = t5.getMonth(), r4 = (se(t5.getFullYear()) ? ue : ce)[n3];
              if (!(e3 > r4 - t5.getDate())) {
                t5.setDate(t5.getDate() + e3);
                break;
              }
              e3 -= r4 - t5.getDate() + 1, t5.setDate(1), 11 > n3 ? t5.setMonth(n3 + 1) : (t5.setMonth(0), t5.setFullYear(t5.getFullYear() + 1));
            }
            return n3 = new Date(t5.getFullYear() + 1, 0, 4), e3 = c2(new Date(t5.getFullYear(), 0, 4)), n3 = c2(n3), 0 >= u2(e3, t5) ? 0 >= u2(n3, t5) ? t5.getFullYear() + 1 : t5.getFullYear() : t5.getFullYear() - 1;
          }
          var p2 = i2()[o2 + 40 >> 2 >>> 0];
          for (var f2 in o2 = { Lc: i2()[o2 >> 2 >>> 0], Kc: i2()[o2 + 4 >> 2 >>> 0], dc: i2()[o2 + 8 >> 2 >>> 0], jc: i2()[o2 + 12 >> 2 >>> 0], ec: i2()[o2 + 16 >> 2 >>> 0], Xb: i2()[o2 + 20 >> 2 >>> 0], Tb: i2()[o2 + 24 >> 2 >>> 0], Wb: i2()[o2 + 28 >> 2 >>> 0], Rc: i2()[o2 + 32 >> 2 >>> 0], Jc: i2()[o2 + 36 >> 2 >>> 0], Mc: p2 ? B(p2) : "" }, r3 = B(r3), p2 = { "%c": "%a %b %d %H:%M:%S %Y", "%D": "%m/%d/%y", "%F": "%Y-%m-%d", "%h": "%b", "%r": "%I:%M:%S %p", "%R": "%H:%M", "%T": "%H:%M:%S", "%x": "%m/%d/%y", "%X": "%H:%M:%S", "%Ec": "%c", "%EC": "%C", "%Ex": "%m/%d/%y", "%EX": "%H:%M:%S", "%Ey": "%y", "%EY": "%Y", "%Od": "%d", "%Oe": "%e", "%OH": "%H", "%OI": "%I", "%Om": "%m", "%OM": "%M", "%OS": "%S", "%Ou": "%u", "%OU": "%U", "%OV": "%V", "%Ow": "%w", "%OW": "%W", "%Oy": "%y" }) r3 = r3.replace(new RegExp(f2, "g"), p2[f2]);
          var d2 = "Sunday Monday Tuesday Wednesday Thursday Friday Saturday".split(" "), h2 = "January February March April May June July August September October November December".split(" ");
          for (f2 in p2 = { "%a": function(t5) {
            return d2[t5.Tb].substring(0, 3);
          }, "%A": function(t5) {
            return d2[t5.Tb];
          }, "%b": function(t5) {
            return h2[t5.ec].substring(0, 3);
          }, "%B": function(t5) {
            return h2[t5.ec];
          }, "%C": function(t5) {
            return s2((t5.Xb + 1900) / 100 | 0, 2);
          }, "%d": function(t5) {
            return s2(t5.jc, 2);
          }, "%e": function(t5) {
            return a2(t5.jc, 2, " ");
          }, "%g": function(t5) {
            return l2(t5).toString().substring(2);
          }, "%G": function(t5) {
            return l2(t5);
          }, "%H": function(t5) {
            return s2(t5.dc, 2);
          }, "%I": function(t5) {
            return 0 == (t5 = t5.dc) ? t5 = 12 : 12 < t5 && (t5 -= 12), s2(t5, 2);
          }, "%j": function(t5) {
            for (var e3 = 0, n3 = 0; n3 <= t5.ec - 1; e3 += (se(t5.Xb + 1900) ? ue : ce)[n3++]) ;
            return s2(t5.jc + e3, 3);
          }, "%m": function(t5) {
            return s2(t5.ec + 1, 2);
          }, "%M": function(t5) {
            return s2(t5.Kc, 2);
          }, "%n": function() {
            return "\n";
          }, "%p": function(t5) {
            return 0 <= t5.dc && 12 > t5.dc ? "AM" : "PM";
          }, "%S": function(t5) {
            return s2(t5.Lc, 2);
          }, "%t": function() {
            return "	";
          }, "%u": function(t5) {
            return t5.Tb || 7;
          }, "%U": function(t5) {
            return s2(Math.floor((t5.Wb + 7 - t5.Tb) / 7), 2);
          }, "%V": function(t5) {
            var e3 = Math.floor((t5.Wb + 7 - (t5.Tb + 6) % 7) / 7);
            if (2 >= (t5.Tb + 371 - t5.Wb - 2) % 7 && e3++, e3) 53 == e3 && (4 == (n3 = (t5.Tb + 371 - t5.Wb) % 7) || 3 == n3 && se(t5.Xb) || (e3 = 1));
            else {
              e3 = 52;
              var n3 = (t5.Tb + 7 - t5.Wb - 1) % 7;
              (4 == n3 || 5 == n3 && se(t5.Xb % 400 - 1)) && e3++;
            }
            return s2(e3, 2);
          }, "%w": function(t5) {
            return t5.Tb;
          }, "%W": function(t5) {
            return s2(Math.floor((t5.Wb + 7 - (t5.Tb + 6) % 7) / 7), 2);
          }, "%y": function(t5) {
            return (t5.Xb + 1900).toString().substring(2);
          }, "%Y": function(t5) {
            return t5.Xb + 1900;
          }, "%z": function(t5) {
            var e3 = 0 <= (t5 = t5.Jc);
            return t5 = Math.abs(t5) / 60, (e3 ? "+" : "-") + String("0000" + (t5 / 60 * 100 + t5 % 60)).slice(-4);
          }, "%Z": function(t5) {
            return t5.Mc;
          }, "%%": function() {
            return "%";
          } }, r3 = r3.replace(/%%/g, "\0\0"), p2) r3.includes(f2) && (r3 = r3.replace(new RegExp(f2, "g"), p2[f2](o2)));
          return f2 = function(t5) {
            var e3 = Array(G(t5) + 1);
            return z(t5, e3, 0, e3.length), e3;
          }(r3 = r3.replace(/\0\0/g, "%")), f2.length > n2 ? 0 : (function(t5, n3) {
            e2().set(t5, n3 >>> 0);
          }(f2, t4), f2.length - 1);
        }
        dt.fc();
        var pe = [null, pt, bt, At, It, Pt, Dt, $t, kt, Ct, Ft, Nt, Rt, Lt, Mt, jt, Ut, zt, Gt, qt, Jt, Qt, te, ee, ne, oe], fe = { b: function(t4) {
          return he(t4 + 24) + 24;
        }, n: function(t4) {
          return (t4 = new St(t4)).uc() || (t4.hc(true), xt--), t4.ic(false), wt.push(t4), t4.sc(), t4.vc();
        }, ma: function(t4) {
          throw P("Unexpected exception thrown, this is not properly supported - aborting"), j = true, t4;
        }, x: function() {
          Se(0);
          var t4 = wt.pop();
          if (t4.Hc() && !t4.kc()) {
            var e3 = t4.Dc();
            e3 && yt(e3)(t4.Zb), Ot(t4.Zb);
          }
          Tt = 0;
        }, e: function() {
          var t4 = Tt;
          if (!t4) return ae = 0;
          var e3 = new St(t4);
          e3.cc(t4);
          var n2 = e3.bc();
          if (!n2) return ae = 0, t4;
          for (var r3 = Array.prototype.slice.call(arguments), i3 = 0; i3 < r3.length; i3++) {
            var o2 = r3[i3];
            if (0 === o2 || o2 === n2) break;
            if (Pe(o2, n2, e3.Sb + 16)) return ae = o2, t4;
          }
          return ae = n2, t4;
        }, l: function() {
          var t4 = Tt;
          if (!t4) return ae = 0;
          var e3 = new St(t4);
          e3.cc(t4);
          var n2 = e3.bc();
          if (!n2) return ae = 0, t4;
          for (var r3 = Array.prototype.slice.call(arguments), i3 = 0; i3 < r3.length; i3++) {
            var o2 = r3[i3];
            if (0 === o2 || o2 === n2) break;
            if (Pe(o2, n2, e3.Sb + 16)) return ae = o2, t4;
          }
          return ae = n2, t4;
        }, h: function() {
          var t4 = Tt;
          if (!t4) return ae = 0;
          var e3 = new St(t4);
          e3.cc(t4);
          var n2 = e3.bc();
          if (!n2) return ae = 0, t4;
          for (var r3 = Array.prototype.slice.call(arguments), i3 = 0; i3 < r3.length; i3++) {
            var o2 = r3[i3];
            if (0 === o2 || o2 === n2) break;
            if (Pe(o2, n2, e3.Sb + 16)) return ae = o2, t4;
          }
          return ae = n2, t4;
        }, t: Ot, M: function() {
          var t4 = wt.pop();
          t4 || it("no exception to throw");
          var e3 = t4.Zb;
          throw t4.kc() || (wt.push(t4), t4.ic(true), t4.hc(false), xt++), Tt = e3, e3;
        }, c: function(t4, e3, n2) {
          throw new St(t4).fc(e3, n2), Tt = t4, xt++, t4;
        }, pa: function() {
          return xt;
        }, Fa: function(t4) {
          ye(t4, !v, 1, !_), dt.pc();
        }, T: function(t4) {
          x ? postMessage({ cmd: "cleanupThread", thread: t4 }) : ct(t4);
        }, xa: Et, j: function(t4) {
          throw Tt || (Tt = t4), t4;
        }, H: It, Ma: Pt, ua: Dt, wa: $t, oa: kt, Ka: Ct, Ca: Ft, Ja: Nt, V: Rt, va: Lt, sa: Mt, La: jt, ta: Ut, Ta: function() {
        }, X: function() {
          it("To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking");
        }, Ua: function() {
          it("To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking");
        }, W: function() {
          return Date.now();
        }, ya: function() {
          return 2097152;
        }, Oa: function() {
          return true;
        }, za: function(t4, e3, n2, r3) {
          if (t4 == e3) setTimeout(() => Vt(r3));
          else if (x) postMessage({ targetThread: t4, cmd: "processProxyingQueue", queue: r3 });
          else {
            if (!(t4 = dt.Vb[t4])) return;
            t4.postMessage({ cmd: "processProxyingQueue", queue: r3 });
          }
          return 1;
        }, Ea: function() {
          return -1;
        }, Pa: function(t4, e3) {
          t4 = new Date(1e3 * Bt(t4)), i2()[e3 >> 2 >>> 0] = t4.getUTCSeconds(), i2()[e3 + 4 >> 2 >>> 0] = t4.getUTCMinutes(), i2()[e3 + 8 >> 2 >>> 0] = t4.getUTCHours(), i2()[e3 + 12 >> 2 >>> 0] = t4.getUTCDate(), i2()[e3 + 16 >> 2 >>> 0] = t4.getUTCMonth(), i2()[e3 + 20 >> 2 >>> 0] = t4.getUTCFullYear() - 1900, i2()[e3 + 24 >> 2 >>> 0] = t4.getUTCDay(), t4 = (t4.getTime() - Date.UTC(t4.getUTCFullYear(), 0, 1, 0, 0, 0, 0)) / 864e5 | 0, i2()[e3 + 28 >> 2 >>> 0] = t4;
        }, Qa: function(t4, e3) {
          t4 = new Date(1e3 * Bt(t4)), i2()[e3 >> 2 >>> 0] = t4.getSeconds(), i2()[e3 + 4 >> 2 >>> 0] = t4.getMinutes(), i2()[e3 + 8 >> 2 >>> 0] = t4.getHours(), i2()[e3 + 12 >> 2 >>> 0] = t4.getDate(), i2()[e3 + 16 >> 2 >>> 0] = t4.getMonth(), i2()[e3 + 20 >> 2 >>> 0] = t4.getFullYear() - 1900, i2()[e3 + 24 >> 2 >>> 0] = t4.getDay();
          var n2 = new Date(t4.getFullYear(), 0, 1), r3 = (t4.getTime() - n2.getTime()) / 864e5 | 0;
          i2()[e3 + 28 >> 2 >>> 0] = r3, i2()[e3 + 36 >> 2 >>> 0] = -60 * t4.getTimezoneOffset(), r3 = new Date(t4.getFullYear(), 6, 1).getTimezoneOffset(), t4 = 0 | (r3 != (n2 = n2.getTimezoneOffset()) && t4.getTimezoneOffset() == Math.min(n2, r3)), i2()[e3 + 32 >> 2 >>> 0] = t4;
        }, Ra: function(t4) {
          var e3 = new Date(i2()[t4 + 20 >> 2 >>> 0] + 1900, i2()[t4 + 16 >> 2 >>> 0], i2()[t4 + 12 >> 2 >>> 0], i2()[t4 + 8 >> 2 >>> 0], i2()[t4 + 4 >> 2 >>> 0], i2()[t4 >> 2 >>> 0], 0), n2 = i2()[t4 + 32 >> 2 >>> 0], r3 = e3.getTimezoneOffset(), o2 = new Date(e3.getFullYear(), 0, 1), a2 = new Date(e3.getFullYear(), 6, 1).getTimezoneOffset(), s2 = o2.getTimezoneOffset(), u2 = Math.min(s2, a2);
          return 0 > n2 ? i2()[t4 + 32 >> 2 >>> 0] = Number(a2 != s2 && u2 == r3) : 0 < n2 != (u2 == r3) && (a2 = Math.max(s2, a2), e3.setTime(e3.getTime() + 6e4 * ((0 < n2 ? u2 : a2) - r3))), i2()[t4 + 24 >> 2 >>> 0] = e3.getDay(), n2 = (e3.getTime() - o2.getTime()) / 864e5 | 0, i2()[t4 + 28 >> 2 >>> 0] = n2, i2()[t4 >> 2 >>> 0] = e3.getSeconds(), i2()[t4 + 4 >> 2 >>> 0] = e3.getMinutes(), i2()[t4 + 8 >> 2 >>> 0] = e3.getHours(), i2()[t4 + 12 >> 2 >>> 0] = e3.getDate(), i2()[t4 + 16 >> 2 >>> 0] = e3.getMonth(), e3.getTime() / 1e3 | 0;
        }, Aa: zt, Ba: Gt, Sa: function t4(e3, n2, r3) {
          t4.Ac || (t4.Ac = true, qt(e3, n2, r3));
        }, y: function() {
          it("");
        }, U: function() {
          if (!w && !v) {
            var t4 = "Blocking on the main thread is very dangerous, see https://emscripten.org/docs/porting/pthreads.html#blocking-on-the-main-browser-thread";
            _t || (_t = {}), _t[t4] || (_t[t4] = 1, w && (t4 = "warning: " + t4), P(t4));
          }
        }, ra: function() {
          return 4294901760;
        }, B: vt, Ia: function(t4, e3, n2) {
          r2().copyWithin(t4 >>> 0, e3 >>> 0, e3 + n2 >>> 0);
        }, F: function() {
          return w ? n(9719).cpus().length : navigator.hardwareConcurrency;
        }, Da: function(t4, e3, n2) {
          Yt.length = e3, n2 >>= 3;
          for (var r3 = 0; r3 < e3; r3++) Yt[r3] = a()[n2 + r3 >>> 0];
          return (0 > t4 ? st[-t4 - 1] : pe[t4]).apply(null, Yt);
        }, qa: function(t4) {
          var e3 = r2().length;
          if ((t4 >>>= 0) <= e3 || 4294901760 < t4) return false;
          for (var n2 = 1; 4 >= n2; n2 *= 2) {
            var i3 = e3 * (1 + 0.2 / n2);
            i3 = Math.min(i3, t4 + 100663296);
            var o2 = Math;
            i3 = Math.max(t4, i3), o2 = o2.min.call(o2, 4294901760, i3 + (65536 - i3 % 65536) % 65536);
            t: {
              try {
                $.grow(o2 - C.byteLength + 65535 >>> 16), H($.buffer);
                var a2 = 1;
                break t;
              } catch (t5) {
              }
              a2 = void 0;
            }
            if (a2) return true;
          }
          return false;
        }, Na: function() {
          throw "unwind";
        }, Ga: Jt, Ha: Qt, J: ft, I: te, S: ee, ga: ne, R: oe, d: function() {
          return ae;
        }, na: function t4(r3, i3) {
          t4.lc || (t4.lc = function() {
            if ("object" == typeof crypto && "function" == typeof crypto.getRandomValues) {
              var t5 = new Uint8Array(1);
              return () => (crypto.getRandomValues(t5), t5[0]);
            }
            if (w) try {
              var e3 = n(6113);
              return () => e3.randomBytes(1)[0];
            } catch (t6) {
            }
            return () => it("randomDevice");
          }());
          for (var o2 = 0; o2 < i3; o2++) e2()[r3 + o2 >> 0 >>> 0] = t4.lc();
          return 0;
        }, ia: function(t4, e3, n2) {
          var r3 = Ae();
          try {
            return yt(t4)(e3, n2);
          } catch (t5) {
            if (Ee(r3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, ja: function(t4, e3, n2) {
          var r3 = Ae();
          try {
            return yt(t4)(e3, n2);
          } catch (t5) {
            if (Ee(r3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, K: function(t4) {
          var e3 = Ae();
          try {
            return yt(t4)();
          } catch (t5) {
            if (Ee(e3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, f: function(t4, e3) {
          var n2 = Ae();
          try {
            return yt(t4)(e3);
          } catch (t5) {
            if (Ee(n2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, P: function(t4, e3, n2) {
          var r3 = Ae();
          try {
            return yt(t4)(e3, n2);
          } catch (t5) {
            if (Ee(r3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, Q: function(t4, e3, n2) {
          var r3 = Ae();
          try {
            return yt(t4)(e3, n2);
          } catch (t5) {
            if (Ee(r3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, k: function(t4, e3, n2) {
          var r3 = Ae();
          try {
            return yt(t4)(e3, n2);
          } catch (t5) {
            if (Ee(r3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, p: function(t4, e3, n2, r3) {
          var i3 = Ae();
          try {
            return yt(t4)(e3, n2, r3);
          } catch (t5) {
            if (Ee(i3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, q: function(t4, e3, n2, r3, i3) {
          var o2 = Ae();
          try {
            return yt(t4)(e3, n2, r3, i3);
          } catch (t5) {
            if (Ee(o2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, N: function(t4, e3, n2, r3, i3, o2) {
          var a2 = Ae();
          try {
            return yt(t4)(e3, n2, r3, i3, o2);
          } catch (t5) {
            if (Ee(a2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, s: function(t4, e3, n2, r3, i3, o2) {
          var a2 = Ae();
          try {
            return yt(t4)(e3, n2, r3, i3, o2);
          } catch (t5) {
            if (Ee(a2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, w: function(t4, e3, n2, r3, i3, o2, a2) {
          var s2 = Ae();
          try {
            return yt(t4)(e3, n2, r3, i3, o2, a2);
          } catch (t5) {
            if (Ee(s2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, L: function(t4, e3, n2, r3, i3, o2, a2, s2) {
          var u2 = Ae();
          try {
            return yt(t4)(e3, n2, r3, i3, o2, a2, s2);
          } catch (t5) {
            if (Ee(u2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, E: function(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2) {
          var f2 = Ae();
          try {
            return yt(t4)(e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2);
          } catch (t5) {
            if (Ee(f2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, aa: function(t4, e3, n2, r3, i3, o2, a2, s2) {
          var u2 = Ae();
          try {
            return je(t4, e3, n2, r3, i3, o2, a2, s2);
          } catch (t5) {
            if (Ee(u2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, _: function(t4, e3, n2, r3, i3, o2, a2) {
          var s2 = Ae();
          try {
            return ke(t4, e3, n2, r3, i3, o2, a2);
          } catch (t5) {
            if (Ee(s2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, Z: function(t4, e3, n2, r3, i3) {
          var o2 = Ae();
          try {
            return Ue(t4, e3, n2, r3, i3);
          } catch (t5) {
            if (Ee(o2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, ca: function(t4, e3, n2, r3) {
          var i3 = Ae();
          try {
            return Le(t4, e3, n2, r3);
          } catch (t5) {
            if (Ee(i3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, $: function(t4) {
          var e3 = Ae();
          try {
            return $e(t4);
          } catch (t5) {
            if (Ee(e3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, ba: function(t4, e3) {
          var n2 = Ae();
          try {
            return Me(t4, e3);
          } catch (t5) {
            if (Ee(n2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, Y: function(t4, e3, n2) {
          var r3 = Ae();
          try {
            return Ce(t4, e3, n2);
          } catch (t5) {
            if (Ee(r3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, g: function(t4) {
          var e3 = Ae();
          try {
            yt(t4)();
          } catch (t5) {
            if (Ee(e3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, r: function(t4, e3) {
          var n2 = Ae();
          try {
            yt(t4)(e3);
          } catch (t5) {
            if (Ee(n2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, i: function(t4, e3, n2) {
          var r3 = Ae();
          try {
            yt(t4)(e3, n2);
          } catch (t5) {
            if (Ee(r3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, ha: function(t4, e3, n2, r3) {
          var i3 = Ae();
          try {
            yt(t4)(e3, n2, r3);
          } catch (t5) {
            if (Ee(i3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, m: function(t4, e3, n2, r3) {
          var i3 = Ae();
          try {
            yt(t4)(e3, n2, r3);
          } catch (t5) {
            if (Ee(i3), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, v: function(t4, e3, n2, r3, i3) {
          var o2 = Ae();
          try {
            yt(t4)(e3, n2, r3, i3);
          } catch (t5) {
            if (Ee(o2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, u: function(t4, e3, n2, r3, i3, o2) {
          var a2 = Ae();
          try {
            yt(t4)(e3, n2, r3, i3, o2);
          } catch (t5) {
            if (Ee(a2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, O: function(t4, e3, n2, r3, i3, o2, a2) {
          var s2 = Ae();
          try {
            yt(t4)(e3, n2, r3, i3, o2, a2);
          } catch (t5) {
            if (Ee(s2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, A: function(t4, e3, n2, r3, i3, o2, a2, s2) {
          var u2 = Ae();
          try {
            yt(t4)(e3, n2, r3, i3, o2, a2, s2);
          } catch (t5) {
            if (Ee(u2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, ka: function(t4, e3, n2, r3, i3, o2, a2, s2, u2) {
          var c2 = Ae();
          try {
            yt(t4)(e3, n2, r3, i3, o2, a2, s2, u2);
          } catch (t5) {
            if (Ee(c2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, C: function(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2) {
          var p2 = Ae();
          try {
            yt(t4)(e3, n2, r3, i3, o2, a2, s2, u2, c2, l2);
          } catch (t5) {
            if (Ee(p2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, D: function(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2, f2, d2, h2, g2) {
          var b2 = Ae();
          try {
            yt(t4)(e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2, f2, d2, h2, g2);
          } catch (t5) {
            if (Ee(b2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, fa: function(t4, e3, n2, r3, i3, o2, a2, s2) {
          var u2 = Ae();
          try {
            Fe(t4, e3, n2, r3, i3, o2, a2, s2);
          } catch (t5) {
            if (Ee(u2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, da: function(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2) {
          var f2 = Ae();
          try {
            Re(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2);
          } catch (t5) {
            if (Ee(f2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, ea: function(t4, e3, n2, r3, i3, o2) {
          var a2 = Ae();
          try {
            Ne(t4, e3, n2, r3, i3, o2);
          } catch (t5) {
            if (Ee(a2), t5 !== t5 + 0) throw t5;
            Se(1, 0);
          }
        }, o: function(t4) {
          return t4;
        }, a: $ || s.wasmMemory, G: function(t4) {
          ae = t4;
        }, la: le, z: function(t4, e3, n2, r3) {
          return le(t4, e3, n2, r3);
        } };
        !function() {
          function t4(t5, e4) {
            s.asm = t5.exports, dt.qc.push(s.asm.sb), W = s.asm.ub, Y.unshift(s.asm.Va), k = e4, x || (et--, s.monitorRunDependencies && s.monitorRunDependencies(et), 0 == et && (rt && (t5 = rt, rt = null, t5())));
          }
          function e3(e4) {
            t4(e4.instance, e4.module);
          }
          function n2(t5) {
            return function() {
              if (!E && (_ || v)) {
                if ("function" == typeof fetch && !tt.startsWith("file://")) return fetch(tt, { credentials: "same-origin" }).then(function(t6) {
                  if (!t6.ok) throw "failed to load wasm binary file at '" + tt + "'";
                  return t6.arrayBuffer();
                }).catch(function() {
                  return at();
                });
                if (p) return new Promise(function(t6, e4) {
                  p(tt, function(e5) {
                    t6(new Uint8Array(e5));
                  }, e4);
                });
              }
              return Promise.resolve().then(function() {
                return at();
              });
            }().then(function(t6) {
              return WebAssembly.instantiate(t6, r3);
            }).then(function(t6) {
              return t6;
            }).then(t5, function(t6) {
              P("failed to asynchronously prepare wasm: " + t6), it(t6);
            });
          }
          var r3 = { a: fe };
          if (x || (et++, s.monitorRunDependencies && s.monitorRunDependencies(et)), s.instantiateWasm) try {
            return s.instantiateWasm(r3, t4);
          } catch (t5) {
            return P("Module.instantiateWasm callback failed with error: " + t5), false;
          }
          (E || "function" != typeof WebAssembly.instantiateStreaming || ot() || tt.startsWith("file://") || w || "function" != typeof fetch ? n2(e3) : fetch(tt, { credentials: "same-origin" }).then(function(t5) {
            return WebAssembly.instantiateStreaming(t5, r3).then(e3, function(t6) {
              return P("wasm streaming compile failed: " + t6), P("falling back to ArrayBuffer instantiation"), n2(e3);
            });
          })).catch(c);
        }(), s.___wasm_call_ctors = function() {
          return (s.___wasm_call_ctors = s.asm.Va).apply(null, arguments);
        }, s._OrtInit = function() {
          return (s._OrtInit = s.asm.Wa).apply(null, arguments);
        }, s._OrtCreateSessionOptions = function() {
          return (s._OrtCreateSessionOptions = s.asm.Xa).apply(null, arguments);
        }, s._OrtAppendExecutionProvider = function() {
          return (s._OrtAppendExecutionProvider = s.asm.Ya).apply(null, arguments);
        }, s._OrtAddSessionConfigEntry = function() {
          return (s._OrtAddSessionConfigEntry = s.asm.Za).apply(null, arguments);
        }, s._OrtReleaseSessionOptions = function() {
          return (s._OrtReleaseSessionOptions = s.asm._a).apply(null, arguments);
        }, s._OrtCreateSession = function() {
          return (s._OrtCreateSession = s.asm.$a).apply(null, arguments);
        }, s._OrtReleaseSession = function() {
          return (s._OrtReleaseSession = s.asm.ab).apply(null, arguments);
        }, s._OrtGetInputCount = function() {
          return (s._OrtGetInputCount = s.asm.bb).apply(null, arguments);
        }, s._OrtGetOutputCount = function() {
          return (s._OrtGetOutputCount = s.asm.cb).apply(null, arguments);
        }, s._OrtGetInputName = function() {
          return (s._OrtGetInputName = s.asm.db).apply(null, arguments);
        }, s._OrtGetOutputName = function() {
          return (s._OrtGetOutputName = s.asm.eb).apply(null, arguments);
        }, s._OrtFree = function() {
          return (s._OrtFree = s.asm.fb).apply(null, arguments);
        }, s._OrtCreateTensor = function() {
          return (s._OrtCreateTensor = s.asm.gb).apply(null, arguments);
        }, s._OrtGetTensorData = function() {
          return (s._OrtGetTensorData = s.asm.hb).apply(null, arguments);
        }, s._OrtReleaseTensor = function() {
          return (s._OrtReleaseTensor = s.asm.ib).apply(null, arguments);
        }, s._OrtCreateRunOptions = function() {
          return (s._OrtCreateRunOptions = s.asm.jb).apply(null, arguments);
        }, s._OrtAddRunConfigEntry = function() {
          return (s._OrtAddRunConfigEntry = s.asm.kb).apply(null, arguments);
        }, s._OrtReleaseRunOptions = function() {
          return (s._OrtReleaseRunOptions = s.asm.lb).apply(null, arguments);
        }, s._OrtRun = function() {
          return (s._OrtRun = s.asm.mb).apply(null, arguments);
        }, s._OrtEndProfiling = function() {
          return (s._OrtEndProfiling = s.asm.nb).apply(null, arguments);
        };
        var de = s._pthread_self = function() {
          return (de = s._pthread_self = s.asm.ob).apply(null, arguments);
        }, he = s._malloc = function() {
          return (he = s._malloc = s.asm.pb).apply(null, arguments);
        }, ge = s._free = function() {
          return (ge = s._free = s.asm.qb).apply(null, arguments);
        }, be = s._fflush = function() {
          return (be = s._fflush = s.asm.rb).apply(null, arguments);
        };
        s.__emscripten_tls_init = function() {
          return (s.__emscripten_tls_init = s.asm.sb).apply(null, arguments);
        };
        var me = s.___funcs_on_exit = function() {
          return (me = s.___funcs_on_exit = s.asm.tb).apply(null, arguments);
        }, ye = s.__emscripten_thread_init = function() {
          return (ye = s.__emscripten_thread_init = s.asm.vb).apply(null, arguments);
        };
        s.__emscripten_thread_crashed = function() {
          return (s.__emscripten_thread_crashed = s.asm.wb).apply(null, arguments);
        };
        var _e, ve = s._emscripten_run_in_main_runtime_thread_js = function() {
          return (ve = s._emscripten_run_in_main_runtime_thread_js = s.asm.xb).apply(null, arguments);
        }, we = s.__emscripten_proxy_execute_task_queue = function() {
          return (we = s.__emscripten_proxy_execute_task_queue = s.asm.yb).apply(null, arguments);
        }, xe = s.__emscripten_thread_free_data = function() {
          return (xe = s.__emscripten_thread_free_data = s.asm.zb).apply(null, arguments);
        }, Te = s.__emscripten_thread_exit = function() {
          return (Te = s.__emscripten_thread_exit = s.asm.Ab).apply(null, arguments);
        }, Se = s._setThrew = function() {
          return (Se = s._setThrew = s.asm.Bb).apply(null, arguments);
        }, Oe = s._emscripten_stack_set_limits = function() {
          return (Oe = s._emscripten_stack_set_limits = s.asm.Cb).apply(null, arguments);
        }, Ae = s.stackSave = function() {
          return (Ae = s.stackSave = s.asm.Db).apply(null, arguments);
        }, Ee = s.stackRestore = function() {
          return (Ee = s.stackRestore = s.asm.Eb).apply(null, arguments);
        }, Ie = s.stackAlloc = function() {
          return (Ie = s.stackAlloc = s.asm.Fb).apply(null, arguments);
        }, Pe = s.___cxa_can_catch = function() {
          return (Pe = s.___cxa_can_catch = s.asm.Gb).apply(null, arguments);
        }, De = s.___cxa_is_pointer_type = function() {
          return (De = s.___cxa_is_pointer_type = s.asm.Hb).apply(null, arguments);
        }, $e = s.dynCall_j = function() {
          return ($e = s.dynCall_j = s.asm.Ib).apply(null, arguments);
        }, ke = s.dynCall_iiiiij = function() {
          return (ke = s.dynCall_iiiiij = s.asm.Jb).apply(null, arguments);
        }, Ce = s.dynCall_jii = function() {
          return (Ce = s.dynCall_jii = s.asm.Kb).apply(null, arguments);
        }, Fe = s.dynCall_viiiiij = function() {
          return (Fe = s.dynCall_viiiiij = s.asm.Lb).apply(null, arguments);
        }, Ne = s.dynCall_vjji = function() {
          return (Ne = s.dynCall_vjji = s.asm.Mb).apply(null, arguments);
        }, Re = s.dynCall_viiijjjii = function() {
          return (Re = s.dynCall_viiijjjii = s.asm.Nb).apply(null, arguments);
        }, Le = s.dynCall_iij = function() {
          return (Le = s.dynCall_iij = s.asm.Ob).apply(null, arguments);
        }, Me = s.dynCall_ji = function() {
          return (Me = s.dynCall_ji = s.asm.Pb).apply(null, arguments);
        }, je = s.dynCall_iiiiiij = function() {
          return (je = s.dynCall_iiiiiij = s.asm.Qb).apply(null, arguments);
        }, Ue = s.dynCall_iiij = function() {
          return (Ue = s.dynCall_iiij = s.asm.Rb).apply(null, arguments);
        };
        function Ve() {
          function t4() {
            if (!_e && (_e = true, s.calledRun = true, !j) && (x || ht(Y), u(s), s.onRuntimeInitialized && s.onRuntimeInitialized(), !x)) {
              if (s.postRun) for ("function" == typeof s.postRun && (s.postRun = [s.postRun]); s.postRun.length; ) {
                var t5 = s.postRun.shift();
                Z.unshift(t5);
              }
              ht(Z);
            }
          }
          if (!(0 < et)) if (x) u(s), x || ht(Y), postMessage({ cmd: "loaded" });
          else {
            if (s.preRun) for ("function" == typeof s.preRun && (s.preRun = [s.preRun]); s.preRun.length; ) Q();
            ht(X), 0 < et || (s.setStatus ? (s.setStatus("Running..."), setTimeout(function() {
              setTimeout(function() {
                s.setStatus("");
              }, 1), t4();
            }, 1)) : t4());
          }
        }
        if (s.UTF8ToString = B, s.stringToUTF8 = function(t4, e3, n2) {
          return z(t4, r2(), e3, n2);
        }, s.lengthBytesUTF8 = G, s.keepRuntimeAlive = J, s.wasmMemory = $, s.stackSave = Ae, s.stackRestore = Ee, s.stackAlloc = Ie, s.ExitStatus = ut, s.PThread = dt, rt = function t4() {
          _e || Ve(), _e || (rt = t4);
        }, s.preInit) for ("function" == typeof s.preInit && (s.preInit = [s.preInit]); 0 < s.preInit.length; ) s.preInit.pop()();
        return Ve(), t3.ready;
      });
      t2.exports = r;
    }, 932: (t2, e, n) => {
      var _scriptDir, r = (_scriptDir = (_scriptDir = "undefined" != typeof document && document.currentScript ? document.currentScript.src : void 0) || __filename, function(t3) {
        var e2, r2, i2;
        t3 = t3 || {}, e2 || (e2 = void 0 !== t3 ? t3 : {}), e2.ready = new Promise(function(t4, e3) {
          r2 = t4, i2 = e3;
        });
        var o, a, s, u, c, l, p = Object.assign({}, e2), f = "./this.program", d = (t4, e3) => {
          throw e3;
        }, h = "object" == typeof window, g = "function" == typeof importScripts, b = "object" == typeof process && "object" == typeof process.versions && "string" == typeof process.versions.node, m = "";
        b ? (m = g ? n(1423).dirname(m) + "/" : __dirname + "/", l = () => {
          c || (u = n(6231), c = n(1423));
        }, o = function(t4, e3) {
          return l(), t4 = c.normalize(t4), u.readFileSync(t4, e3 ? void 0 : "utf8");
        }, s = (t4) => ((t4 = o(t4, true)).buffer || (t4 = new Uint8Array(t4)), t4), a = (t4, e3, n2) => {
          l(), t4 = c.normalize(t4), u.readFile(t4, function(t5, r3) {
            t5 ? n2(t5) : e3(r3.buffer);
          });
        }, 1 < process.argv.length && (f = process.argv[1].replace(/\\/g, "/")), process.argv.slice(2), process.on("uncaughtException", function(t4) {
          if (!(t4 instanceof K)) throw t4;
        }), process.on("unhandledRejection", function(t4) {
          throw t4;
        }), d = (t4, e3) => {
          if (w || 0 < U) throw process.exitCode = t4, e3;
          e3 instanceof K || v("exiting due to exception: " + e3), process.exit(t4);
        }, e2.inspect = function() {
          return "[Emscripten Module object]";
        }) : (h || g) && (g ? m = self.location.href : "undefined" != typeof document && document.currentScript && (m = document.currentScript.src), _scriptDir && (m = _scriptDir), m = 0 !== m.indexOf("blob:") ? m.substr(0, m.replace(/[?#].*/, "").lastIndexOf("/") + 1) : "", o = (t4) => {
          var e3 = new XMLHttpRequest();
          return e3.open("GET", t4, false), e3.send(null), e3.responseText;
        }, g && (s = (t4) => {
          var e3 = new XMLHttpRequest();
          return e3.open("GET", t4, false), e3.responseType = "arraybuffer", e3.send(null), new Uint8Array(e3.response);
        }), a = (t4, e3, n2) => {
          var r3 = new XMLHttpRequest();
          r3.open("GET", t4, true), r3.responseType = "arraybuffer", r3.onload = () => {
            200 == r3.status || 0 == r3.status && r3.response ? e3(r3.response) : n2();
          }, r3.onerror = n2, r3.send(null);
        });
        var y, _ = e2.print || console.log.bind(console), v = e2.printErr || console.warn.bind(console);
        Object.assign(e2, p), p = null, e2.thisProgram && (f = e2.thisProgram), e2.quit && (d = e2.quit), e2.wasmBinary && (y = e2.wasmBinary);
        var w = e2.noExitRuntime || false;
        "object" != typeof WebAssembly && q("no native wasm support detected");
        var x, T, S, O, A, E, I = false, P = "undefined" != typeof TextDecoder ? new TextDecoder("utf8") : void 0;
        function D(t4, e3, n2) {
          var r3 = (e3 >>>= 0) + n2;
          for (n2 = e3; t4[n2] && !(n2 >= r3); ) ++n2;
          if (16 < n2 - e3 && t4.buffer && P) return P.decode(t4.subarray(e3, n2));
          for (r3 = ""; e3 < n2; ) {
            var i3 = t4[e3++];
            if (128 & i3) {
              var o2 = 63 & t4[e3++];
              if (192 == (224 & i3)) r3 += String.fromCharCode((31 & i3) << 6 | o2);
              else {
                var a2 = 63 & t4[e3++];
                65536 > (i3 = 224 == (240 & i3) ? (15 & i3) << 12 | o2 << 6 | a2 : (7 & i3) << 18 | o2 << 12 | a2 << 6 | 63 & t4[e3++]) ? r3 += String.fromCharCode(i3) : (i3 -= 65536, r3 += String.fromCharCode(55296 | i3 >> 10, 56320 | 1023 & i3));
              }
            } else r3 += String.fromCharCode(i3);
          }
          return r3;
        }
        function $(t4, e3) {
          return (t4 >>>= 0) ? D(O, t4, e3) : "";
        }
        function k(t4, e3, n2, r3) {
          if (!(0 < r3)) return 0;
          var i3 = n2 >>>= 0;
          r3 = n2 + r3 - 1;
          for (var o2 = 0; o2 < t4.length; ++o2) {
            var a2 = t4.charCodeAt(o2);
            if (55296 <= a2 && 57343 >= a2 && (a2 = 65536 + ((1023 & a2) << 10) | 1023 & t4.charCodeAt(++o2)), 127 >= a2) {
              if (n2 >= r3) break;
              e3[n2++ >>> 0] = a2;
            } else {
              if (2047 >= a2) {
                if (n2 + 1 >= r3) break;
                e3[n2++ >>> 0] = 192 | a2 >> 6;
              } else {
                if (65535 >= a2) {
                  if (n2 + 2 >= r3) break;
                  e3[n2++ >>> 0] = 224 | a2 >> 12;
                } else {
                  if (n2 + 3 >= r3) break;
                  e3[n2++ >>> 0] = 240 | a2 >> 18, e3[n2++ >>> 0] = 128 | a2 >> 12 & 63;
                }
                e3[n2++ >>> 0] = 128 | a2 >> 6 & 63;
              }
              e3[n2++ >>> 0] = 128 | 63 & a2;
            }
          }
          return e3[n2 >>> 0] = 0, n2 - i3;
        }
        function C(t4) {
          for (var e3 = 0, n2 = 0; n2 < t4.length; ++n2) {
            var r3 = t4.charCodeAt(n2);
            127 >= r3 ? e3++ : 2047 >= r3 ? e3 += 2 : 55296 <= r3 && 57343 >= r3 ? (e3 += 4, ++n2) : e3 += 3;
          }
          return e3;
        }
        function F() {
          var t4 = x.buffer;
          T = t4, e2.HEAP8 = S = new Int8Array(t4), e2.HEAP16 = new Int16Array(t4), e2.HEAP32 = A = new Int32Array(t4), e2.HEAPU8 = O = new Uint8Array(t4), e2.HEAPU16 = new Uint16Array(t4), e2.HEAPU32 = E = new Uint32Array(t4), e2.HEAPF32 = new Float32Array(t4), e2.HEAPF64 = new Float64Array(t4);
        }
        var N, R = [], L = [], M = [], j = [], U = 0;
        function V() {
          var t4 = e2.preRun.shift();
          R.unshift(t4);
        }
        var B, z = 0, H = null;
        function q(t4) {
          throw e2.onAbort && e2.onAbort(t4), v(t4 = "Aborted(" + t4 + ")"), I = true, t4 = new WebAssembly.RuntimeError(t4 + ". Build with -sASSERTIONS for more info."), i2(t4), t4;
        }
        function W() {
          return B.startsWith("data:application/octet-stream;base64,");
        }
        if (B = "ort-wasm.wasm", !W()) {
          var X = B;
          B = e2.locateFile ? e2.locateFile(X, m) : m + X;
        }
        function Y() {
          var t4 = B;
          try {
            if (t4 == B && y) return new Uint8Array(y);
            if (s) return s(t4);
            throw "both async and sync fetching of the wasm failed";
          } catch (t5) {
            q(t5);
          }
        }
        function K(t4) {
          this.name = "ExitStatus", this.message = "Program terminated with exit(" + t4 + ")", this.status = t4;
        }
        function Z(t4) {
          for (; 0 < t4.length; ) t4.shift()(e2);
        }
        var J = [], Q = 0, tt = 0;
        function et(t4) {
          this.Db = t4, this.zb = t4 - 24, this.Ub = function(t5) {
            E[this.zb + 4 >> 2 >>> 0] = t5;
          }, this.Eb = function() {
            return E[this.zb + 4 >> 2 >>> 0];
          }, this.Sb = function(t5) {
            E[this.zb + 8 >> 2 >>> 0] = t5;
          }, this.Wb = function() {
            return E[this.zb + 8 >> 2 >>> 0];
          }, this.Tb = function() {
            A[this.zb >> 2 >>> 0] = 0;
          }, this.Ib = function(t5) {
            S[this.zb + 12 >> 0 >>> 0] = t5 ? 1 : 0;
          }, this.Pb = function() {
            return 0 != S[this.zb + 12 >> 0 >>> 0];
          }, this.Jb = function(t5) {
            S[this.zb + 13 >> 0 >>> 0] = t5 ? 1 : 0;
          }, this.Lb = function() {
            return 0 != S[this.zb + 13 >> 0 >>> 0];
          }, this.Rb = function(t5, e3) {
            this.Fb(0), this.Ub(t5), this.Sb(e3), this.Tb(), this.Ib(false), this.Jb(false);
          }, this.Nb = function() {
            A[this.zb >> 2 >>> 0] += 1;
          }, this.Xb = function() {
            var t5 = A[this.zb >> 2 >>> 0];
            return A[this.zb >> 2 >>> 0] = t5 - 1, 1 === t5;
          }, this.Fb = function(t5) {
            E[this.zb + 16 >> 2 >>> 0] = t5;
          }, this.Ob = function() {
            return E[this.zb + 16 >> 2 >>> 0];
          }, this.Qb = function() {
            if (Et(this.Eb())) return E[this.Db >> 2 >>> 0];
            var t5 = this.Ob();
            return 0 !== t5 ? t5 : this.Db;
          };
        }
        function nt(t4) {
          return _t(new et(t4).zb);
        }
        var rt = [];
        function it(t4) {
          var e3 = rt[t4];
          return e3 || (t4 >= rt.length && (rt.length = t4 + 1), rt[t4] = e3 = N.get(t4)), e3;
        }
        function ot(t4) {
          var e3 = C(t4) + 1, n2 = yt(e3);
          return n2 && k(t4, S, n2, e3), n2;
        }
        var at = {};
        function st() {
          if (!ut) {
            var t4, e3 = { USER: "web_user", LOGNAME: "web_user", PATH: "/", PWD: "/", HOME: "/home/web_user", LANG: ("object" == typeof navigator && navigator.languages && navigator.languages[0] || "C").replace("-", "_") + ".UTF-8", _: f || "./this.program" };
            for (t4 in at) void 0 === at[t4] ? delete e3[t4] : e3[t4] = at[t4];
            var n2 = [];
            for (t4 in e3) n2.push(t4 + "=" + e3[t4]);
            ut = n2;
          }
          return ut;
        }
        var ut, ct = [null, [], []];
        function lt2(t4, e3) {
          var n2 = ct[t4];
          0 === e3 || 10 === e3 ? ((1 === t4 ? _ : v)(D(n2, 0)), n2.length = 0) : n2.push(e3);
        }
        var pt = 0;
        function ft(t4) {
          return 0 == t4 % 4 && (0 != t4 % 100 || 0 == t4 % 400);
        }
        var dt = [31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31], ht = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];
        function gt2(t4, e3, n2, r3) {
          function i3(t5, e4, n3) {
            for (t5 = "number" == typeof t5 ? t5.toString() : t5 || ""; t5.length < e4; ) t5 = n3[0] + t5;
            return t5;
          }
          function o2(t5, e4) {
            return i3(t5, e4, "0");
          }
          function a2(t5, e4) {
            function n3(t6) {
              return 0 > t6 ? -1 : 0 < t6 ? 1 : 0;
            }
            var r4;
            return 0 === (r4 = n3(t5.getFullYear() - e4.getFullYear())) && 0 === (r4 = n3(t5.getMonth() - e4.getMonth())) && (r4 = n3(t5.getDate() - e4.getDate())), r4;
          }
          function s2(t5) {
            switch (t5.getDay()) {
              case 0:
                return new Date(t5.getFullYear() - 1, 11, 29);
              case 1:
                return t5;
              case 2:
                return new Date(t5.getFullYear(), 0, 3);
              case 3:
                return new Date(t5.getFullYear(), 0, 2);
              case 4:
                return new Date(t5.getFullYear(), 0, 1);
              case 5:
                return new Date(t5.getFullYear() - 1, 11, 31);
              case 6:
                return new Date(t5.getFullYear() - 1, 11, 30);
            }
          }
          function u2(t5) {
            var e4 = t5.Bb;
            for (t5 = new Date(new Date(t5.Cb + 1900, 0, 1).getTime()); 0 < e4; ) {
              var n3 = t5.getMonth(), r4 = (ft(t5.getFullYear()) ? dt : ht)[n3];
              if (!(e4 > r4 - t5.getDate())) {
                t5.setDate(t5.getDate() + e4);
                break;
              }
              e4 -= r4 - t5.getDate() + 1, t5.setDate(1), 11 > n3 ? t5.setMonth(n3 + 1) : (t5.setMonth(0), t5.setFullYear(t5.getFullYear() + 1));
            }
            return n3 = new Date(t5.getFullYear() + 1, 0, 4), e4 = s2(new Date(t5.getFullYear(), 0, 4)), n3 = s2(n3), 0 >= a2(e4, t5) ? 0 >= a2(n3, t5) ? t5.getFullYear() + 1 : t5.getFullYear() : t5.getFullYear() - 1;
          }
          var c2 = A[r3 + 40 >> 2 >>> 0];
          for (var l2 in r3 = { $b: A[r3 >> 2 >>> 0], Zb: A[r3 + 4 >> 2 >>> 0], Gb: A[r3 + 8 >> 2 >>> 0], Kb: A[r3 + 12 >> 2 >>> 0], Hb: A[r3 + 16 >> 2 >>> 0], Cb: A[r3 + 20 >> 2 >>> 0], Ab: A[r3 + 24 >> 2 >>> 0], Bb: A[r3 + 28 >> 2 >>> 0], bc: A[r3 + 32 >> 2 >>> 0], Yb: A[r3 + 36 >> 2 >>> 0], ac: c2 ? $(c2) : "" }, n2 = $(n2), c2 = { "%c": "%a %b %d %H:%M:%S %Y", "%D": "%m/%d/%y", "%F": "%Y-%m-%d", "%h": "%b", "%r": "%I:%M:%S %p", "%R": "%H:%M", "%T": "%H:%M:%S", "%x": "%m/%d/%y", "%X": "%H:%M:%S", "%Ec": "%c", "%EC": "%C", "%Ex": "%m/%d/%y", "%EX": "%H:%M:%S", "%Ey": "%y", "%EY": "%Y", "%Od": "%d", "%Oe": "%e", "%OH": "%H", "%OI": "%I", "%Om": "%m", "%OM": "%M", "%OS": "%S", "%Ou": "%u", "%OU": "%U", "%OV": "%V", "%Ow": "%w", "%OW": "%W", "%Oy": "%y" }) n2 = n2.replace(new RegExp(l2, "g"), c2[l2]);
          var p2 = "Sunday Monday Tuesday Wednesday Thursday Friday Saturday".split(" "), f2 = "January February March April May June July August September October November December".split(" ");
          for (l2 in c2 = { "%a": function(t5) {
            return p2[t5.Ab].substring(0, 3);
          }, "%A": function(t5) {
            return p2[t5.Ab];
          }, "%b": function(t5) {
            return f2[t5.Hb].substring(0, 3);
          }, "%B": function(t5) {
            return f2[t5.Hb];
          }, "%C": function(t5) {
            return o2((t5.Cb + 1900) / 100 | 0, 2);
          }, "%d": function(t5) {
            return o2(t5.Kb, 2);
          }, "%e": function(t5) {
            return i3(t5.Kb, 2, " ");
          }, "%g": function(t5) {
            return u2(t5).toString().substring(2);
          }, "%G": function(t5) {
            return u2(t5);
          }, "%H": function(t5) {
            return o2(t5.Gb, 2);
          }, "%I": function(t5) {
            return 0 == (t5 = t5.Gb) ? t5 = 12 : 12 < t5 && (t5 -= 12), o2(t5, 2);
          }, "%j": function(t5) {
            for (var e4 = 0, n3 = 0; n3 <= t5.Hb - 1; e4 += (ft(t5.Cb + 1900) ? dt : ht)[n3++]) ;
            return o2(t5.Kb + e4, 3);
          }, "%m": function(t5) {
            return o2(t5.Hb + 1, 2);
          }, "%M": function(t5) {
            return o2(t5.Zb, 2);
          }, "%n": function() {
            return "\n";
          }, "%p": function(t5) {
            return 0 <= t5.Gb && 12 > t5.Gb ? "AM" : "PM";
          }, "%S": function(t5) {
            return o2(t5.$b, 2);
          }, "%t": function() {
            return "	";
          }, "%u": function(t5) {
            return t5.Ab || 7;
          }, "%U": function(t5) {
            return o2(Math.floor((t5.Bb + 7 - t5.Ab) / 7), 2);
          }, "%V": function(t5) {
            var e4 = Math.floor((t5.Bb + 7 - (t5.Ab + 6) % 7) / 7);
            if (2 >= (t5.Ab + 371 - t5.Bb - 2) % 7 && e4++, e4) 53 == e4 && (4 == (n3 = (t5.Ab + 371 - t5.Bb) % 7) || 3 == n3 && ft(t5.Cb) || (e4 = 1));
            else {
              e4 = 52;
              var n3 = (t5.Ab + 7 - t5.Bb - 1) % 7;
              (4 == n3 || 5 == n3 && ft(t5.Cb % 400 - 1)) && e4++;
            }
            return o2(e4, 2);
          }, "%w": function(t5) {
            return t5.Ab;
          }, "%W": function(t5) {
            return o2(Math.floor((t5.Bb + 7 - (t5.Ab + 6) % 7) / 7), 2);
          }, "%y": function(t5) {
            return (t5.Cb + 1900).toString().substring(2);
          }, "%Y": function(t5) {
            return t5.Cb + 1900;
          }, "%z": function(t5) {
            var e4 = 0 <= (t5 = t5.Yb);
            return t5 = Math.abs(t5) / 60, (e4 ? "+" : "-") + String("0000" + (t5 / 60 * 100 + t5 % 60)).slice(-4);
          }, "%Z": function(t5) {
            return t5.ac;
          }, "%%": function() {
            return "%";
          } }, n2 = n2.replace(/%%/g, "\0\0"), c2) n2.includes(l2) && (n2 = n2.replace(new RegExp(l2, "g"), c2[l2](r3)));
          return l2 = function(t5) {
            var e4 = Array(C(t5) + 1);
            return k(t5, e4, 0, e4.length), e4;
          }(n2 = n2.replace(/\0\0/g, "%")), l2.length > e3 ? 0 : (S.set(l2, t4 >>> 0), l2.length - 1);
        }
        var bt = { a: function(t4) {
          return yt(t4 + 24) + 24;
        }, m: function(t4) {
          return (t4 = new et(t4)).Pb() || (t4.Ib(true), Q--), t4.Jb(false), J.push(t4), t4.Nb(), t4.Qb();
        }, ia: function(t4) {
          throw v("Unexpected exception thrown, this is not properly supported - aborting"), I = true, t4;
        }, w: function() {
          xt(0);
          var t4 = J.pop();
          if (t4.Xb() && !t4.Lb()) {
            var e3 = t4.Wb();
            e3 && it(e3)(t4.Db), nt(t4.Db);
          }
          tt = 0;
        }, d: function() {
          var t4 = tt;
          if (!t4) return pt = 0;
          var e3 = new et(t4);
          e3.Fb(t4);
          var n2 = e3.Eb();
          if (!n2) return pt = 0, t4;
          for (var r3 = Array.prototype.slice.call(arguments), i3 = 0; i3 < r3.length; i3++) {
            var o2 = r3[i3];
            if (0 === o2 || o2 === n2) break;
            if (At(o2, n2, e3.zb + 16)) return pt = o2, t4;
          }
          return pt = n2, t4;
        }, k: function() {
          var t4 = tt;
          if (!t4) return pt = 0;
          var e3 = new et(t4);
          e3.Fb(t4);
          var n2 = e3.Eb();
          if (!n2) return pt = 0, t4;
          for (var r3 = Array.prototype.slice.call(arguments), i3 = 0; i3 < r3.length; i3++) {
            var o2 = r3[i3];
            if (0 === o2 || o2 === n2) break;
            if (At(o2, n2, e3.zb + 16)) return pt = o2, t4;
          }
          return pt = n2, t4;
        }, g: function() {
          var t4 = tt;
          if (!t4) return pt = 0;
          var e3 = new et(t4);
          e3.Fb(t4);
          var n2 = e3.Eb();
          if (!n2) return pt = 0, t4;
          for (var r3 = Array.prototype.slice.call(arguments), i3 = 0; i3 < r3.length; i3++) {
            var o2 = r3[i3];
            if (0 === o2 || o2 === n2) break;
            if (At(o2, n2, e3.zb + 16)) return pt = o2, t4;
          }
          return pt = n2, t4;
        }, s: nt, L: function() {
          var t4 = J.pop();
          t4 || q("no exception to throw");
          var e3 = t4.Db;
          throw t4.Lb() || (J.push(t4), t4.Jb(true), t4.Ib(false), Q++), tt = e3, e3;
        }, b: function(t4, e3, n2) {
          throw new et(t4).Rb(e3, n2), tt = t4, Q++, t4;
        }, la: function() {
          return Q;
        }, i: function(t4) {
          throw tt || (tt = t4), t4;
        }, H: function() {
          return 0;
        }, Ba: function() {
        }, pa: function() {
        }, ra: function() {
        }, ka: function() {
          return 0;
        }, za: function() {
        }, ua: function() {
        }, ya: function() {
        }, R: function() {
        }, qa: function() {
        }, na: function() {
        }, Aa: function() {
        }, oa: function() {
        }, Ha: function() {
        }, Ja: function() {
          q("To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking");
        }, Ia: function() {
          q("To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking");
        }, S: function() {
          return Date.now();
        }, Ca: function() {
          return true;
        }, Da: function(t4, e3) {
          t4 = new Date(1e3 * (E[t4 >>> 2] + 4294967296 * A[t4 + 4 >>> 2])), A[e3 >> 2 >>> 0] = t4.getUTCSeconds(), A[e3 + 4 >> 2 >>> 0] = t4.getUTCMinutes(), A[e3 + 8 >> 2 >>> 0] = t4.getUTCHours(), A[e3 + 12 >> 2 >>> 0] = t4.getUTCDate(), A[e3 + 16 >> 2 >>> 0] = t4.getUTCMonth(), A[e3 + 20 >> 2 >>> 0] = t4.getUTCFullYear() - 1900, A[e3 + 24 >> 2 >>> 0] = t4.getUTCDay(), A[e3 + 28 >> 2 >>> 0] = (t4.getTime() - Date.UTC(t4.getUTCFullYear(), 0, 1, 0, 0, 0, 0)) / 864e5 | 0;
        }, Ea: function(t4, e3) {
          t4 = new Date(1e3 * (E[t4 >>> 2] + 4294967296 * A[t4 + 4 >>> 2])), A[e3 >> 2 >>> 0] = t4.getSeconds(), A[e3 + 4 >> 2 >>> 0] = t4.getMinutes(), A[e3 + 8 >> 2 >>> 0] = t4.getHours(), A[e3 + 12 >> 2 >>> 0] = t4.getDate(), A[e3 + 16 >> 2 >>> 0] = t4.getMonth(), A[e3 + 20 >> 2 >>> 0] = t4.getFullYear() - 1900, A[e3 + 24 >> 2 >>> 0] = t4.getDay();
          var n2 = new Date(t4.getFullYear(), 0, 1);
          A[e3 + 28 >> 2 >>> 0] = (t4.getTime() - n2.getTime()) / 864e5 | 0, A[e3 + 36 >> 2 >>> 0] = -60 * t4.getTimezoneOffset();
          var r3 = new Date(t4.getFullYear(), 6, 1).getTimezoneOffset();
          n2 = n2.getTimezoneOffset(), A[e3 + 32 >> 2 >>> 0] = 0 | (r3 != n2 && t4.getTimezoneOffset() == Math.min(n2, r3));
        }, Fa: function(t4) {
          var e3 = new Date(A[t4 + 20 >> 2 >>> 0] + 1900, A[t4 + 16 >> 2 >>> 0], A[t4 + 12 >> 2 >>> 0], A[t4 + 8 >> 2 >>> 0], A[t4 + 4 >> 2 >>> 0], A[t4 >> 2 >>> 0], 0), n2 = A[t4 + 32 >> 2 >>> 0], r3 = e3.getTimezoneOffset(), i3 = new Date(e3.getFullYear(), 0, 1), o2 = new Date(e3.getFullYear(), 6, 1).getTimezoneOffset(), a2 = i3.getTimezoneOffset(), s2 = Math.min(a2, o2);
          return 0 > n2 ? A[t4 + 32 >> 2 >>> 0] = Number(o2 != a2 && s2 == r3) : 0 < n2 != (s2 == r3) && (o2 = Math.max(a2, o2), e3.setTime(e3.getTime() + 6e4 * ((0 < n2 ? s2 : o2) - r3))), A[t4 + 24 >> 2 >>> 0] = e3.getDay(), A[t4 + 28 >> 2 >>> 0] = (e3.getTime() - i3.getTime()) / 864e5 | 0, A[t4 >> 2 >>> 0] = e3.getSeconds(), A[t4 + 4 >> 2 >>> 0] = e3.getMinutes(), A[t4 + 8 >> 2 >>> 0] = e3.getHours(), A[t4 + 12 >> 2 >>> 0] = e3.getDate(), A[t4 + 16 >> 2 >>> 0] = e3.getMonth(), e3.getTime() / 1e3 | 0;
        }, sa: function() {
          return -52;
        }, ta: function() {
        }, Ga: function t4(e3, n2, r3) {
          t4.Vb || (t4.Vb = true, function(t5, e4, n3) {
            function r4(t6) {
              return (t6 = t6.toTimeString().match(/\(([A-Za-z ]+)\)$/)) ? t6[1] : "GMT";
            }
            var i3 = (/* @__PURE__ */ new Date()).getFullYear(), o2 = new Date(i3, 0, 1), a2 = new Date(i3, 6, 1);
            i3 = o2.getTimezoneOffset();
            var s2 = a2.getTimezoneOffset();
            A[t5 >> 2 >>> 0] = 60 * Math.max(i3, s2), A[e4 >> 2 >>> 0] = Number(i3 != s2), t5 = r4(o2), e4 = r4(a2), t5 = ot(t5), e4 = ot(e4), s2 < i3 ? (E[n3 >> 2 >>> 0] = t5, E[n3 + 4 >> 2 >>> 0] = e4) : (E[n3 >> 2 >>> 0] = e4, E[n3 + 4 >> 2 >>> 0] = t5);
          }(e3, n2, r3));
        }, B: function() {
          q("");
        }, ma: function() {
          return 4294901760;
        }, I: b ? () => {
          var t4 = process.hrtime();
          return 1e3 * t4[0] + t4[1] / 1e6;
        } : () => performance.now(), xa: function(t4, e3, n2) {
          O.copyWithin(t4 >>> 0, e3 >>> 0, e3 + n2 >>> 0);
        }, G: function(t4) {
          var e3 = O.length;
          if (4294901760 < (t4 >>>= 0)) return false;
          for (var n2 = 1; 4 >= n2; n2 *= 2) {
            var r3 = e3 * (1 + 0.2 / n2);
            r3 = Math.min(r3, t4 + 100663296);
            var i3 = Math;
            r3 = Math.max(t4, r3), i3 = i3.min.call(i3, 4294901760, r3 + (65536 - r3 % 65536) % 65536);
            t: {
              try {
                x.grow(i3 - T.byteLength + 65535 >>> 16), F();
                var o2 = 1;
                break t;
              } catch (t5) {
              }
              o2 = void 0;
            }
            if (o2) return true;
          }
          return false;
        }, va: function(t4, e3) {
          var n2 = 0;
          return st().forEach(function(r3, i3) {
            var o2 = e3 + n2;
            for (i3 = E[t4 + 4 * i3 >> 2 >>> 0] = o2, o2 = 0; o2 < r3.length; ++o2) S[i3++ >> 0 >>> 0] = r3.charCodeAt(o2);
            S[i3 >> 0 >>> 0] = 0, n2 += r3.length + 1;
          }), 0;
        }, wa: function(t4, e3) {
          var n2 = st();
          E[t4 >> 2 >>> 0] = n2.length;
          var r3 = 0;
          return n2.forEach(function(t5) {
            r3 += t5.length + 1;
          }), E[e3 >> 2 >>> 0] = r3, 0;
        }, ba: function(t4) {
          w || 0 < U || (wt(), Z(M), vt(0), ct[1].length && lt2(1, 10), ct[2].length && lt2(2, 10)), w || 0 < U || (e2.onExit && e2.onExit(t4), I = true), d(t4, new K(t4));
        }, E: function() {
          return 52;
        }, Q: function() {
          return 52;
        }, ca: function() {
          return 70;
        }, P: function(t4, e3, n2, r3) {
          for (var i3 = 0, o2 = 0; o2 < n2; o2++) {
            var a2 = E[e3 >> 2 >>> 0], s2 = E[e3 + 4 >> 2 >>> 0];
            e3 += 8;
            for (var u2 = 0; u2 < s2; u2++) lt2(t4, O[a2 + u2 >>> 0]);
            i3 += s2;
          }
          return E[r3 >> 2 >>> 0] = i3, 0;
        }, c: function() {
          return pt;
        }, ja: function t4(e3, r3) {
          t4.Mb || (t4.Mb = function() {
            if ("object" == typeof crypto && "function" == typeof crypto.getRandomValues) {
              var t5 = new Uint8Array(1);
              return () => (crypto.getRandomValues(t5), t5[0]);
            }
            if (b) try {
              var e4 = n(6113);
              return () => e4.randomBytes(1)[0];
            } catch (t6) {
            }
            return () => q("randomDevice");
          }());
          for (var i3 = 0; i3 < r3; i3++) S[e3 + i3 >> 0 >>> 0] = t4.Mb();
          return 0;
        }, ea: function(t4, e3, n2) {
          var r3 = Tt();
          try {
            return it(t4)(e3, n2);
          } catch (t5) {
            if (St(r3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, fa: function(t4, e3, n2) {
          var r3 = Tt();
          try {
            return it(t4)(e3, n2);
          } catch (t5) {
            if (St(r3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, J: function(t4) {
          var e3 = Tt();
          try {
            return it(t4)();
          } catch (t5) {
            if (St(e3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, e: function(t4, e3) {
          var n2 = Tt();
          try {
            return it(t4)(e3);
          } catch (t5) {
            if (St(n2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, N: function(t4, e3, n2) {
          var r3 = Tt();
          try {
            return it(t4)(e3, n2);
          } catch (t5) {
            if (St(r3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, O: function(t4, e3, n2) {
          var r3 = Tt();
          try {
            return it(t4)(e3, n2);
          } catch (t5) {
            if (St(r3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, j: function(t4, e3, n2) {
          var r3 = Tt();
          try {
            return it(t4)(e3, n2);
          } catch (t5) {
            if (St(r3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, o: function(t4, e3, n2, r3) {
          var i3 = Tt();
          try {
            return it(t4)(e3, n2, r3);
          } catch (t5) {
            if (St(i3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, p: function(t4, e3, n2, r3, i3) {
          var o2 = Tt();
          try {
            return it(t4)(e3, n2, r3, i3);
          } catch (t5) {
            if (St(o2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, M: function(t4, e3, n2, r3, i3, o2) {
          var a2 = Tt();
          try {
            return it(t4)(e3, n2, r3, i3, o2);
          } catch (t5) {
            if (St(a2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, r: function(t4, e3, n2, r3, i3, o2) {
          var a2 = Tt();
          try {
            return it(t4)(e3, n2, r3, i3, o2);
          } catch (t5) {
            if (St(a2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, v: function(t4, e3, n2, r3, i3, o2, a2) {
          var s2 = Tt();
          try {
            return it(t4)(e3, n2, r3, i3, o2, a2);
          } catch (t5) {
            if (St(s2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, K: function(t4, e3, n2, r3, i3, o2, a2, s2) {
          var u2 = Tt();
          try {
            return it(t4)(e3, n2, r3, i3, o2, a2, s2);
          } catch (t5) {
            if (St(u2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, D: function(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2) {
          var f2 = Tt();
          try {
            return it(t4)(e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2);
          } catch (t5) {
            if (St(f2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, X: function(t4, e3, n2, r3, i3, o2, a2, s2) {
          var u2 = Tt();
          try {
            return Rt(t4, e3, n2, r3, i3, o2, a2, s2);
          } catch (t5) {
            if (St(u2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, V: function(t4, e3, n2, r3, i3, o2, a2) {
          var s2 = Tt();
          try {
            return Pt(t4, e3, n2, r3, i3, o2, a2);
          } catch (t5) {
            if (St(s2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, U: function(t4, e3, n2, r3, i3) {
          var o2 = Tt();
          try {
            return Lt(t4, e3, n2, r3, i3);
          } catch (t5) {
            if (St(o2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, Z: function(t4, e3, n2, r3) {
          var i3 = Tt();
          try {
            return Ft(t4, e3, n2, r3);
          } catch (t5) {
            if (St(i3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, W: function(t4) {
          var e3 = Tt();
          try {
            return It(t4);
          } catch (t5) {
            if (St(e3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, Y: function(t4, e3) {
          var n2 = Tt();
          try {
            return Nt(t4, e3);
          } catch (t5) {
            if (St(n2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, T: function(t4, e3, n2) {
          var r3 = Tt();
          try {
            return Dt(t4, e3, n2);
          } catch (t5) {
            if (St(r3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, f: function(t4) {
          var e3 = Tt();
          try {
            it(t4)();
          } catch (t5) {
            if (St(e3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, q: function(t4, e3) {
          var n2 = Tt();
          try {
            it(t4)(e3);
          } catch (t5) {
            if (St(n2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, h: function(t4, e3, n2) {
          var r3 = Tt();
          try {
            it(t4)(e3, n2);
          } catch (t5) {
            if (St(r3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, da: function(t4, e3, n2, r3) {
          var i3 = Tt();
          try {
            it(t4)(e3, n2, r3);
          } catch (t5) {
            if (St(i3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, l: function(t4, e3, n2, r3) {
          var i3 = Tt();
          try {
            it(t4)(e3, n2, r3);
          } catch (t5) {
            if (St(i3), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, t: function(t4, e3, n2, r3, i3) {
          var o2 = Tt();
          try {
            it(t4)(e3, n2, r3, i3);
          } catch (t5) {
            if (St(o2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, u: function(t4, e3, n2, r3, i3, o2) {
          var a2 = Tt();
          try {
            it(t4)(e3, n2, r3, i3, o2);
          } catch (t5) {
            if (St(a2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, x: function(t4, e3, n2, r3, i3, o2, a2) {
          var s2 = Tt();
          try {
            it(t4)(e3, n2, r3, i3, o2, a2);
          } catch (t5) {
            if (St(s2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, z: function(t4, e3, n2, r3, i3, o2, a2, s2) {
          var u2 = Tt();
          try {
            it(t4)(e3, n2, r3, i3, o2, a2, s2);
          } catch (t5) {
            if (St(u2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, ga: function(t4, e3, n2, r3, i3, o2, a2, s2, u2) {
          var c2 = Tt();
          try {
            it(t4)(e3, n2, r3, i3, o2, a2, s2, u2);
          } catch (t5) {
            if (St(c2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, A: function(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2) {
          var p2 = Tt();
          try {
            it(t4)(e3, n2, r3, i3, o2, a2, s2, u2, c2, l2);
          } catch (t5) {
            if (St(p2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, C: function(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2, f2, d2, h2, g2) {
          var b2 = Tt();
          try {
            it(t4)(e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2, f2, d2, h2, g2);
          } catch (t5) {
            if (St(b2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, aa: function(t4, e3, n2, r3, i3, o2, a2, s2) {
          var u2 = Tt();
          try {
            $t(t4, e3, n2, r3, i3, o2, a2, s2);
          } catch (t5) {
            if (St(u2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, _: function(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2) {
          var f2 = Tt();
          try {
            Ct(t4, e3, n2, r3, i3, o2, a2, s2, u2, c2, l2, p2);
          } catch (t5) {
            if (St(f2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, $: function(t4, e3, n2, r3, i3, o2) {
          var a2 = Tt();
          try {
            kt(t4, e3, n2, r3, i3, o2);
          } catch (t5) {
            if (St(a2), t5 !== t5 + 0) throw t5;
            xt(1, 0);
          }
        }, n: function(t4) {
          return t4;
        }, F: function(t4) {
          pt = t4;
        }, ha: gt2, y: function(t4, e3, n2, r3) {
          return gt2(t4, e3, n2, r3);
        } };
        !function() {
          function t4(t5) {
            e2.asm = t5.exports, x = e2.asm.Ka, F(), N = e2.asm.ib, L.unshift(e2.asm.La), z--, e2.monitorRunDependencies && e2.monitorRunDependencies(z), 0 == z && (H && (t5 = H, H = null, t5()));
          }
          function n2(e3) {
            t4(e3.instance);
          }
          function r3(t5) {
            return function() {
              if (!y && (h || g)) {
                if ("function" == typeof fetch && !B.startsWith("file://")) return fetch(B, { credentials: "same-origin" }).then(function(t6) {
                  if (!t6.ok) throw "failed to load wasm binary file at '" + B + "'";
                  return t6.arrayBuffer();
                }).catch(function() {
                  return Y();
                });
                if (a) return new Promise(function(t6, e3) {
                  a(B, function(e4) {
                    t6(new Uint8Array(e4));
                  }, e3);
                });
              }
              return Promise.resolve().then(function() {
                return Y();
              });
            }().then(function(t6) {
              return WebAssembly.instantiate(t6, o2);
            }).then(function(t6) {
              return t6;
            }).then(t5, function(t6) {
              v("failed to asynchronously prepare wasm: " + t6), q(t6);
            });
          }
          var o2 = { a: bt };
          if (z++, e2.monitorRunDependencies && e2.monitorRunDependencies(z), e2.instantiateWasm) try {
            return e2.instantiateWasm(o2, t4);
          } catch (t5) {
            return v("Module.instantiateWasm callback failed with error: " + t5), false;
          }
          (y || "function" != typeof WebAssembly.instantiateStreaming || W() || B.startsWith("file://") || b || "function" != typeof fetch ? r3(n2) : fetch(B, { credentials: "same-origin" }).then(function(t5) {
            return WebAssembly.instantiateStreaming(t5, o2).then(n2, function(t6) {
              return v("wasm streaming compile failed: " + t6), v("falling back to ArrayBuffer instantiation"), r3(n2);
            });
          })).catch(i2);
        }(), e2.___wasm_call_ctors = function() {
          return (e2.___wasm_call_ctors = e2.asm.La).apply(null, arguments);
        }, e2._OrtInit = function() {
          return (e2._OrtInit = e2.asm.Ma).apply(null, arguments);
        }, e2._OrtCreateSessionOptions = function() {
          return (e2._OrtCreateSessionOptions = e2.asm.Na).apply(null, arguments);
        }, e2._OrtAppendExecutionProvider = function() {
          return (e2._OrtAppendExecutionProvider = e2.asm.Oa).apply(null, arguments);
        }, e2._OrtAddSessionConfigEntry = function() {
          return (e2._OrtAddSessionConfigEntry = e2.asm.Pa).apply(null, arguments);
        }, e2._OrtReleaseSessionOptions = function() {
          return (e2._OrtReleaseSessionOptions = e2.asm.Qa).apply(null, arguments);
        }, e2._OrtCreateSession = function() {
          return (e2._OrtCreateSession = e2.asm.Ra).apply(null, arguments);
        }, e2._OrtReleaseSession = function() {
          return (e2._OrtReleaseSession = e2.asm.Sa).apply(null, arguments);
        }, e2._OrtGetInputCount = function() {
          return (e2._OrtGetInputCount = e2.asm.Ta).apply(null, arguments);
        }, e2._OrtGetOutputCount = function() {
          return (e2._OrtGetOutputCount = e2.asm.Ua).apply(null, arguments);
        }, e2._OrtGetInputName = function() {
          return (e2._OrtGetInputName = e2.asm.Va).apply(null, arguments);
        }, e2._OrtGetOutputName = function() {
          return (e2._OrtGetOutputName = e2.asm.Wa).apply(null, arguments);
        }, e2._OrtFree = function() {
          return (e2._OrtFree = e2.asm.Xa).apply(null, arguments);
        }, e2._OrtCreateTensor = function() {
          return (e2._OrtCreateTensor = e2.asm.Ya).apply(null, arguments);
        }, e2._OrtGetTensorData = function() {
          return (e2._OrtGetTensorData = e2.asm.Za).apply(null, arguments);
        }, e2._OrtReleaseTensor = function() {
          return (e2._OrtReleaseTensor = e2.asm._a).apply(null, arguments);
        }, e2._OrtCreateRunOptions = function() {
          return (e2._OrtCreateRunOptions = e2.asm.$a).apply(null, arguments);
        }, e2._OrtAddRunConfigEntry = function() {
          return (e2._OrtAddRunConfigEntry = e2.asm.ab).apply(null, arguments);
        }, e2._OrtReleaseRunOptions = function() {
          return (e2._OrtReleaseRunOptions = e2.asm.bb).apply(null, arguments);
        }, e2._OrtRun = function() {
          return (e2._OrtRun = e2.asm.cb).apply(null, arguments);
        }, e2._OrtEndProfiling = function() {
          return (e2._OrtEndProfiling = e2.asm.db).apply(null, arguments);
        };
        var mt, yt = e2._malloc = function() {
          return (yt = e2._malloc = e2.asm.eb).apply(null, arguments);
        }, _t = e2._free = function() {
          return (_t = e2._free = e2.asm.fb).apply(null, arguments);
        }, vt = e2._fflush = function() {
          return (vt = e2._fflush = e2.asm.gb).apply(null, arguments);
        }, wt = e2.___funcs_on_exit = function() {
          return (wt = e2.___funcs_on_exit = e2.asm.hb).apply(null, arguments);
        }, xt = e2._setThrew = function() {
          return (xt = e2._setThrew = e2.asm.jb).apply(null, arguments);
        }, Tt = e2.stackSave = function() {
          return (Tt = e2.stackSave = e2.asm.kb).apply(null, arguments);
        }, St = e2.stackRestore = function() {
          return (St = e2.stackRestore = e2.asm.lb).apply(null, arguments);
        }, Ot = e2.stackAlloc = function() {
          return (Ot = e2.stackAlloc = e2.asm.mb).apply(null, arguments);
        }, At = e2.___cxa_can_catch = function() {
          return (At = e2.___cxa_can_catch = e2.asm.nb).apply(null, arguments);
        }, Et = e2.___cxa_is_pointer_type = function() {
          return (Et = e2.___cxa_is_pointer_type = e2.asm.ob).apply(null, arguments);
        }, It = e2.dynCall_j = function() {
          return (It = e2.dynCall_j = e2.asm.pb).apply(null, arguments);
        }, Pt = e2.dynCall_iiiiij = function() {
          return (Pt = e2.dynCall_iiiiij = e2.asm.qb).apply(null, arguments);
        }, Dt = e2.dynCall_jii = function() {
          return (Dt = e2.dynCall_jii = e2.asm.rb).apply(null, arguments);
        }, $t = e2.dynCall_viiiiij = function() {
          return ($t = e2.dynCall_viiiiij = e2.asm.sb).apply(null, arguments);
        }, kt = e2.dynCall_vjji = function() {
          return (kt = e2.dynCall_vjji = e2.asm.tb).apply(null, arguments);
        }, Ct = e2.dynCall_viiijjjii = function() {
          return (Ct = e2.dynCall_viiijjjii = e2.asm.ub).apply(null, arguments);
        }, Ft = e2.dynCall_iij = function() {
          return (Ft = e2.dynCall_iij = e2.asm.vb).apply(null, arguments);
        }, Nt = e2.dynCall_ji = function() {
          return (Nt = e2.dynCall_ji = e2.asm.wb).apply(null, arguments);
        }, Rt = e2.dynCall_iiiiiij = function() {
          return (Rt = e2.dynCall_iiiiiij = e2.asm.xb).apply(null, arguments);
        }, Lt = e2.dynCall_iiij = function() {
          return (Lt = e2.dynCall_iiij = e2.asm.yb).apply(null, arguments);
        };
        function Mt() {
          function t4() {
            if (!mt && (mt = true, e2.calledRun = true, !I)) {
              if (Z(L), r2(e2), e2.onRuntimeInitialized && e2.onRuntimeInitialized(), e2.postRun) for ("function" == typeof e2.postRun && (e2.postRun = [e2.postRun]); e2.postRun.length; ) {
                var t5 = e2.postRun.shift();
                j.unshift(t5);
              }
              Z(j);
            }
          }
          if (!(0 < z)) {
            if (e2.preRun) for ("function" == typeof e2.preRun && (e2.preRun = [e2.preRun]); e2.preRun.length; ) V();
            Z(R), 0 < z || (e2.setStatus ? (e2.setStatus("Running..."), setTimeout(function() {
              setTimeout(function() {
                e2.setStatus("");
              }, 1), t4();
            }, 1)) : t4());
          }
        }
        if (e2.UTF8ToString = $, e2.stringToUTF8 = function(t4, e3, n2) {
          return k(t4, O, e3, n2);
        }, e2.lengthBytesUTF8 = C, e2.stackSave = Tt, e2.stackRestore = St, e2.stackAlloc = Ot, H = function t4() {
          mt || Mt(), mt || (H = t4);
        }, e2.preInit) for ("function" == typeof e2.preInit && (e2.preInit = [e2.preInit]); 0 < e2.preInit.length; ) e2.preInit.pop()();
        return Mt(), t3.ready;
      });
      t2.exports = r;
    }, 4537: (t2) => {
      t2.exports = function(t3, e) {
        for (var n = new Array(arguments.length - 1), r = 0, i2 = 2, o = true; i2 < arguments.length; ) n[r++] = arguments[i2++];
        return new Promise(function(i3, a) {
          n[r] = function(t4) {
            if (o) if (o = false, t4) a(t4);
            else {
              for (var e2 = new Array(arguments.length - 1), n2 = 0; n2 < e2.length; ) e2[n2++] = arguments[n2];
              i3.apply(null, e2);
            }
          };
          try {
            t3.apply(e || null, n);
          } catch (t4) {
            o && (o = false, a(t4));
          }
        });
      };
    }, 7419: (t2, e) => {
      var n = e;
      n.length = function(t3) {
        var e2 = t3.length;
        if (!e2) return 0;
        for (var n2 = 0; --e2 % 4 > 1 && "=" === t3.charAt(e2); ) ++n2;
        return Math.ceil(3 * t3.length) / 4 - n2;
      };
      for (var r = new Array(64), i2 = new Array(123), o = 0; o < 64; ) i2[r[o] = o < 26 ? o + 65 : o < 52 ? o + 71 : o < 62 ? o - 4 : o - 59 | 43] = o++;
      n.encode = function(t3, e2, n2) {
        for (var i3, o2 = null, a2 = [], s = 0, u = 0; e2 < n2; ) {
          var c = t3[e2++];
          switch (u) {
            case 0:
              a2[s++] = r[c >> 2], i3 = (3 & c) << 4, u = 1;
              break;
            case 1:
              a2[s++] = r[i3 | c >> 4], i3 = (15 & c) << 2, u = 2;
              break;
            case 2:
              a2[s++] = r[i3 | c >> 6], a2[s++] = r[63 & c], u = 0;
          }
          s > 8191 && ((o2 || (o2 = [])).push(String.fromCharCode.apply(String, a2)), s = 0);
        }
        return u && (a2[s++] = r[i3], a2[s++] = 61, 1 === u && (a2[s++] = 61)), o2 ? (s && o2.push(String.fromCharCode.apply(String, a2.slice(0, s))), o2.join("")) : String.fromCharCode.apply(String, a2.slice(0, s));
      };
      var a = "invalid encoding";
      n.decode = function(t3, e2, n2) {
        for (var r2, o2 = n2, s = 0, u = 0; u < t3.length; ) {
          var c = t3.charCodeAt(u++);
          if (61 === c && s > 1) break;
          if (void 0 === (c = i2[c])) throw Error(a);
          switch (s) {
            case 0:
              r2 = c, s = 1;
              break;
            case 1:
              e2[n2++] = r2 << 2 | (48 & c) >> 4, r2 = c, s = 2;
              break;
            case 2:
              e2[n2++] = (15 & r2) << 4 | (60 & c) >> 2, r2 = c, s = 3;
              break;
            case 3:
              e2[n2++] = (3 & r2) << 6 | c, s = 0;
          }
        }
        if (1 === s) throw Error(a);
        return n2 - o2;
      }, n.test = function(t3) {
        return /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/.test(t3);
      };
    }, 9211: (t2) => {
      function e() {
        this._listeners = {};
      }
      t2.exports = e, e.prototype.on = function(t3, e2, n) {
        return (this._listeners[t3] || (this._listeners[t3] = [])).push({ fn: e2, ctx: n || this }), this;
      }, e.prototype.off = function(t3, e2) {
        if (void 0 === t3) this._listeners = {};
        else if (void 0 === e2) this._listeners[t3] = [];
        else for (var n = this._listeners[t3], r = 0; r < n.length; ) n[r].fn === e2 ? n.splice(r, 1) : ++r;
        return this;
      }, e.prototype.emit = function(t3) {
        var e2 = this._listeners[t3];
        if (e2) {
          for (var n = [], r = 1; r < arguments.length; ) n.push(arguments[r++]);
          for (r = 0; r < e2.length; ) e2[r].fn.apply(e2[r++].ctx, n);
        }
        return this;
      };
    }, 945: (t2) => {
      function e(t3) {
        return "undefined" != typeof Float32Array ? function() {
          var e2 = new Float32Array([-0]), n2 = new Uint8Array(e2.buffer), r2 = 128 === n2[3];
          function i3(t4, r3, i4) {
            e2[0] = t4, r3[i4] = n2[0], r3[i4 + 1] = n2[1], r3[i4 + 2] = n2[2], r3[i4 + 3] = n2[3];
          }
          function o2(t4, r3, i4) {
            e2[0] = t4, r3[i4] = n2[3], r3[i4 + 1] = n2[2], r3[i4 + 2] = n2[1], r3[i4 + 3] = n2[0];
          }
          function a(t4, r3) {
            return n2[0] = t4[r3], n2[1] = t4[r3 + 1], n2[2] = t4[r3 + 2], n2[3] = t4[r3 + 3], e2[0];
          }
          function s(t4, r3) {
            return n2[3] = t4[r3], n2[2] = t4[r3 + 1], n2[1] = t4[r3 + 2], n2[0] = t4[r3 + 3], e2[0];
          }
          t3.writeFloatLE = r2 ? i3 : o2, t3.writeFloatBE = r2 ? o2 : i3, t3.readFloatLE = r2 ? a : s, t3.readFloatBE = r2 ? s : a;
        }() : function() {
          function e2(t4, e3, n2, r2) {
            var i3 = e3 < 0 ? 1 : 0;
            if (i3 && (e3 = -e3), 0 === e3) t4(1 / e3 > 0 ? 0 : 2147483648, n2, r2);
            else if (isNaN(e3)) t4(2143289344, n2, r2);
            else if (e3 > 34028234663852886e22) t4((i3 << 31 | 2139095040) >>> 0, n2, r2);
            else if (e3 < 11754943508222875e-54) t4((i3 << 31 | Math.round(e3 / 1401298464324817e-60)) >>> 0, n2, r2);
            else {
              var o2 = Math.floor(Math.log(e3) / Math.LN2);
              t4((i3 << 31 | o2 + 127 << 23 | 8388607 & Math.round(e3 * Math.pow(2, -o2) * 8388608)) >>> 0, n2, r2);
            }
          }
          function a(t4, e3, n2) {
            var r2 = t4(e3, n2), i3 = 2 * (r2 >> 31) + 1, o2 = r2 >>> 23 & 255, a2 = 8388607 & r2;
            return 255 === o2 ? a2 ? NaN : i3 * (1 / 0) : 0 === o2 ? 1401298464324817e-60 * i3 * a2 : i3 * Math.pow(2, o2 - 150) * (a2 + 8388608);
          }
          t3.writeFloatLE = e2.bind(null, n), t3.writeFloatBE = e2.bind(null, r), t3.readFloatLE = a.bind(null, i2), t3.readFloatBE = a.bind(null, o);
        }(), "undefined" != typeof Float64Array ? function() {
          var e2 = new Float64Array([-0]), n2 = new Uint8Array(e2.buffer), r2 = 128 === n2[7];
          function i3(t4, r3, i4) {
            e2[0] = t4, r3[i4] = n2[0], r3[i4 + 1] = n2[1], r3[i4 + 2] = n2[2], r3[i4 + 3] = n2[3], r3[i4 + 4] = n2[4], r3[i4 + 5] = n2[5], r3[i4 + 6] = n2[6], r3[i4 + 7] = n2[7];
          }
          function o2(t4, r3, i4) {
            e2[0] = t4, r3[i4] = n2[7], r3[i4 + 1] = n2[6], r3[i4 + 2] = n2[5], r3[i4 + 3] = n2[4], r3[i4 + 4] = n2[3], r3[i4 + 5] = n2[2], r3[i4 + 6] = n2[1], r3[i4 + 7] = n2[0];
          }
          function a(t4, r3) {
            return n2[0] = t4[r3], n2[1] = t4[r3 + 1], n2[2] = t4[r3 + 2], n2[3] = t4[r3 + 3], n2[4] = t4[r3 + 4], n2[5] = t4[r3 + 5], n2[6] = t4[r3 + 6], n2[7] = t4[r3 + 7], e2[0];
          }
          function s(t4, r3) {
            return n2[7] = t4[r3], n2[6] = t4[r3 + 1], n2[5] = t4[r3 + 2], n2[4] = t4[r3 + 3], n2[3] = t4[r3 + 4], n2[2] = t4[r3 + 5], n2[1] = t4[r3 + 6], n2[0] = t4[r3 + 7], e2[0];
          }
          t3.writeDoubleLE = r2 ? i3 : o2, t3.writeDoubleBE = r2 ? o2 : i3, t3.readDoubleLE = r2 ? a : s, t3.readDoubleBE = r2 ? s : a;
        }() : function() {
          function e2(t4, e3, n2, r2, i3, o2) {
            var a2 = r2 < 0 ? 1 : 0;
            if (a2 && (r2 = -r2), 0 === r2) t4(0, i3, o2 + e3), t4(1 / r2 > 0 ? 0 : 2147483648, i3, o2 + n2);
            else if (isNaN(r2)) t4(0, i3, o2 + e3), t4(2146959360, i3, o2 + n2);
            else if (r2 > 17976931348623157e292) t4(0, i3, o2 + e3), t4((a2 << 31 | 2146435072) >>> 0, i3, o2 + n2);
            else {
              var s;
              if (r2 < 22250738585072014e-324) t4((s = r2 / 5e-324) >>> 0, i3, o2 + e3), t4((a2 << 31 | s / 4294967296) >>> 0, i3, o2 + n2);
              else {
                var u = Math.floor(Math.log(r2) / Math.LN2);
                1024 === u && (u = 1023), t4(4503599627370496 * (s = r2 * Math.pow(2, -u)) >>> 0, i3, o2 + e3), t4((a2 << 31 | u + 1023 << 20 | 1048576 * s & 1048575) >>> 0, i3, o2 + n2);
              }
            }
          }
          function a(t4, e3, n2, r2, i3) {
            var o2 = t4(r2, i3 + e3), a2 = t4(r2, i3 + n2), s = 2 * (a2 >> 31) + 1, u = a2 >>> 20 & 2047, c = 4294967296 * (1048575 & a2) + o2;
            return 2047 === u ? c ? NaN : s * (1 / 0) : 0 === u ? 5e-324 * s * c : s * Math.pow(2, u - 1075) * (c + 4503599627370496);
          }
          t3.writeDoubleLE = e2.bind(null, n, 0, 4), t3.writeDoubleBE = e2.bind(null, r, 4, 0), t3.readDoubleLE = a.bind(null, i2, 0, 4), t3.readDoubleBE = a.bind(null, o, 4, 0);
        }(), t3;
      }
      function n(t3, e2, n2) {
        e2[n2] = 255 & t3, e2[n2 + 1] = t3 >>> 8 & 255, e2[n2 + 2] = t3 >>> 16 & 255, e2[n2 + 3] = t3 >>> 24;
      }
      function r(t3, e2, n2) {
        e2[n2] = t3 >>> 24, e2[n2 + 1] = t3 >>> 16 & 255, e2[n2 + 2] = t3 >>> 8 & 255, e2[n2 + 3] = 255 & t3;
      }
      function i2(t3, e2) {
        return (t3[e2] | t3[e2 + 1] << 8 | t3[e2 + 2] << 16 | t3[e2 + 3] << 24) >>> 0;
      }
      function o(t3, e2) {
        return (t3[e2] << 24 | t3[e2 + 1] << 16 | t3[e2 + 2] << 8 | t3[e2 + 3]) >>> 0;
      }
      t2.exports = e(e);
    }, 7199: (module) => {
      function inquire(moduleName) {
        try {
          var mod = eval("quire".replace(/^/, "re"))(moduleName);
          if (mod && (mod.length || Object.keys(mod).length)) return mod;
        } catch (t2) {
        }
        return null;
      }
      module.exports = inquire;
    }, 6662: (t2) => {
      t2.exports = function(t3, e, n) {
        var r = n || 8192, i2 = r >>> 1, o = null, a = r;
        return function(n2) {
          if (n2 < 1 || n2 > i2) return t3(n2);
          a + n2 > r && (o = t3(r), a = 0);
          var s = e.call(o, a, a += n2);
          return 7 & a && (a = 1 + (7 | a)), s;
        };
      };
    }, 4997: (t2, e) => {
      var n = e;
      n.length = function(t3) {
        for (var e2 = 0, n2 = 0, r = 0; r < t3.length; ++r) (n2 = t3.charCodeAt(r)) < 128 ? e2 += 1 : n2 < 2048 ? e2 += 2 : 55296 == (64512 & n2) && 56320 == (64512 & t3.charCodeAt(r + 1)) ? (++r, e2 += 4) : e2 += 3;
        return e2;
      }, n.read = function(t3, e2, n2) {
        if (n2 - e2 < 1) return "";
        for (var r, i2 = null, o = [], a = 0; e2 < n2; ) (r = t3[e2++]) < 128 ? o[a++] = r : r > 191 && r < 224 ? o[a++] = (31 & r) << 6 | 63 & t3[e2++] : r > 239 && r < 365 ? (r = ((7 & r) << 18 | (63 & t3[e2++]) << 12 | (63 & t3[e2++]) << 6 | 63 & t3[e2++]) - 65536, o[a++] = 55296 + (r >> 10), o[a++] = 56320 + (1023 & r)) : o[a++] = (15 & r) << 12 | (63 & t3[e2++]) << 6 | 63 & t3[e2++], a > 8191 && ((i2 || (i2 = [])).push(String.fromCharCode.apply(String, o)), a = 0);
        return i2 ? (a && i2.push(String.fromCharCode.apply(String, o.slice(0, a))), i2.join("")) : String.fromCharCode.apply(String, o.slice(0, a));
      }, n.write = function(t3, e2, n2) {
        for (var r, i2, o = n2, a = 0; a < t3.length; ++a) (r = t3.charCodeAt(a)) < 128 ? e2[n2++] = r : r < 2048 ? (e2[n2++] = r >> 6 | 192, e2[n2++] = 63 & r | 128) : 55296 == (64512 & r) && 56320 == (64512 & (i2 = t3.charCodeAt(a + 1))) ? (r = 65536 + ((1023 & r) << 10) + (1023 & i2), ++a, e2[n2++] = r >> 18 | 240, e2[n2++] = r >> 12 & 63 | 128, e2[n2++] = r >> 6 & 63 | 128, e2[n2++] = 63 & r | 128) : (e2[n2++] = r >> 12 | 224, e2[n2++] = r >> 6 & 63 | 128, e2[n2++] = 63 & r | 128);
        return n2 - o;
      };
    }, 3442: (t2, e) => {
      e.__esModule = true;
      var n = function() {
        function t3(e2) {
          if (!e2) throw new TypeError("Invalid argument; `value` has no value.");
          this.value = t3.EMPTY, e2 && t3.isGuid(e2) && (this.value = e2);
        }
        return t3.isGuid = function(e2) {
          var n2 = e2.toString();
          return e2 && (e2 instanceof t3 || t3.validator.test(n2));
        }, t3.create = function() {
          return new t3([t3.gen(2), t3.gen(1), t3.gen(1), t3.gen(1), t3.gen(3)].join("-"));
        }, t3.createEmpty = function() {
          return new t3("emptyguid");
        }, t3.parse = function(e2) {
          return new t3(e2);
        }, t3.raw = function() {
          return [t3.gen(2), t3.gen(1), t3.gen(1), t3.gen(1), t3.gen(3)].join("-");
        }, t3.gen = function(t4) {
          for (var e2 = "", n2 = 0; n2 < t4; n2++) e2 += (65536 * (1 + Math.random()) | 0).toString(16).substring(1);
          return e2;
        }, t3.prototype.equals = function(e2) {
          return t3.isGuid(e2) && this.value === e2.toString();
        }, t3.prototype.isEmpty = function() {
          return this.value === t3.EMPTY;
        }, t3.prototype.toString = function() {
          return this.value;
        }, t3.prototype.toJSON = function() {
          return { value: this.value };
        }, t3.validator = new RegExp("^[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12}$", "i"), t3.EMPTY = "00000000-0000-0000-0000-000000000000", t3;
      }();
      e.Guid = n;
    }, 3720: (t2) => {
      t2.exports = n;
      var e = null;
      try {
        e = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;
      } catch (t3) {
      }
      function n(t3, e2, n2) {
        this.low = 0 | t3, this.high = 0 | e2, this.unsigned = !!n2;
      }
      function r(t3) {
        return true === (t3 && t3.__isLong__);
      }
      n.prototype.__isLong__, Object.defineProperty(n.prototype, "__isLong__", { value: true }), n.isLong = r;
      var i2 = {}, o = {};
      function a(t3, e2) {
        var n2, r2, a2;
        return e2 ? (a2 = 0 <= (t3 >>>= 0) && t3 < 256) && (r2 = o[t3]) ? r2 : (n2 = u(t3, (0 | t3) < 0 ? -1 : 0, true), a2 && (o[t3] = n2), n2) : (a2 = -128 <= (t3 |= 0) && t3 < 128) && (r2 = i2[t3]) ? r2 : (n2 = u(t3, t3 < 0 ? -1 : 0, false), a2 && (i2[t3] = n2), n2);
      }
      function s(t3, e2) {
        if (isNaN(t3)) return e2 ? m : b;
        if (e2) {
          if (t3 < 0) return m;
          if (t3 >= d) return x;
        } else {
          if (t3 <= -h) return T;
          if (t3 + 1 >= h) return w;
        }
        return t3 < 0 ? s(-t3, e2).neg() : u(t3 % f | 0, t3 / f | 0, e2);
      }
      function u(t3, e2, r2) {
        return new n(t3, e2, r2);
      }
      n.fromInt = a, n.fromNumber = s, n.fromBits = u;
      var c = Math.pow;
      function l(t3, e2, n2) {
        if (0 === t3.length) throw Error("empty string");
        if ("NaN" === t3 || "Infinity" === t3 || "+Infinity" === t3 || "-Infinity" === t3) return b;
        if ("number" == typeof e2 ? (n2 = e2, e2 = false) : e2 = !!e2, (n2 = n2 || 10) < 2 || 36 < n2) throw RangeError("radix");
        var r2;
        if ((r2 = t3.indexOf("-")) > 0) throw Error("interior hyphen");
        if (0 === r2) return l(t3.substring(1), e2, n2).neg();
        for (var i3 = s(c(n2, 8)), o2 = b, a2 = 0; a2 < t3.length; a2 += 8) {
          var u2 = Math.min(8, t3.length - a2), p2 = parseInt(t3.substring(a2, a2 + u2), n2);
          if (u2 < 8) {
            var f2 = s(c(n2, u2));
            o2 = o2.mul(f2).add(s(p2));
          } else o2 = (o2 = o2.mul(i3)).add(s(p2));
        }
        return o2.unsigned = e2, o2;
      }
      function p(t3, e2) {
        return "number" == typeof t3 ? s(t3, e2) : "string" == typeof t3 ? l(t3, e2) : u(t3.low, t3.high, "boolean" == typeof e2 ? e2 : t3.unsigned);
      }
      n.fromString = l, n.fromValue = p;
      var f = 4294967296, d = f * f, h = d / 2, g = a(1 << 24), b = a(0);
      n.ZERO = b;
      var m = a(0, true);
      n.UZERO = m;
      var y = a(1);
      n.ONE = y;
      var _ = a(1, true);
      n.UONE = _;
      var v = a(-1);
      n.NEG_ONE = v;
      var w = u(-1, 2147483647, false);
      n.MAX_VALUE = w;
      var x = u(-1, -1, true);
      n.MAX_UNSIGNED_VALUE = x;
      var T = u(0, -2147483648, false);
      n.MIN_VALUE = T;
      var S = n.prototype;
      S.toInt = function() {
        return this.unsigned ? this.low >>> 0 : this.low;
      }, S.toNumber = function() {
        return this.unsigned ? (this.high >>> 0) * f + (this.low >>> 0) : this.high * f + (this.low >>> 0);
      }, S.toString = function(t3) {
        if ((t3 = t3 || 10) < 2 || 36 < t3) throw RangeError("radix");
        if (this.isZero()) return "0";
        if (this.isNegative()) {
          if (this.eq(T)) {
            var e2 = s(t3), n2 = this.div(e2), r2 = n2.mul(e2).sub(this);
            return n2.toString(t3) + r2.toInt().toString(t3);
          }
          return "-" + this.neg().toString(t3);
        }
        for (var i3 = s(c(t3, 6), this.unsigned), o2 = this, a2 = ""; ; ) {
          var u2 = o2.div(i3), l2 = (o2.sub(u2.mul(i3)).toInt() >>> 0).toString(t3);
          if ((o2 = u2).isZero()) return l2 + a2;
          for (; l2.length < 6; ) l2 = "0" + l2;
          a2 = "" + l2 + a2;
        }
      }, S.getHighBits = function() {
        return this.high;
      }, S.getHighBitsUnsigned = function() {
        return this.high >>> 0;
      }, S.getLowBits = function() {
        return this.low;
      }, S.getLowBitsUnsigned = function() {
        return this.low >>> 0;
      }, S.getNumBitsAbs = function() {
        if (this.isNegative()) return this.eq(T) ? 64 : this.neg().getNumBitsAbs();
        for (var t3 = 0 != this.high ? this.high : this.low, e2 = 31; e2 > 0 && 0 == (t3 & 1 << e2); e2--) ;
        return 0 != this.high ? e2 + 33 : e2 + 1;
      }, S.isZero = function() {
        return 0 === this.high && 0 === this.low;
      }, S.eqz = S.isZero, S.isNegative = function() {
        return !this.unsigned && this.high < 0;
      }, S.isPositive = function() {
        return this.unsigned || this.high >= 0;
      }, S.isOdd = function() {
        return 1 == (1 & this.low);
      }, S.isEven = function() {
        return 0 == (1 & this.low);
      }, S.equals = function(t3) {
        return r(t3) || (t3 = p(t3)), (this.unsigned === t3.unsigned || this.high >>> 31 != 1 || t3.high >>> 31 != 1) && this.high === t3.high && this.low === t3.low;
      }, S.eq = S.equals, S.notEquals = function(t3) {
        return !this.eq(t3);
      }, S.neq = S.notEquals, S.ne = S.notEquals, S.lessThan = function(t3) {
        return this.comp(t3) < 0;
      }, S.lt = S.lessThan, S.lessThanOrEqual = function(t3) {
        return this.comp(t3) <= 0;
      }, S.lte = S.lessThanOrEqual, S.le = S.lessThanOrEqual, S.greaterThan = function(t3) {
        return this.comp(t3) > 0;
      }, S.gt = S.greaterThan, S.greaterThanOrEqual = function(t3) {
        return this.comp(t3) >= 0;
      }, S.gte = S.greaterThanOrEqual, S.ge = S.greaterThanOrEqual, S.compare = function(t3) {
        if (r(t3) || (t3 = p(t3)), this.eq(t3)) return 0;
        var e2 = this.isNegative(), n2 = t3.isNegative();
        return e2 && !n2 ? -1 : !e2 && n2 ? 1 : this.unsigned ? t3.high >>> 0 > this.high >>> 0 || t3.high === this.high && t3.low >>> 0 > this.low >>> 0 ? -1 : 1 : this.sub(t3).isNegative() ? -1 : 1;
      }, S.comp = S.compare, S.negate = function() {
        return !this.unsigned && this.eq(T) ? T : this.not().add(y);
      }, S.neg = S.negate, S.add = function(t3) {
        r(t3) || (t3 = p(t3));
        var e2 = this.high >>> 16, n2 = 65535 & this.high, i3 = this.low >>> 16, o2 = 65535 & this.low, a2 = t3.high >>> 16, s2 = 65535 & t3.high, c2 = t3.low >>> 16, l2 = 0, f2 = 0, d2 = 0, h2 = 0;
        return d2 += (h2 += o2 + (65535 & t3.low)) >>> 16, f2 += (d2 += i3 + c2) >>> 16, l2 += (f2 += n2 + s2) >>> 16, l2 += e2 + a2, u((d2 &= 65535) << 16 | (h2 &= 65535), (l2 &= 65535) << 16 | (f2 &= 65535), this.unsigned);
      }, S.subtract = function(t3) {
        return r(t3) || (t3 = p(t3)), this.add(t3.neg());
      }, S.sub = S.subtract, S.multiply = function(t3) {
        if (this.isZero()) return b;
        if (r(t3) || (t3 = p(t3)), e) return u(e.mul(this.low, this.high, t3.low, t3.high), e.get_high(), this.unsigned);
        if (t3.isZero()) return b;
        if (this.eq(T)) return t3.isOdd() ? T : b;
        if (t3.eq(T)) return this.isOdd() ? T : b;
        if (this.isNegative()) return t3.isNegative() ? this.neg().mul(t3.neg()) : this.neg().mul(t3).neg();
        if (t3.isNegative()) return this.mul(t3.neg()).neg();
        if (this.lt(g) && t3.lt(g)) return s(this.toNumber() * t3.toNumber(), this.unsigned);
        var n2 = this.high >>> 16, i3 = 65535 & this.high, o2 = this.low >>> 16, a2 = 65535 & this.low, c2 = t3.high >>> 16, l2 = 65535 & t3.high, f2 = t3.low >>> 16, d2 = 65535 & t3.low, h2 = 0, m2 = 0, y2 = 0, _2 = 0;
        return y2 += (_2 += a2 * d2) >>> 16, m2 += (y2 += o2 * d2) >>> 16, y2 &= 65535, m2 += (y2 += a2 * f2) >>> 16, h2 += (m2 += i3 * d2) >>> 16, m2 &= 65535, h2 += (m2 += o2 * f2) >>> 16, m2 &= 65535, h2 += (m2 += a2 * l2) >>> 16, h2 += n2 * d2 + i3 * f2 + o2 * l2 + a2 * c2, u((y2 &= 65535) << 16 | (_2 &= 65535), (h2 &= 65535) << 16 | (m2 &= 65535), this.unsigned);
      }, S.mul = S.multiply, S.divide = function(t3) {
        if (r(t3) || (t3 = p(t3)), t3.isZero()) throw Error("division by zero");
        var n2, i3, o2;
        if (e) return this.unsigned || -2147483648 !== this.high || -1 !== t3.low || -1 !== t3.high ? u((this.unsigned ? e.div_u : e.div_s)(this.low, this.high, t3.low, t3.high), e.get_high(), this.unsigned) : this;
        if (this.isZero()) return this.unsigned ? m : b;
        if (this.unsigned) {
          if (t3.unsigned || (t3 = t3.toUnsigned()), t3.gt(this)) return m;
          if (t3.gt(this.shru(1))) return _;
          o2 = m;
        } else {
          if (this.eq(T)) return t3.eq(y) || t3.eq(v) ? T : t3.eq(T) ? y : (n2 = this.shr(1).div(t3).shl(1)).eq(b) ? t3.isNegative() ? y : v : (i3 = this.sub(t3.mul(n2)), o2 = n2.add(i3.div(t3)));
          if (t3.eq(T)) return this.unsigned ? m : b;
          if (this.isNegative()) return t3.isNegative() ? this.neg().div(t3.neg()) : this.neg().div(t3).neg();
          if (t3.isNegative()) return this.div(t3.neg()).neg();
          o2 = b;
        }
        for (i3 = this; i3.gte(t3); ) {
          n2 = Math.max(1, Math.floor(i3.toNumber() / t3.toNumber()));
          for (var a2 = Math.ceil(Math.log(n2) / Math.LN2), l2 = a2 <= 48 ? 1 : c(2, a2 - 48), f2 = s(n2), d2 = f2.mul(t3); d2.isNegative() || d2.gt(i3); ) d2 = (f2 = s(n2 -= l2, this.unsigned)).mul(t3);
          f2.isZero() && (f2 = y), o2 = o2.add(f2), i3 = i3.sub(d2);
        }
        return o2;
      }, S.div = S.divide, S.modulo = function(t3) {
        return r(t3) || (t3 = p(t3)), e ? u((this.unsigned ? e.rem_u : e.rem_s)(this.low, this.high, t3.low, t3.high), e.get_high(), this.unsigned) : this.sub(this.div(t3).mul(t3));
      }, S.mod = S.modulo, S.rem = S.modulo, S.not = function() {
        return u(~this.low, ~this.high, this.unsigned);
      }, S.and = function(t3) {
        return r(t3) || (t3 = p(t3)), u(this.low & t3.low, this.high & t3.high, this.unsigned);
      }, S.or = function(t3) {
        return r(t3) || (t3 = p(t3)), u(this.low | t3.low, this.high | t3.high, this.unsigned);
      }, S.xor = function(t3) {
        return r(t3) || (t3 = p(t3)), u(this.low ^ t3.low, this.high ^ t3.high, this.unsigned);
      }, S.shiftLeft = function(t3) {
        return r(t3) && (t3 = t3.toInt()), 0 == (t3 &= 63) ? this : t3 < 32 ? u(this.low << t3, this.high << t3 | this.low >>> 32 - t3, this.unsigned) : u(0, this.low << t3 - 32, this.unsigned);
      }, S.shl = S.shiftLeft, S.shiftRight = function(t3) {
        return r(t3) && (t3 = t3.toInt()), 0 == (t3 &= 63) ? this : t3 < 32 ? u(this.low >>> t3 | this.high << 32 - t3, this.high >> t3, this.unsigned) : u(this.high >> t3 - 32, this.high >= 0 ? 0 : -1, this.unsigned);
      }, S.shr = S.shiftRight, S.shiftRightUnsigned = function(t3) {
        if (r(t3) && (t3 = t3.toInt()), 0 == (t3 &= 63)) return this;
        var e2 = this.high;
        return t3 < 32 ? u(this.low >>> t3 | e2 << 32 - t3, e2 >>> t3, this.unsigned) : u(32 === t3 ? e2 : e2 >>> t3 - 32, 0, this.unsigned);
      }, S.shru = S.shiftRightUnsigned, S.shr_u = S.shiftRightUnsigned, S.toSigned = function() {
        return this.unsigned ? u(this.low, this.high, false) : this;
      }, S.toUnsigned = function() {
        return this.unsigned ? this : u(this.low, this.high, true);
      }, S.toBytes = function(t3) {
        return t3 ? this.toBytesLE() : this.toBytesBE();
      }, S.toBytesLE = function() {
        var t3 = this.high, e2 = this.low;
        return [255 & e2, e2 >>> 8 & 255, e2 >>> 16 & 255, e2 >>> 24, 255 & t3, t3 >>> 8 & 255, t3 >>> 16 & 255, t3 >>> 24];
      }, S.toBytesBE = function() {
        var t3 = this.high, e2 = this.low;
        return [t3 >>> 24, t3 >>> 16 & 255, t3 >>> 8 & 255, 255 & t3, e2 >>> 24, e2 >>> 16 & 255, e2 >>> 8 & 255, 255 & e2];
      }, n.fromBytes = function(t3, e2, r2) {
        return r2 ? n.fromBytesLE(t3, e2) : n.fromBytesBE(t3, e2);
      }, n.fromBytesLE = function(t3, e2) {
        return new n(t3[0] | t3[1] << 8 | t3[2] << 16 | t3[3] << 24, t3[4] | t3[5] << 8 | t3[6] << 16 | t3[7] << 24, e2);
      }, n.fromBytesBE = function(t3, e2) {
        return new n(t3[4] << 24 | t3[5] << 16 | t3[6] << 8 | t3[7], t3[0] << 24 | t3[1] << 16 | t3[2] << 8 | t3[3], e2);
      };
    }, 1446: (t2, e, n) => {
      var r, i2, o, a = n(2100), s = a.Reader, u = a.Writer, c = a.util, l = a.roots.default || (a.roots.default = {});
      l.onnx = ((o = {}).Version = (r = {}, (i2 = Object.create(r))[r[0] = "_START_VERSION"] = 0, i2[r[1] = "IR_VERSION_2017_10_10"] = 1, i2[r[2] = "IR_VERSION_2017_10_30"] = 2, i2[r[3] = "IR_VERSION_2017_11_3"] = 3, i2[r[4] = "IR_VERSION_2019_1_22"] = 4, i2[r[5] = "IR_VERSION"] = 5, i2), o.AttributeProto = function() {
        function t3(t4) {
          if (this.floats = [], this.ints = [], this.strings = [], this.tensors = [], this.graphs = [], t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.name = "", t3.prototype.refAttrName = "", t3.prototype.docString = "", t3.prototype.type = 0, t3.prototype.f = 0, t3.prototype.i = c.Long ? c.Long.fromBits(0, 0, false) : 0, t3.prototype.s = c.newBuffer([]), t3.prototype.t = null, t3.prototype.g = null, t3.prototype.floats = c.emptyArray, t3.prototype.ints = c.emptyArray, t3.prototype.strings = c.emptyArray, t3.prototype.tensors = c.emptyArray, t3.prototype.graphs = c.emptyArray, t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          if (e2 || (e2 = u.create()), null != t4.name && t4.hasOwnProperty("name") && e2.uint32(10).string(t4.name), null != t4.f && t4.hasOwnProperty("f") && e2.uint32(21).float(t4.f), null != t4.i && t4.hasOwnProperty("i") && e2.uint32(24).int64(t4.i), null != t4.s && t4.hasOwnProperty("s") && e2.uint32(34).bytes(t4.s), null != t4.t && t4.hasOwnProperty("t") && l.onnx.TensorProto.encode(t4.t, e2.uint32(42).fork()).ldelim(), null != t4.g && t4.hasOwnProperty("g") && l.onnx.GraphProto.encode(t4.g, e2.uint32(50).fork()).ldelim(), null != t4.floats && t4.floats.length) {
            e2.uint32(58).fork();
            for (var n2 = 0; n2 < t4.floats.length; ++n2) e2.float(t4.floats[n2]);
            e2.ldelim();
          }
          if (null != t4.ints && t4.ints.length) {
            for (e2.uint32(66).fork(), n2 = 0; n2 < t4.ints.length; ++n2) e2.int64(t4.ints[n2]);
            e2.ldelim();
          }
          if (null != t4.strings && t4.strings.length) for (n2 = 0; n2 < t4.strings.length; ++n2) e2.uint32(74).bytes(t4.strings[n2]);
          if (null != t4.tensors && t4.tensors.length) for (n2 = 0; n2 < t4.tensors.length; ++n2) l.onnx.TensorProto.encode(t4.tensors[n2], e2.uint32(82).fork()).ldelim();
          if (null != t4.graphs && t4.graphs.length) for (n2 = 0; n2 < t4.graphs.length; ++n2) l.onnx.GraphProto.encode(t4.graphs[n2], e2.uint32(90).fork()).ldelim();
          return null != t4.docString && t4.hasOwnProperty("docString") && e2.uint32(106).string(t4.docString), null != t4.type && t4.hasOwnProperty("type") && e2.uint32(160).int32(t4.type), null != t4.refAttrName && t4.hasOwnProperty("refAttrName") && e2.uint32(170).string(t4.refAttrName), e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.AttributeProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                r2.name = t4.string();
                break;
              case 21:
                r2.refAttrName = t4.string();
                break;
              case 13:
                r2.docString = t4.string();
                break;
              case 20:
                r2.type = t4.int32();
                break;
              case 2:
                r2.f = t4.float();
                break;
              case 3:
                r2.i = t4.int64();
                break;
              case 4:
                r2.s = t4.bytes();
                break;
              case 5:
                r2.t = l.onnx.TensorProto.decode(t4, t4.uint32());
                break;
              case 6:
                r2.g = l.onnx.GraphProto.decode(t4, t4.uint32());
                break;
              case 7:
                if (r2.floats && r2.floats.length || (r2.floats = []), 2 == (7 & i3)) for (var o2 = t4.uint32() + t4.pos; t4.pos < o2; ) r2.floats.push(t4.float());
                else r2.floats.push(t4.float());
                break;
              case 8:
                if (r2.ints && r2.ints.length || (r2.ints = []), 2 == (7 & i3)) for (o2 = t4.uint32() + t4.pos; t4.pos < o2; ) r2.ints.push(t4.int64());
                else r2.ints.push(t4.int64());
                break;
              case 9:
                r2.strings && r2.strings.length || (r2.strings = []), r2.strings.push(t4.bytes());
                break;
              case 10:
                r2.tensors && r2.tensors.length || (r2.tensors = []), r2.tensors.push(l.onnx.TensorProto.decode(t4, t4.uint32()));
                break;
              case 11:
                r2.graphs && r2.graphs.length || (r2.graphs = []), r2.graphs.push(l.onnx.GraphProto.decode(t4, t4.uint32()));
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          if ("object" != typeof t4 || null === t4) return "object expected";
          if (null != t4.name && t4.hasOwnProperty("name") && !c.isString(t4.name)) return "name: string expected";
          if (null != t4.refAttrName && t4.hasOwnProperty("refAttrName") && !c.isString(t4.refAttrName)) return "refAttrName: string expected";
          if (null != t4.docString && t4.hasOwnProperty("docString") && !c.isString(t4.docString)) return "docString: string expected";
          if (null != t4.type && t4.hasOwnProperty("type")) switch (t4.type) {
            default:
              return "type: enum value expected";
            case 0:
            case 1:
            case 2:
            case 3:
            case 4:
            case 5:
            case 6:
            case 7:
            case 8:
            case 9:
            case 10:
          }
          if (null != t4.f && t4.hasOwnProperty("f") && "number" != typeof t4.f) return "f: number expected";
          if (null != t4.i && t4.hasOwnProperty("i") && !(c.isInteger(t4.i) || t4.i && c.isInteger(t4.i.low) && c.isInteger(t4.i.high))) return "i: integer|Long expected";
          if (null != t4.s && t4.hasOwnProperty("s") && !(t4.s && "number" == typeof t4.s.length || c.isString(t4.s))) return "s: buffer expected";
          if (null != t4.t && t4.hasOwnProperty("t") && (n2 = l.onnx.TensorProto.verify(t4.t))) return "t." + n2;
          if (null != t4.g && t4.hasOwnProperty("g") && (n2 = l.onnx.GraphProto.verify(t4.g))) return "g." + n2;
          if (null != t4.floats && t4.hasOwnProperty("floats")) {
            if (!Array.isArray(t4.floats)) return "floats: array expected";
            for (var e2 = 0; e2 < t4.floats.length; ++e2) if ("number" != typeof t4.floats[e2]) return "floats: number[] expected";
          }
          if (null != t4.ints && t4.hasOwnProperty("ints")) {
            if (!Array.isArray(t4.ints)) return "ints: array expected";
            for (e2 = 0; e2 < t4.ints.length; ++e2) if (!(c.isInteger(t4.ints[e2]) || t4.ints[e2] && c.isInteger(t4.ints[e2].low) && c.isInteger(t4.ints[e2].high))) return "ints: integer|Long[] expected";
          }
          if (null != t4.strings && t4.hasOwnProperty("strings")) {
            if (!Array.isArray(t4.strings)) return "strings: array expected";
            for (e2 = 0; e2 < t4.strings.length; ++e2) if (!(t4.strings[e2] && "number" == typeof t4.strings[e2].length || c.isString(t4.strings[e2]))) return "strings: buffer[] expected";
          }
          if (null != t4.tensors && t4.hasOwnProperty("tensors")) {
            if (!Array.isArray(t4.tensors)) return "tensors: array expected";
            for (e2 = 0; e2 < t4.tensors.length; ++e2) if (n2 = l.onnx.TensorProto.verify(t4.tensors[e2])) return "tensors." + n2;
          }
          if (null != t4.graphs && t4.hasOwnProperty("graphs")) {
            if (!Array.isArray(t4.graphs)) return "graphs: array expected";
            for (e2 = 0; e2 < t4.graphs.length; ++e2) {
              var n2;
              if (n2 = l.onnx.GraphProto.verify(t4.graphs[e2])) return "graphs." + n2;
            }
          }
          return null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.AttributeProto) return t4;
          var e2 = new l.onnx.AttributeProto();
          switch (null != t4.name && (e2.name = String(t4.name)), null != t4.refAttrName && (e2.refAttrName = String(t4.refAttrName)), null != t4.docString && (e2.docString = String(t4.docString)), t4.type) {
            case "UNDEFINED":
            case 0:
              e2.type = 0;
              break;
            case "FLOAT":
            case 1:
              e2.type = 1;
              break;
            case "INT":
            case 2:
              e2.type = 2;
              break;
            case "STRING":
            case 3:
              e2.type = 3;
              break;
            case "TENSOR":
            case 4:
              e2.type = 4;
              break;
            case "GRAPH":
            case 5:
              e2.type = 5;
              break;
            case "FLOATS":
            case 6:
              e2.type = 6;
              break;
            case "INTS":
            case 7:
              e2.type = 7;
              break;
            case "STRINGS":
            case 8:
              e2.type = 8;
              break;
            case "TENSORS":
            case 9:
              e2.type = 9;
              break;
            case "GRAPHS":
            case 10:
              e2.type = 10;
          }
          if (null != t4.f && (e2.f = Number(t4.f)), null != t4.i && (c.Long ? (e2.i = c.Long.fromValue(t4.i)).unsigned = false : "string" == typeof t4.i ? e2.i = parseInt(t4.i, 10) : "number" == typeof t4.i ? e2.i = t4.i : "object" == typeof t4.i && (e2.i = new c.LongBits(t4.i.low >>> 0, t4.i.high >>> 0).toNumber())), null != t4.s && ("string" == typeof t4.s ? c.base64.decode(t4.s, e2.s = c.newBuffer(c.base64.length(t4.s)), 0) : t4.s.length && (e2.s = t4.s)), null != t4.t) {
            if ("object" != typeof t4.t) throw TypeError(".onnx.AttributeProto.t: object expected");
            e2.t = l.onnx.TensorProto.fromObject(t4.t);
          }
          if (null != t4.g) {
            if ("object" != typeof t4.g) throw TypeError(".onnx.AttributeProto.g: object expected");
            e2.g = l.onnx.GraphProto.fromObject(t4.g);
          }
          if (t4.floats) {
            if (!Array.isArray(t4.floats)) throw TypeError(".onnx.AttributeProto.floats: array expected");
            e2.floats = [];
            for (var n2 = 0; n2 < t4.floats.length; ++n2) e2.floats[n2] = Number(t4.floats[n2]);
          }
          if (t4.ints) {
            if (!Array.isArray(t4.ints)) throw TypeError(".onnx.AttributeProto.ints: array expected");
            for (e2.ints = [], n2 = 0; n2 < t4.ints.length; ++n2) c.Long ? (e2.ints[n2] = c.Long.fromValue(t4.ints[n2])).unsigned = false : "string" == typeof t4.ints[n2] ? e2.ints[n2] = parseInt(t4.ints[n2], 10) : "number" == typeof t4.ints[n2] ? e2.ints[n2] = t4.ints[n2] : "object" == typeof t4.ints[n2] && (e2.ints[n2] = new c.LongBits(t4.ints[n2].low >>> 0, t4.ints[n2].high >>> 0).toNumber());
          }
          if (t4.strings) {
            if (!Array.isArray(t4.strings)) throw TypeError(".onnx.AttributeProto.strings: array expected");
            for (e2.strings = [], n2 = 0; n2 < t4.strings.length; ++n2) "string" == typeof t4.strings[n2] ? c.base64.decode(t4.strings[n2], e2.strings[n2] = c.newBuffer(c.base64.length(t4.strings[n2])), 0) : t4.strings[n2].length && (e2.strings[n2] = t4.strings[n2]);
          }
          if (t4.tensors) {
            if (!Array.isArray(t4.tensors)) throw TypeError(".onnx.AttributeProto.tensors: array expected");
            for (e2.tensors = [], n2 = 0; n2 < t4.tensors.length; ++n2) {
              if ("object" != typeof t4.tensors[n2]) throw TypeError(".onnx.AttributeProto.tensors: object expected");
              e2.tensors[n2] = l.onnx.TensorProto.fromObject(t4.tensors[n2]);
            }
          }
          if (t4.graphs) {
            if (!Array.isArray(t4.graphs)) throw TypeError(".onnx.AttributeProto.graphs: array expected");
            for (e2.graphs = [], n2 = 0; n2 < t4.graphs.length; ++n2) {
              if ("object" != typeof t4.graphs[n2]) throw TypeError(".onnx.AttributeProto.graphs: object expected");
              e2.graphs[n2] = l.onnx.GraphProto.fromObject(t4.graphs[n2]);
            }
          }
          return e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          if ((e2.arrays || e2.defaults) && (n2.floats = [], n2.ints = [], n2.strings = [], n2.tensors = [], n2.graphs = []), e2.defaults) {
            if (n2.name = "", n2.f = 0, c.Long) {
              var r2 = new c.Long(0, 0, false);
              n2.i = e2.longs === String ? r2.toString() : e2.longs === Number ? r2.toNumber() : r2;
            } else n2.i = e2.longs === String ? "0" : 0;
            e2.bytes === String ? n2.s = "" : (n2.s = [], e2.bytes !== Array && (n2.s = c.newBuffer(n2.s))), n2.t = null, n2.g = null, n2.docString = "", n2.type = e2.enums === String ? "UNDEFINED" : 0, n2.refAttrName = "";
          }
          if (null != t4.name && t4.hasOwnProperty("name") && (n2.name = t4.name), null != t4.f && t4.hasOwnProperty("f") && (n2.f = e2.json && !isFinite(t4.f) ? String(t4.f) : t4.f), null != t4.i && t4.hasOwnProperty("i") && ("number" == typeof t4.i ? n2.i = e2.longs === String ? String(t4.i) : t4.i : n2.i = e2.longs === String ? c.Long.prototype.toString.call(t4.i) : e2.longs === Number ? new c.LongBits(t4.i.low >>> 0, t4.i.high >>> 0).toNumber() : t4.i), null != t4.s && t4.hasOwnProperty("s") && (n2.s = e2.bytes === String ? c.base64.encode(t4.s, 0, t4.s.length) : e2.bytes === Array ? Array.prototype.slice.call(t4.s) : t4.s), null != t4.t && t4.hasOwnProperty("t") && (n2.t = l.onnx.TensorProto.toObject(t4.t, e2)), null != t4.g && t4.hasOwnProperty("g") && (n2.g = l.onnx.GraphProto.toObject(t4.g, e2)), t4.floats && t4.floats.length) {
            n2.floats = [];
            for (var i3 = 0; i3 < t4.floats.length; ++i3) n2.floats[i3] = e2.json && !isFinite(t4.floats[i3]) ? String(t4.floats[i3]) : t4.floats[i3];
          }
          if (t4.ints && t4.ints.length) for (n2.ints = [], i3 = 0; i3 < t4.ints.length; ++i3) "number" == typeof t4.ints[i3] ? n2.ints[i3] = e2.longs === String ? String(t4.ints[i3]) : t4.ints[i3] : n2.ints[i3] = e2.longs === String ? c.Long.prototype.toString.call(t4.ints[i3]) : e2.longs === Number ? new c.LongBits(t4.ints[i3].low >>> 0, t4.ints[i3].high >>> 0).toNumber() : t4.ints[i3];
          if (t4.strings && t4.strings.length) for (n2.strings = [], i3 = 0; i3 < t4.strings.length; ++i3) n2.strings[i3] = e2.bytes === String ? c.base64.encode(t4.strings[i3], 0, t4.strings[i3].length) : e2.bytes === Array ? Array.prototype.slice.call(t4.strings[i3]) : t4.strings[i3];
          if (t4.tensors && t4.tensors.length) for (n2.tensors = [], i3 = 0; i3 < t4.tensors.length; ++i3) n2.tensors[i3] = l.onnx.TensorProto.toObject(t4.tensors[i3], e2);
          if (t4.graphs && t4.graphs.length) for (n2.graphs = [], i3 = 0; i3 < t4.graphs.length; ++i3) n2.graphs[i3] = l.onnx.GraphProto.toObject(t4.graphs[i3], e2);
          return null != t4.docString && t4.hasOwnProperty("docString") && (n2.docString = t4.docString), null != t4.type && t4.hasOwnProperty("type") && (n2.type = e2.enums === String ? l.onnx.AttributeProto.AttributeType[t4.type] : t4.type), null != t4.refAttrName && t4.hasOwnProperty("refAttrName") && (n2.refAttrName = t4.refAttrName), n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3.AttributeType = function() {
          var t4 = {}, e2 = Object.create(t4);
          return e2[t4[0] = "UNDEFINED"] = 0, e2[t4[1] = "FLOAT"] = 1, e2[t4[2] = "INT"] = 2, e2[t4[3] = "STRING"] = 3, e2[t4[4] = "TENSOR"] = 4, e2[t4[5] = "GRAPH"] = 5, e2[t4[6] = "FLOATS"] = 6, e2[t4[7] = "INTS"] = 7, e2[t4[8] = "STRINGS"] = 8, e2[t4[9] = "TENSORS"] = 9, e2[t4[10] = "GRAPHS"] = 10, e2;
        }(), t3;
      }(), o.ValueInfoProto = function() {
        function t3(t4) {
          if (t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.name = "", t3.prototype.type = null, t3.prototype.docString = "", t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          return e2 || (e2 = u.create()), null != t4.name && t4.hasOwnProperty("name") && e2.uint32(10).string(t4.name), null != t4.type && t4.hasOwnProperty("type") && l.onnx.TypeProto.encode(t4.type, e2.uint32(18).fork()).ldelim(), null != t4.docString && t4.hasOwnProperty("docString") && e2.uint32(26).string(t4.docString), e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.ValueInfoProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                r2.name = t4.string();
                break;
              case 2:
                r2.type = l.onnx.TypeProto.decode(t4, t4.uint32());
                break;
              case 3:
                r2.docString = t4.string();
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          if ("object" != typeof t4 || null === t4) return "object expected";
          if (null != t4.name && t4.hasOwnProperty("name") && !c.isString(t4.name)) return "name: string expected";
          if (null != t4.type && t4.hasOwnProperty("type")) {
            var e2 = l.onnx.TypeProto.verify(t4.type);
            if (e2) return "type." + e2;
          }
          return null != t4.docString && t4.hasOwnProperty("docString") && !c.isString(t4.docString) ? "docString: string expected" : null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.ValueInfoProto) return t4;
          var e2 = new l.onnx.ValueInfoProto();
          if (null != t4.name && (e2.name = String(t4.name)), null != t4.type) {
            if ("object" != typeof t4.type) throw TypeError(".onnx.ValueInfoProto.type: object expected");
            e2.type = l.onnx.TypeProto.fromObject(t4.type);
          }
          return null != t4.docString && (e2.docString = String(t4.docString)), e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          return e2.defaults && (n2.name = "", n2.type = null, n2.docString = ""), null != t4.name && t4.hasOwnProperty("name") && (n2.name = t4.name), null != t4.type && t4.hasOwnProperty("type") && (n2.type = l.onnx.TypeProto.toObject(t4.type, e2)), null != t4.docString && t4.hasOwnProperty("docString") && (n2.docString = t4.docString), n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3;
      }(), o.NodeProto = function() {
        function t3(t4) {
          if (this.input = [], this.output = [], this.attribute = [], t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.input = c.emptyArray, t3.prototype.output = c.emptyArray, t3.prototype.name = "", t3.prototype.opType = "", t3.prototype.domain = "", t3.prototype.attribute = c.emptyArray, t3.prototype.docString = "", t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          if (e2 || (e2 = u.create()), null != t4.input && t4.input.length) for (var n2 = 0; n2 < t4.input.length; ++n2) e2.uint32(10).string(t4.input[n2]);
          if (null != t4.output && t4.output.length) for (n2 = 0; n2 < t4.output.length; ++n2) e2.uint32(18).string(t4.output[n2]);
          if (null != t4.name && t4.hasOwnProperty("name") && e2.uint32(26).string(t4.name), null != t4.opType && t4.hasOwnProperty("opType") && e2.uint32(34).string(t4.opType), null != t4.attribute && t4.attribute.length) for (n2 = 0; n2 < t4.attribute.length; ++n2) l.onnx.AttributeProto.encode(t4.attribute[n2], e2.uint32(42).fork()).ldelim();
          return null != t4.docString && t4.hasOwnProperty("docString") && e2.uint32(50).string(t4.docString), null != t4.domain && t4.hasOwnProperty("domain") && e2.uint32(58).string(t4.domain), e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.NodeProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                r2.input && r2.input.length || (r2.input = []), r2.input.push(t4.string());
                break;
              case 2:
                r2.output && r2.output.length || (r2.output = []), r2.output.push(t4.string());
                break;
              case 3:
                r2.name = t4.string();
                break;
              case 4:
                r2.opType = t4.string();
                break;
              case 7:
                r2.domain = t4.string();
                break;
              case 5:
                r2.attribute && r2.attribute.length || (r2.attribute = []), r2.attribute.push(l.onnx.AttributeProto.decode(t4, t4.uint32()));
                break;
              case 6:
                r2.docString = t4.string();
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          if ("object" != typeof t4 || null === t4) return "object expected";
          if (null != t4.input && t4.hasOwnProperty("input")) {
            if (!Array.isArray(t4.input)) return "input: array expected";
            for (var e2 = 0; e2 < t4.input.length; ++e2) if (!c.isString(t4.input[e2])) return "input: string[] expected";
          }
          if (null != t4.output && t4.hasOwnProperty("output")) {
            if (!Array.isArray(t4.output)) return "output: array expected";
            for (e2 = 0; e2 < t4.output.length; ++e2) if (!c.isString(t4.output[e2])) return "output: string[] expected";
          }
          if (null != t4.name && t4.hasOwnProperty("name") && !c.isString(t4.name)) return "name: string expected";
          if (null != t4.opType && t4.hasOwnProperty("opType") && !c.isString(t4.opType)) return "opType: string expected";
          if (null != t4.domain && t4.hasOwnProperty("domain") && !c.isString(t4.domain)) return "domain: string expected";
          if (null != t4.attribute && t4.hasOwnProperty("attribute")) {
            if (!Array.isArray(t4.attribute)) return "attribute: array expected";
            for (e2 = 0; e2 < t4.attribute.length; ++e2) {
              var n2 = l.onnx.AttributeProto.verify(t4.attribute[e2]);
              if (n2) return "attribute." + n2;
            }
          }
          return null != t4.docString && t4.hasOwnProperty("docString") && !c.isString(t4.docString) ? "docString: string expected" : null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.NodeProto) return t4;
          var e2 = new l.onnx.NodeProto();
          if (t4.input) {
            if (!Array.isArray(t4.input)) throw TypeError(".onnx.NodeProto.input: array expected");
            e2.input = [];
            for (var n2 = 0; n2 < t4.input.length; ++n2) e2.input[n2] = String(t4.input[n2]);
          }
          if (t4.output) {
            if (!Array.isArray(t4.output)) throw TypeError(".onnx.NodeProto.output: array expected");
            for (e2.output = [], n2 = 0; n2 < t4.output.length; ++n2) e2.output[n2] = String(t4.output[n2]);
          }
          if (null != t4.name && (e2.name = String(t4.name)), null != t4.opType && (e2.opType = String(t4.opType)), null != t4.domain && (e2.domain = String(t4.domain)), t4.attribute) {
            if (!Array.isArray(t4.attribute)) throw TypeError(".onnx.NodeProto.attribute: array expected");
            for (e2.attribute = [], n2 = 0; n2 < t4.attribute.length; ++n2) {
              if ("object" != typeof t4.attribute[n2]) throw TypeError(".onnx.NodeProto.attribute: object expected");
              e2.attribute[n2] = l.onnx.AttributeProto.fromObject(t4.attribute[n2]);
            }
          }
          return null != t4.docString && (e2.docString = String(t4.docString)), e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          if ((e2.arrays || e2.defaults) && (n2.input = [], n2.output = [], n2.attribute = []), e2.defaults && (n2.name = "", n2.opType = "", n2.docString = "", n2.domain = ""), t4.input && t4.input.length) {
            n2.input = [];
            for (var r2 = 0; r2 < t4.input.length; ++r2) n2.input[r2] = t4.input[r2];
          }
          if (t4.output && t4.output.length) for (n2.output = [], r2 = 0; r2 < t4.output.length; ++r2) n2.output[r2] = t4.output[r2];
          if (null != t4.name && t4.hasOwnProperty("name") && (n2.name = t4.name), null != t4.opType && t4.hasOwnProperty("opType") && (n2.opType = t4.opType), t4.attribute && t4.attribute.length) for (n2.attribute = [], r2 = 0; r2 < t4.attribute.length; ++r2) n2.attribute[r2] = l.onnx.AttributeProto.toObject(t4.attribute[r2], e2);
          return null != t4.docString && t4.hasOwnProperty("docString") && (n2.docString = t4.docString), null != t4.domain && t4.hasOwnProperty("domain") && (n2.domain = t4.domain), n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3;
      }(), o.ModelProto = function() {
        function t3(t4) {
          if (this.opsetImport = [], this.metadataProps = [], t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.irVersion = c.Long ? c.Long.fromBits(0, 0, false) : 0, t3.prototype.opsetImport = c.emptyArray, t3.prototype.producerName = "", t3.prototype.producerVersion = "", t3.prototype.domain = "", t3.prototype.modelVersion = c.Long ? c.Long.fromBits(0, 0, false) : 0, t3.prototype.docString = "", t3.prototype.graph = null, t3.prototype.metadataProps = c.emptyArray, t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          if (e2 || (e2 = u.create()), null != t4.irVersion && t4.hasOwnProperty("irVersion") && e2.uint32(8).int64(t4.irVersion), null != t4.producerName && t4.hasOwnProperty("producerName") && e2.uint32(18).string(t4.producerName), null != t4.producerVersion && t4.hasOwnProperty("producerVersion") && e2.uint32(26).string(t4.producerVersion), null != t4.domain && t4.hasOwnProperty("domain") && e2.uint32(34).string(t4.domain), null != t4.modelVersion && t4.hasOwnProperty("modelVersion") && e2.uint32(40).int64(t4.modelVersion), null != t4.docString && t4.hasOwnProperty("docString") && e2.uint32(50).string(t4.docString), null != t4.graph && t4.hasOwnProperty("graph") && l.onnx.GraphProto.encode(t4.graph, e2.uint32(58).fork()).ldelim(), null != t4.opsetImport && t4.opsetImport.length) for (var n2 = 0; n2 < t4.opsetImport.length; ++n2) l.onnx.OperatorSetIdProto.encode(t4.opsetImport[n2], e2.uint32(66).fork()).ldelim();
          if (null != t4.metadataProps && t4.metadataProps.length) for (n2 = 0; n2 < t4.metadataProps.length; ++n2) l.onnx.StringStringEntryProto.encode(t4.metadataProps[n2], e2.uint32(114).fork()).ldelim();
          return e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.ModelProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                r2.irVersion = t4.int64();
                break;
              case 8:
                r2.opsetImport && r2.opsetImport.length || (r2.opsetImport = []), r2.opsetImport.push(l.onnx.OperatorSetIdProto.decode(t4, t4.uint32()));
                break;
              case 2:
                r2.producerName = t4.string();
                break;
              case 3:
                r2.producerVersion = t4.string();
                break;
              case 4:
                r2.domain = t4.string();
                break;
              case 5:
                r2.modelVersion = t4.int64();
                break;
              case 6:
                r2.docString = t4.string();
                break;
              case 7:
                r2.graph = l.onnx.GraphProto.decode(t4, t4.uint32());
                break;
              case 14:
                r2.metadataProps && r2.metadataProps.length || (r2.metadataProps = []), r2.metadataProps.push(l.onnx.StringStringEntryProto.decode(t4, t4.uint32()));
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          if ("object" != typeof t4 || null === t4) return "object expected";
          if (null != t4.irVersion && t4.hasOwnProperty("irVersion") && !(c.isInteger(t4.irVersion) || t4.irVersion && c.isInteger(t4.irVersion.low) && c.isInteger(t4.irVersion.high))) return "irVersion: integer|Long expected";
          if (null != t4.opsetImport && t4.hasOwnProperty("opsetImport")) {
            if (!Array.isArray(t4.opsetImport)) return "opsetImport: array expected";
            for (var e2 = 0; e2 < t4.opsetImport.length; ++e2) if (n2 = l.onnx.OperatorSetIdProto.verify(t4.opsetImport[e2])) return "opsetImport." + n2;
          }
          if (null != t4.producerName && t4.hasOwnProperty("producerName") && !c.isString(t4.producerName)) return "producerName: string expected";
          if (null != t4.producerVersion && t4.hasOwnProperty("producerVersion") && !c.isString(t4.producerVersion)) return "producerVersion: string expected";
          if (null != t4.domain && t4.hasOwnProperty("domain") && !c.isString(t4.domain)) return "domain: string expected";
          if (null != t4.modelVersion && t4.hasOwnProperty("modelVersion") && !(c.isInteger(t4.modelVersion) || t4.modelVersion && c.isInteger(t4.modelVersion.low) && c.isInteger(t4.modelVersion.high))) return "modelVersion: integer|Long expected";
          if (null != t4.docString && t4.hasOwnProperty("docString") && !c.isString(t4.docString)) return "docString: string expected";
          if (null != t4.graph && t4.hasOwnProperty("graph") && (n2 = l.onnx.GraphProto.verify(t4.graph))) return "graph." + n2;
          if (null != t4.metadataProps && t4.hasOwnProperty("metadataProps")) {
            if (!Array.isArray(t4.metadataProps)) return "metadataProps: array expected";
            for (e2 = 0; e2 < t4.metadataProps.length; ++e2) {
              var n2;
              if (n2 = l.onnx.StringStringEntryProto.verify(t4.metadataProps[e2])) return "metadataProps." + n2;
            }
          }
          return null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.ModelProto) return t4;
          var e2 = new l.onnx.ModelProto();
          if (null != t4.irVersion && (c.Long ? (e2.irVersion = c.Long.fromValue(t4.irVersion)).unsigned = false : "string" == typeof t4.irVersion ? e2.irVersion = parseInt(t4.irVersion, 10) : "number" == typeof t4.irVersion ? e2.irVersion = t4.irVersion : "object" == typeof t4.irVersion && (e2.irVersion = new c.LongBits(t4.irVersion.low >>> 0, t4.irVersion.high >>> 0).toNumber())), t4.opsetImport) {
            if (!Array.isArray(t4.opsetImport)) throw TypeError(".onnx.ModelProto.opsetImport: array expected");
            e2.opsetImport = [];
            for (var n2 = 0; n2 < t4.opsetImport.length; ++n2) {
              if ("object" != typeof t4.opsetImport[n2]) throw TypeError(".onnx.ModelProto.opsetImport: object expected");
              e2.opsetImport[n2] = l.onnx.OperatorSetIdProto.fromObject(t4.opsetImport[n2]);
            }
          }
          if (null != t4.producerName && (e2.producerName = String(t4.producerName)), null != t4.producerVersion && (e2.producerVersion = String(t4.producerVersion)), null != t4.domain && (e2.domain = String(t4.domain)), null != t4.modelVersion && (c.Long ? (e2.modelVersion = c.Long.fromValue(t4.modelVersion)).unsigned = false : "string" == typeof t4.modelVersion ? e2.modelVersion = parseInt(t4.modelVersion, 10) : "number" == typeof t4.modelVersion ? e2.modelVersion = t4.modelVersion : "object" == typeof t4.modelVersion && (e2.modelVersion = new c.LongBits(t4.modelVersion.low >>> 0, t4.modelVersion.high >>> 0).toNumber())), null != t4.docString && (e2.docString = String(t4.docString)), null != t4.graph) {
            if ("object" != typeof t4.graph) throw TypeError(".onnx.ModelProto.graph: object expected");
            e2.graph = l.onnx.GraphProto.fromObject(t4.graph);
          }
          if (t4.metadataProps) {
            if (!Array.isArray(t4.metadataProps)) throw TypeError(".onnx.ModelProto.metadataProps: array expected");
            for (e2.metadataProps = [], n2 = 0; n2 < t4.metadataProps.length; ++n2) {
              if ("object" != typeof t4.metadataProps[n2]) throw TypeError(".onnx.ModelProto.metadataProps: object expected");
              e2.metadataProps[n2] = l.onnx.StringStringEntryProto.fromObject(t4.metadataProps[n2]);
            }
          }
          return e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          if ((e2.arrays || e2.defaults) && (n2.opsetImport = [], n2.metadataProps = []), e2.defaults) {
            if (c.Long) {
              var r2 = new c.Long(0, 0, false);
              n2.irVersion = e2.longs === String ? r2.toString() : e2.longs === Number ? r2.toNumber() : r2;
            } else n2.irVersion = e2.longs === String ? "0" : 0;
            n2.producerName = "", n2.producerVersion = "", n2.domain = "", c.Long ? (r2 = new c.Long(0, 0, false), n2.modelVersion = e2.longs === String ? r2.toString() : e2.longs === Number ? r2.toNumber() : r2) : n2.modelVersion = e2.longs === String ? "0" : 0, n2.docString = "", n2.graph = null;
          }
          if (null != t4.irVersion && t4.hasOwnProperty("irVersion") && ("number" == typeof t4.irVersion ? n2.irVersion = e2.longs === String ? String(t4.irVersion) : t4.irVersion : n2.irVersion = e2.longs === String ? c.Long.prototype.toString.call(t4.irVersion) : e2.longs === Number ? new c.LongBits(t4.irVersion.low >>> 0, t4.irVersion.high >>> 0).toNumber() : t4.irVersion), null != t4.producerName && t4.hasOwnProperty("producerName") && (n2.producerName = t4.producerName), null != t4.producerVersion && t4.hasOwnProperty("producerVersion") && (n2.producerVersion = t4.producerVersion), null != t4.domain && t4.hasOwnProperty("domain") && (n2.domain = t4.domain), null != t4.modelVersion && t4.hasOwnProperty("modelVersion") && ("number" == typeof t4.modelVersion ? n2.modelVersion = e2.longs === String ? String(t4.modelVersion) : t4.modelVersion : n2.modelVersion = e2.longs === String ? c.Long.prototype.toString.call(t4.modelVersion) : e2.longs === Number ? new c.LongBits(t4.modelVersion.low >>> 0, t4.modelVersion.high >>> 0).toNumber() : t4.modelVersion), null != t4.docString && t4.hasOwnProperty("docString") && (n2.docString = t4.docString), null != t4.graph && t4.hasOwnProperty("graph") && (n2.graph = l.onnx.GraphProto.toObject(t4.graph, e2)), t4.opsetImport && t4.opsetImport.length) {
            n2.opsetImport = [];
            for (var i3 = 0; i3 < t4.opsetImport.length; ++i3) n2.opsetImport[i3] = l.onnx.OperatorSetIdProto.toObject(t4.opsetImport[i3], e2);
          }
          if (t4.metadataProps && t4.metadataProps.length) for (n2.metadataProps = [], i3 = 0; i3 < t4.metadataProps.length; ++i3) n2.metadataProps[i3] = l.onnx.StringStringEntryProto.toObject(t4.metadataProps[i3], e2);
          return n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3;
      }(), o.StringStringEntryProto = function() {
        function t3(t4) {
          if (t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.key = "", t3.prototype.value = "", t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          return e2 || (e2 = u.create()), null != t4.key && t4.hasOwnProperty("key") && e2.uint32(10).string(t4.key), null != t4.value && t4.hasOwnProperty("value") && e2.uint32(18).string(t4.value), e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.StringStringEntryProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                r2.key = t4.string();
                break;
              case 2:
                r2.value = t4.string();
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          return "object" != typeof t4 || null === t4 ? "object expected" : null != t4.key && t4.hasOwnProperty("key") && !c.isString(t4.key) ? "key: string expected" : null != t4.value && t4.hasOwnProperty("value") && !c.isString(t4.value) ? "value: string expected" : null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.StringStringEntryProto) return t4;
          var e2 = new l.onnx.StringStringEntryProto();
          return null != t4.key && (e2.key = String(t4.key)), null != t4.value && (e2.value = String(t4.value)), e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          return e2.defaults && (n2.key = "", n2.value = ""), null != t4.key && t4.hasOwnProperty("key") && (n2.key = t4.key), null != t4.value && t4.hasOwnProperty("value") && (n2.value = t4.value), n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3;
      }(), o.TensorAnnotation = function() {
        function t3(t4) {
          if (this.quantParameterTensorNames = [], t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.tensorName = "", t3.prototype.quantParameterTensorNames = c.emptyArray, t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          if (e2 || (e2 = u.create()), null != t4.tensorName && t4.hasOwnProperty("tensorName") && e2.uint32(10).string(t4.tensorName), null != t4.quantParameterTensorNames && t4.quantParameterTensorNames.length) for (var n2 = 0; n2 < t4.quantParameterTensorNames.length; ++n2) l.onnx.StringStringEntryProto.encode(t4.quantParameterTensorNames[n2], e2.uint32(18).fork()).ldelim();
          return e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.TensorAnnotation(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                r2.tensorName = t4.string();
                break;
              case 2:
                r2.quantParameterTensorNames && r2.quantParameterTensorNames.length || (r2.quantParameterTensorNames = []), r2.quantParameterTensorNames.push(l.onnx.StringStringEntryProto.decode(t4, t4.uint32()));
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          if ("object" != typeof t4 || null === t4) return "object expected";
          if (null != t4.tensorName && t4.hasOwnProperty("tensorName") && !c.isString(t4.tensorName)) return "tensorName: string expected";
          if (null != t4.quantParameterTensorNames && t4.hasOwnProperty("quantParameterTensorNames")) {
            if (!Array.isArray(t4.quantParameterTensorNames)) return "quantParameterTensorNames: array expected";
            for (var e2 = 0; e2 < t4.quantParameterTensorNames.length; ++e2) {
              var n2 = l.onnx.StringStringEntryProto.verify(t4.quantParameterTensorNames[e2]);
              if (n2) return "quantParameterTensorNames." + n2;
            }
          }
          return null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.TensorAnnotation) return t4;
          var e2 = new l.onnx.TensorAnnotation();
          if (null != t4.tensorName && (e2.tensorName = String(t4.tensorName)), t4.quantParameterTensorNames) {
            if (!Array.isArray(t4.quantParameterTensorNames)) throw TypeError(".onnx.TensorAnnotation.quantParameterTensorNames: array expected");
            e2.quantParameterTensorNames = [];
            for (var n2 = 0; n2 < t4.quantParameterTensorNames.length; ++n2) {
              if ("object" != typeof t4.quantParameterTensorNames[n2]) throw TypeError(".onnx.TensorAnnotation.quantParameterTensorNames: object expected");
              e2.quantParameterTensorNames[n2] = l.onnx.StringStringEntryProto.fromObject(t4.quantParameterTensorNames[n2]);
            }
          }
          return e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          if ((e2.arrays || e2.defaults) && (n2.quantParameterTensorNames = []), e2.defaults && (n2.tensorName = ""), null != t4.tensorName && t4.hasOwnProperty("tensorName") && (n2.tensorName = t4.tensorName), t4.quantParameterTensorNames && t4.quantParameterTensorNames.length) {
            n2.quantParameterTensorNames = [];
            for (var r2 = 0; r2 < t4.quantParameterTensorNames.length; ++r2) n2.quantParameterTensorNames[r2] = l.onnx.StringStringEntryProto.toObject(t4.quantParameterTensorNames[r2], e2);
          }
          return n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3;
      }(), o.GraphProto = function() {
        function t3(t4) {
          if (this.node = [], this.initializer = [], this.input = [], this.output = [], this.valueInfo = [], this.quantizationAnnotation = [], t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.node = c.emptyArray, t3.prototype.name = "", t3.prototype.initializer = c.emptyArray, t3.prototype.docString = "", t3.prototype.input = c.emptyArray, t3.prototype.output = c.emptyArray, t3.prototype.valueInfo = c.emptyArray, t3.prototype.quantizationAnnotation = c.emptyArray, t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          if (e2 || (e2 = u.create()), null != t4.node && t4.node.length) for (var n2 = 0; n2 < t4.node.length; ++n2) l.onnx.NodeProto.encode(t4.node[n2], e2.uint32(10).fork()).ldelim();
          if (null != t4.name && t4.hasOwnProperty("name") && e2.uint32(18).string(t4.name), null != t4.initializer && t4.initializer.length) for (n2 = 0; n2 < t4.initializer.length; ++n2) l.onnx.TensorProto.encode(t4.initializer[n2], e2.uint32(42).fork()).ldelim();
          if (null != t4.docString && t4.hasOwnProperty("docString") && e2.uint32(82).string(t4.docString), null != t4.input && t4.input.length) for (n2 = 0; n2 < t4.input.length; ++n2) l.onnx.ValueInfoProto.encode(t4.input[n2], e2.uint32(90).fork()).ldelim();
          if (null != t4.output && t4.output.length) for (n2 = 0; n2 < t4.output.length; ++n2) l.onnx.ValueInfoProto.encode(t4.output[n2], e2.uint32(98).fork()).ldelim();
          if (null != t4.valueInfo && t4.valueInfo.length) for (n2 = 0; n2 < t4.valueInfo.length; ++n2) l.onnx.ValueInfoProto.encode(t4.valueInfo[n2], e2.uint32(106).fork()).ldelim();
          if (null != t4.quantizationAnnotation && t4.quantizationAnnotation.length) for (n2 = 0; n2 < t4.quantizationAnnotation.length; ++n2) l.onnx.TensorAnnotation.encode(t4.quantizationAnnotation[n2], e2.uint32(114).fork()).ldelim();
          return e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.GraphProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                r2.node && r2.node.length || (r2.node = []), r2.node.push(l.onnx.NodeProto.decode(t4, t4.uint32()));
                break;
              case 2:
                r2.name = t4.string();
                break;
              case 5:
                r2.initializer && r2.initializer.length || (r2.initializer = []), r2.initializer.push(l.onnx.TensorProto.decode(t4, t4.uint32()));
                break;
              case 10:
                r2.docString = t4.string();
                break;
              case 11:
                r2.input && r2.input.length || (r2.input = []), r2.input.push(l.onnx.ValueInfoProto.decode(t4, t4.uint32()));
                break;
              case 12:
                r2.output && r2.output.length || (r2.output = []), r2.output.push(l.onnx.ValueInfoProto.decode(t4, t4.uint32()));
                break;
              case 13:
                r2.valueInfo && r2.valueInfo.length || (r2.valueInfo = []), r2.valueInfo.push(l.onnx.ValueInfoProto.decode(t4, t4.uint32()));
                break;
              case 14:
                r2.quantizationAnnotation && r2.quantizationAnnotation.length || (r2.quantizationAnnotation = []), r2.quantizationAnnotation.push(l.onnx.TensorAnnotation.decode(t4, t4.uint32()));
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          if ("object" != typeof t4 || null === t4) return "object expected";
          if (null != t4.node && t4.hasOwnProperty("node")) {
            if (!Array.isArray(t4.node)) return "node: array expected";
            for (var e2 = 0; e2 < t4.node.length; ++e2) if (n2 = l.onnx.NodeProto.verify(t4.node[e2])) return "node." + n2;
          }
          if (null != t4.name && t4.hasOwnProperty("name") && !c.isString(t4.name)) return "name: string expected";
          if (null != t4.initializer && t4.hasOwnProperty("initializer")) {
            if (!Array.isArray(t4.initializer)) return "initializer: array expected";
            for (e2 = 0; e2 < t4.initializer.length; ++e2) if (n2 = l.onnx.TensorProto.verify(t4.initializer[e2])) return "initializer." + n2;
          }
          if (null != t4.docString && t4.hasOwnProperty("docString") && !c.isString(t4.docString)) return "docString: string expected";
          if (null != t4.input && t4.hasOwnProperty("input")) {
            if (!Array.isArray(t4.input)) return "input: array expected";
            for (e2 = 0; e2 < t4.input.length; ++e2) if (n2 = l.onnx.ValueInfoProto.verify(t4.input[e2])) return "input." + n2;
          }
          if (null != t4.output && t4.hasOwnProperty("output")) {
            if (!Array.isArray(t4.output)) return "output: array expected";
            for (e2 = 0; e2 < t4.output.length; ++e2) if (n2 = l.onnx.ValueInfoProto.verify(t4.output[e2])) return "output." + n2;
          }
          if (null != t4.valueInfo && t4.hasOwnProperty("valueInfo")) {
            if (!Array.isArray(t4.valueInfo)) return "valueInfo: array expected";
            for (e2 = 0; e2 < t4.valueInfo.length; ++e2) if (n2 = l.onnx.ValueInfoProto.verify(t4.valueInfo[e2])) return "valueInfo." + n2;
          }
          if (null != t4.quantizationAnnotation && t4.hasOwnProperty("quantizationAnnotation")) {
            if (!Array.isArray(t4.quantizationAnnotation)) return "quantizationAnnotation: array expected";
            for (e2 = 0; e2 < t4.quantizationAnnotation.length; ++e2) {
              var n2;
              if (n2 = l.onnx.TensorAnnotation.verify(t4.quantizationAnnotation[e2])) return "quantizationAnnotation." + n2;
            }
          }
          return null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.GraphProto) return t4;
          var e2 = new l.onnx.GraphProto();
          if (t4.node) {
            if (!Array.isArray(t4.node)) throw TypeError(".onnx.GraphProto.node: array expected");
            e2.node = [];
            for (var n2 = 0; n2 < t4.node.length; ++n2) {
              if ("object" != typeof t4.node[n2]) throw TypeError(".onnx.GraphProto.node: object expected");
              e2.node[n2] = l.onnx.NodeProto.fromObject(t4.node[n2]);
            }
          }
          if (null != t4.name && (e2.name = String(t4.name)), t4.initializer) {
            if (!Array.isArray(t4.initializer)) throw TypeError(".onnx.GraphProto.initializer: array expected");
            for (e2.initializer = [], n2 = 0; n2 < t4.initializer.length; ++n2) {
              if ("object" != typeof t4.initializer[n2]) throw TypeError(".onnx.GraphProto.initializer: object expected");
              e2.initializer[n2] = l.onnx.TensorProto.fromObject(t4.initializer[n2]);
            }
          }
          if (null != t4.docString && (e2.docString = String(t4.docString)), t4.input) {
            if (!Array.isArray(t4.input)) throw TypeError(".onnx.GraphProto.input: array expected");
            for (e2.input = [], n2 = 0; n2 < t4.input.length; ++n2) {
              if ("object" != typeof t4.input[n2]) throw TypeError(".onnx.GraphProto.input: object expected");
              e2.input[n2] = l.onnx.ValueInfoProto.fromObject(t4.input[n2]);
            }
          }
          if (t4.output) {
            if (!Array.isArray(t4.output)) throw TypeError(".onnx.GraphProto.output: array expected");
            for (e2.output = [], n2 = 0; n2 < t4.output.length; ++n2) {
              if ("object" != typeof t4.output[n2]) throw TypeError(".onnx.GraphProto.output: object expected");
              e2.output[n2] = l.onnx.ValueInfoProto.fromObject(t4.output[n2]);
            }
          }
          if (t4.valueInfo) {
            if (!Array.isArray(t4.valueInfo)) throw TypeError(".onnx.GraphProto.valueInfo: array expected");
            for (e2.valueInfo = [], n2 = 0; n2 < t4.valueInfo.length; ++n2) {
              if ("object" != typeof t4.valueInfo[n2]) throw TypeError(".onnx.GraphProto.valueInfo: object expected");
              e2.valueInfo[n2] = l.onnx.ValueInfoProto.fromObject(t4.valueInfo[n2]);
            }
          }
          if (t4.quantizationAnnotation) {
            if (!Array.isArray(t4.quantizationAnnotation)) throw TypeError(".onnx.GraphProto.quantizationAnnotation: array expected");
            for (e2.quantizationAnnotation = [], n2 = 0; n2 < t4.quantizationAnnotation.length; ++n2) {
              if ("object" != typeof t4.quantizationAnnotation[n2]) throw TypeError(".onnx.GraphProto.quantizationAnnotation: object expected");
              e2.quantizationAnnotation[n2] = l.onnx.TensorAnnotation.fromObject(t4.quantizationAnnotation[n2]);
            }
          }
          return e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          if ((e2.arrays || e2.defaults) && (n2.node = [], n2.initializer = [], n2.input = [], n2.output = [], n2.valueInfo = [], n2.quantizationAnnotation = []), e2.defaults && (n2.name = "", n2.docString = ""), t4.node && t4.node.length) {
            n2.node = [];
            for (var r2 = 0; r2 < t4.node.length; ++r2) n2.node[r2] = l.onnx.NodeProto.toObject(t4.node[r2], e2);
          }
          if (null != t4.name && t4.hasOwnProperty("name") && (n2.name = t4.name), t4.initializer && t4.initializer.length) for (n2.initializer = [], r2 = 0; r2 < t4.initializer.length; ++r2) n2.initializer[r2] = l.onnx.TensorProto.toObject(t4.initializer[r2], e2);
          if (null != t4.docString && t4.hasOwnProperty("docString") && (n2.docString = t4.docString), t4.input && t4.input.length) for (n2.input = [], r2 = 0; r2 < t4.input.length; ++r2) n2.input[r2] = l.onnx.ValueInfoProto.toObject(t4.input[r2], e2);
          if (t4.output && t4.output.length) for (n2.output = [], r2 = 0; r2 < t4.output.length; ++r2) n2.output[r2] = l.onnx.ValueInfoProto.toObject(t4.output[r2], e2);
          if (t4.valueInfo && t4.valueInfo.length) for (n2.valueInfo = [], r2 = 0; r2 < t4.valueInfo.length; ++r2) n2.valueInfo[r2] = l.onnx.ValueInfoProto.toObject(t4.valueInfo[r2], e2);
          if (t4.quantizationAnnotation && t4.quantizationAnnotation.length) for (n2.quantizationAnnotation = [], r2 = 0; r2 < t4.quantizationAnnotation.length; ++r2) n2.quantizationAnnotation[r2] = l.onnx.TensorAnnotation.toObject(t4.quantizationAnnotation[r2], e2);
          return n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3;
      }(), o.TensorProto = function() {
        function t3(t4) {
          if (this.dims = [], this.floatData = [], this.int32Data = [], this.stringData = [], this.int64Data = [], this.externalData = [], this.doubleData = [], this.uint64Data = [], t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.dims = c.emptyArray, t3.prototype.dataType = 0, t3.prototype.segment = null, t3.prototype.floatData = c.emptyArray, t3.prototype.int32Data = c.emptyArray, t3.prototype.stringData = c.emptyArray, t3.prototype.int64Data = c.emptyArray, t3.prototype.name = "", t3.prototype.docString = "", t3.prototype.rawData = c.newBuffer([]), t3.prototype.externalData = c.emptyArray, t3.prototype.dataLocation = 0, t3.prototype.doubleData = c.emptyArray, t3.prototype.uint64Data = c.emptyArray, t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          if (e2 || (e2 = u.create()), null != t4.dims && t4.dims.length) {
            e2.uint32(10).fork();
            for (var n2 = 0; n2 < t4.dims.length; ++n2) e2.int64(t4.dims[n2]);
            e2.ldelim();
          }
          if (null != t4.dataType && t4.hasOwnProperty("dataType") && e2.uint32(16).int32(t4.dataType), null != t4.segment && t4.hasOwnProperty("segment") && l.onnx.TensorProto.Segment.encode(t4.segment, e2.uint32(26).fork()).ldelim(), null != t4.floatData && t4.floatData.length) {
            for (e2.uint32(34).fork(), n2 = 0; n2 < t4.floatData.length; ++n2) e2.float(t4.floatData[n2]);
            e2.ldelim();
          }
          if (null != t4.int32Data && t4.int32Data.length) {
            for (e2.uint32(42).fork(), n2 = 0; n2 < t4.int32Data.length; ++n2) e2.int32(t4.int32Data[n2]);
            e2.ldelim();
          }
          if (null != t4.stringData && t4.stringData.length) for (n2 = 0; n2 < t4.stringData.length; ++n2) e2.uint32(50).bytes(t4.stringData[n2]);
          if (null != t4.int64Data && t4.int64Data.length) {
            for (e2.uint32(58).fork(), n2 = 0; n2 < t4.int64Data.length; ++n2) e2.int64(t4.int64Data[n2]);
            e2.ldelim();
          }
          if (null != t4.name && t4.hasOwnProperty("name") && e2.uint32(66).string(t4.name), null != t4.rawData && t4.hasOwnProperty("rawData") && e2.uint32(74).bytes(t4.rawData), null != t4.doubleData && t4.doubleData.length) {
            for (e2.uint32(82).fork(), n2 = 0; n2 < t4.doubleData.length; ++n2) e2.double(t4.doubleData[n2]);
            e2.ldelim();
          }
          if (null != t4.uint64Data && t4.uint64Data.length) {
            for (e2.uint32(90).fork(), n2 = 0; n2 < t4.uint64Data.length; ++n2) e2.uint64(t4.uint64Data[n2]);
            e2.ldelim();
          }
          if (null != t4.docString && t4.hasOwnProperty("docString") && e2.uint32(98).string(t4.docString), null != t4.externalData && t4.externalData.length) for (n2 = 0; n2 < t4.externalData.length; ++n2) l.onnx.StringStringEntryProto.encode(t4.externalData[n2], e2.uint32(106).fork()).ldelim();
          return null != t4.dataLocation && t4.hasOwnProperty("dataLocation") && e2.uint32(112).int32(t4.dataLocation), e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.TensorProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                if (r2.dims && r2.dims.length || (r2.dims = []), 2 == (7 & i3)) for (var o2 = t4.uint32() + t4.pos; t4.pos < o2; ) r2.dims.push(t4.int64());
                else r2.dims.push(t4.int64());
                break;
              case 2:
                r2.dataType = t4.int32();
                break;
              case 3:
                r2.segment = l.onnx.TensorProto.Segment.decode(t4, t4.uint32());
                break;
              case 4:
                if (r2.floatData && r2.floatData.length || (r2.floatData = []), 2 == (7 & i3)) for (o2 = t4.uint32() + t4.pos; t4.pos < o2; ) r2.floatData.push(t4.float());
                else r2.floatData.push(t4.float());
                break;
              case 5:
                if (r2.int32Data && r2.int32Data.length || (r2.int32Data = []), 2 == (7 & i3)) for (o2 = t4.uint32() + t4.pos; t4.pos < o2; ) r2.int32Data.push(t4.int32());
                else r2.int32Data.push(t4.int32());
                break;
              case 6:
                r2.stringData && r2.stringData.length || (r2.stringData = []), r2.stringData.push(t4.bytes());
                break;
              case 7:
                if (r2.int64Data && r2.int64Data.length || (r2.int64Data = []), 2 == (7 & i3)) for (o2 = t4.uint32() + t4.pos; t4.pos < o2; ) r2.int64Data.push(t4.int64());
                else r2.int64Data.push(t4.int64());
                break;
              case 8:
                r2.name = t4.string();
                break;
              case 12:
                r2.docString = t4.string();
                break;
              case 9:
                r2.rawData = t4.bytes();
                break;
              case 13:
                r2.externalData && r2.externalData.length || (r2.externalData = []), r2.externalData.push(l.onnx.StringStringEntryProto.decode(t4, t4.uint32()));
                break;
              case 14:
                r2.dataLocation = t4.int32();
                break;
              case 10:
                if (r2.doubleData && r2.doubleData.length || (r2.doubleData = []), 2 == (7 & i3)) for (o2 = t4.uint32() + t4.pos; t4.pos < o2; ) r2.doubleData.push(t4.double());
                else r2.doubleData.push(t4.double());
                break;
              case 11:
                if (r2.uint64Data && r2.uint64Data.length || (r2.uint64Data = []), 2 == (7 & i3)) for (o2 = t4.uint32() + t4.pos; t4.pos < o2; ) r2.uint64Data.push(t4.uint64());
                else r2.uint64Data.push(t4.uint64());
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          if ("object" != typeof t4 || null === t4) return "object expected";
          if (null != t4.dims && t4.hasOwnProperty("dims")) {
            if (!Array.isArray(t4.dims)) return "dims: array expected";
            for (var e2 = 0; e2 < t4.dims.length; ++e2) if (!(c.isInteger(t4.dims[e2]) || t4.dims[e2] && c.isInteger(t4.dims[e2].low) && c.isInteger(t4.dims[e2].high))) return "dims: integer|Long[] expected";
          }
          if (null != t4.dataType && t4.hasOwnProperty("dataType") && !c.isInteger(t4.dataType)) return "dataType: integer expected";
          if (null != t4.segment && t4.hasOwnProperty("segment") && (n2 = l.onnx.TensorProto.Segment.verify(t4.segment))) return "segment." + n2;
          if (null != t4.floatData && t4.hasOwnProperty("floatData")) {
            if (!Array.isArray(t4.floatData)) return "floatData: array expected";
            for (e2 = 0; e2 < t4.floatData.length; ++e2) if ("number" != typeof t4.floatData[e2]) return "floatData: number[] expected";
          }
          if (null != t4.int32Data && t4.hasOwnProperty("int32Data")) {
            if (!Array.isArray(t4.int32Data)) return "int32Data: array expected";
            for (e2 = 0; e2 < t4.int32Data.length; ++e2) if (!c.isInteger(t4.int32Data[e2])) return "int32Data: integer[] expected";
          }
          if (null != t4.stringData && t4.hasOwnProperty("stringData")) {
            if (!Array.isArray(t4.stringData)) return "stringData: array expected";
            for (e2 = 0; e2 < t4.stringData.length; ++e2) if (!(t4.stringData[e2] && "number" == typeof t4.stringData[e2].length || c.isString(t4.stringData[e2]))) return "stringData: buffer[] expected";
          }
          if (null != t4.int64Data && t4.hasOwnProperty("int64Data")) {
            if (!Array.isArray(t4.int64Data)) return "int64Data: array expected";
            for (e2 = 0; e2 < t4.int64Data.length; ++e2) if (!(c.isInteger(t4.int64Data[e2]) || t4.int64Data[e2] && c.isInteger(t4.int64Data[e2].low) && c.isInteger(t4.int64Data[e2].high))) return "int64Data: integer|Long[] expected";
          }
          if (null != t4.name && t4.hasOwnProperty("name") && !c.isString(t4.name)) return "name: string expected";
          if (null != t4.docString && t4.hasOwnProperty("docString") && !c.isString(t4.docString)) return "docString: string expected";
          if (null != t4.rawData && t4.hasOwnProperty("rawData") && !(t4.rawData && "number" == typeof t4.rawData.length || c.isString(t4.rawData))) return "rawData: buffer expected";
          if (null != t4.externalData && t4.hasOwnProperty("externalData")) {
            if (!Array.isArray(t4.externalData)) return "externalData: array expected";
            for (e2 = 0; e2 < t4.externalData.length; ++e2) {
              var n2;
              if (n2 = l.onnx.StringStringEntryProto.verify(t4.externalData[e2])) return "externalData." + n2;
            }
          }
          if (null != t4.dataLocation && t4.hasOwnProperty("dataLocation")) switch (t4.dataLocation) {
            default:
              return "dataLocation: enum value expected";
            case 0:
            case 1:
          }
          if (null != t4.doubleData && t4.hasOwnProperty("doubleData")) {
            if (!Array.isArray(t4.doubleData)) return "doubleData: array expected";
            for (e2 = 0; e2 < t4.doubleData.length; ++e2) if ("number" != typeof t4.doubleData[e2]) return "doubleData: number[] expected";
          }
          if (null != t4.uint64Data && t4.hasOwnProperty("uint64Data")) {
            if (!Array.isArray(t4.uint64Data)) return "uint64Data: array expected";
            for (e2 = 0; e2 < t4.uint64Data.length; ++e2) if (!(c.isInteger(t4.uint64Data[e2]) || t4.uint64Data[e2] && c.isInteger(t4.uint64Data[e2].low) && c.isInteger(t4.uint64Data[e2].high))) return "uint64Data: integer|Long[] expected";
          }
          return null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.TensorProto) return t4;
          var e2 = new l.onnx.TensorProto();
          if (t4.dims) {
            if (!Array.isArray(t4.dims)) throw TypeError(".onnx.TensorProto.dims: array expected");
            e2.dims = [];
            for (var n2 = 0; n2 < t4.dims.length; ++n2) c.Long ? (e2.dims[n2] = c.Long.fromValue(t4.dims[n2])).unsigned = false : "string" == typeof t4.dims[n2] ? e2.dims[n2] = parseInt(t4.dims[n2], 10) : "number" == typeof t4.dims[n2] ? e2.dims[n2] = t4.dims[n2] : "object" == typeof t4.dims[n2] && (e2.dims[n2] = new c.LongBits(t4.dims[n2].low >>> 0, t4.dims[n2].high >>> 0).toNumber());
          }
          if (null != t4.dataType && (e2.dataType = 0 | t4.dataType), null != t4.segment) {
            if ("object" != typeof t4.segment) throw TypeError(".onnx.TensorProto.segment: object expected");
            e2.segment = l.onnx.TensorProto.Segment.fromObject(t4.segment);
          }
          if (t4.floatData) {
            if (!Array.isArray(t4.floatData)) throw TypeError(".onnx.TensorProto.floatData: array expected");
            for (e2.floatData = [], n2 = 0; n2 < t4.floatData.length; ++n2) e2.floatData[n2] = Number(t4.floatData[n2]);
          }
          if (t4.int32Data) {
            if (!Array.isArray(t4.int32Data)) throw TypeError(".onnx.TensorProto.int32Data: array expected");
            for (e2.int32Data = [], n2 = 0; n2 < t4.int32Data.length; ++n2) e2.int32Data[n2] = 0 | t4.int32Data[n2];
          }
          if (t4.stringData) {
            if (!Array.isArray(t4.stringData)) throw TypeError(".onnx.TensorProto.stringData: array expected");
            for (e2.stringData = [], n2 = 0; n2 < t4.stringData.length; ++n2) "string" == typeof t4.stringData[n2] ? c.base64.decode(t4.stringData[n2], e2.stringData[n2] = c.newBuffer(c.base64.length(t4.stringData[n2])), 0) : t4.stringData[n2].length && (e2.stringData[n2] = t4.stringData[n2]);
          }
          if (t4.int64Data) {
            if (!Array.isArray(t4.int64Data)) throw TypeError(".onnx.TensorProto.int64Data: array expected");
            for (e2.int64Data = [], n2 = 0; n2 < t4.int64Data.length; ++n2) c.Long ? (e2.int64Data[n2] = c.Long.fromValue(t4.int64Data[n2])).unsigned = false : "string" == typeof t4.int64Data[n2] ? e2.int64Data[n2] = parseInt(t4.int64Data[n2], 10) : "number" == typeof t4.int64Data[n2] ? e2.int64Data[n2] = t4.int64Data[n2] : "object" == typeof t4.int64Data[n2] && (e2.int64Data[n2] = new c.LongBits(t4.int64Data[n2].low >>> 0, t4.int64Data[n2].high >>> 0).toNumber());
          }
          if (null != t4.name && (e2.name = String(t4.name)), null != t4.docString && (e2.docString = String(t4.docString)), null != t4.rawData && ("string" == typeof t4.rawData ? c.base64.decode(t4.rawData, e2.rawData = c.newBuffer(c.base64.length(t4.rawData)), 0) : t4.rawData.length && (e2.rawData = t4.rawData)), t4.externalData) {
            if (!Array.isArray(t4.externalData)) throw TypeError(".onnx.TensorProto.externalData: array expected");
            for (e2.externalData = [], n2 = 0; n2 < t4.externalData.length; ++n2) {
              if ("object" != typeof t4.externalData[n2]) throw TypeError(".onnx.TensorProto.externalData: object expected");
              e2.externalData[n2] = l.onnx.StringStringEntryProto.fromObject(t4.externalData[n2]);
            }
          }
          switch (t4.dataLocation) {
            case "DEFAULT":
            case 0:
              e2.dataLocation = 0;
              break;
            case "EXTERNAL":
            case 1:
              e2.dataLocation = 1;
          }
          if (t4.doubleData) {
            if (!Array.isArray(t4.doubleData)) throw TypeError(".onnx.TensorProto.doubleData: array expected");
            for (e2.doubleData = [], n2 = 0; n2 < t4.doubleData.length; ++n2) e2.doubleData[n2] = Number(t4.doubleData[n2]);
          }
          if (t4.uint64Data) {
            if (!Array.isArray(t4.uint64Data)) throw TypeError(".onnx.TensorProto.uint64Data: array expected");
            for (e2.uint64Data = [], n2 = 0; n2 < t4.uint64Data.length; ++n2) c.Long ? (e2.uint64Data[n2] = c.Long.fromValue(t4.uint64Data[n2])).unsigned = true : "string" == typeof t4.uint64Data[n2] ? e2.uint64Data[n2] = parseInt(t4.uint64Data[n2], 10) : "number" == typeof t4.uint64Data[n2] ? e2.uint64Data[n2] = t4.uint64Data[n2] : "object" == typeof t4.uint64Data[n2] && (e2.uint64Data[n2] = new c.LongBits(t4.uint64Data[n2].low >>> 0, t4.uint64Data[n2].high >>> 0).toNumber(true));
          }
          return e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          if ((e2.arrays || e2.defaults) && (n2.dims = [], n2.floatData = [], n2.int32Data = [], n2.stringData = [], n2.int64Data = [], n2.doubleData = [], n2.uint64Data = [], n2.externalData = []), e2.defaults && (n2.dataType = 0, n2.segment = null, n2.name = "", e2.bytes === String ? n2.rawData = "" : (n2.rawData = [], e2.bytes !== Array && (n2.rawData = c.newBuffer(n2.rawData))), n2.docString = "", n2.dataLocation = e2.enums === String ? "DEFAULT" : 0), t4.dims && t4.dims.length) {
            n2.dims = [];
            for (var r2 = 0; r2 < t4.dims.length; ++r2) "number" == typeof t4.dims[r2] ? n2.dims[r2] = e2.longs === String ? String(t4.dims[r2]) : t4.dims[r2] : n2.dims[r2] = e2.longs === String ? c.Long.prototype.toString.call(t4.dims[r2]) : e2.longs === Number ? new c.LongBits(t4.dims[r2].low >>> 0, t4.dims[r2].high >>> 0).toNumber() : t4.dims[r2];
          }
          if (null != t4.dataType && t4.hasOwnProperty("dataType") && (n2.dataType = t4.dataType), null != t4.segment && t4.hasOwnProperty("segment") && (n2.segment = l.onnx.TensorProto.Segment.toObject(t4.segment, e2)), t4.floatData && t4.floatData.length) for (n2.floatData = [], r2 = 0; r2 < t4.floatData.length; ++r2) n2.floatData[r2] = e2.json && !isFinite(t4.floatData[r2]) ? String(t4.floatData[r2]) : t4.floatData[r2];
          if (t4.int32Data && t4.int32Data.length) for (n2.int32Data = [], r2 = 0; r2 < t4.int32Data.length; ++r2) n2.int32Data[r2] = t4.int32Data[r2];
          if (t4.stringData && t4.stringData.length) for (n2.stringData = [], r2 = 0; r2 < t4.stringData.length; ++r2) n2.stringData[r2] = e2.bytes === String ? c.base64.encode(t4.stringData[r2], 0, t4.stringData[r2].length) : e2.bytes === Array ? Array.prototype.slice.call(t4.stringData[r2]) : t4.stringData[r2];
          if (t4.int64Data && t4.int64Data.length) for (n2.int64Data = [], r2 = 0; r2 < t4.int64Data.length; ++r2) "number" == typeof t4.int64Data[r2] ? n2.int64Data[r2] = e2.longs === String ? String(t4.int64Data[r2]) : t4.int64Data[r2] : n2.int64Data[r2] = e2.longs === String ? c.Long.prototype.toString.call(t4.int64Data[r2]) : e2.longs === Number ? new c.LongBits(t4.int64Data[r2].low >>> 0, t4.int64Data[r2].high >>> 0).toNumber() : t4.int64Data[r2];
          if (null != t4.name && t4.hasOwnProperty("name") && (n2.name = t4.name), null != t4.rawData && t4.hasOwnProperty("rawData") && (n2.rawData = e2.bytes === String ? c.base64.encode(t4.rawData, 0, t4.rawData.length) : e2.bytes === Array ? Array.prototype.slice.call(t4.rawData) : t4.rawData), t4.doubleData && t4.doubleData.length) for (n2.doubleData = [], r2 = 0; r2 < t4.doubleData.length; ++r2) n2.doubleData[r2] = e2.json && !isFinite(t4.doubleData[r2]) ? String(t4.doubleData[r2]) : t4.doubleData[r2];
          if (t4.uint64Data && t4.uint64Data.length) for (n2.uint64Data = [], r2 = 0; r2 < t4.uint64Data.length; ++r2) "number" == typeof t4.uint64Data[r2] ? n2.uint64Data[r2] = e2.longs === String ? String(t4.uint64Data[r2]) : t4.uint64Data[r2] : n2.uint64Data[r2] = e2.longs === String ? c.Long.prototype.toString.call(t4.uint64Data[r2]) : e2.longs === Number ? new c.LongBits(t4.uint64Data[r2].low >>> 0, t4.uint64Data[r2].high >>> 0).toNumber(true) : t4.uint64Data[r2];
          if (null != t4.docString && t4.hasOwnProperty("docString") && (n2.docString = t4.docString), t4.externalData && t4.externalData.length) for (n2.externalData = [], r2 = 0; r2 < t4.externalData.length; ++r2) n2.externalData[r2] = l.onnx.StringStringEntryProto.toObject(t4.externalData[r2], e2);
          return null != t4.dataLocation && t4.hasOwnProperty("dataLocation") && (n2.dataLocation = e2.enums === String ? l.onnx.TensorProto.DataLocation[t4.dataLocation] : t4.dataLocation), n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3.DataType = function() {
          var t4 = {}, e2 = Object.create(t4);
          return e2[t4[0] = "UNDEFINED"] = 0, e2[t4[1] = "FLOAT"] = 1, e2[t4[2] = "UINT8"] = 2, e2[t4[3] = "INT8"] = 3, e2[t4[4] = "UINT16"] = 4, e2[t4[5] = "INT16"] = 5, e2[t4[6] = "INT32"] = 6, e2[t4[7] = "INT64"] = 7, e2[t4[8] = "STRING"] = 8, e2[t4[9] = "BOOL"] = 9, e2[t4[10] = "FLOAT16"] = 10, e2[t4[11] = "DOUBLE"] = 11, e2[t4[12] = "UINT32"] = 12, e2[t4[13] = "UINT64"] = 13, e2[t4[14] = "COMPLEX64"] = 14, e2[t4[15] = "COMPLEX128"] = 15, e2[t4[16] = "BFLOAT16"] = 16, e2;
        }(), t3.Segment = function() {
          function t4(t5) {
            if (t5) for (var e2 = Object.keys(t5), n2 = 0; n2 < e2.length; ++n2) null != t5[e2[n2]] && (this[e2[n2]] = t5[e2[n2]]);
          }
          return t4.prototype.begin = c.Long ? c.Long.fromBits(0, 0, false) : 0, t4.prototype.end = c.Long ? c.Long.fromBits(0, 0, false) : 0, t4.create = function(e2) {
            return new t4(e2);
          }, t4.encode = function(t5, e2) {
            return e2 || (e2 = u.create()), null != t5.begin && t5.hasOwnProperty("begin") && e2.uint32(8).int64(t5.begin), null != t5.end && t5.hasOwnProperty("end") && e2.uint32(16).int64(t5.end), e2;
          }, t4.encodeDelimited = function(t5, e2) {
            return this.encode(t5, e2).ldelim();
          }, t4.decode = function(t5, e2) {
            t5 instanceof s || (t5 = s.create(t5));
            for (var n2 = void 0 === e2 ? t5.len : t5.pos + e2, r2 = new l.onnx.TensorProto.Segment(); t5.pos < n2; ) {
              var i3 = t5.uint32();
              switch (i3 >>> 3) {
                case 1:
                  r2.begin = t5.int64();
                  break;
                case 2:
                  r2.end = t5.int64();
                  break;
                default:
                  t5.skipType(7 & i3);
              }
            }
            return r2;
          }, t4.decodeDelimited = function(t5) {
            return t5 instanceof s || (t5 = new s(t5)), this.decode(t5, t5.uint32());
          }, t4.verify = function(t5) {
            return "object" != typeof t5 || null === t5 ? "object expected" : null != t5.begin && t5.hasOwnProperty("begin") && !(c.isInteger(t5.begin) || t5.begin && c.isInteger(t5.begin.low) && c.isInteger(t5.begin.high)) ? "begin: integer|Long expected" : null != t5.end && t5.hasOwnProperty("end") && !(c.isInteger(t5.end) || t5.end && c.isInteger(t5.end.low) && c.isInteger(t5.end.high)) ? "end: integer|Long expected" : null;
          }, t4.fromObject = function(t5) {
            if (t5 instanceof l.onnx.TensorProto.Segment) return t5;
            var e2 = new l.onnx.TensorProto.Segment();
            return null != t5.begin && (c.Long ? (e2.begin = c.Long.fromValue(t5.begin)).unsigned = false : "string" == typeof t5.begin ? e2.begin = parseInt(t5.begin, 10) : "number" == typeof t5.begin ? e2.begin = t5.begin : "object" == typeof t5.begin && (e2.begin = new c.LongBits(t5.begin.low >>> 0, t5.begin.high >>> 0).toNumber())), null != t5.end && (c.Long ? (e2.end = c.Long.fromValue(t5.end)).unsigned = false : "string" == typeof t5.end ? e2.end = parseInt(t5.end, 10) : "number" == typeof t5.end ? e2.end = t5.end : "object" == typeof t5.end && (e2.end = new c.LongBits(t5.end.low >>> 0, t5.end.high >>> 0).toNumber())), e2;
          }, t4.toObject = function(t5, e2) {
            e2 || (e2 = {});
            var n2 = {};
            if (e2.defaults) {
              if (c.Long) {
                var r2 = new c.Long(0, 0, false);
                n2.begin = e2.longs === String ? r2.toString() : e2.longs === Number ? r2.toNumber() : r2;
              } else n2.begin = e2.longs === String ? "0" : 0;
              c.Long ? (r2 = new c.Long(0, 0, false), n2.end = e2.longs === String ? r2.toString() : e2.longs === Number ? r2.toNumber() : r2) : n2.end = e2.longs === String ? "0" : 0;
            }
            return null != t5.begin && t5.hasOwnProperty("begin") && ("number" == typeof t5.begin ? n2.begin = e2.longs === String ? String(t5.begin) : t5.begin : n2.begin = e2.longs === String ? c.Long.prototype.toString.call(t5.begin) : e2.longs === Number ? new c.LongBits(t5.begin.low >>> 0, t5.begin.high >>> 0).toNumber() : t5.begin), null != t5.end && t5.hasOwnProperty("end") && ("number" == typeof t5.end ? n2.end = e2.longs === String ? String(t5.end) : t5.end : n2.end = e2.longs === String ? c.Long.prototype.toString.call(t5.end) : e2.longs === Number ? new c.LongBits(t5.end.low >>> 0, t5.end.high >>> 0).toNumber() : t5.end), n2;
          }, t4.prototype.toJSON = function() {
            return this.constructor.toObject(this, a.util.toJSONOptions);
          }, t4;
        }(), t3.DataLocation = function() {
          var t4 = {}, e2 = Object.create(t4);
          return e2[t4[0] = "DEFAULT"] = 0, e2[t4[1] = "EXTERNAL"] = 1, e2;
        }(), t3;
      }(), o.TensorShapeProto = function() {
        function t3(t4) {
          if (this.dim = [], t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.dim = c.emptyArray, t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          if (e2 || (e2 = u.create()), null != t4.dim && t4.dim.length) for (var n2 = 0; n2 < t4.dim.length; ++n2) l.onnx.TensorShapeProto.Dimension.encode(t4.dim[n2], e2.uint32(10).fork()).ldelim();
          return e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.TensorShapeProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            i3 >>> 3 == 1 ? (r2.dim && r2.dim.length || (r2.dim = []), r2.dim.push(l.onnx.TensorShapeProto.Dimension.decode(t4, t4.uint32()))) : t4.skipType(7 & i3);
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          if ("object" != typeof t4 || null === t4) return "object expected";
          if (null != t4.dim && t4.hasOwnProperty("dim")) {
            if (!Array.isArray(t4.dim)) return "dim: array expected";
            for (var e2 = 0; e2 < t4.dim.length; ++e2) {
              var n2 = l.onnx.TensorShapeProto.Dimension.verify(t4.dim[e2]);
              if (n2) return "dim." + n2;
            }
          }
          return null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.TensorShapeProto) return t4;
          var e2 = new l.onnx.TensorShapeProto();
          if (t4.dim) {
            if (!Array.isArray(t4.dim)) throw TypeError(".onnx.TensorShapeProto.dim: array expected");
            e2.dim = [];
            for (var n2 = 0; n2 < t4.dim.length; ++n2) {
              if ("object" != typeof t4.dim[n2]) throw TypeError(".onnx.TensorShapeProto.dim: object expected");
              e2.dim[n2] = l.onnx.TensorShapeProto.Dimension.fromObject(t4.dim[n2]);
            }
          }
          return e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          if ((e2.arrays || e2.defaults) && (n2.dim = []), t4.dim && t4.dim.length) {
            n2.dim = [];
            for (var r2 = 0; r2 < t4.dim.length; ++r2) n2.dim[r2] = l.onnx.TensorShapeProto.Dimension.toObject(t4.dim[r2], e2);
          }
          return n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3.Dimension = function() {
          function t4(t5) {
            if (t5) for (var e3 = Object.keys(t5), n2 = 0; n2 < e3.length; ++n2) null != t5[e3[n2]] && (this[e3[n2]] = t5[e3[n2]]);
          }
          var e2;
          return t4.prototype.dimValue = c.Long ? c.Long.fromBits(0, 0, false) : 0, t4.prototype.dimParam = "", t4.prototype.denotation = "", Object.defineProperty(t4.prototype, "value", { get: c.oneOfGetter(e2 = ["dimValue", "dimParam"]), set: c.oneOfSetter(e2) }), t4.create = function(e3) {
            return new t4(e3);
          }, t4.encode = function(t5, e3) {
            return e3 || (e3 = u.create()), null != t5.dimValue && t5.hasOwnProperty("dimValue") && e3.uint32(8).int64(t5.dimValue), null != t5.dimParam && t5.hasOwnProperty("dimParam") && e3.uint32(18).string(t5.dimParam), null != t5.denotation && t5.hasOwnProperty("denotation") && e3.uint32(26).string(t5.denotation), e3;
          }, t4.encodeDelimited = function(t5, e3) {
            return this.encode(t5, e3).ldelim();
          }, t4.decode = function(t5, e3) {
            t5 instanceof s || (t5 = s.create(t5));
            for (var n2 = void 0 === e3 ? t5.len : t5.pos + e3, r2 = new l.onnx.TensorShapeProto.Dimension(); t5.pos < n2; ) {
              var i3 = t5.uint32();
              switch (i3 >>> 3) {
                case 1:
                  r2.dimValue = t5.int64();
                  break;
                case 2:
                  r2.dimParam = t5.string();
                  break;
                case 3:
                  r2.denotation = t5.string();
                  break;
                default:
                  t5.skipType(7 & i3);
              }
            }
            return r2;
          }, t4.decodeDelimited = function(t5) {
            return t5 instanceof s || (t5 = new s(t5)), this.decode(t5, t5.uint32());
          }, t4.verify = function(t5) {
            if ("object" != typeof t5 || null === t5) return "object expected";
            var e3 = {};
            if (null != t5.dimValue && t5.hasOwnProperty("dimValue") && (e3.value = 1, !(c.isInteger(t5.dimValue) || t5.dimValue && c.isInteger(t5.dimValue.low) && c.isInteger(t5.dimValue.high)))) return "dimValue: integer|Long expected";
            if (null != t5.dimParam && t5.hasOwnProperty("dimParam")) {
              if (1 === e3.value) return "value: multiple values";
              if (e3.value = 1, !c.isString(t5.dimParam)) return "dimParam: string expected";
            }
            return null != t5.denotation && t5.hasOwnProperty("denotation") && !c.isString(t5.denotation) ? "denotation: string expected" : null;
          }, t4.fromObject = function(t5) {
            if (t5 instanceof l.onnx.TensorShapeProto.Dimension) return t5;
            var e3 = new l.onnx.TensorShapeProto.Dimension();
            return null != t5.dimValue && (c.Long ? (e3.dimValue = c.Long.fromValue(t5.dimValue)).unsigned = false : "string" == typeof t5.dimValue ? e3.dimValue = parseInt(t5.dimValue, 10) : "number" == typeof t5.dimValue ? e3.dimValue = t5.dimValue : "object" == typeof t5.dimValue && (e3.dimValue = new c.LongBits(t5.dimValue.low >>> 0, t5.dimValue.high >>> 0).toNumber())), null != t5.dimParam && (e3.dimParam = String(t5.dimParam)), null != t5.denotation && (e3.denotation = String(t5.denotation)), e3;
          }, t4.toObject = function(t5, e3) {
            e3 || (e3 = {});
            var n2 = {};
            return e3.defaults && (n2.denotation = ""), null != t5.dimValue && t5.hasOwnProperty("dimValue") && ("number" == typeof t5.dimValue ? n2.dimValue = e3.longs === String ? String(t5.dimValue) : t5.dimValue : n2.dimValue = e3.longs === String ? c.Long.prototype.toString.call(t5.dimValue) : e3.longs === Number ? new c.LongBits(t5.dimValue.low >>> 0, t5.dimValue.high >>> 0).toNumber() : t5.dimValue, e3.oneofs && (n2.value = "dimValue")), null != t5.dimParam && t5.hasOwnProperty("dimParam") && (n2.dimParam = t5.dimParam, e3.oneofs && (n2.value = "dimParam")), null != t5.denotation && t5.hasOwnProperty("denotation") && (n2.denotation = t5.denotation), n2;
          }, t4.prototype.toJSON = function() {
            return this.constructor.toObject(this, a.util.toJSONOptions);
          }, t4;
        }(), t3;
      }(), o.TypeProto = function() {
        function t3(t4) {
          if (t4) for (var e3 = Object.keys(t4), n2 = 0; n2 < e3.length; ++n2) null != t4[e3[n2]] && (this[e3[n2]] = t4[e3[n2]]);
        }
        var e2;
        return t3.prototype.tensorType = null, t3.prototype.denotation = "", Object.defineProperty(t3.prototype, "value", { get: c.oneOfGetter(e2 = ["tensorType"]), set: c.oneOfSetter(e2) }), t3.create = function(e3) {
          return new t3(e3);
        }, t3.encode = function(t4, e3) {
          return e3 || (e3 = u.create()), null != t4.tensorType && t4.hasOwnProperty("tensorType") && l.onnx.TypeProto.Tensor.encode(t4.tensorType, e3.uint32(10).fork()).ldelim(), null != t4.denotation && t4.hasOwnProperty("denotation") && e3.uint32(50).string(t4.denotation), e3;
        }, t3.encodeDelimited = function(t4, e3) {
          return this.encode(t4, e3).ldelim();
        }, t3.decode = function(t4, e3) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e3 ? t4.len : t4.pos + e3, r2 = new l.onnx.TypeProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                r2.tensorType = l.onnx.TypeProto.Tensor.decode(t4, t4.uint32());
                break;
              case 6:
                r2.denotation = t4.string();
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          if ("object" != typeof t4 || null === t4) return "object expected";
          if (null != t4.tensorType && t4.hasOwnProperty("tensorType")) {
            var e3 = l.onnx.TypeProto.Tensor.verify(t4.tensorType);
            if (e3) return "tensorType." + e3;
          }
          return null != t4.denotation && t4.hasOwnProperty("denotation") && !c.isString(t4.denotation) ? "denotation: string expected" : null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.TypeProto) return t4;
          var e3 = new l.onnx.TypeProto();
          if (null != t4.tensorType) {
            if ("object" != typeof t4.tensorType) throw TypeError(".onnx.TypeProto.tensorType: object expected");
            e3.tensorType = l.onnx.TypeProto.Tensor.fromObject(t4.tensorType);
          }
          return null != t4.denotation && (e3.denotation = String(t4.denotation)), e3;
        }, t3.toObject = function(t4, e3) {
          e3 || (e3 = {});
          var n2 = {};
          return e3.defaults && (n2.denotation = ""), null != t4.tensorType && t4.hasOwnProperty("tensorType") && (n2.tensorType = l.onnx.TypeProto.Tensor.toObject(t4.tensorType, e3), e3.oneofs && (n2.value = "tensorType")), null != t4.denotation && t4.hasOwnProperty("denotation") && (n2.denotation = t4.denotation), n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3.Tensor = function() {
          function t4(t5) {
            if (t5) for (var e3 = Object.keys(t5), n2 = 0; n2 < e3.length; ++n2) null != t5[e3[n2]] && (this[e3[n2]] = t5[e3[n2]]);
          }
          return t4.prototype.elemType = 0, t4.prototype.shape = null, t4.create = function(e3) {
            return new t4(e3);
          }, t4.encode = function(t5, e3) {
            return e3 || (e3 = u.create()), null != t5.elemType && t5.hasOwnProperty("elemType") && e3.uint32(8).int32(t5.elemType), null != t5.shape && t5.hasOwnProperty("shape") && l.onnx.TensorShapeProto.encode(t5.shape, e3.uint32(18).fork()).ldelim(), e3;
          }, t4.encodeDelimited = function(t5, e3) {
            return this.encode(t5, e3).ldelim();
          }, t4.decode = function(t5, e3) {
            t5 instanceof s || (t5 = s.create(t5));
            for (var n2 = void 0 === e3 ? t5.len : t5.pos + e3, r2 = new l.onnx.TypeProto.Tensor(); t5.pos < n2; ) {
              var i3 = t5.uint32();
              switch (i3 >>> 3) {
                case 1:
                  r2.elemType = t5.int32();
                  break;
                case 2:
                  r2.shape = l.onnx.TensorShapeProto.decode(t5, t5.uint32());
                  break;
                default:
                  t5.skipType(7 & i3);
              }
            }
            return r2;
          }, t4.decodeDelimited = function(t5) {
            return t5 instanceof s || (t5 = new s(t5)), this.decode(t5, t5.uint32());
          }, t4.verify = function(t5) {
            if ("object" != typeof t5 || null === t5) return "object expected";
            if (null != t5.elemType && t5.hasOwnProperty("elemType") && !c.isInteger(t5.elemType)) return "elemType: integer expected";
            if (null != t5.shape && t5.hasOwnProperty("shape")) {
              var e3 = l.onnx.TensorShapeProto.verify(t5.shape);
              if (e3) return "shape." + e3;
            }
            return null;
          }, t4.fromObject = function(t5) {
            if (t5 instanceof l.onnx.TypeProto.Tensor) return t5;
            var e3 = new l.onnx.TypeProto.Tensor();
            if (null != t5.elemType && (e3.elemType = 0 | t5.elemType), null != t5.shape) {
              if ("object" != typeof t5.shape) throw TypeError(".onnx.TypeProto.Tensor.shape: object expected");
              e3.shape = l.onnx.TensorShapeProto.fromObject(t5.shape);
            }
            return e3;
          }, t4.toObject = function(t5, e3) {
            e3 || (e3 = {});
            var n2 = {};
            return e3.defaults && (n2.elemType = 0, n2.shape = null), null != t5.elemType && t5.hasOwnProperty("elemType") && (n2.elemType = t5.elemType), null != t5.shape && t5.hasOwnProperty("shape") && (n2.shape = l.onnx.TensorShapeProto.toObject(t5.shape, e3)), n2;
          }, t4.prototype.toJSON = function() {
            return this.constructor.toObject(this, a.util.toJSONOptions);
          }, t4;
        }(), t3;
      }(), o.OperatorSetIdProto = function() {
        function t3(t4) {
          if (t4) for (var e2 = Object.keys(t4), n2 = 0; n2 < e2.length; ++n2) null != t4[e2[n2]] && (this[e2[n2]] = t4[e2[n2]]);
        }
        return t3.prototype.domain = "", t3.prototype.version = c.Long ? c.Long.fromBits(0, 0, false) : 0, t3.create = function(e2) {
          return new t3(e2);
        }, t3.encode = function(t4, e2) {
          return e2 || (e2 = u.create()), null != t4.domain && t4.hasOwnProperty("domain") && e2.uint32(10).string(t4.domain), null != t4.version && t4.hasOwnProperty("version") && e2.uint32(16).int64(t4.version), e2;
        }, t3.encodeDelimited = function(t4, e2) {
          return this.encode(t4, e2).ldelim();
        }, t3.decode = function(t4, e2) {
          t4 instanceof s || (t4 = s.create(t4));
          for (var n2 = void 0 === e2 ? t4.len : t4.pos + e2, r2 = new l.onnx.OperatorSetIdProto(); t4.pos < n2; ) {
            var i3 = t4.uint32();
            switch (i3 >>> 3) {
              case 1:
                r2.domain = t4.string();
                break;
              case 2:
                r2.version = t4.int64();
                break;
              default:
                t4.skipType(7 & i3);
            }
          }
          return r2;
        }, t3.decodeDelimited = function(t4) {
          return t4 instanceof s || (t4 = new s(t4)), this.decode(t4, t4.uint32());
        }, t3.verify = function(t4) {
          return "object" != typeof t4 || null === t4 ? "object expected" : null != t4.domain && t4.hasOwnProperty("domain") && !c.isString(t4.domain) ? "domain: string expected" : null != t4.version && t4.hasOwnProperty("version") && !(c.isInteger(t4.version) || t4.version && c.isInteger(t4.version.low) && c.isInteger(t4.version.high)) ? "version: integer|Long expected" : null;
        }, t3.fromObject = function(t4) {
          if (t4 instanceof l.onnx.OperatorSetIdProto) return t4;
          var e2 = new l.onnx.OperatorSetIdProto();
          return null != t4.domain && (e2.domain = String(t4.domain)), null != t4.version && (c.Long ? (e2.version = c.Long.fromValue(t4.version)).unsigned = false : "string" == typeof t4.version ? e2.version = parseInt(t4.version, 10) : "number" == typeof t4.version ? e2.version = t4.version : "object" == typeof t4.version && (e2.version = new c.LongBits(t4.version.low >>> 0, t4.version.high >>> 0).toNumber())), e2;
        }, t3.toObject = function(t4, e2) {
          e2 || (e2 = {});
          var n2 = {};
          if (e2.defaults) if (n2.domain = "", c.Long) {
            var r2 = new c.Long(0, 0, false);
            n2.version = e2.longs === String ? r2.toString() : e2.longs === Number ? r2.toNumber() : r2;
          } else n2.version = e2.longs === String ? "0" : 0;
          return null != t4.domain && t4.hasOwnProperty("domain") && (n2.domain = t4.domain), null != t4.version && t4.hasOwnProperty("version") && ("number" == typeof t4.version ? n2.version = e2.longs === String ? String(t4.version) : t4.version : n2.version = e2.longs === String ? c.Long.prototype.toString.call(t4.version) : e2.longs === Number ? new c.LongBits(t4.version.low >>> 0, t4.version.high >>> 0).toNumber() : t4.version), n2;
        }, t3.prototype.toJSON = function() {
          return this.constructor.toObject(this, a.util.toJSONOptions);
        }, t3;
      }(), o), t2.exports = l;
    }, 2100: (t2, e, n) => {
      t2.exports = n(9482);
    }, 9482: (t2, e, n) => {
      var r = e;
      function i2() {
        r.util._configure(), r.Writer._configure(r.BufferWriter), r.Reader._configure(r.BufferReader);
      }
      r.build = "minimal", r.Writer = n(1173), r.BufferWriter = n(3155), r.Reader = n(1408), r.BufferReader = n(593), r.util = n(9693), r.rpc = n(5994), r.roots = n(5054), r.configure = i2, i2();
    }, 1408: (t2, e, n) => {
      t2.exports = u;
      var r, i2 = n(9693), o = i2.LongBits, a = i2.utf8;
      function s(t3, e2) {
        return RangeError("index out of range: " + t3.pos + " + " + (e2 || 1) + " > " + t3.len);
      }
      function u(t3) {
        this.buf = t3, this.pos = 0, this.len = t3.length;
      }
      var c, l = "undefined" != typeof Uint8Array ? function(t3) {
        if (t3 instanceof Uint8Array || Array.isArray(t3)) return new u(t3);
        throw Error("illegal buffer");
      } : function(t3) {
        if (Array.isArray(t3)) return new u(t3);
        throw Error("illegal buffer");
      }, p = function() {
        return i2.Buffer ? function(t3) {
          return (u.create = function(t4) {
            return i2.Buffer.isBuffer(t4) ? new r(t4) : l(t4);
          })(t3);
        } : l;
      };
      function f() {
        var t3 = new o(0, 0), e2 = 0;
        if (!(this.len - this.pos > 4)) {
          for (; e2 < 3; ++e2) {
            if (this.pos >= this.len) throw s(this);
            if (t3.lo = (t3.lo | (127 & this.buf[this.pos]) << 7 * e2) >>> 0, this.buf[this.pos++] < 128) return t3;
          }
          return t3.lo = (t3.lo | (127 & this.buf[this.pos++]) << 7 * e2) >>> 0, t3;
        }
        for (; e2 < 4; ++e2) if (t3.lo = (t3.lo | (127 & this.buf[this.pos]) << 7 * e2) >>> 0, this.buf[this.pos++] < 128) return t3;
        if (t3.lo = (t3.lo | (127 & this.buf[this.pos]) << 28) >>> 0, t3.hi = (t3.hi | (127 & this.buf[this.pos]) >> 4) >>> 0, this.buf[this.pos++] < 128) return t3;
        if (e2 = 0, this.len - this.pos > 4) {
          for (; e2 < 5; ++e2) if (t3.hi = (t3.hi | (127 & this.buf[this.pos]) << 7 * e2 + 3) >>> 0, this.buf[this.pos++] < 128) return t3;
        } else for (; e2 < 5; ++e2) {
          if (this.pos >= this.len) throw s(this);
          if (t3.hi = (t3.hi | (127 & this.buf[this.pos]) << 7 * e2 + 3) >>> 0, this.buf[this.pos++] < 128) return t3;
        }
        throw Error("invalid varint encoding");
      }
      function d(t3, e2) {
        return (t3[e2 - 4] | t3[e2 - 3] << 8 | t3[e2 - 2] << 16 | t3[e2 - 1] << 24) >>> 0;
      }
      function h() {
        if (this.pos + 8 > this.len) throw s(this, 8);
        return new o(d(this.buf, this.pos += 4), d(this.buf, this.pos += 4));
      }
      u.create = p(), u.prototype._slice = i2.Array.prototype.subarray || i2.Array.prototype.slice, u.prototype.uint32 = (c = 4294967295, function() {
        if (c = (127 & this.buf[this.pos]) >>> 0, this.buf[this.pos++] < 128) return c;
        if (c = (c | (127 & this.buf[this.pos]) << 7) >>> 0, this.buf[this.pos++] < 128) return c;
        if (c = (c | (127 & this.buf[this.pos]) << 14) >>> 0, this.buf[this.pos++] < 128) return c;
        if (c = (c | (127 & this.buf[this.pos]) << 21) >>> 0, this.buf[this.pos++] < 128) return c;
        if (c = (c | (15 & this.buf[this.pos]) << 28) >>> 0, this.buf[this.pos++] < 128) return c;
        if ((this.pos += 5) > this.len) throw this.pos = this.len, s(this, 10);
        return c;
      }), u.prototype.int32 = function() {
        return 0 | this.uint32();
      }, u.prototype.sint32 = function() {
        var t3 = this.uint32();
        return t3 >>> 1 ^ -(1 & t3) | 0;
      }, u.prototype.bool = function() {
        return 0 !== this.uint32();
      }, u.prototype.fixed32 = function() {
        if (this.pos + 4 > this.len) throw s(this, 4);
        return d(this.buf, this.pos += 4);
      }, u.prototype.sfixed32 = function() {
        if (this.pos + 4 > this.len) throw s(this, 4);
        return 0 | d(this.buf, this.pos += 4);
      }, u.prototype.float = function() {
        if (this.pos + 4 > this.len) throw s(this, 4);
        var t3 = i2.float.readFloatLE(this.buf, this.pos);
        return this.pos += 4, t3;
      }, u.prototype.double = function() {
        if (this.pos + 8 > this.len) throw s(this, 4);
        var t3 = i2.float.readDoubleLE(this.buf, this.pos);
        return this.pos += 8, t3;
      }, u.prototype.bytes = function() {
        var t3 = this.uint32(), e2 = this.pos, n2 = this.pos + t3;
        if (n2 > this.len) throw s(this, t3);
        return this.pos += t3, Array.isArray(this.buf) ? this.buf.slice(e2, n2) : e2 === n2 ? new this.buf.constructor(0) : this._slice.call(this.buf, e2, n2);
      }, u.prototype.string = function() {
        var t3 = this.bytes();
        return a.read(t3, 0, t3.length);
      }, u.prototype.skip = function(t3) {
        if ("number" == typeof t3) {
          if (this.pos + t3 > this.len) throw s(this, t3);
          this.pos += t3;
        } else do {
          if (this.pos >= this.len) throw s(this);
        } while (128 & this.buf[this.pos++]);
        return this;
      }, u.prototype.skipType = function(t3) {
        switch (t3) {
          case 0:
            this.skip();
            break;
          case 1:
            this.skip(8);
            break;
          case 2:
            this.skip(this.uint32());
            break;
          case 3:
            for (; 4 != (t3 = 7 & this.uint32()); ) this.skipType(t3);
            break;
          case 5:
            this.skip(4);
            break;
          default:
            throw Error("invalid wire type " + t3 + " at offset " + this.pos);
        }
        return this;
      }, u._configure = function(t3) {
        r = t3, u.create = p(), r._configure();
        var e2 = i2.Long ? "toLong" : "toNumber";
        i2.merge(u.prototype, { int64: function() {
          return f.call(this)[e2](false);
        }, uint64: function() {
          return f.call(this)[e2](true);
        }, sint64: function() {
          return f.call(this).zzDecode()[e2](false);
        }, fixed64: function() {
          return h.call(this)[e2](true);
        }, sfixed64: function() {
          return h.call(this)[e2](false);
        } });
      };
    }, 593: (t2, e, n) => {
      t2.exports = o;
      var r = n(1408);
      (o.prototype = Object.create(r.prototype)).constructor = o;
      var i2 = n(9693);
      function o(t3) {
        r.call(this, t3);
      }
      o._configure = function() {
        i2.Buffer && (o.prototype._slice = i2.Buffer.prototype.slice);
      }, o.prototype.string = function() {
        var t3 = this.uint32();
        return this.buf.utf8Slice ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + t3, this.len)) : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + t3, this.len));
      }, o._configure();
    }, 5054: (t2) => {
      t2.exports = {};
    }, 5994: (t2, e, n) => {
      e.Service = n(7948);
    }, 7948: (t2, e, n) => {
      t2.exports = i2;
      var r = n(9693);
      function i2(t3, e2, n2) {
        if ("function" != typeof t3) throw TypeError("rpcImpl must be a function");
        r.EventEmitter.call(this), this.rpcImpl = t3, this.requestDelimited = Boolean(e2), this.responseDelimited = Boolean(n2);
      }
      (i2.prototype = Object.create(r.EventEmitter.prototype)).constructor = i2, i2.prototype.rpcCall = function t3(e2, n2, i3, o, a) {
        if (!o) throw TypeError("request must be specified");
        var s = this;
        if (!a) return r.asPromise(t3, s, e2, n2, i3, o);
        if (s.rpcImpl) try {
          return s.rpcImpl(e2, n2[s.requestDelimited ? "encodeDelimited" : "encode"](o).finish(), function(t4, n3) {
            if (t4) return s.emit("error", t4, e2), a(t4);
            if (null !== n3) {
              if (!(n3 instanceof i3)) try {
                n3 = i3[s.responseDelimited ? "decodeDelimited" : "decode"](n3);
              } catch (t5) {
                return s.emit("error", t5, e2), a(t5);
              }
              return s.emit("data", n3, e2), a(null, n3);
            }
            s.end(true);
          });
        } catch (t4) {
          return s.emit("error", t4, e2), void setTimeout(function() {
            a(t4);
          }, 0);
        }
        else setTimeout(function() {
          a(Error("already ended"));
        }, 0);
      }, i2.prototype.end = function(t3) {
        return this.rpcImpl && (t3 || this.rpcImpl(null, null, null), this.rpcImpl = null, this.emit("end").off()), this;
      };
    }, 1945: (t2, e, n) => {
      t2.exports = i2;
      var r = n(9693);
      function i2(t3, e2) {
        this.lo = t3 >>> 0, this.hi = e2 >>> 0;
      }
      var o = i2.zero = new i2(0, 0);
      o.toNumber = function() {
        return 0;
      }, o.zzEncode = o.zzDecode = function() {
        return this;
      }, o.length = function() {
        return 1;
      };
      var a = i2.zeroHash = "\0\0\0\0\0\0\0\0";
      i2.fromNumber = function(t3) {
        if (0 === t3) return o;
        var e2 = t3 < 0;
        e2 && (t3 = -t3);
        var n2 = t3 >>> 0, r2 = (t3 - n2) / 4294967296 >>> 0;
        return e2 && (r2 = ~r2 >>> 0, n2 = ~n2 >>> 0, ++n2 > 4294967295 && (n2 = 0, ++r2 > 4294967295 && (r2 = 0))), new i2(n2, r2);
      }, i2.from = function(t3) {
        if ("number" == typeof t3) return i2.fromNumber(t3);
        if (r.isString(t3)) {
          if (!r.Long) return i2.fromNumber(parseInt(t3, 10));
          t3 = r.Long.fromString(t3);
        }
        return t3.low || t3.high ? new i2(t3.low >>> 0, t3.high >>> 0) : o;
      }, i2.prototype.toNumber = function(t3) {
        if (!t3 && this.hi >>> 31) {
          var e2 = 1 + ~this.lo >>> 0, n2 = ~this.hi >>> 0;
          return e2 || (n2 = n2 + 1 >>> 0), -(e2 + 4294967296 * n2);
        }
        return this.lo + 4294967296 * this.hi;
      }, i2.prototype.toLong = function(t3) {
        return r.Long ? new r.Long(0 | this.lo, 0 | this.hi, Boolean(t3)) : { low: 0 | this.lo, high: 0 | this.hi, unsigned: Boolean(t3) };
      };
      var s = String.prototype.charCodeAt;
      i2.fromHash = function(t3) {
        return t3 === a ? o : new i2((s.call(t3, 0) | s.call(t3, 1) << 8 | s.call(t3, 2) << 16 | s.call(t3, 3) << 24) >>> 0, (s.call(t3, 4) | s.call(t3, 5) << 8 | s.call(t3, 6) << 16 | s.call(t3, 7) << 24) >>> 0);
      }, i2.prototype.toHash = function() {
        return String.fromCharCode(255 & this.lo, this.lo >>> 8 & 255, this.lo >>> 16 & 255, this.lo >>> 24, 255 & this.hi, this.hi >>> 8 & 255, this.hi >>> 16 & 255, this.hi >>> 24);
      }, i2.prototype.zzEncode = function() {
        var t3 = this.hi >> 31;
        return this.hi = ((this.hi << 1 | this.lo >>> 31) ^ t3) >>> 0, this.lo = (this.lo << 1 ^ t3) >>> 0, this;
      }, i2.prototype.zzDecode = function() {
        var t3 = -(1 & this.lo);
        return this.lo = ((this.lo >>> 1 | this.hi << 31) ^ t3) >>> 0, this.hi = (this.hi >>> 1 ^ t3) >>> 0, this;
      }, i2.prototype.length = function() {
        var t3 = this.lo, e2 = (this.lo >>> 28 | this.hi << 4) >>> 0, n2 = this.hi >>> 24;
        return 0 === n2 ? 0 === e2 ? t3 < 16384 ? t3 < 128 ? 1 : 2 : t3 < 2097152 ? 3 : 4 : e2 < 16384 ? e2 < 128 ? 5 : 6 : e2 < 2097152 ? 7 : 8 : n2 < 128 ? 9 : 10;
      };
    }, 9693: function(t2, e, n) {
      var r = e;
      function i2(t3, e2, n2) {
        for (var r2 = Object.keys(e2), i3 = 0; i3 < r2.length; ++i3) void 0 !== t3[r2[i3]] && n2 || (t3[r2[i3]] = e2[r2[i3]]);
        return t3;
      }
      function o(t3) {
        function e2(t4, n2) {
          if (!(this instanceof e2)) return new e2(t4, n2);
          Object.defineProperty(this, "message", { get: function() {
            return t4;
          } }), Error.captureStackTrace ? Error.captureStackTrace(this, e2) : Object.defineProperty(this, "stack", { value: new Error().stack || "" }), n2 && i2(this, n2);
        }
        return (e2.prototype = Object.create(Error.prototype)).constructor = e2, Object.defineProperty(e2.prototype, "name", { get: function() {
          return t3;
        } }), e2.prototype.toString = function() {
          return this.name + ": " + this.message;
        }, e2;
      }
      r.asPromise = n(4537), r.base64 = n(7419), r.EventEmitter = n(9211), r.float = n(945), r.inquire = n(7199), r.utf8 = n(4997), r.pool = n(6662), r.LongBits = n(1945), r.isNode = Boolean("undefined" != typeof commonjsGlobal && commonjsGlobal && commonjsGlobal.process && commonjsGlobal.process.versions && commonjsGlobal.process.versions.node), r.global = r.isNode && commonjsGlobal || "undefined" != typeof window && window || "undefined" != typeof self && self || this, r.emptyArray = Object.freeze ? Object.freeze([]) : [], r.emptyObject = Object.freeze ? Object.freeze({}) : {}, r.isInteger = Number.isInteger || function(t3) {
        return "number" == typeof t3 && isFinite(t3) && Math.floor(t3) === t3;
      }, r.isString = function(t3) {
        return "string" == typeof t3 || t3 instanceof String;
      }, r.isObject = function(t3) {
        return t3 && "object" == typeof t3;
      }, r.isset = r.isSet = function(t3, e2) {
        var n2 = t3[e2];
        return !(null == n2 || !t3.hasOwnProperty(e2)) && ("object" != typeof n2 || (Array.isArray(n2) ? n2.length : Object.keys(n2).length) > 0);
      }, r.Buffer = function() {
        try {
          var t3 = r.inquire("buffer").Buffer;
          return t3.prototype.utf8Write ? t3 : null;
        } catch (t4) {
          return null;
        }
      }(), r._Buffer_from = null, r._Buffer_allocUnsafe = null, r.newBuffer = function(t3) {
        return "number" == typeof t3 ? r.Buffer ? r._Buffer_allocUnsafe(t3) : new r.Array(t3) : r.Buffer ? r._Buffer_from(t3) : "undefined" == typeof Uint8Array ? t3 : new Uint8Array(t3);
      }, r.Array = "undefined" != typeof Uint8Array ? Uint8Array : Array, r.Long = r.global.dcodeIO && r.global.dcodeIO.Long || r.global.Long || r.inquire("long"), r.key2Re = /^true|false|0|1$/, r.key32Re = /^-?(?:0|[1-9][0-9]*)$/, r.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/, r.longToHash = function(t3) {
        return t3 ? r.LongBits.from(t3).toHash() : r.LongBits.zeroHash;
      }, r.longFromHash = function(t3, e2) {
        var n2 = r.LongBits.fromHash(t3);
        return r.Long ? r.Long.fromBits(n2.lo, n2.hi, e2) : n2.toNumber(Boolean(e2));
      }, r.merge = i2, r.lcFirst = function(t3) {
        return t3.charAt(0).toLowerCase() + t3.substring(1);
      }, r.newError = o, r.ProtocolError = o("ProtocolError"), r.oneOfGetter = function(t3) {
        for (var e2 = {}, n2 = 0; n2 < t3.length; ++n2) e2[t3[n2]] = 1;
        return function() {
          for (var t4 = Object.keys(this), n3 = t4.length - 1; n3 > -1; --n3) if (1 === e2[t4[n3]] && void 0 !== this[t4[n3]] && null !== this[t4[n3]]) return t4[n3];
        };
      }, r.oneOfSetter = function(t3) {
        return function(e2) {
          for (var n2 = 0; n2 < t3.length; ++n2) t3[n2] !== e2 && delete this[t3[n2]];
        };
      }, r.toJSONOptions = { longs: String, enums: String, bytes: String, json: true }, r._configure = function() {
        var t3 = r.Buffer;
        t3 ? (r._Buffer_from = t3.from !== Uint8Array.from && t3.from || function(e2, n2) {
          return new t3(e2, n2);
        }, r._Buffer_allocUnsafe = t3.allocUnsafe || function(e2) {
          return new t3(e2);
        }) : r._Buffer_from = r._Buffer_allocUnsafe = null;
      };
    }, 1173: (t2, e, n) => {
      t2.exports = p;
      var r, i2 = n(9693), o = i2.LongBits, a = i2.base64, s = i2.utf8;
      function u(t3, e2, n2) {
        this.fn = t3, this.len = e2, this.next = void 0, this.val = n2;
      }
      function c() {
      }
      function l(t3) {
        this.head = t3.head, this.tail = t3.tail, this.len = t3.len, this.next = t3.states;
      }
      function p() {
        this.len = 0, this.head = new u(c, 0, 0), this.tail = this.head, this.states = null;
      }
      var f = function() {
        return i2.Buffer ? function() {
          return (p.create = function() {
            return new r();
          })();
        } : function() {
          return new p();
        };
      };
      function d(t3, e2, n2) {
        e2[n2] = 255 & t3;
      }
      function h(t3, e2) {
        this.len = t3, this.next = void 0, this.val = e2;
      }
      function g(t3, e2, n2) {
        for (; t3.hi; ) e2[n2++] = 127 & t3.lo | 128, t3.lo = (t3.lo >>> 7 | t3.hi << 25) >>> 0, t3.hi >>>= 7;
        for (; t3.lo > 127; ) e2[n2++] = 127 & t3.lo | 128, t3.lo = t3.lo >>> 7;
        e2[n2++] = t3.lo;
      }
      function b(t3, e2, n2) {
        e2[n2] = 255 & t3, e2[n2 + 1] = t3 >>> 8 & 255, e2[n2 + 2] = t3 >>> 16 & 255, e2[n2 + 3] = t3 >>> 24;
      }
      p.create = f(), p.alloc = function(t3) {
        return new i2.Array(t3);
      }, i2.Array !== Array && (p.alloc = i2.pool(p.alloc, i2.Array.prototype.subarray)), p.prototype._push = function(t3, e2, n2) {
        return this.tail = this.tail.next = new u(t3, e2, n2), this.len += e2, this;
      }, h.prototype = Object.create(u.prototype), h.prototype.fn = function(t3, e2, n2) {
        for (; t3 > 127; ) e2[n2++] = 127 & t3 | 128, t3 >>>= 7;
        e2[n2] = t3;
      }, p.prototype.uint32 = function(t3) {
        return this.len += (this.tail = this.tail.next = new h((t3 >>>= 0) < 128 ? 1 : t3 < 16384 ? 2 : t3 < 2097152 ? 3 : t3 < 268435456 ? 4 : 5, t3)).len, this;
      }, p.prototype.int32 = function(t3) {
        return t3 < 0 ? this._push(g, 10, o.fromNumber(t3)) : this.uint32(t3);
      }, p.prototype.sint32 = function(t3) {
        return this.uint32((t3 << 1 ^ t3 >> 31) >>> 0);
      }, p.prototype.uint64 = function(t3) {
        var e2 = o.from(t3);
        return this._push(g, e2.length(), e2);
      }, p.prototype.int64 = p.prototype.uint64, p.prototype.sint64 = function(t3) {
        var e2 = o.from(t3).zzEncode();
        return this._push(g, e2.length(), e2);
      }, p.prototype.bool = function(t3) {
        return this._push(d, 1, t3 ? 1 : 0);
      }, p.prototype.fixed32 = function(t3) {
        return this._push(b, 4, t3 >>> 0);
      }, p.prototype.sfixed32 = p.prototype.fixed32, p.prototype.fixed64 = function(t3) {
        var e2 = o.from(t3);
        return this._push(b, 4, e2.lo)._push(b, 4, e2.hi);
      }, p.prototype.sfixed64 = p.prototype.fixed64, p.prototype.float = function(t3) {
        return this._push(i2.float.writeFloatLE, 4, t3);
      }, p.prototype.double = function(t3) {
        return this._push(i2.float.writeDoubleLE, 8, t3);
      };
      var m = i2.Array.prototype.set ? function(t3, e2, n2) {
        e2.set(t3, n2);
      } : function(t3, e2, n2) {
        for (var r2 = 0; r2 < t3.length; ++r2) e2[n2 + r2] = t3[r2];
      };
      p.prototype.bytes = function(t3) {
        var e2 = t3.length >>> 0;
        if (!e2) return this._push(d, 1, 0);
        if (i2.isString(t3)) {
          var n2 = p.alloc(e2 = a.length(t3));
          a.decode(t3, n2, 0), t3 = n2;
        }
        return this.uint32(e2)._push(m, e2, t3);
      }, p.prototype.string = function(t3) {
        var e2 = s.length(t3);
        return e2 ? this.uint32(e2)._push(s.write, e2, t3) : this._push(d, 1, 0);
      }, p.prototype.fork = function() {
        return this.states = new l(this), this.head = this.tail = new u(c, 0, 0), this.len = 0, this;
      }, p.prototype.reset = function() {
        return this.states ? (this.head = this.states.head, this.tail = this.states.tail, this.len = this.states.len, this.states = this.states.next) : (this.head = this.tail = new u(c, 0, 0), this.len = 0), this;
      }, p.prototype.ldelim = function() {
        var t3 = this.head, e2 = this.tail, n2 = this.len;
        return this.reset().uint32(n2), n2 && (this.tail.next = t3.next, this.tail = e2, this.len += n2), this;
      }, p.prototype.finish = function() {
        for (var t3 = this.head.next, e2 = this.constructor.alloc(this.len), n2 = 0; t3; ) t3.fn(t3.val, e2, n2), n2 += t3.len, t3 = t3.next;
        return e2;
      }, p._configure = function(t3) {
        r = t3, p.create = f(), r._configure();
      };
    }, 3155: (t2, e, n) => {
      t2.exports = o;
      var r = n(1173);
      (o.prototype = Object.create(r.prototype)).constructor = o;
      var i2 = n(9693);
      function o() {
        r.call(this);
      }
      function a(t3, e2, n2) {
        t3.length < 40 ? i2.utf8.write(t3, e2, n2) : e2.utf8Write ? e2.utf8Write(t3, n2) : e2.write(t3, n2);
      }
      o._configure = function() {
        o.alloc = i2._Buffer_allocUnsafe, o.writeBytesBuffer = i2.Buffer && i2.Buffer.prototype instanceof Uint8Array && "set" === i2.Buffer.prototype.set.name ? function(t3, e2, n2) {
          e2.set(t3, n2);
        } : function(t3, e2, n2) {
          if (t3.copy) t3.copy(e2, n2, 0, t3.length);
          else for (var r2 = 0; r2 < t3.length; ) e2[n2++] = t3[r2++];
        };
      }, o.prototype.bytes = function(t3) {
        i2.isString(t3) && (t3 = i2._Buffer_from(t3, "base64"));
        var e2 = t3.length >>> 0;
        return this.uint32(e2), e2 && this._push(o.writeBytesBuffer, e2, t3), this;
      }, o.prototype.string = function(t3) {
        var e2 = i2.Buffer.byteLength(t3);
        return this.uint32(e2), e2 && this._push(a, e2, t3), this;
      }, o._configure();
    }, 7714: (t2, e, n) => {
      e.R = void 0;
      const r = n(6919), i2 = n(7448);
      e.R = new class {
        async init() {
        }
        async createSessionHandler(t3, e2) {
          const n2 = new r.Session(e2);
          return await n2.loadModel(t3), new i2.OnnxjsSessionHandler(n2);
        }
      }();
    }, 4200: (t2, e, n) => {
      e.c8 = e.rX = void 0;
      const r = n(6207), i2 = n(9719), o = n(2157), a = n(2306);
      e.rX = () => {
        if (("number" != typeof r.env.wasm.initTimeout || r.env.wasm.initTimeout < 0) && (r.env.wasm.initTimeout = 0), "boolean" != typeof r.env.wasm.simd && (r.env.wasm.simd = true), "boolean" != typeof r.env.wasm.proxy && (r.env.wasm.proxy = false), "number" != typeof r.env.wasm.numThreads || !Number.isInteger(r.env.wasm.numThreads) || r.env.wasm.numThreads <= 0) {
          const t3 = "undefined" == typeof navigator ? (0, i2.cpus)().length : navigator.hardwareConcurrency;
          r.env.wasm.numThreads = Math.min(4, Math.ceil((t3 || 1) / 2));
        }
      }, e.c8 = new class {
        async init() {
          (0, e.rX)(), await (0, o.initWasm)();
        }
        async createSessionHandler(t3, e2) {
          const n2 = new a.OnnxruntimeWebAssemblySessionHandler();
          return await n2.loadModel(t3, e2), Promise.resolve(n2);
        }
      }();
    }, 6018: function(t2, e, n) {
      var r = this && this.__createBinding || (Object.create ? function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2);
        var i3 = Object.getOwnPropertyDescriptor(e2, n2);
        i3 && !("get" in i3 ? !e2.__esModule : i3.writable || i3.configurable) || (i3 = { enumerable: true, get: function() {
          return e2[n2];
        } }), Object.defineProperty(t3, r2, i3);
      } : function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2), t3[r2] = e2[n2];
      }), i2 = this && this.__exportStar || function(t3, e2) {
        for (var n2 in t3) "default" === n2 || Object.prototype.hasOwnProperty.call(e2, n2) || r(e2, t3, n2);
      };
      Object.defineProperty(e, "__esModule", { value: true }), i2(n(6207), e);
      const o = n(6207);
      {
        const t3 = n(7714).R;
        (0, o.registerBackend)("webgl", t3, -10);
      }
      {
        const t3 = n(4200).c8;
        (0, o.registerBackend)("cpu", t3, 10), (0, o.registerBackend)("wasm", t3, 10), (0, o.registerBackend)("xnnpack", t3, 9);
      }
    }, 246: (t2, e) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createAttributeWithCacheKey = void 0;
      class n {
        constructor(t3) {
          Object.assign(this, t3);
        }
        get cacheKey() {
          return this._cacheKey || (this._cacheKey = Object.getOwnPropertyNames(this).sort().map((t3) => `${this[t3]}`).join(";")), this._cacheKey;
        }
      }
      e.createAttributeWithCacheKey = (t3) => new n(t3);
    }, 7778: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.Attribute = void 0;
      const r = n(1446), i2 = n(9395), o = n(9162), a = n(2517);
      var s = i2.onnxruntime.experimental.fbs;
      class u {
        constructor(t3) {
          if (this._attributes = /* @__PURE__ */ new Map(), null != t3) {
            for (const e2 of t3) e2 instanceof r.onnx.AttributeProto ? this._attributes.set(e2.name, [u.getValue(e2), u.getType(e2)]) : e2 instanceof s.Attribute && this._attributes.set(e2.name(), [u.getValue(e2), u.getType(e2)]);
            if (this._attributes.size < t3.length) throw new Error("duplicated attribute names");
          }
        }
        set(t3, e2, n2) {
          this._attributes.set(t3, [n2, e2]);
        }
        delete(t3) {
          this._attributes.delete(t3);
        }
        getFloat(t3, e2) {
          return this.get(t3, "float", e2);
        }
        getInt(t3, e2) {
          return this.get(t3, "int", e2);
        }
        getString(t3, e2) {
          return this.get(t3, "string", e2);
        }
        getTensor(t3, e2) {
          return this.get(t3, "tensor", e2);
        }
        getFloats(t3, e2) {
          return this.get(t3, "floats", e2);
        }
        getInts(t3, e2) {
          return this.get(t3, "ints", e2);
        }
        getStrings(t3, e2) {
          return this.get(t3, "strings", e2);
        }
        getTensors(t3, e2) {
          return this.get(t3, "tensors", e2);
        }
        get(t3, e2, n2) {
          const r2 = this._attributes.get(t3);
          if (void 0 === r2) {
            if (void 0 !== n2) return n2;
            throw new Error(`required attribute not found: ${t3}`);
          }
          if (r2[1] !== e2) throw new Error(`type mismatch: expected ${e2} but got ${r2[1]}`);
          return r2[0];
        }
        static getType(t3) {
          const e2 = t3 instanceof r.onnx.AttributeProto ? t3.type : t3.type();
          switch (e2) {
            case r.onnx.AttributeProto.AttributeType.FLOAT:
              return "float";
            case r.onnx.AttributeProto.AttributeType.INT:
              return "int";
            case r.onnx.AttributeProto.AttributeType.STRING:
              return "string";
            case r.onnx.AttributeProto.AttributeType.TENSOR:
              return "tensor";
            case r.onnx.AttributeProto.AttributeType.FLOATS:
              return "floats";
            case r.onnx.AttributeProto.AttributeType.INTS:
              return "ints";
            case r.onnx.AttributeProto.AttributeType.STRINGS:
              return "strings";
            case r.onnx.AttributeProto.AttributeType.TENSORS:
              return "tensors";
            default:
              throw new Error(`attribute type is not supported yet: ${r.onnx.AttributeProto.AttributeType[e2]}`);
          }
        }
        static getValue(t3) {
          const e2 = t3 instanceof r.onnx.AttributeProto ? t3.type : t3.type();
          if (e2 === r.onnx.AttributeProto.AttributeType.GRAPH || e2 === r.onnx.AttributeProto.AttributeType.GRAPHS) throw new Error("graph attribute is not supported yet");
          const n2 = this.getValueNoCheck(t3);
          if (e2 === r.onnx.AttributeProto.AttributeType.INT && a.LongUtil.isLong(n2)) return a.LongUtil.longToNumber(n2);
          if (e2 === r.onnx.AttributeProto.AttributeType.INTS) {
            const t4 = n2, e3 = new Array(t4.length);
            for (let n3 = 0; n3 < t4.length; n3++) {
              const r2 = t4[n3];
              e3[n3] = a.LongUtil.longToNumber(r2);
            }
            return e3;
          }
          if (e2 === r.onnx.AttributeProto.AttributeType.TENSOR) return t3 instanceof r.onnx.AttributeProto ? o.Tensor.fromProto(n2) : o.Tensor.fromOrtTensor(n2);
          if (e2 === r.onnx.AttributeProto.AttributeType.TENSORS) {
            if (t3 instanceof r.onnx.AttributeProto) return n2.map((t4) => o.Tensor.fromProto(t4));
            if (t3 instanceof s.Attribute) return n2.map((t4) => o.Tensor.fromOrtTensor(t4));
          }
          if (e2 === r.onnx.AttributeProto.AttributeType.STRING && t3 instanceof r.onnx.AttributeProto) {
            const t4 = n2;
            return (0, a.decodeUtf8String)(t4);
          }
          return e2 === r.onnx.AttributeProto.AttributeType.STRINGS && t3 instanceof r.onnx.AttributeProto ? n2.map(a.decodeUtf8String) : n2;
        }
        static getValueNoCheck(t3) {
          return t3 instanceof r.onnx.AttributeProto ? this.getValueNoCheckFromOnnxFormat(t3) : this.getValueNoCheckFromOrtFormat(t3);
        }
        static getValueNoCheckFromOnnxFormat(t3) {
          switch (t3.type) {
            case r.onnx.AttributeProto.AttributeType.FLOAT:
              return t3.f;
            case r.onnx.AttributeProto.AttributeType.INT:
              return t3.i;
            case r.onnx.AttributeProto.AttributeType.STRING:
              return t3.s;
            case r.onnx.AttributeProto.AttributeType.TENSOR:
              return t3.t;
            case r.onnx.AttributeProto.AttributeType.GRAPH:
              return t3.g;
            case r.onnx.AttributeProto.AttributeType.FLOATS:
              return t3.floats;
            case r.onnx.AttributeProto.AttributeType.INTS:
              return t3.ints;
            case r.onnx.AttributeProto.AttributeType.STRINGS:
              return t3.strings;
            case r.onnx.AttributeProto.AttributeType.TENSORS:
              return t3.tensors;
            case r.onnx.AttributeProto.AttributeType.GRAPHS:
              return t3.graphs;
            default:
              throw new Error(`unsupported attribute type: ${r.onnx.AttributeProto.AttributeType[t3.type]}`);
          }
        }
        static getValueNoCheckFromOrtFormat(t3) {
          switch (t3.type()) {
            case s.AttributeType.FLOAT:
              return t3.f();
            case s.AttributeType.INT:
              return t3.i();
            case s.AttributeType.STRING:
              return t3.s();
            case s.AttributeType.TENSOR:
              return t3.t();
            case s.AttributeType.GRAPH:
              return t3.g();
            case s.AttributeType.FLOATS:
              return t3.floatsArray();
            case s.AttributeType.INTS: {
              const e2 = [];
              for (let n2 = 0; n2 < t3.intsLength(); n2++) e2.push(t3.ints(n2));
              return e2;
            }
            case s.AttributeType.STRINGS: {
              const e2 = [];
              for (let n2 = 0; n2 < t3.stringsLength(); n2++) e2.push(t3.strings(n2));
              return e2;
            }
            case s.AttributeType.TENSORS: {
              const e2 = [];
              for (let n2 = 0; n2 < t3.tensorsLength(); n2++) e2.push(t3.tensors(n2));
              return e2;
            }
            default:
              throw new Error(`unsupported attribute type: ${s.AttributeType[t3.type()]}`);
          }
        }
      }
      e.Attribute = u;
    }, 7091: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.resolveBackend = e.backend = void 0;
      const r = n(5038), i2 = /* @__PURE__ */ new Map();
      async function o(t3) {
        const n2 = e.backend;
        if (void 0 !== n2[t3] && function(t4) {
          const e2 = t4;
          return "initialize" in e2 && "function" == typeof e2.initialize && "createSessionHandler" in e2 && "function" == typeof e2.createSessionHandler && "dispose" in e2 && "function" == typeof e2.dispose;
        }(n2[t3])) {
          const e2 = n2[t3];
          let r2 = e2.initialize();
          if ("object" == typeof r2 && "then" in r2 && (r2 = await r2), r2) return i2.set(t3, e2), e2;
        }
      }
      e.backend = { webgl: new r.WebGLBackend() }, e.resolveBackend = async function t3(e2) {
        if (!e2) return t3(["webgl"]);
        {
          const t4 = "string" == typeof e2 ? [e2] : e2;
          for (const e3 of t4) {
            const t5 = i2.get(e3);
            if (t5) return t5;
            const n2 = await o(e3);
            if (n2) return n2;
          }
        }
        throw new Error("no available backend to use");
      };
    }, 5038: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.WebGLBackend = void 0;
      const r = n(6207), i2 = n(3694), o = n(6416), a = n(7305);
      e.WebGLBackend = class {
        get contextId() {
          return r.env.webgl.contextId;
        }
        set contextId(t3) {
          r.env.webgl.contextId = t3;
        }
        get matmulMaxBatchSize() {
          return r.env.webgl.matmulMaxBatchSize;
        }
        set matmulMaxBatchSize(t3) {
          r.env.webgl.matmulMaxBatchSize = t3;
        }
        get textureCacheMode() {
          return r.env.webgl.textureCacheMode;
        }
        set textureCacheMode(t3) {
          r.env.webgl.textureCacheMode = t3;
        }
        get pack() {
          return r.env.webgl.pack;
        }
        set pack(t3) {
          r.env.webgl.pack = t3;
        }
        get async() {
          return r.env.webgl.async;
        }
        set async(t3) {
          r.env.webgl.async = t3;
        }
        initialize() {
          try {
            return this.glContext = (0, a.createWebGLContext)(this.contextId), "number" != typeof this.matmulMaxBatchSize && (this.matmulMaxBatchSize = 16), "string" != typeof this.textureCacheMode && (this.textureCacheMode = "full"), "boolean" != typeof this.pack && (this.pack = false), "boolean" != typeof this.async && (this.async = false), i2.Logger.setWithEnv(r.env), i2.Logger.verbose("WebGLBackend", `Created WebGLContext: ${typeof this.glContext} with matmulMaxBatchSize: ${this.matmulMaxBatchSize}; textureCacheMode: ${this.textureCacheMode}; pack: ${this.pack}; async: ${this.async}.`), true;
          } catch (t3) {
            return i2.Logger.warning("WebGLBackend", `Unable to initialize WebGLBackend. ${t3}`), false;
          }
        }
        createSessionHandler(t3) {
          return new o.WebGLSessionHandler(this, t3);
        }
        dispose() {
          this.glContext.dispose();
        }
      };
    }, 5107: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.CoordsGlslLib = void 0;
      const r = n(2517), i2 = n(8520), o = n(5060), a = n(7859), s = n(9390);
      class u extends i2.GlslLib {
        constructor(t3) {
          super(t3);
        }
        getFunctions() {
          return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, this.offsetToCoords()), this.coordsToOffset()), this.toVec()), this.valueFrom()), this.getCommonUtilFuncs()), this.getInputsSamplingSnippets()), this.getOutputSamplingSnippet());
        }
        getCustomTypes() {
          return {};
        }
        offsetToCoords() {
          return { offsetToCoords: new i2.GlslLibRoutine("\n      vec2 offsetToCoords(int offset, int width, int height) {\n        int t = offset / width;\n        int s = offset - t*width;\n        vec2 coords = (vec2(s,t) + vec2(0.5,0.5)) / vec2(width, height);\n        return coords;\n      }\n      ") };
        }
        coordsToOffset() {
          return { coordsToOffset: new i2.GlslLibRoutine("\n      int coordsToOffset(vec2 coords, int width, int height) {\n        float s = coords.s * float(width);\n        float t = coords.t * float(height);\n        int offset = int(t) * width + int(s);\n        return offset;\n      }\n      ") };
        }
        getOutputSamplingSnippet() {
          const t3 = this.context.outputTextureLayout;
          return t3.isPacked ? this.getPackedOutputSamplingSnippet(t3) : this.getUnpackedOutputSamplingSnippet(t3);
        }
        getPackedOutputSamplingSnippet(t3) {
          const e2 = t3.unpackedShape, n2 = [t3.width, t3.height], r2 = {}, a2 = "getOutputCoords";
          switch (e2.length) {
            case 0:
              r2[a2] = this.getOutputScalarCoords();
              break;
            case 1:
              r2[a2] = this.getOutputPacked1DCoords(e2, n2);
              break;
            case 2:
              r2[a2] = this.getOutputPacked2DCoords(e2, n2);
              break;
            case 3:
              r2[a2] = this.getOutputPacked3DCoords(e2, n2);
              break;
            default:
              r2[a2] = this.getOutputPackedNDCoords(e2, n2);
          }
          const s2 = `
      void setOutput(vec4 val) {
        ${(0, o.getGlsl)(this.context.glContext.version).output} = val;
      }
    `;
          return r2.floatTextureSetRGBA = new i2.GlslLibRoutine(s2), r2;
        }
        getUnpackedOutputSamplingSnippet(t3) {
          const e2 = t3.unpackedShape, n2 = [t3.width, t3.height], r2 = {}, a2 = "getOutputCoords";
          switch (e2.length) {
            case 0:
              r2[a2] = this.getOutputScalarCoords();
              break;
            case 1:
              r2[a2] = this.getOutputUnpacked1DCoords(e2, n2);
              break;
            case 2:
              r2[a2] = this.getOutputUnpacked2DCoords(e2, n2);
              break;
            case 3:
              r2[a2] = this.getOutputUnpacked3DCoords(e2, n2);
              break;
            case 4:
              r2[a2] = this.getOutputUnpacked4DCoords(e2, n2);
              break;
            case 5:
              r2[a2] = this.getOutputUnpacked5DCoords(e2, n2);
              break;
            case 6:
              r2[a2] = this.getOutputUnpacked6DCoords(e2, n2);
              break;
            default:
              throw new Error(`Unsupported output dimensionality: ${e2.length}`);
          }
          const s2 = `
        void setOutput(float val) {
          ${(0, o.getGlsl)(this.context.glContext.version).output} = vec4(val, 0, 0, 0);
        }
    `;
          return r2.floatTextureSetR = new i2.GlslLibRoutine(s2), r2;
        }
        getOutputScalarCoords() {
          return new i2.GlslLibRoutine("\n      int getOutputCoords() {\n        return 0;\n      }\n    ");
        }
        getOutputPacked1DCoords(t3, e2) {
          const n2 = e2;
          let r2 = "";
          return 1 === n2[0] ? (r2 = `
          int getOutputCoords() {
            return 2 * int(TexCoords.y * ${n2[1]}.0);
          }
        `, new i2.GlslLibRoutine(r2)) : 1 === n2[1] ? (r2 = `
          int getOutputCoords() {
            return 2 * int(TexCoords.x * ${n2[0]}.0);
          }
        `, new i2.GlslLibRoutine(r2)) : (r2 = `
        int getOutputCoords() {
          ivec2 resTexRC = ivec2(TexCoords.xy *
                                 vec2(${n2[0]}, ${n2[1]}));
          return 2 * (resTexRC.y * ${n2[0]} + resTexRC.x);
        }
      `, new i2.GlslLibRoutine(r2));
        }
        getOutputPacked2DCoords(t3, e2) {
          let n2 = "";
          if (r.ArrayUtil.arraysEqual(t3, e2)) return n2 = `
        ivec2 getOutputCoords() {
          return 2 * ivec2(TexCoords.xy * vec2(${e2[0]}, ${e2[1]}));
        }
      `, new i2.GlslLibRoutine(n2);
          const o2 = e2, a2 = Math.ceil(t3[1] / 2);
          return n2 = `
        ivec2 getOutputCoords() {
          ivec2 resTexRC = ivec2(TexCoords.xy *
                                vec2(${o2[0]}, ${o2[1]}));

          int index = resTexRC.y * ${o2[0]} + resTexRC.x;

          // reverse r and c order for packed texture
          int r = imod(index, ${a2}) * 2;
          int c = 2 * (index / ${a2});

          return ivec2(r, c);
        }
      `, new i2.GlslLibRoutine(n2);
        }
        getOutputPacked3DCoords(t3, e2) {
          const n2 = [e2[0], e2[1]], r2 = Math.ceil(t3[2] / 2), o2 = r2 * Math.ceil(t3[1] / 2), a2 = `
        ivec3 getOutputCoords() {
          ivec2 resTexRC = ivec2(TexCoords.xy *
                                vec2(${n2[0]}, ${n2[1]}));
          int index = resTexRC.y * ${n2[0]} + resTexRC.x;

          int b = index / ${o2};
          index -= b * ${o2};

          // reverse r and c order for packed texture
          int r = imod(index, ${r2}) * 2;
          int c = 2 * (index / ${r2});

          return ivec3(b, r, c);
        }
      `;
          return new i2.GlslLibRoutine(a2);
        }
        getOutputPackedNDCoords(t3, e2) {
          const n2 = [e2[0], e2[1]], r2 = Math.ceil(t3[t3.length - 1] / 2), o2 = r2 * Math.ceil(t3[t3.length - 2] / 2);
          let a2 = o2, s2 = "", u2 = "b, r, c";
          for (let e3 = 2; e3 < t3.length - 1; e3++) a2 *= t3[t3.length - e3 - 1], s2 = `
      int b${e3} = index / ${a2};
      index -= b${e3} * ${a2};
    ` + s2, u2 = `b${e3}, ` + u2;
          const c = `
      ivec${t3.length} getOutputCoords() {
        ivec2 resTexRC = ivec2(TexCoords.xy *
                              vec2(${n2[0]}, ${n2[1]}));
        int index = resTexRC.y * ${n2[0]} + resTexRC.x;

        ${s2}

        int b = index / ${o2};
        index -= b * ${o2};

        // reverse r and c order for packed texture
        int r = imod(index, ${r2}) * 2;
        int c = 2 * (index / ${r2});

        return ivec${t3.length}(${u2});
      }
    `;
          return new i2.GlslLibRoutine(c);
        }
        getOutputUnpacked1DCoords(t3, e2) {
          const n2 = `
        int getOutputCoords() {
          ivec2 resTexRC = ivec2(TexCoords.xy *
                                vec2(${e2[0]}, ${e2[1]}));
          return resTexRC.y * ${e2[0]} + resTexRC.x;
        }
      `;
          return new i2.GlslLibRoutine(n2);
        }
        getOutputUnpacked2DCoords(t3, e2) {
          const n2 = `
        ivec2 getOutputCoords() {
          ivec2 resTexRC = ivec2(TexCoords.xy *
                                vec2(${e2[0]}, ${e2[1]}));
          int index = resTexRC.y * ${e2[0]} + resTexRC.x;
          int r = index / ${t3[1]};
          int c = index - r * ${t3[1]};
          return ivec2(r, c);
        }
      `;
          return new i2.GlslLibRoutine(n2);
        }
        getOutputUnpacked3DCoords(t3, e2) {
          let n2 = "";
          const r2 = t3.length;
          let o2 = null;
          r2 < 2 && (o2 = []), o2 = new Array(r2 - 1), o2[r2 - 2] = t3[r2 - 1];
          for (let e3 = r2 - 3; e3 >= 0; --e3) o2[e3] = o2[e3 + 1] * t3[e3 + 1];
          const a2 = ["r", "c", "d"], s2 = o2.map((t4, e3) => `int ${a2[e3]} = index / ${t4}; ${e3 === o2.length - 1 ? `int ${a2[e3 + 1]} = index - ${a2[e3]} * ${t4}` : `index -= ${a2[e3]} * ${t4}`};`).join("");
          return n2 = `
        ivec3 getOutputCoords() {
          ivec2 resTexRC = ivec2(TexCoords.xy *
                                vec2(${e2[0]}, ${e2[1]}));
          int index = resTexRC.y * ${e2[0]} + resTexRC.x;
          ${s2}
          return ivec3(r, c, d);
        }
      `, new i2.GlslLibRoutine(n2);
        }
        getOutputUnpacked4DCoords(t3, e2) {
          let n2 = "";
          const r2 = t3.length;
          let o2 = null;
          r2 < 2 && (o2 = []), o2 = new Array(r2 - 1), o2[r2 - 2] = t3[r2 - 1];
          for (let e3 = r2 - 3; e3 >= 0; --e3) o2[e3] = o2[e3 + 1] * t3[e3 + 1];
          const a2 = ["r", "c", "d", "d2"], s2 = o2.map((t4, e3) => `int ${a2[e3]} = index / ${t4}; ${e3 === o2.length - 1 ? `int ${a2[e3 + 1]} = index - ${a2[e3]} * ${t4}` : `index -= ${a2[e3]} * ${t4}`};`).join("");
          return n2 = `
      ivec4 getOutputCoords() {
          ivec2 resTexRC = ivec2(TexCoords.xy *
                                vec2(${e2[0]}, ${e2[1]}));
          int index = resTexRC.y * ${e2[0]} + resTexRC.x;
          ${s2}
          return ivec4(r, c, d, d2);
        }
      `, new i2.GlslLibRoutine(n2);
        }
        getOutputUnpacked5DCoords(t3, e2) {
          let n2 = "";
          const r2 = t3.length;
          let o2 = null;
          r2 < 2 && (o2 = []), o2 = new Array(r2 - 1), o2[r2 - 2] = t3[r2 - 1];
          for (let e3 = r2 - 3; e3 >= 0; --e3) o2[e3] = o2[e3 + 1] * t3[e3 + 1];
          const a2 = ["r", "c", "d", "d2", "d3"], s2 = o2.map((t4, e3) => `int ${a2[e3]} = index / ${t4}; ${e3 === o2.length - 1 ? `int ${a2[e3 + 1]} = index - ${a2[e3]} * ${t4}` : `index -= ${a2[e3]} * ${t4}`};`).join("");
          return n2 = `
      ivec5 getOutputCoords() {
          ivec2 resTexRC = ivec2(TexCoords.xy *
                                vec2(${e2[0]}, ${e2[1]}));
          int index = resTexRC.y * ${e2[0]} + resTexRC.x;
          ${s2}
          return ivec5(r, c, d, d2, d3);
        }
      `, new i2.GlslLibRoutine(n2);
        }
        getOutputUnpacked6DCoords(t3, e2) {
          let n2 = "";
          const r2 = t3.length;
          let o2 = null;
          r2 < 2 && (o2 = []), o2 = new Array(r2 - 1), o2[r2 - 2] = t3[r2 - 1];
          for (let e3 = r2 - 3; e3 >= 0; --e3) o2[e3] = o2[e3 + 1] * t3[e3 + 1];
          const a2 = ["r", "c", "d", "d2", "d3", "d4"], s2 = o2.map((t4, e3) => `int ${a2[e3]} = index / ${t4}; ${e3 === o2.length - 1 ? `int ${a2[e3 + 1]} = index - ${a2[e3]} * ${t4}` : `index -= ${a2[e3]} * ${t4}`};`).join("");
          return n2 = `
     ivec6 getOutputCoords() {
         ivec2 resTexRC = ivec2(TexCoords.xy *
                               vec2(${e2[0]}, ${e2[1]}));
         int index = resTexRC.y * ${e2[0]} + resTexRC.x;
         ${s2}
         return ivec6(r, c, d, d2, d3, d4);
       }
     `, new i2.GlslLibRoutine(n2);
        }
        getCommonUtilFuncs() {
          const t3 = {};
          let e2 = "uvFromFlat";
          t3[e2] = new i2.GlslLibRoutine("\n    vec2 uvFromFlat(int texNumR, int texNumC, int index) {\n      int texC = index / texNumR;\n      int texR = index - texC * texNumR;\n      // TODO: swap texR, texC order in following function so row is corresponding to u and column is corresponding to\n      //       v.\n      return (vec2(texR, texC) + halfCR) / vec2(texNumR, texNumC);\n    }\n    "), e2 = "packedUVfrom1D", t3[e2] = new i2.GlslLibRoutine("\n      vec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n        int texelIndex = index / 2;\n        int texR = texelIndex / texNumC;\n        int texC = texelIndex - texR * texNumC;\n        return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n      }\n      "), e2 = "packedUVfrom2D", t3[e2] = new i2.GlslLibRoutine("\n      vec2 packedUVfrom2D(int texNumR, int texNumC, int texelsInLogicalRow, int row, int col) {\n        int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n        int texR = texelIndex / texNumC;\n        int texC = texelIndex - texR * texNumC;\n        return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n      }\n      "), e2 = "packedUVfrom3D", t3[e2] = new i2.GlslLibRoutine("\n      vec2 packedUVfrom3D(int texNumR, int texNumC,\n          int texelsInBatch, int texelsInLogicalRow, int b,\n          int row, int col) {\n        int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n        int texR = index / texNumC;\n        int texC = index - texR * texNumC;\n        return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n      }\n      "), e2 = "sampleTexture";
          const n2 = (0, o.getGlsl)(this.context.glContext.version);
          return t3[e2] = new i2.GlslLibRoutine(`
        float sampleTexture(sampler2D textureSampler, vec2 uv) {
            return ${n2.texture2D}(textureSampler, uv).r;
        }`), t3;
        }
        getInputsSamplingSnippets() {
          const t3 = {}, e2 = this.context.outputTextureLayout;
          return this.context.programInfo.inputNames.forEach((n2, r2) => {
            const i3 = this.context.inputTextureLayouts[r2], o2 = (0, s.generateShaderFuncNameFromInputSamplerName)(n2);
            i3.isPacked ? t3[o2] = this.getPackedSamplerFromInput(o2, n2, i3) : t3[o2] = this.getUnpackedSamplerFromInput(o2, n2, i3);
            const a2 = (0, s.generateShaderFuncNameFromInputSamplerNameAtOutCoords)(n2);
            i3.unpackedShape.length <= e2.unpackedShape.length && (i3.isPacked ? t3[a2] = this.getPackedSamplerAtOutputCoords(a2, i3, e2, n2) : t3[a2] = this.getUnpackedSamplerAtOutputCoords(a2, i3, e2, n2));
          }), t3;
        }
        getPackedSamplerAtOutputCoords(t3, e2, n2, o2) {
          const a2 = e2.unpackedShape, u2 = n2.unpackedShape, c = o2, l = (0, s.generateShaderFuncNameFromInputSamplerName)(c), p = a2.length, f = u2.length, d = r.BroadcastUtil.getBroadcastDims(a2, u2), h = (0, s.getCoordsDataType)(f), g = f - p;
          let b;
          const m = (0, s.getGlChannels)();
          b = 0 === p ? "" : f < 2 && d.length >= 1 ? "coords = 0;" : d.map((t4) => `coords.${m[t4 + g]} = 0;`).join("\n");
          let y = "";
          y = f < 2 && p > 0 ? "coords" : a2.map((t4, e3) => `coords.${m[e3 + g]}`).join(", ");
          let _ = "return outputValue;";
          const v = 1 === r.ShapeUtil.size(a2), w = 1 === r.ShapeUtil.size(u2);
          if (1 !== p || v || w) {
            if (v && !w) _ = 1 === f ? "\n          return vec4(outputValue.x, outputValue.x, 0., 0.);\n        " : "\n          return vec4(outputValue.x);\n        ";
            else if (d.length) {
              const t4 = p - 2, e3 = p - 1;
              d.indexOf(t4) > -1 && d.indexOf(e3) > -1 ? _ = "return vec4(outputValue.x);" : d.indexOf(t4) > -1 ? _ = "return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);" : d.indexOf(e3) > -1 && (_ = "return vec4(outputValue.xx, outputValue.zz);");
            }
          } else _ = "\n        return vec4(outputValue.xy, outputValue.xy);\n      ";
          const x = `
      vec4 ${t3}() {
        ${h} coords = getOutputCoords();
        
        int lastDim = coords.${m[f - 1]};
        coords.${m[f - 1]} = coords.${m[f - 2]};
        coords.${m[f - 2]} = lastDim;
      
        ${b}
        vec4 outputValue = ${l}(${y});
        ${_}
      }
    `;
          return new i2.GlslLibRoutine(x, ["coordinates.getOutputCoords"]);
        }
        getUnpackedSamplerAtOutputCoords(t3, e2, n2, o2) {
          const a2 = [n2.width, n2.height], u2 = [e2.width, e2.height], c = e2.unpackedShape.length, l = n2.unpackedShape.length, p = e2.unpackedShape, f = n2.unpackedShape, d = (0, s.generateShaderFuncNameFromInputSamplerName)(o2);
          if (c === l && r.ArrayUtil.arraysEqual(u2, a2)) {
            const e3 = `
          float ${t3}() {
            return sampleTexture(${o2}, TexCoords);
          }
        `;
            return new i2.GlslLibRoutine(e3, ["coordinates.sampleTexture"]);
          }
          const h = (0, s.getCoordsDataType)(l), g = r.BroadcastUtil.getBroadcastDims(p, f), b = l - c;
          let m;
          const y = (0, s.getGlChannels)();
          m = 0 === c ? "" : l < 2 && g.length >= 1 ? "coords = 0;" : g.map((t4) => `coords.${y[t4 + b]} = 0;`).join("\n");
          let _ = "";
          _ = l < 2 && c > 0 ? "coords" : e2.unpackedShape.map((t4, e3) => `coords.${y[e3 + b]}`).join(", ");
          const v = `
        float ${t3}() {
          ${h} coords = getOutputCoords();
          ${m}
          return ${d}(${_});
        }
      `;
          return new i2.GlslLibRoutine(v, ["coordinates.getOutputCoords"]);
        }
        getPackedSamplerFromInput(t3, e2, n2) {
          switch (n2.unpackedShape.length) {
            case 0:
              return this.getPackedSamplerScalar(t3, e2);
            case 1:
              return this.getPackedSampler1D(t3, e2, n2);
            case 2:
              return this.getPackedSampler2D(t3, e2, n2);
            case 3:
              return this.getPackedSampler3D(t3, e2, n2);
            default:
              return this.getPackedSamplerND(t3, e2, n2);
          }
        }
        getUnpackedSamplerFromInput(t3, e2, n2) {
          const r2 = n2.unpackedShape;
          switch (r2.length) {
            case 0:
              return this.getUnpackedSamplerScalar(t3, e2, n2);
            case 1:
              return this.getUnpackedSampler1D(t3, e2, n2);
            case 2:
              return this.getUnpackedSampler2D(t3, e2, n2);
            case 3:
              return this.getUnpackedSampler3D(t3, e2, n2);
            case 4:
              return this.getUnpackedSampler4D(t3, e2, n2);
            case 5:
              return this.getUnpackedSampler5D(t3, e2, n2);
            case 6:
              return this.getUnpackedSampler6D(t3, e2, n2);
            default:
              throw new Error(`Unsupported dimension ${r2.length}-D`);
          }
        }
        getPackedSamplerScalar(t3, e2) {
          const n2 = `
          vec4 ${t3}() {
            return ${(0, o.getGlsl)(this.context.glContext.version).texture2D}(${e2}, halfCR);
          }
        `;
          return new i2.GlslLibRoutine(n2);
        }
        getPackedSampler1D(t3, e2, n2) {
          const r2 = [n2.width, n2.height], a2 = [r2[1], r2[0]], s2 = (0, o.getGlsl)(this.context.glContext.version), u2 = `vec4 ${t3}(int index) {
      vec2 uv = packedUVfrom1D(
      ${a2[0]}, ${a2[1]}, index);
      return ${s2.texture2D}(${e2}, uv);
    }`;
          return new i2.GlslLibRoutine(u2, ["coordinates.packedUVfrom1D"]);
        }
        getPackedSampler2D(t3, e2, n2) {
          const a2 = n2.unpackedShape, s2 = [n2.width, n2.height], u2 = (0, o.getGlsl)(this.context.glContext.version), c = s2[0], l = s2[1];
          if (null != s2 && r.ArrayUtil.arraysEqual(a2, s2)) {
            const n3 = `vec4 ${t3}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${l}.0, ${c}.0);
        return ${u2.texture2D}(${e2}, uv);
      }`;
            return new i2.GlslLibRoutine(n3);
          }
          const p = s2, f = Math.ceil(a2[1] / 2), d = `vec4 ${t3}(int row, int col) {
      vec2 uv = packedUVfrom2D(${p[1]}, ${p[0]}, ${f}, row, col);
      return ${u2.texture2D}(${e2}, uv);
    }`;
          return new i2.GlslLibRoutine(d, ["coordinates.packedUVfrom2D"]);
        }
        getPackedSampler3D(t3, e2, n2) {
          const r2 = n2.unpackedShape, a2 = [n2.width, n2.height], u2 = [a2[0], a2[1]], c = (0, o.getGlsl)(this.context.glContext.version);
          if (1 === r2[0]) {
            const o2 = r2.slice(1), a3 = [1, 2], u3 = (0, s.squeezeInputShape)(r2, o2), c2 = ["b", "row", "col"], l2 = JSON.parse(JSON.stringify(n2));
            l2.unpackedShape = u3;
            const p2 = this.getPackedSamplerFromInput(t3, e2, l2), f2 = `${p2.routineBody}
      vec4 ${t3}(int b, int row, int col) {
        return ${t3}(${(0, s.getSqueezedParams)(c2, a3)});
      } `;
            return new i2.GlslLibRoutine(f2, p2.dependencies);
          }
          const l = u2[0], p = u2[1], f = Math.ceil(r2[2] / 2), d = `vec4 ${t3}(int b, int row, int col) {
      vec2 uv = packedUVfrom3D(
        ${p}, ${l}, ${f * Math.ceil(r2[1] / 2)}, ${f}, b, row, col);
      return ${c.texture2D}(${e2}, uv);}`;
          return new i2.GlslLibRoutine(d, ["coordinates.packedUVfrom3D"]);
        }
        getPackedSamplerND(t3, e2, n2) {
          const r2 = n2.unpackedShape, a2 = r2.length, s2 = [n2.width, n2.height], u2 = (0, o.getGlsl)(this.context.glContext.version), c = [s2[0], s2[1]], l = c[1], p = c[0], f = Math.ceil(r2[a2 - 1] / 2);
          let d = f * Math.ceil(r2[a2 - 2] / 2), h = "int b, int row, int col", g = `b * ${d} + (row / 2) * ${f} + (col / 2)`;
          for (let t4 = 2; t4 < a2 - 1; t4++) h = `int b${t4}, ` + h, d *= r2[a2 - t4 - 1], g = `b${t4} * ${d} + ` + g;
          const b = `vec4 ${t3}(${h}) {
      int index = ${g};
      int texR = index / ${p};
      int texC = index - texR * ${p};
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${p}, ${l});
      return ${u2.texture2D}(${e2}, uv);
    }`;
          return new i2.GlslLibRoutine(b);
        }
        getUnpackedSamplerScalar(t3, e2, n2) {
          const [r2, o2] = [n2.width, n2.height];
          if (1 === r2 && 1 === o2) {
            const n3 = `
          float ${t3}() {
            return sampleTexture(${e2}, halfCR);
          }
        `;
            return new i2.GlslLibRoutine(n3, ["coordinates.sampleTexture"]);
          }
          const a2 = `
        float ${t3}() {
          int offset_${e2} = coordsToOffset(TexCoords, ${r2}, ${o2});
          vec2 uv = uvFromFlat(${r2}, ${o2}, offset_${e2});
          return sampleTexture(${e2}, uv);
        }
      `;
          return new i2.GlslLibRoutine(a2, ["coordinates.uvFromFlat", "coordinates.sampleTexture", "coordinates.coordsToOffset"]);
        }
        getUnpackedSampler1D(t3, e2, n2) {
          const r2 = n2.width, o2 = n2.height;
          if (1 === o2 && 1 === r2) {
            const n3 = `
        float ${t3}(int index) {
          return sampleTexture(${e2}, halfCR);
        }
      `;
            return new i2.GlslLibRoutine(n3, ["coordinates.sampleTexture"]);
          }
          if (1 === o2) {
            const n3 = `
          float ${t3}(int index) {
            vec2 uv = vec2((float(index) + 0.5) / ${r2}.0, 0.5);
            return sampleTexture(${e2}, uv);
          }
        `;
            return new i2.GlslLibRoutine(n3, ["coordinates.sampleTexture"]);
          }
          if (1 === r2) {
            const n3 = `
          float ${t3}(int index) {
            vec2 uv = vec2(0.5, (float(index) + 0.5) / ${o2}.0);
            return sampleTexture(${e2}, uv);
          }
        `;
            return new i2.GlslLibRoutine(n3, ["coordinates.sampleTexture"]);
          }
          const a2 = `
        float ${t3}(int index) {
          vec2 uv = uvFromFlat(${r2}, ${o2}, index);
          return sampleTexture(${e2}, uv);
        }
      `;
          return new i2.GlslLibRoutine(a2, ["coordinates.uvFromFlat", "coordinates.sampleTexture"]);
        }
        getUnpackedSampler2D(t3, e2, n2) {
          const o2 = n2.unpackedShape, u2 = [n2.height, n2.width];
          if (null != u2 && r.ArrayUtil.arraysEqual(o2, u2)) {
            const n3 = `
          float ${t3}(int row, int col) {
            vec2 uv = (vec2(row, col) + halfCR) / vec2(${u2[1]}.0, ${u2[0]}.0);
            return sampleTexture(${e2}, uv);
          }
        `;
            return new i2.GlslLibRoutine(n3, ["coordinates.sampleTexture"]);
          }
          const { newShape: c, keptDims: l } = (0, a.squeezeShape)(o2), p = c;
          if (p.length < o2.length) {
            const r2 = (0, s.squeezeInputShape)(o2, p), a2 = JSON.parse(JSON.stringify(n2));
            a2.unpackedShape = r2;
            const u3 = ["col", "row"], c2 = `
          ${this.getUnpackedSamplerFromInput(t3, e2, a2).routineBody}
          float ${t3}(int row, int col) {
            return ${t3}(${(0, s.getSqueezedParams)(u3, l)});
          }
        `;
            return new i2.GlslLibRoutine(c2, ["coordinates.sampleTexture"]);
          }
          const f = u2[1], d = u2[0];
          if (1 === d) {
            const n3 = `
          float ${t3}(int row, int col) {
            int offset_${e2} = coordsToOffset(TexCoords, ${f}, ${d});
            float index = dot(vec3(row, col, offset_${e2}), vec3(${o2[1]}, 1, 1));
            vec2 uv = vec2(0.5, (index + 0.5) / ${f}.0);
            return sampleTexture(${e2}, uv);
          }
        `;
            return new i2.GlslLibRoutine(n3, ["coordinates.sampleTexture", "coordinates.coordsToOffset"]);
          }
          if (1 === f) {
            const n3 = `
          float ${t3}(int row, int col) {
            int offset_${e2} = coordsToOffset(TexCoords, ${f}, ${d});
            float index = dot(vec3(row, col, offset_${e2}), vec3(${o2[1]}, 1, 1));
            vec2 uv = vec2((index + 0.5) / ${d}.0, 0.5);
            return sampleTexture(${e2}, uv);
          }
        `;
            return new i2.GlslLibRoutine(n3, ["coordinates.sampleTexture", "coordinates.coordsToOffset"]);
          }
          const h = `
        float ${t3}(int row, int col) {
          int index = col * ${o2[1]} + row;
          vec2 uv = uvFromFlat(${f}, ${d}, index);
          return sampleTexture(${e2}, uv);
        }
      `;
          return new i2.GlslLibRoutine(h, ["coordinates.uvFromFlat", "coordinates.sampleTexture", "coordinates.coordsToOffset"]);
        }
        getUnpackedSampler3D(t3, e2, n2) {
          const r2 = n2.unpackedShape, o2 = r2[1] * r2[2], u2 = r2[2], { newShape: c, keptDims: l } = (0, a.squeezeShape)(r2), p = c;
          if (p.length < r2.length) {
            const o3 = (0, s.squeezeInputShape)(r2, p), a2 = ["batch", "col", "row"], u3 = JSON.parse(JSON.stringify(n2));
            u3.unpackedShape = o3;
            const c2 = this.getUnpackedSamplerFromInput(t3, e2, u3), f2 = l.reverse(), d = `
          ${c2.routineBody}
          float ${t3}(int batch, int row, int col) {
            return ${t3}(${(0, s.getSqueezedParams)(a2, f2)});
          }
        `;
            return new i2.GlslLibRoutine(d, c2.dependencies);
          }
          const f = `
          float ${t3}(int depth, int row, int col) {
            // Explicitly use integer operations as dot() only works on floats.
            int index = depth * ${o2} + col * ${u2} + row;
            vec2 uv = uvFromFlat(${n2.width}, ${n2.height}, index);
            return sampleTexture(${e2}, uv);
          }
      `;
          return new i2.GlslLibRoutine(f, ["coordinates.uvFromFlat", "coordinates.sampleTexture", "coordinates.coordsToOffset"]);
        }
        getUnpackedSampler4D(t3, e2, n2) {
          const r2 = n2.unpackedShape, o2 = r2[3], a2 = r2[2] * o2, s2 = `
        float ${t3}(int row, int col, int depth, int depth2) {
          int index = row * ${r2[1] * a2} + col * ${a2} +
              depth2 * ${o2} + depth;
          vec2 uv = uvFromFlat(${n2.width}, ${n2.height}, index);
          return sampleTexture(${e2}, uv);
        }
      `;
          return new i2.GlslLibRoutine(s2, ["coordinates.uvFromFlat", "coordinates.sampleTexture"]);
        }
        getUnpackedSampler5D(t3, e2, n2) {
          const r2 = n2.unpackedShape, o2 = r2[4], u2 = r2[3] * o2, c = r2[2] * u2, l = r2[1] * c, { newShape: p, keptDims: f } = (0, a.squeezeShape)(r2);
          if (p.length < r2.length) {
            const o3 = (0, s.squeezeInputShape)(r2, p), a2 = ["row", "col", "depth", "depth2", "depth3"], u3 = JSON.parse(JSON.stringify(n2));
            u3.unpackedShape = o3;
            const c2 = `
          ${this.getUnpackedSamplerFromInput(t3, e2, u3).routineBody}
          float ${t3}(int row, int col, int depth, int depth2, int depth3) {
            return ${t3}(${(0, s.getSqueezedParams)(a2, f)});
          }
        `;
            return new i2.GlslLibRoutine(c2, ["coordinates.sampleTexture", "coordinates.uvFromFlat"]);
          }
          const d = `
        float ${t3}(int row, int col, int depth, int depth2, int depth3) {
          int index = row * ${l} + col * ${c} + depth * ${u2} +
          depth3 * ${o2} + depth2;
          vec2 uv = uvFromFlat(${n2.width}, ${n2.height}, index);
          return sampleTexture(${e2}, uv);
        }
      `;
          return new i2.GlslLibRoutine(d, ["coordinates.sampleTexture", "coordinates.uvFromFlat"]);
        }
        getUnpackedSampler6D(t3, e2, n2) {
          const r2 = n2.unpackedShape, o2 = r2[5], u2 = r2[4] * o2, c = r2[3] * u2, l = r2[2] * c, p = r2[1] * l, { newShape: f, keptDims: d } = (0, a.squeezeShape)(r2);
          if (f.length < r2.length) {
            const o3 = (0, s.squeezeInputShape)(r2, f), a2 = ["row", "col", "depth", "depth2", "depth3", "depth4"], u3 = JSON.parse(JSON.stringify(n2));
            u3.unpackedShape = o3;
            const c2 = `
            ${this.getUnpackedSamplerFromInput(t3, e2, u3).routineBody}
            float ${t3}(int row, int col, int depth,
              int depth2, int depth3, int depth4) {
              return ${t3}(${(0, s.getSqueezedParams)(a2, d)});
            }
          `;
            return new i2.GlslLibRoutine(c2, ["coordinates.sampleTexture", "coordinates.uvFromFlat"]);
          }
          const h = `
          float ${t3}(int row, int col, int depth,
            int depth2, int depth3, int depth4) {
            int index = row * ${p} + col * ${l} + depth * ${c} +
            depth2 * ${u2} + depth3 * ${o2} + depth4;
            vec2 uv = uvFromFlat(${n2.width}, ${n2.height}, index);
            return sampleTexture(${e2}, uv);
          }
        `;
          return new i2.GlslLibRoutine(h, ["coordinates.uvFromFlat", "coordinates.sampleTexture", "coordinates.coordsToOffset"]);
        }
        toVec() {
          const t3 = this.context.outputTextureLayout, e2 = t3.shape.length, n2 = t3.strides, r2 = t3.width, o2 = t3.height, a2 = [];
          for (let t4 = 0; t4 < e2 - 1; ++t4) a2.push(`
        c[${t4}] = offset / ${n2[t4]};`), a2.push(`
        offset -= c[${t4}] * ${n2[t4]};`);
          a2.push(`
        c[${e2 - 1}] = offset;`);
          const s2 = `
      void toVec(vec2 texCoords, out int c[${e2}]) {
        int offset = coordsToOffset(texCoords, ${r2}, ${o2});
        ${a2.join("")}
      }
      void toVec(int offset, out int c[${e2}]) {
        ${a2.join("")}
      }
    `;
          return { toVec: new i2.GlslLibRoutine(s2, ["coordinates.coordsToOffset"]) };
        }
        valueFrom() {
          const t3 = {};
          return this.context.programInfo.inputNames.forEach((e2, n2) => {
            const r2 = this.context.inputTextureLayouts[n2], o2 = (r2.unpackedShape.length > 0 ? r2.unpackedShape : r2.shape).length;
            let a2 = `_${e2}`;
            t3[a2] = new i2.GlslLibRoutine(this.getValueFromSingle(e2, o2, r2.width, r2.height, false), [`shapeUtils.indicesToOffset${a2}`, "coordinates.offsetToCoords", "fragcolor.getColorAsFloat"]), a2 += "_T", t3[a2] = new i2.GlslLibRoutine(this.getValueFromSingle(e2, o2, r2.width, r2.height, true), [`shapeUtils.indicesToOffset${a2}`, "coordinates.offsetToCoords", "fragcolor.getColorAsFloat"]);
          }), t3;
        }
        getValueFromSingle(t3, e2, n2, r2, i3) {
          let a2 = `_${t3}`;
          return i3 && (a2 += "_T"), `
        float ${a2}(int m[${e2}]) {
          int offset = indicesToOffset${a2}(m);
          vec2 coords = offsetToCoords(offset, ${n2}, ${r2});
          float value = getColorAsFloat(${(0, o.getGlsl)(this.context.glContext.version).texture2D}(${t3}, coords));
          return value;
        }
        `;
        }
        getPackedValueFrom(t3, e2, n2, r2, i3) {
          let a2 = `_${t3}_Pack`;
          return i3 && (a2 += "_T"), `
        vec4 ${a2}(int m[${e2}]) {
          int offset = indicesToOffset_${t3}(m);
          vec2 coords = offsetToCoords(offset, ${n2}, ${r2});
          return ${(0, o.getGlsl)(this.context.glContext.version).texture2D}(${t3}, coords);
        }
        `;
        }
      }
      e.CoordsGlslLib = u;
    }, 8520: (t2, e) => {
      var n;
      Object.defineProperty(e, "__esModule", { value: true }), e.TopologicalSortGlslRoutines = e.GlslLibRoutineNode = e.GlslLibRoutine = e.GlslLib = e.GlslContext = e.FunctionType = void 0, (n = e.FunctionType || (e.FunctionType = {}))[n.ValueBased = 0] = "ValueBased", n[n.Positional = 1] = "Positional", e.GlslContext = class {
        constructor(t3, e2, n2, r) {
          this.glContext = t3, this.programInfo = e2, this.inputTextureLayouts = n2, this.outputTextureLayout = r;
        }
      }, e.GlslLib = class {
        constructor(t3) {
          this.context = t3;
        }
      }, e.GlslLibRoutine = class {
        constructor(t3, e2) {
          this.routineBody = t3, this.dependencies = e2;
        }
      }, e.GlslLibRoutineNode = class {
        constructor(t3, e2, n2) {
          this.name = t3, this.dependencies = n2 || [], e2 && (this.routineBody = e2);
        }
        addDependency(t3) {
          t3 && this.dependencies.push(t3);
        }
      }, e.TopologicalSortGlslRoutines = class {
        static returnOrderedNodes(t3) {
          if (!t3 || 0 === t3.length) return [];
          if (1 === t3.length) return t3;
          const e2 = /* @__PURE__ */ new Set(), n2 = /* @__PURE__ */ new Set(), r = new Array();
          return this.createOrderedNodes(t3, e2, n2, r), r;
        }
        static createOrderedNodes(t3, e2, n2, r) {
          for (let i2 = 0; i2 < t3.length; ++i2) this.dfsTraverse(t3[i2], e2, n2, r);
        }
        static dfsTraverse(t3, e2, n2, r) {
          if (!t3 || n2.has(t3.name)) return;
          if (e2.has(t3.name)) throw new Error("Cyclic dependency detected. Can't topologically sort routines needed for shader.");
          e2.add(t3.name);
          const i2 = t3.dependencies;
          if (i2 && i2.length > 0) for (let t4 = 0; t4 < i2.length; ++t4) this.dfsTraverse(i2[t4], e2, n2, r);
          r.push(t3), n2.add(t3.name), e2.delete(t3.name);
        }
      };
    }, 7341: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.EncodingGlslLib = void 0;
      const r = n(8520);
      class i2 extends r.GlslLib {
        constructor(t3) {
          super(t3);
        }
        getFunctions() {
          return Object.assign(Object.assign({}, this.encodeFloat32()), this.decodeFloat32());
        }
        getCustomTypes() {
          return {};
        }
        encodeFloat32() {
          return { encode: new r.GlslLibRoutine("highp vec4 encode(highp float f) {\n        return vec4(f, 0.0, 0.0, 0.0);\n      }\n        ") };
        }
        decodeFloat32() {
          return { decode: new r.GlslLibRoutine("highp float decode(highp vec4 rgba) {\n        return rgba.r;\n      }\n        ") };
        }
        encodeUint8() {
          const t3 = i2.isLittleEndian() ? "rgba.rgba=rgba.abgr;" : "";
          return { encode: new r.GlslLibRoutine(`
      highp vec4 encode(highp float f) {
        highp float F = abs(f);
        highp float Sign = step(0.0,-f);
        highp float Exponent = floor(log2(F));
        highp float Mantissa = (exp2(- Exponent) * F);
        Exponent = floor(log2(F) + 127.0) + floor(log2(Mantissa));
        highp vec4 rgba;
        rgba[0] = 128.0 * Sign  + floor(Exponent*exp2(-1.0));
        rgba[1] = 128.0 * mod(Exponent,2.0) + mod(floor(Mantissa*128.0),128.0);
        rgba[2] = floor(mod(floor(Mantissa*exp2(23.0 -8.0)),exp2(8.0)));
        rgba[3] = floor(exp2(23.0)*mod(Mantissa,exp2(-15.0)));
        ${t3}
        rgba = rgba / 255.0; // values need to be normalized to [0,1]
        return rgba;
    }
        `) };
        }
        decodeUint8() {
          const t3 = i2.isLittleEndian() ? "rgba.rgba=rgba.abgr;" : "";
          return { decode: new r.GlslLibRoutine(`
        highp float decode(highp vec4 rgba) {
          rgba = rgba * 255.0; // values need to be de-normalized from [0,1] to [0,255]
          ${t3}
          highp float Sign = 1.0 - step(128.0,rgba[0])*2.0;
          highp float Exponent = 2.0 * mod(rgba[0],128.0) + step(128.0,rgba[1]) - 127.0;
          highp float Mantissa = mod(rgba[1],128.0)*65536.0 + rgba[2]*256.0 +rgba[3] + float(0x800000);
          highp float Result =  Sign * exp2(Exponent) * (Mantissa * exp2(-23.0 ));
          return Result;
      }
        `) };
        }
        static isLittleEndian() {
          const t3 = new ArrayBuffer(4), e2 = new Uint32Array(t3), n2 = new Uint8Array(t3);
          if (e2[0] = 3735928559, 239 === n2[0]) return true;
          if (222 === n2[0]) return false;
          throw new Error("unknown endianness");
        }
      }
      e.EncodingGlslLib = i2;
    }, 9894: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.FragColorGlslLib = void 0;
      const r = n(8520), i2 = n(5060);
      class o extends r.GlslLib {
        constructor(t3) {
          super(t3);
        }
        getFunctions() {
          return Object.assign(Object.assign({}, this.setFragColor()), this.getColorAsFloat());
        }
        getCustomTypes() {
          return {};
        }
        setFragColor() {
          const t3 = (0, i2.getGlsl)(this.context.glContext.version);
          return { setFragColor: new r.GlslLibRoutine(`
        void setFragColor(float value) {
            ${t3.output} = encode(value);
        }
        `, ["encoding.encode"]) };
        }
        getColorAsFloat() {
          return { getColorAsFloat: new r.GlslLibRoutine("\n        float getColorAsFloat(vec4 color) {\n            return decode(color);\n        }\n        ", ["encoding.decode"]) };
        }
      }
      e.FragColorGlslLib = o;
    }, 2848: (t2, e) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.replaceInlines = void 0;
      const n = /@inline[\s\n\r]+(\w+)[\s\n\r]+([0-9a-zA-Z_]+)\s*\(([^)]*)\)\s*{(([^}]|[\n\r])*)}/gm;
      e.replaceInlines = function(t3) {
        const e2 = {};
        let r;
        for (; null !== (r = n.exec(t3)); ) {
          const t4 = r[3].split(",").map((t5) => {
            const e3 = t5.trim().split(" ");
            return e3 && 2 === e3.length ? { type: e3[0], name: e3[1] } : null;
          }).filter((t5) => null !== t5);
          e2[r[2]] = { params: t4, body: r[4] };
        }
        for (const n2 in e2) {
          const i2 = "(\\w+)?\\s+([_0-9a-zA-Z]+)\\s+=\\s+__FUNC__\\((.*)\\)\\s*;".replace("__FUNC__", n2), o = new RegExp(i2, "gm");
          for (; null !== (r = o.exec(t3)); ) {
            const i3 = r[1], o2 = r[2], a = r[3].split(","), s = i3 ? `${i3} ${o2};` : "";
            let u = e2[n2].body, c = "";
            e2[n2].params.forEach((t4, e3) => {
              t4 && (c += `${t4.type} ${t4.name} = ${a[e3]};
`);
            }), u = `${c}
 ${u}`, u = u.replace("return", `${o2} = `);
            const l = `
      ${s}
      {
        ${u}
      }
      `;
            t3 = t3.replace(r[0], l);
          }
        }
        return t3.replace(n, "");
      };
    }, 8879: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.GlslPreprocessor = void 0;
      const r = n(8520), i2 = n(2848), o = n(5483), a = n(5060);
      e.GlslPreprocessor = class {
        constructor(t3, e2, n2, i3) {
          this.libs = {}, this.glslLibRoutineDependencyGraph = {}, this.context = new r.GlslContext(t3, e2, n2, i3), Object.keys(o.glslRegistry).forEach((t4) => {
            const e3 = new o.glslRegistry[t4](this.context);
            this.libs[t4] = e3;
          });
          const a2 = this.glslLibRoutineDependencyGraph;
          for (const t4 in this.libs) {
            const e3 = this.libs[t4].getFunctions();
            for (const n3 in e3) {
              const i4 = t4 + "." + n3;
              let o2;
              a2[i4] ? (o2 = a2[i4], o2.routineBody = e3[n3].routineBody) : (o2 = new r.GlslLibRoutineNode(i4, e3[n3].routineBody), a2[i4] = o2);
              const s = e3[n3].dependencies;
              if (s) for (let t5 = 0; t5 < s.length; ++t5) if (a2[s[t5]]) o2.addDependency(a2[s[t5]]);
              else {
                const e4 = new r.GlslLibRoutineNode(s[t5]);
                a2[s[t5]] = e4, o2.addDependency(e4);
              }
            }
          }
        }
        preprocess() {
          const t3 = this.context.programInfo;
          let e2 = t3.shaderSource;
          return this.context.programInfo.hasMain || (e2 = `${e2}
      ${(0, a.getDefaultFragShaderMain)(this.context.glContext.version, this.context.outputTextureLayout.shape.length)}`), e2 = (0, i2.replaceInlines)(e2), `${(0, a.getFragShaderPreamble)(this.context.glContext.version)}
    ${this.getUniforms(t3.inputNames, t3.variables)}
    ${this.getImports(e2)}
    ${e2}`;
        }
        getImports(t3) {
          const e2 = this.selectGlslLibRoutinesToBeIncluded(t3);
          if (0 === e2.length) return "";
          let n2 = "";
          for (let t4 = 0; t4 < e2.length; ++t4) {
            if (!e2[t4].routineBody) throw new Error(`Missing body for the Glsl Library routine: ${e2[t4].name}`);
            n2 += e2[t4].routineBody + "\n";
          }
          return n2;
        }
        selectGlslLibRoutinesToBeIncluded(t3) {
          const e2 = [];
          return Object.keys(this.glslLibRoutineDependencyGraph).forEach((n2) => {
            const r2 = n2.split(".")[1];
            -1 !== t3.indexOf(r2) && e2.push(this.glslLibRoutineDependencyGraph[n2]);
          }), r.TopologicalSortGlslRoutines.returnOrderedNodes(e2);
        }
        getUniforms(t3, e2) {
          const n2 = [];
          if (t3) for (const e3 of t3) n2.push(`uniform sampler2D ${e3};`);
          if (e2) for (const t4 of e2) n2.push(`uniform ${t4.type} ${t4.name}${t4.arrayLength ? `[${t4.arrayLength}]` : ""};`);
          return n2.join("\n");
        }
      };
    }, 5483: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.glslRegistry = void 0;
      const r = n(5107), i2 = n(7341), o = n(9894), a = n(2655), s = n(3891);
      e.glslRegistry = { encoding: i2.EncodingGlslLib, fragcolor: o.FragColorGlslLib, vec: s.VecGlslLib, shapeUtils: a.ShapeUtilsGlslLib, coordinates: r.CoordsGlslLib };
    }, 2655: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.ShapeUtilsGlslLib = void 0;
      const r = n(8520);
      class i2 extends r.GlslLib {
        constructor(t3) {
          super(t3);
        }
        getFunctions() {
          return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, this.bcastIndex()), this.bcastMatmulIndex()), this.offsetToIndices()), this.indicesToOffset()), this.incrementIndices());
        }
        getCustomTypes() {
          return {};
        }
        bcastIndex() {
          const t3 = this.context.outputTextureLayout.shape.length, e2 = {};
          return this.context.programInfo.inputNames.forEach((n2, i3) => {
            const o = this.context.inputTextureLayouts[i3].unpackedShape;
            if (o.length <= t3) {
              const i4 = o.length, a = t3 - i4, s = `bcastIndices_${n2}`;
              let u = "";
              for (let t4 = 0; t4 < i4; ++t4) u += `
          realIndices[${t4}] = int( mod(float(bcastedIndices[${a + t4}]), ${o[t4]}.0) );
          `;
              const c = `
        void ${s} (int bcastedIndices[${t3}], out int realIndices[${i4}]) {
          ${u}
        }
        `;
              e2[s] = new r.GlslLibRoutine(c);
            }
          }), e2;
        }
        bcastMatmulIndex() {
          const t3 = this.context.outputTextureLayout.shape.length, e2 = {};
          return this.context.programInfo.inputNames.forEach((n2, i3) => {
            const o = this.context.inputTextureLayouts[i3].shape;
            if (!(o.length < 2 || o.length > t3)) {
              const i4 = o.length, a = t3 - i4, s = `bcastMatmulIndices_${n2}`;
              let u = "";
              for (let t4 = 0; t4 < i4 - 2; ++t4) u += `
          realIndices[${t4}] = int( mod(float(bcastedIndices[${a + t4}]), ${o[t4]}.0) );
          `;
              const c = `
        void ${s}(int bcastedIndices[${t3}], out int realIndices[${i4}]) {
          ${u}
          realIndices[${i4 - 1}] = bcastedIndices[${t3 - 1}];
          realIndices[${i4 - 2}] = bcastedIndices[${t3 - 2}];
        }
        `;
              e2[s] = new r.GlslLibRoutine(c);
            }
          }), e2;
        }
        indicesToOffset() {
          const t3 = {};
          return this.context.programInfo.inputNames.forEach((e2, n2) => {
            const o = this.context.inputTextureLayouts[n2].shape, a = this.context.inputTextureLayouts[n2].strides, s = o.length;
            let u = `indicesToOffset_${e2}`;
            t3[u] = new r.GlslLibRoutine(i2.indexToOffsetSingle(u, s, a)), u = `indicesToOffset_${e2}_T`, t3[u] = new r.GlslLibRoutine(i2.indexToOffsetSingle(u, s, a.slice().reverse()));
          }), t3;
        }
        static indexToOffsetSingle(t3, e2, n2) {
          let r2 = "";
          for (let t4 = e2 - 1; t4 >= 0; --t4) r2 += `
        offset += indices[${t4}] * ${n2[t4]};
        `;
          return `
      int ${t3}(int indices[${e2}]) {
        int offset = 0;
        ${r2}
        return offset;
      }
      `;
        }
        offsetToIndices() {
          const t3 = {};
          return this.context.programInfo.inputNames.forEach((e2, n2) => {
            const o = this.context.inputTextureLayouts[n2].shape, a = this.context.inputTextureLayouts[n2].strides, s = o.length;
            let u = `offsetToIndices_${e2}`;
            t3[u] = new r.GlslLibRoutine(i2.offsetToIndicesSingle(u, s, a)), u = `offsetToIndices_${e2}_T`, t3[u] = new r.GlslLibRoutine(i2.offsetToIndicesSingle(u, s, a.slice().reverse()));
          }), t3;
        }
        static offsetToIndicesSingle(t3, e2, n2) {
          const r2 = [];
          for (let t4 = 0; t4 < e2 - 1; ++t4) r2.push(`
      indices[${t4}] = offset / ${n2[t4]};`), r2.push(`
        offset -= indices[${t4}] * ${n2[t4]};`);
          return r2.push(`
      indices[${e2 - 1}] = offset;`), `
      void ${t3}(int offset, out int indices[${e2}]) {
        ${r2.join("")}
      }
      `;
        }
        incrementIndices() {
          const t3 = {};
          return this.context.programInfo.inputNames.forEach((e2, n2) => {
            const i3 = this.context.inputTextureLayouts[n2].shape, o = i3.length, a = `incrementIndices_${e2}`;
            let s = "";
            for (let t4 = 0; t4 < o; ++t4) s += `
        shape[${t4}] = ${i3[t4]};`;
            const u = `
        void ${a}(int axis, out int indices[${o}]) {
          int shape[${o}];
          ${s};
          for(int i = ${o} -1 ; i >= 0; --i) {
            if(i > axis) continue;
            indices[i] += 1;
            if(indices[i] < shape[i]) {
              break;
            }
            indices[i] = 0;
          }
        }
        `;
            t3[a] = new r.GlslLibRoutine(u);
          }), t3;
        }
      }
      e.ShapeUtilsGlslLib = i2;
    }, 5060: (t2, e) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.getDefaultFragShaderMain = e.getFragShaderPreamble = e.getVertexShaderSource = e.getGlsl = void 0;
      const n = { version: "", attribute: "attribute", varyingVertex: "varying", varyingFrag: "varying", texture2D: "texture2D", output: "gl_FragColor", outputDeclaration: "" }, r = { version: "#version 300 es", attribute: "in", varyingVertex: "out", varyingFrag: "in", texture2D: "texture", output: "outputColor", outputDeclaration: "out vec4 outputColor;" };
      function i2(t3) {
        return 1 === t3 ? n : r;
      }
      e.getGlsl = i2, e.getVertexShaderSource = function(t3) {
        const e2 = i2(t3);
        return `${e2.version}
      precision highp float;
      ${e2.attribute} vec3 position;
      ${e2.attribute} vec2 textureCoord;

      ${e2.varyingVertex} vec2 TexCoords;

      void main()
      {
          gl_Position = vec4(position, 1.0);
          TexCoords = textureCoord;
      }`;
      }, e.getFragShaderPreamble = function(t3) {
        const e2 = i2(t3);
        return `${e2.version}
    precision highp float;
    precision highp int;
    precision highp sampler2D;
    ${e2.varyingFrag} vec2 TexCoords;
    ${e2.outputDeclaration}
    const vec2 halfCR = vec2(0.5, 0.5);

    // Custom vector types to handle higher dimenalities.
    struct ivec5
    {
      int x;
      int y;
      int z;
      int w;
      int u;
    };

    struct ivec6
    {
      int x;
      int y;
      int z;
      int w;
      int u;
      int v;
    };

    int imod(int x, int y) {
      return x - y * (x / y);
    }

    `;
      }, e.getDefaultFragShaderMain = function(t3, e2) {
        return `
  void main() {
    int indices[${e2}];
    toVec(TexCoords, indices);
    vec4 result = vec4(process(indices));
    ${i2(t3).output} = result;
  }
  `;
      };
    }, 3891: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.VecGlslLib = void 0;
      const r = n(8520);
      class i2 extends r.GlslLib {
        constructor(t3) {
          super(t3);
        }
        getCustomTypes() {
          return {};
        }
        getFunctions() {
          return Object.assign(Object.assign(Object.assign(Object.assign({}, this.binaryVecFunctions()), this.copyVec()), this.setVecItem()), this.getVecItem());
        }
        binaryVecFunctions() {
          const t3 = this.context.outputTextureLayout.shape.length, e2 = { add: "+=", sub: "-=", mul: "*=", div: "/=" }, n2 = {};
          for (const i3 in e2) {
            const o = `${i3}Vec`;
            let a = "";
            for (let n3 = 0; n3 < t3; ++n3) a += `
          dest[${n3}] ${e2[i3]} src[${n3}];
          `;
            const s = `
        void ${o}(int src[${t3}], out int dest[${t3}]) {
          ${a}
        }
        `;
            n2[o] = new r.GlslLibRoutine(s);
          }
          return n2;
        }
        copyVec() {
          const t3 = this.context.outputTextureLayout.shape.length;
          let e2 = "";
          for (let n3 = 0; n3 < t3; ++n3) e2 += `
        dest[${n3}] = src[${n3}];
        `;
          const n2 = `
      void copyVec(int src[${t3}], out int dest[${t3}]) {
        ${e2}
      }
      `;
          return { copyVec: new r.GlslLibRoutine(n2) };
        }
        setVecItem() {
          const t3 = this.context.outputTextureLayout.shape.length;
          let e2 = `
        if(index < 0)
            index =${t3} + index;
        if (index == 0)
            m[0] = value;
        `;
          for (let n3 = 1; n3 < t3 - 1; ++n3) e2 += `
        else if (index == ${n3})
            m[${n3}] = value;
            `;
          e2 += `
        else
            m[${t3 - 1}] = value;
        `;
          const n2 = `
      void setVecItem(out int m[${t3}], int index, int value) {
        ${e2}
      }
        `;
          return { setVecItem: new r.GlslLibRoutine(n2) };
        }
        getVecItem() {
          const t3 = this.context.outputTextureLayout.shape.length;
          let e2 = `
        if(index < 0)
            index = ${t3} + index;
        if (index == 0)
            return m[0];
      `;
          for (let n3 = 1; n3 < t3 - 1; ++n3) e2 += `
        else if (index == ${n3})
            return m[${n3}];
      `;
          e2 += `
        else
            return m[${t3 - 1}];
        `;
          const n2 = `
      int getVecItem(int m[${t3}], int index) {
        ${e2}
      }
    `;
          return { getVecItem: new r.GlslLibRoutine(n2) };
        }
      }
      e.VecGlslLib = i2;
    }, 8316: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.WebGLInferenceHandler = void 0;
      const r = n(3694), i2 = n(9162), o = n(2517), a = n(2403), s = n(7019), u = n(8710), c = n(5611), l = n(4057), p = n(2039);
      e.WebGLInferenceHandler = class {
        constructor(t3) {
          this.session = t3, this.packedTextureDataCache = /* @__PURE__ */ new Map(), this.unpackedTextureDataCache = /* @__PURE__ */ new Map();
        }
        calculateTextureWidthAndHeight(t3, e2) {
          return (0, l.calculateTextureWidthAndHeight)(this.session.layoutStrategy, t3, e2);
        }
        executeProgram(t3, e2) {
          if (e2.length < t3.inputNames.length) throw new Error(`Input size mustn't be less than ${t3.inputNames.length}.`);
          if (t3.inputNames.length !== t3.inputTypes.length) throw new Error("input names size does not match input types");
          const n2 = [];
          for (let r3 = 0; r3 < t3.inputNames.length; ++r3) n2[r3] = this.getOrCreateTextureData(e2[r3], t3.inputTypes[r3]);
          const r2 = ((t4, e3) => {
            const n3 = e3.map((t5) => `${t5.unpackedShape.join(",")};${t5.width}x${t5.height}`).join("_");
            let r3 = t4.name;
            return t4.cacheHint && (r3 += "[" + t4.cacheHint + "]"), r3 += ":" + n3, r3;
          })(t3, n2);
          let i3 = this.session.programManager.getArtifact(r2);
          const o2 = i3 ? i3.programInfo : "function" == typeof t3.get ? t3.get() : t3, a2 = (0, l.createTextureLayoutFromTextureType)(this.session.layoutStrategy, o2.output.dims, o2.output.textureType), s2 = this.createTextureData(a2, o2.output.type);
          return i3 || (i3 = this.session.programManager.build(o2, n2, s2), this.session.programManager.setArtifact(r2, i3)), this.runProgram(i3, n2, s2), s2;
        }
        run(t3, e2) {
          return this.executeProgram(t3, e2).tensor;
        }
        runProgram(t3, e2, n2) {
          for (let n3 = 0; n3 < e2.length; ++n3) if (!!e2[n3].isPacked != (t3.programInfo.inputTypes[n3] === p.TextureType.packed)) throw new Error(`input[${n3}] property packed inconsistent`);
          if (!!n2.isPacked != (t3.programInfo.output.textureType === p.TextureType.packed)) throw new Error("output property packed inconsistent");
          this.session.programManager.run(t3, e2, n2);
        }
        getOrCreateTextureData(t3, e2) {
          let n2 = this.getTextureData(t3.dataId, e2 === p.TextureType.packed);
          if (!n2 && (n2 = this.getTextureData(t3.dataId, e2 !== p.TextureType.packed), n2)) return e2 === p.TextureType.packed ? this.pack(n2) : this.unpack(n2);
          if (!n2) {
            const r2 = (0, l.createTextureLayoutFromTextureType)(this.session.layoutStrategy, t3.dims, e2);
            if (e2 === p.TextureType.packedLastDimension) {
              const n3 = 1, r3 = 4, i3 = t3.dims;
              if (4 === i3.length) {
                const o2 = [i3[0], Math.ceil(i3[1] * i3[2] * i3[3] / r3)], a2 = (0, l.createTextureLayoutFromTextureType)(this.session.layoutStrategy, o2, e2);
                let s2 = t3.numberData;
                if (i3[1] * i3[2] * i3[3] % r3 != 0) {
                  const e3 = i3[0], o3 = i3[1] * i3[2] * i3[3], a3 = Math.ceil(o3 * n3 / r3) * r3;
                  s2 = new Float32Array(e3 * a3);
                  for (let r4 = 0; r4 < e3; ++r4) {
                    const e4 = r4 * o3, i4 = r4 * a3 + r4 % n3 * o3;
                    s2.set(t3.numberData.subarray(e4, e4 + o3), i4);
                  }
                }
                return this.createTextureData(a2, t3.type, s2, t3, 1);
              }
            }
            if (e2 === p.TextureType.packed) {
              const e3 = (0, l.createTextureLayoutFromShape)(this.session.layoutStrategy, t3.dims, 1, [], { reverseWH: true }), r3 = this.createTextureData(e3, t3.type, t3.numberData, t3, 1);
              n2 = this.pack(r3);
            } else n2 = this.createTextureData(r2, t3.type, t3.numberData, t3, 1);
          }
          return n2;
        }
        createTextureDataFromLayoutBindTensor(t3, e2, n2, r2) {
          return this.createTextureData(t3, e2, n2, r2, 1);
        }
        createTextureData(t3, e2, n2, i3, o2) {
          r.Logger.verbose("InferenceHandler", `Creating TextureData: layout:[${JSON.stringify(t3)}]`);
          const a2 = this.session.textureManager.createTextureFromLayout(e2, t3, n2, o2);
          return this.createTextureDataFromTexture(t3, e2, a2, i3);
        }
        reshapeUnpacked(t3, e2) {
          const n2 = this.getOrCreateTextureData(t3, p.TextureType.unpacked), r2 = { channels: n2.channels, height: n2.height, width: n2.width, shape: 0 !== e2.length ? e2 : [1], strides: o.ShapeUtil.computeStrides(e2), unpackedShape: e2 };
          return this.createTextureDataFromTexture(r2, t3.type, n2.texture).tensor;
        }
        reshapePacked(t3, e2) {
          const n2 = this.getOrCreateTextureData(t3, p.TextureType.packed);
          if ((0, s.isReshapeCheap)(t3.dims, e2)) {
            const r3 = { channels: n2.channels, height: n2.height, width: n2.width, shape: 0 !== e2.length ? e2 : [1], strides: o.ShapeUtil.computeStrides(e2), unpackedShape: e2, isPacked: true };
            return this.createTextureDataFromTexture(r3, t3.type, n2.texture).tensor;
          }
          const r2 = (0, s.processDims3D)(t3.dims), i3 = (0, s.processDims3D)(e2), a2 = this.reshapePacked(t3, r2), u2 = this.run((0, s.createPackedReshape3DProgramInfoLoader)(this, a2, i3), [a2]);
          return this.reshapePacked(u2, e2);
        }
        cast(t3, e2) {
          const n2 = this.getOrCreateTextureData(t3, p.TextureType.unpacked);
          return this.createTextureDataFromTexture(n2, e2, n2.texture).tensor;
        }
        createTextureDataFromTexture(t3, e2, n2, r2, o2) {
          const a2 = Object.assign(Object.assign({}, t3), { tensor: r2 || new i2.Tensor(t3.unpackedShape, e2, (t4) => this.readTexture(a2), async (t4) => this.readTextureAsync(a2), void 0, o2), texture: n2 });
          return this.setTextureData(a2.tensor.dataId, a2, t3.isPacked), a2;
        }
        getTextureData(t3, e2 = false) {
          return this.session.isInitializer(t3) ? this.session.getTextureData(t3, e2) : e2 ? this.packedTextureDataCache.get(t3) : this.unpackedTextureDataCache.get(t3);
        }
        setTextureData(t3, e2, n2 = false) {
          this.session.isInitializer(t3) ? this.session.setTextureData(t3, e2, n2) : (n2 ? this.packedTextureDataCache : this.unpackedTextureDataCache).set(t3, e2);
        }
        isTextureLayoutCached(t3, e2 = false) {
          return !!this.getTextureData(t3.dataId, e2);
        }
        dispose() {
          this.session.textureManager.clearActiveTextures(), this.packedTextureDataCache.forEach((t3) => this.session.textureManager.releaseTexture(t3)), this.packedTextureDataCache = /* @__PURE__ */ new Map(), this.unpackedTextureDataCache.forEach((t3) => this.session.textureManager.releaseTexture(t3)), this.unpackedTextureDataCache = /* @__PURE__ */ new Map();
        }
        readTexture(t3) {
          return t3.isPacked ? this.readTexture(this.unpack(t3)) : this.session.backend.glContext.isFloat32DownloadSupported ? this.session.textureManager.readTexture(t3, t3.tensor.type, t3.channels) : this.session.textureManager.readUint8TextureAsFloat((0, u.encodeAsUint8)(this, t3));
        }
        async readTextureAsync(t3) {
          return t3.isPacked ? this.readTextureAsync(this.unpack(t3)) : this.session.backend.glContext.isFloat32DownloadSupported ? this.session.textureManager.readTextureAsync(t3, t3.tensor.type, t3.channels) : this.session.textureManager.readUint8TextureAsFloat((0, u.encodeAsUint8)(this, t3));
        }
        pack(t3) {
          return this.executeProgram((0, a.createPackProgramInfoLoader)(this, t3.tensor), [t3.tensor]);
        }
        unpack(t3) {
          return this.executeProgram((0, c.createUnpackProgramInfoLoader)(this, t3.tensor), [t3.tensor]);
        }
      };
    }, 1640: function(t2, e, n) {
      var r = this && this.__createBinding || (Object.create ? function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2);
        var i3 = Object.getOwnPropertyDescriptor(e2, n2);
        i3 && !("get" in i3 ? !e2.__esModule : i3.writable || i3.configurable) || (i3 = { enumerable: true, get: function() {
          return e2[n2];
        } }), Object.defineProperty(t3, r2, i3);
      } : function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2), t3[r2] = e2[n2];
      }), i2 = this && this.__setModuleDefault || (Object.create ? function(t3, e2) {
        Object.defineProperty(t3, "default", { enumerable: true, value: e2 });
      } : function(t3, e2) {
        t3.default = e2;
      }), o = this && this.__importStar || function(t3) {
        if (t3 && t3.__esModule) return t3;
        var e2 = {};
        if (null != t3) for (var n2 in t3) "default" !== n2 && Object.prototype.hasOwnProperty.call(t3, n2) && r(e2, t3, n2);
        return i2(e2, t3), e2;
      };
      Object.defineProperty(e, "__esModule", { value: true }), e.WEBGL_OP_RESOLVE_RULES = void 0;
      const a = n(2898), s = o(n(7839)), u = n(4196), c = n(2069), l = n(8138), p = n(9663), f = n(5193), d = n(7992), h = n(1253), g = n(4776), b = n(6572), m = n(3346), y = n(5623), _ = n(2870), v = n(2143), w = n(4939), x = n(718), T = n(2268), S = n(8117), O = n(2278), A = n(5524), E = n(5975), I = n(3933), P = n(6558), D = n(5723), $ = n(3738), k = o(n(4909)), C = n(8428), F = n(9793);
      e.WEBGL_OP_RESOLVE_RULES = [["Abs", "", "6+", k.abs], ["Acos", "", "7+", k.acos], ["Add", "", "7+", s.add], ["And", "", "7+", s.and], ["Asin", "", "7+", k.asin], ["Atan", "", "7+", k.atan], ["AveragePool", "", "7+", v.averagePool, v.parseAveragePoolAttributes], ["BatchNormalization", "", "7+", a.batchNormalization, a.parseBatchNormalizationAttributes], ["Cast", "", "6+", u.cast, u.parseCastAttributes], ["Ceil", "", "6+", k.ceil], ["Clip", "", "6-10", k.clip, k.parseClipAttributes], ["Clip", "", "11+", k.clipV11], ["Concat", "", "4+", c.concat, c.parseConcatAttributes], ["Conv", "", "1+", l.conv, l.parseConvAttributes], ["ConvTranspose", "", "1+", p.convTranspose, p.parseConvTransposeAttributes], ["Cos", "", "7+", k.cos], ["Div", "", "7+", s.div], ["Dropout", "", "7+", k.identity], ["DepthToSpace", "", "1+", f.depthToSpace, f.parseDepthToSpaceAttributes], ["Equal", "", "7+", s.equal], ["Elu", "", "6+", k.elu, k.parseEluAttributes], ["Exp", "", "6+", k.exp], ["Flatten", "", "1+", d.flatten, d.parseFlattenAttributes], ["Floor", "", "6+", k.floor], ["FusedConv", "com.microsoft", "1+", l.conv, l.parseConvAttributes], ["Gather", "", "1+", h.gather, h.parseGatherAttributes], ["Gemm", "", "7-10", g.gemm, g.parseGemmAttributesV7], ["Gemm", "", "11+", g.gemm, g.parseGemmAttributesV11], ["GlobalAveragePool", "", "1+", v.globalAveragePool, v.parseGlobalAveragePoolAttributes], ["GlobalMaxPool", "", "1+", v.globalMaxPool], ["Greater", "", "7+", s.greater], ["Identity", "", "1+", k.identity], ["ImageScaler", "", "1+", b.imageScaler, b.parseImageScalerAttributes], ["InstanceNormalization", "", "6+", m.instanceNormalization, m.parseInstanceNormalizationAttributes], ["LeakyRelu", "", "6+", k.leakyRelu, k.parseLeakyReluAttributes], ["Less", "", "7+", s.less], ["Log", "", "6+", k.log], ["MatMul", "", "1+", y.matMul, y.parseMatMulAttributes], ["MaxPool", "", "1+", v.maxPool, v.parseMaxPoolAttributes], ["Mul", "", "7+", s.mul], ["Neg", "", "6+", k.neg], ["Not", "", "1+", k.not], ["Or", "", "7+", s.or], ["Pad", "", "2-10", _.padV2, _.parsePadAttributesV2], ["Pad", "", "11+", _.padV11, _.parsePadAttributesV11], ["Pow", "", "7+", s.pow], ["PRelu", "", "7+", s.pRelu], ["ReduceLogSum", "", "1+", w.reduceLogSum, w.parseReduceAttributes], ["ReduceMax", "", "1+", w.reduceMax, w.parseReduceAttributes], ["ReduceMean", "", "1+", w.reduceMean, w.parseReduceAttributes], ["ReduceMin", "", "1+", w.reduceMin, w.parseReduceAttributes], ["ReduceProd", "", "1+", w.reduceProd, w.parseReduceAttributes], ["ReduceSum", "", "1-12", w.reduceSum, w.parseReduceAttributes], ["ReduceSumSquare", "", "1+", w.reduceLogSumSquare, w.parseReduceAttributes], ["Relu", "", "6+", k.relu], ["Reshape", "", "5+", x.reshape], ["Resize", "", "10", T.resize, T.parseResizeAttributesV10], ["Resize", "", "11+", T.resize, T.parseResizeAttributesV11], ["Shape", "", "1+", S.shape], ["Sigmoid", "", "6+", k.sigmoid], ["Sin", "", "7+", k.sin], ["Slice", "", "10+", O.sliceV10], ["Slice", "", "1-9", O.slice, O.parseSliceAttributes], ["Softmax", "", "1-12", A.softmax, A.parseSoftmaxAttributes], ["Softmax", "", "13+", A.softmaxV13, A.parseSoftmaxAttributesV13], ["Split", "", "2-12", E.split, E.parseSplitAttributes], ["Sqrt", "", "6+", k.sqrt], ["Squeeze", "", "1-12", I.squeeze, I.parseSqueezeAttributes], ["Squeeze", "", "13+", I.squeezeV13], ["Sub", "", "7+", s.sub], ["Sum", "", "6+", P.sum], ["Tan", "", "7+", k.tan], ["Tanh", "", "6+", k.tanh], ["Tile", "", "6+", D.tile], ["Transpose", "", "1+", $.transpose, $.parseTransposeAttributes], ["Upsample", "", "7-8", F.upsample, F.parseUpsampleAttributesV7], ["Upsample", "", "9", F.upsample, F.parseUpsampleAttributesV9], ["Unsqueeze", "", "1-12", C.unsqueeze, C.parseUnsqueezeAttributes], ["Unsqueeze", "", "13+", C.unsqueezeV13], ["Xor", "", "7+", s.xor]];
    }, 2898: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseBatchNormalizationAttributes = e.batchNormalization = void 0;
      const r = n(246), i2 = n(5060), o = n(2039), a = { name: "BatchNormalization", inputNames: ["A", "Scale", "B", "Mean", "Variance"], inputTypes: [o.TextureType.unpacked, o.TextureType.unpacked, o.TextureType.unpacked, o.TextureType.unpacked, o.TextureType.unpacked] };
      e.batchNormalization = (t3, e2, n2) => (u(e2), [t3.run(Object.assign(Object.assign({}, a), { cacheHint: n2.cacheKey, get: () => s(t3, e2, n2) }), e2)]), e.parseBatchNormalizationAttributes = (t3) => {
        const e2 = t3.attributes.getFloat("epsilon", 1e-5), n2 = t3.attributes.getFloat("momentum", 0.9), i3 = t3.attributes.getInt("spatial", 1);
        return (0, r.createAttributeWithCacheKey)({ epsilon: e2, momentum: n2, spatial: i3 });
      };
      const s = (t3, e2, n2) => {
        const r2 = (0, i2.getGlsl)(t3.session.backend.glContext.version), s2 = e2[0].dims.length, [u2, c] = t3.calculateTextureWidthAndHeight(e2[1].dims, o.TextureType.unpacked), l = `
  float process(int[${s2}] indices) {
    vec2 position = offsetToCoords(indices[1], ${u2}, ${c});
    float scale = getColorAsFloat(${r2.texture2D}(Scale, position));
    float mean = getColorAsFloat(${r2.texture2D}(Mean, position));
    float variance = getColorAsFloat(${r2.texture2D}(Variance, position));
    float b = getColorAsFloat(${r2.texture2D}(B, position));

    return scale * ( (_A(indices) - mean) / sqrt(variance + float(${n2.epsilon})) ) + b;
  }`;
        return Object.assign(Object.assign({}, a), { output: { dims: e2[0].dims, type: e2[0].type, textureType: o.TextureType.unpacked }, shaderSource: l });
      }, u = (t3) => {
        if (!t3 || 5 !== t3.length) throw new Error("BatchNormalization requires 5 inputs.");
        const e2 = t3[0], n2 = t3[1], r2 = t3[2], i3 = t3[3], o2 = t3[4];
        if (e2.dims.length < 3 || 1 !== n2.dims.length || 1 !== r2.dims.length || 1 !== i3.dims.length || 1 !== o2.dims.length) throw new Error("invalid input shape.");
        if (n2.dims[0] !== e2.dims[1] || r2.dims[0] !== e2.dims[1] || i3.dims[0] !== e2.dims[1] || o2.dims[0] !== e2.dims[1]) throw new Error("invalid input shape.");
        if ("float32" !== e2.type && "float64" !== e2.type || "float32" !== n2.type && "float64" !== n2.type || "float32" !== r2.type && "float64" !== r2.type || "float32" !== i3.type && "float64" !== i3.type || "float32" !== o2.type && "float64" !== o2.type) throw new Error("invalid input tensor types.");
      };
    }, 7839: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.xor = e.sub = e.pRelu = e.pow = e.or = e.mul = e.less = e.greater = e.equal = e.div = e.and = e.add = e.glslPRelu = e.glslPow = e.glslXor = e.glslOr = e.glslAnd = e.glslLess = e.glslGreater = e.glslEqual = e.glslSub = e.glslMul = e.glslDiv = e.glslAdd = void 0;
      const r = n(2517), i2 = n(8520), o = n(5060), a = n(2039);
      function s() {
        const t3 = "add_";
        return { body: `
  float ${t3}(float a, float b) {
    return a + b;
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    return v1 + v2;
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function u() {
        const t3 = "div_";
        return { body: `
  float ${t3}(float a, float b) {
    return a / b;
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    return v1 / v2;
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function c() {
        const t3 = "mul_";
        return { body: `
  float ${t3}(float a, float b) {
    return a * b;
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    return v1 * v2;
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function l() {
        const t3 = "sub_";
        return { body: `
  float ${t3}(float a, float b) {
    return a - b;
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    return v1 - v2;
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function p() {
        const t3 = "equal_";
        return { body: `
  float ${t3}(float a, float b) {
    return float(a == b);
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    return vec4(equal(v1, v2));
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function f() {
        const t3 = "greater_";
        return { body: `
  float ${t3}(float a, float b) {
    return float(a > b);
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    return vec4( v1.r > v2.r ,
      v1.g > v2.g,
      v1.b > v2.b,
      v1.a > v2.a );
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function d() {
        const t3 = "less_";
        return { body: `
  float ${t3}(float a, float b) {
    return float(a < b);
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    return vec4( v1.r < v2.r ,
                v1.g < v2.g,
                v1.b < v2.b,
                v1.a < v2.a );
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function h() {
        const t3 = "and_";
        return { body: `
  float ${t3}(float a, float b) {
    return float( bool(a) && bool(b) );
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    bvec4 b1 = bvec4(v1);
    bvec4 b2 = bvec4(v2);
    return vec4( b1.r && b2.r ,
                b1.g && b2.g,
                b1.b && b2.b,
                b1.a && b2.a );
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function g() {
        const t3 = "or_";
        return { body: `
  float ${t3}(float a, float b) {
    return float( bool(a) || bool(b) );
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    bvec4 b1 = bvec4(v1);
    bvec4 b2 = bvec4(v2);
    return vec4( b1.r || b2.r ,
                b1.g || b2.g,
                b1.b || b2.b,
                b1.a || b2.a );
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function b() {
        const t3 = "xor_";
        return { body: `
  float ${t3}(float a, float b) {
    return float( bool(a) ^^ bool(b) );
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    bvec4 b1 = bvec4(v1);
    bvec4 b2 = bvec4(v2);
    return vec4( b1.r ^^ b2.r ,
                b1.g ^^ b2.g,
                b1.b ^^ b2.b,
                b1.a ^^ b2.a );
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      function m() {
        return function(t3) {
          const e2 = `${t3}_`;
          return { body: `
  float ${e2}(float a, float b) {
    return ${t3}(a, b);
  }
  vec4 ${e2}(vec4 v1, vec4 v2) {
    return ${t3}(v1, v2);
  }
  `, name: e2, type: i2.FunctionType.ValueBased };
        }("pow");
      }
      function y() {
        const t3 = "prelu_";
        return { body: `
  float ${t3}(float a, float b) {
    return a < 0.0 ? a * b: a;
  }
  vec4 ${t3}(vec4 v1, vec4 v2) {
    return vec4(
      v1.r < 0.0 ? v1.r * v2.r: v1.r,
      v1.g < 0.0 ? v1.g * v2.g: v1.g,
      v1.b < 0.0 ? v1.b * v2.b: v1.b,
      v1.a < 0.0 ? v1.a * v2.a: v1.a
      );
  }
  `, name: t3, type: i2.FunctionType.ValueBased };
      }
      e.glslAdd = s, e.glslDiv = u, e.glslMul = c, e.glslSub = l, e.glslEqual = p, e.glslGreater = f, e.glslLess = d, e.glslAnd = h, e.glslOr = g, e.glslXor = b, e.glslPow = m, e.glslPRelu = y;
      const _ = (t3, e2, n2, r2 = e2[0].type, i3) => {
        const o2 = t3.session.pack ? a.TextureType.packed : a.TextureType.unpacked;
        return { name: n2.name, inputNames: ["A", "B"], inputTypes: [o2, o2], cacheHint: i3, get: () => v(t3, e2, n2, r2) };
      }, v = (t3, e2, n2, i3 = e2[0].type) => {
        const s2 = t3.session.pack ? a.TextureType.packed : a.TextureType.unpacked, u2 = !r.ShapeUtil.areEqual(e2[0].dims, e2[1].dims);
        let c2 = e2[0].dims;
        const l2 = t3.session.pack;
        if (u2) {
          const a2 = r.BroadcastUtil.calcShape(e2[0].dims, e2[1].dims, false);
          if (!a2) throw new Error("Can't perform binary op on the given tensors");
          c2 = a2;
          const u3 = c2.length, p3 = 0 !== e2[0].dims.length ? e2[0].dims.length : 1, f3 = 0 !== e2[1].dims.length ? e2[1].dims.length : 1, d2 = 0 !== e2[0].dims.length ? "bcastIndices_A(indices, aindices);" : "aindices[0] = 0;", h2 = 0 !== e2[1].dims.length ? "bcastIndices_B(indices, bindices);" : "bindices[0] = 0;", g2 = (0, o.getGlsl)(t3.session.backend.glContext.version), b2 = l2 ? `
      ${n2.body}
      void main() {
        vec4 a = getAAtOutCoords();
        vec4 b = getBAtOutCoords();
        vec4 result = ${n2.name}(a, b);
        ${g2.output} = result;
      }` : `
      ${n2.body}
      float process(int indices[${u3}]) {
        int aindices[${p3}];
        int bindices[${f3}];
        ${d2}
        ${h2}
        return ${n2.name}(_A(aindices), _B(bindices));
      }`;
          return { name: n2.name, inputNames: ["A", "B"], inputTypes: [s2, s2], output: { dims: c2, type: i3, textureType: s2 }, shaderSource: b2, hasMain: l2 };
        }
        const p2 = (0, o.getGlsl)(t3.session.backend.glContext.version), f2 = `
    ${n2.body}
    void main() {
      vec4 v1 = ${p2.texture2D}(A, TexCoords);
      vec4 v2 = ${p2.texture2D}(B, TexCoords);
      vec4 result = ${n2.name}(v1, v2);
      ${p2.output} = result;
    }
    `;
        return { name: n2.name, inputNames: ["A", "B"], inputTypes: [s2, s2], output: { dims: e2[0].dims, type: i3, textureType: s2 }, shaderSource: f2, hasMain: true };
      };
      e.add = (t3, e2) => [t3.run(_(t3, e2, s()), e2)], e.and = (t3, e2) => [t3.run(_(t3, e2, h(), "bool"), e2)], e.div = (t3, e2) => [t3.run(_(t3, e2, u()), e2)], e.equal = (t3, e2) => [t3.run(_(t3, e2, p(), "bool"), e2)], e.greater = (t3, e2) => [t3.run(_(t3, e2, f(), "bool"), e2)], e.less = (t3, e2) => [t3.run(_(t3, e2, d(), "bool"), e2)], e.mul = (t3, e2) => [t3.run(_(t3, e2, c()), e2)], e.or = (t3, e2) => [t3.run(_(t3, e2, g(), "bool"), e2)], e.pow = (t3, e2) => [t3.run(_(t3, e2, m()), e2)], e.pRelu = (t3, e2) => [t3.run(_(t3, e2, y()), e2)], e.sub = (t3, e2) => [t3.run(_(t3, e2, l()), e2)], e.xor = (t3, e2) => [t3.run(_(t3, e2, b(), "bool"), e2)];
    }, 4196: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseCastAttributes = e.cast = void 0;
      const r = n(2517);
      e.cast = (t3, e2, n2) => (i2(e2), [t3.cast(e2[0], n2)]), e.parseCastAttributes = (t3) => r.ProtoUtil.tensorDataTypeFromProto(t3.attributes.getInt("to"));
      const i2 = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Cast requires 1 input.");
        if ("string" === t3[0].type) throw new Error("Invalid input type.");
      };
    }, 1163: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createPackedConcatProgramInfoLoader = void 0;
      const r = n(5060), i2 = n(2039), o = n(9390), a = n(2827);
      e.createPackedConcatProgramInfoLoader = (t3, e2, n2) => {
        const u = (c = e2.length, l = n2.cacheKey, { name: "Concat (packed)", inputNames: Array.from({ length: c }, (t4, e3) => `X${e3}`), inputTypes: Array(c).fill(i2.TextureType.packed), cacheHint: l });
        var c, l;
        return Object.assign(Object.assign({}, u), { get: () => ((t4, e3, n3, u2) => {
          const c2 = n3[0].dims.slice();
          if (u2 >= c2.length || u2 < -1 * c2.length) throw new Error("axis specified for concat doesn't match input dimensionality");
          u2 < 0 && (u2 = c2.length + u2);
          const l2 = c2.slice(0);
          for (let t5 = 1; t5 < n3.length; t5++) {
            const e4 = n3[t5].dims.slice();
            for (let t6 = 0; t6 < c2.length; t6++) if (t6 === u2) l2[u2] += e4[t6];
            else if (c2[t6] !== e4[t6]) throw new Error("non concat dimensions must match");
          }
          const p = l2.length, f = (0, a.getChannels)("coords", p), d = (0, o.getCoordsDataType)(p), h = (0, a.unpackFromChannel)(), g = n3.map((t5) => t5.dims), b = (0, o.getGlChannels)(p), m = new Array(g.length - 1);
          m[0] = g[0][u2];
          for (let t5 = 1; t5 < m.length; t5++) m[t5] = m[t5 - 1] + g[t5][u2];
          const y = b[u2], _ = b.slice(-2), v = b.join();
          let w = `if (${y} < ${m[0]}) {
        return getChannel(
            getX0(${v}), vec2(${_.join()}));
        }`;
          for (let t5 = 1; t5 < m.length; t5++) {
            const e4 = m[t5 - 1];
            w += `
            if (${y} < ${m[t5]}  && ${y} >= ${m[t5 - 1]}) {
              return getChannel(
                getX${t5}(${s(b, y, e4)}),
                vec2(${s(_, y, e4)}));
            }`;
          }
          const x = m.length, T = m[m.length - 1];
          w += `
            return getChannel(
              getX${x}(${s(b, y, T)}),
              vec2(${s(_, y, T)}));`;
          const S = (0, r.getGlsl)(t4.session.backend.glContext.version), O = `
          ${h}
          float getValue(${b.map((t5) => "int " + t5)}) {
            ${w}
          }

          void main() {
            ${d} coords = getOutputCoords();
            int lastDim = coords.${b[p - 1]};
            coords.${b[p - 1]} = coords.${b[p - 2]};
            coords.${b[p - 2]} = lastDim;

            vec4 result = vec4(getValue(${f}), 0., 0., 0.);

            ${f[p - 1]} = ${f[p - 1]} + 1;
            if (${f[p - 1]} < ${l2[p - 1]}) {
              result.g = getValue(${f});
            }

            ${f[p - 2]} = ${f[p - 2]} + 1;
            if (${f[p - 2]} < ${l2[p - 2]}) {
              result.a = getValue(${f});
            }

            ${f[p - 1]} = ${f[p - 1]} - 1;
            if (${f[p - 2]} < ${l2[p - 2]} &&
                ${f[p - 1]} < ${l2[p - 1]}) {
              result.b = getValue(${f});
            }
            ${S.output} = result;
          }
        `;
          return Object.assign(Object.assign({}, e3), { output: { dims: l2, type: n3[0].type, textureType: i2.TextureType.packed }, shaderSource: O, hasMain: true });
        })(t3, u, e2, n2.axis) });
      };
      const s = (t3, e2, n2) => {
        const r2 = t3.indexOf(e2);
        return t3.map((t4, e3) => e3 === r2 ? `${t4} - ${n2}` : t4).join();
      };
    }, 2069: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseConcatAttributes = e.concat = void 0;
      const r = n(246), i2 = n(2039), o = n(1163);
      e.concat = (t3, e2, n2) => (p(e2), t3.session.pack && e2[0].dims.length > 1 ? [t3.run((0, o.createPackedConcatProgramInfoLoader)(t3, e2, n2), e2)] : [t3.run(a(t3, e2, n2), e2)]);
      const a = (t3, e2, n2) => {
        const r2 = (o2 = e2.length, a2 = n2.cacheKey, { name: "Concat", inputNames: Array.from({ length: o2 }, (t4, e3) => `X${e3}`), inputTypes: Array(o2).fill(i2.TextureType.unpacked), cacheHint: a2 });
        var o2, a2;
        return Object.assign(Object.assign({}, r2), { get: () => ((t4, e3, n3, r3) => {
          const o3 = n3[0].dims.slice();
          if (r3 >= o3.length || r3 < -1 * o3.length) throw new Error("axis specified for concat doesn't match input dimensionality");
          r3 < 0 && (r3 = o3.length + r3);
          const a3 = o3.slice(0);
          for (let t5 = 1; t5 < n3.length; t5++) {
            const e4 = n3[t5].dims.slice();
            for (let t6 = 0; t6 < o3.length; t6++) if (t6 === r3) a3[r3] += e4[t6];
            else if (o3[t6] !== e4[t6]) throw new Error("non concat dimensions must match");
          }
          const p2 = a3.length, f = new Array(n3.length);
          let d = 0;
          for (let t5 = 0; t5 < f.length; ++t5) d += n3[t5].dims[r3], f[t5] = d;
          let h = "";
          h = n3.length < 5 ? s(f) : u(f);
          const g = `
        ${c(n3.length, p2)}
        ${l(f)}
        ${h}
        float process(int indices[${p2}]) {
          int textureIndex = getTextureWhereDataResides (indices[${r3}]);

          if(textureIndex != 0) {
            indices[${r3}] = indices[${r3}] - int(getSizeInConcatAxisValueFromIndex(textureIndex-int(1)));
          }

          return fetchDataFromCorrectTexture(textureIndex, indices);
        }`;
          return Object.assign(Object.assign({}, e3), { output: { dims: a3, type: n3[0].type, textureType: i2.TextureType.unpacked }, shaderSource: g });
        })(0, r2, e2, n2.axis) });
      }, s = (t3) => {
        const e2 = t3.map((t4, e3) => `if(index<${t4}) {return ${e3};}
`);
        return `int getTextureWhereDataResides(int index) {
      ${e2.join("")}
    }`;
      }, u = (t3) => s(t3), c = (t3, e2) => {
        const n2 = [`float fetchDataFromCorrectTexture(int textureIndex, int indices[${e2}]) {`];
        for (let e3 = 0; e3 < t3; ++e3) 0 === e3 ? n2.push(`	if (textureIndex == ${e3}) { return _X${e3}(indices); }`) : e3 === t3 - 1 ? n2.push(`	else { return _X${e3}(indices); }`) : n2.push(`	else if (textureIndex == ${e3}) { return _X${e3}(indices); }`);
        return n2.push("	}"), n2.join("\n");
      }, l = (t3) => {
        const e2 = ["int getSizeInConcatAxisValueFromIndex(int index) {"];
        for (let n2 = 0; n2 < t3.length; ++n2) 0 === n2 ? e2.push(`	if (index == ${n2}) { return ${t3[n2]}; }`) : n2 === t3.length - 1 ? e2.push(`	else { return ${t3[n2]}; }`) : e2.push(`	else if (index == ${n2}) { return ${t3[n2]}; }`);
        return e2.push("	}"), e2.join("\n");
      };
      e.parseConcatAttributes = (t3) => (0, r.createAttributeWithCacheKey)({ axis: t3.attributes.getInt("axis") });
      const p = (t3) => {
        if (!t3 || t3.length < 1) throw new Error("too few inputs");
        const e2 = t3[0].type, n2 = t3[0].dims.length;
        if ("string" === e2) throw new Error("string tensor is not supported yet");
        for (const r2 of t3) {
          if (r2.type !== e2) throw new Error("input tensors should be one type");
          if (r2.dims.length !== n2) throw new Error("input tensors should have the same shape");
        }
      };
    }, 4770: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createUnpackedGroupedConvProgramInfoLoader = void 0;
      const r = n(3694), i2 = n(5060), o = n(2039), a = n(8138), s = n(2823);
      e.createUnpackedGroupedConvProgramInfoLoader = (t3, e2, n2) => {
        const u = (c = e2.length > 2, l = n2.cacheKey, { name: "GroupedConv", inputNames: c ? ["X", "W", "Bias"] : ["X", "W"], inputTypes: c ? [o.TextureType.unpacked, o.TextureType.unpacked, o.TextureType.unpacked] : [o.TextureType.unpacked, o.TextureType.unpacked], cacheHint: l });
        var c, l;
        return Object.assign(Object.assign({}, u), { get: () => ((t4, e3, n3, u2) => {
          const c2 = e3.length > 2 ? "value += getBias(output_channel);" : "", l2 = e3[0].dims.slice(), p = e3[1].dims.slice(), f = p[0] / u2.group;
          r.Logger.verbose("GroupedConv", `autpPad:${u2.autoPad}, dilations:${u2.dilations}, group:${u2.group}, kernelShape:${u2.kernelShape}, pads:${u2.pads}, strides:${u2.strides}`);
          const d = (0, a.calculateOutputShape)(l2, p, u2.dilations, u2.pads, u2.strides), h = (0, i2.getGlsl)(t4.session.backend.glContext.version), { activationFunction: g, applyActivation: b } = (0, s.getActivationSnippet)(u2), m = `
  const ivec2 strides = ivec2(${u2.strides[0]}, ${u2.strides[1]});
  const ivec2 pads = ivec2(${u2.pads[0]}, ${u2.pads[1]});
  ${g}
  void main() {
    ivec4 coords = getOutputCoords();
    int batch = coords.x;
    int output_channel = coords.y;
    ivec2 xRCCorner = coords.zw * strides - pads;
    int group_id = output_channel / ${f};

    float value = 0.0;
    for (int wInChannel = 0; wInChannel < ${p[1]}; wInChannel++) {
      int input_channel = group_id * ${p[1]} + wInChannel;
      for (int wHeight = 0; wHeight < ${p[2]}; wHeight++) {
        int xHeight = xRCCorner.x + wHeight * ${u2.dilations[0]};

        if (xHeight < 0 || xHeight >= ${l2[2]}) {
          continue;
        }

        for (int wWidth = 0; wWidth < ${p[3]}; wWidth++) {
          int xWidth = xRCCorner.y + wWidth * ${u2.dilations[1]};
          if (xWidth < 0 || xWidth >= ${l2[3]}) {
            continue;
          }

          float xVal = getX(batch, input_channel, xWidth, xHeight);
          float wVal = getW(output_channel, wInChannel, wWidth, wHeight);
          value += xVal*wVal;
        }
      }
    }
    ${c2}
    ${b}
    ${h.output} = vec4(value, .0, .0, .0);
  }
`;
          return Object.assign(Object.assign({}, n3), { output: { dims: d, type: e3[0].type, textureType: o.TextureType.unpacked }, shaderSource: m, hasMain: true });
        })(t3, e2, u, n2) });
      };
    }, 1386: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.conv2DPacked = e.conv2DPackedPointwise = void 0;
      const r = n(8138), i2 = n(8555), o = n(708);
      e.conv2DPackedPointwise = (t3, e2, n2) => {
        const i3 = e2[0].dims, a = e2[1].dims, s = (0, r.calculateOutputShape)(i3, a, n2.dilations, n2.pads, n2.strides), u = t3.reshapePacked(e2[0], [i3[1], i3[2] * i3[3]]), c = t3.reshapePacked(e2[1], [a[0], a[1]]), l = e2.length > 2 ? [c, u, e2[2]] : [c, u], p = t3.run((0, o.createPackedMatmulProgramInfoLoader)(t3, l, n2), l);
        return t3.reshapePacked(p, s);
      }, e.conv2DPacked = (t3, e2, n2) => {
        const a = e2[0].dims, s = e2[1].dims, u = (0, r.calculateOutputShape)(a, s, n2.dilations, n2.pads, n2.strides), c = t3.run((0, i2.createPackedIm2ColProgramInfoLoader)(t3, e2[0], e2[1], u, n2), [e2[0]]), l = t3.reshapePacked(e2[1], [s[0], s[1] * s[2] * s[3]]), p = 3 === e2.length ? [l, c, e2[2]] : [l, c], f = t3.run((0, o.createPackedMatmulProgramInfoLoader)(t3, p, n2), p);
        return t3.reshapePacked(f, u);
      };
    }, 9663: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseConvTransposeAttributes = e.convTranspose = void 0;
      const r = n(246), i2 = n(5060), o = n(2039), a = n(2823), s = (t3, e2, n2, r2, i3, o2) => (t3 - 1) * e2 + n2 + (r2 - 1) * i3 + 1 - o2, u = (t3, e2, n2, r2, i3) => {
        const o2 = Math.floor(t3 / 2);
        "SAME_UPPER" === e2 ? (n2[r2] = o2, n2[i3] = t3 - o2) : "SAME_LOWER" === e2 && (n2[r2] = t3 - o2, n2[i3] = o2);
      };
      e.convTranspose = (t3, e2, n2) => (f(e2, n2), c(t3, e2, n2));
      const c = (t3, e2, n2) => {
        const r2 = p(n2, e2);
        return [l(t3, e2, r2)];
      }, l = (t3, e2, n2) => t3.run(((t4, e3, n3) => {
        const r2 = (s2 = e3.length > 2, u2 = n3.cacheKey, { name: "ConvTranspose", inputNames: s2 ? ["X", "W", "B"] : ["X", "W"], inputTypes: s2 ? [o.TextureType.unpacked, o.TextureType.unpacked, o.TextureType.unpacked] : [o.TextureType.unpacked, o.TextureType.unpacked], cacheHint: u2 });
        var s2, u2;
        return Object.assign(Object.assign({}, r2), { get: () => ((t5, e4, n4, r3) => {
          const s3 = e4.length > 2 ? "getB(output_channel)" : "0.0", u3 = e4[0].dims, c2 = e4[1].dims, l2 = c2[1], p2 = c2[0] / r3.group, f2 = [e4[0].dims[0], e4[1].dims[1] * r3.group, ...r3.outputShape], d = (0, i2.getGlsl)(t5.session.backend.glContext.version), { activationFunction: h, applyActivation: g } = (0, a.getActivationSnippet)(r3), b = `
  const ivec2 strides = ivec2(${r3.strides[0]}, ${r3.strides[1]});
  const ivec2 pads = ivec2(${r3.pads[0]}, ${r3.pads[1]});
  ${h}
  void main() {
    ivec4 coords = getOutputCoords();
    int batch = coords.x;
    int output_channel = coords.y;

    ivec2 loc = coords.zw + pads;

    int group_id = output_channel / ${l2};
    int wOutChannel = output_channel - group_id * ${l2};

    float value = ${s3};
    for (int inChannelOffset = 0; inChannelOffset < ${p2}; inChannelOffset++) {
      int input_channel = group_id * ${p2} + inChannelOffset;
      for (int wWOff = 0; wWOff < ${c2[2]}; wWOff++) {
        for (int wHOff = 0; wHOff < ${c2[3]}; wHOff++) {
          ivec2 wOff = ivec2(wWOff * ${r3.dilations[0]}, wHOff * ${r3.dilations[1]});
          ivec2 wLoc = loc - wOff;
          ivec2 wLocIn = wLoc / strides;
          if (
            wLocIn * strides == wLoc &&
            wLocIn.x >= 0 && wLocIn.x < ${u3[2]} &&
            wLocIn.y >= 0 && wLocIn.y < ${u3[3]}
          ) {
            float xVal = getX(batch, input_channel, wLocIn.y, wLocIn.x);
            float wVal = getW(input_channel, wOutChannel, wHOff, wWOff);
            value += xVal * wVal;
          }
        }
      }
    }
    ${g}
    ${d.output} = vec4(value, .0, .0, .0);
  }
`;
          return Object.assign(Object.assign({}, n4), { output: { dims: f2, type: e4[0].type, textureType: o.TextureType.unpacked }, shaderSource: b, hasMain: true });
        })(t4, e3, r2, n3) });
      })(t3, e2, n2), e2), p = (t3, e2) => {
        const n2 = t3.kernelShape.slice();
        if (0 === t3.kernelShape.length) for (let t4 = 2; t4 < e2[1].dims.length; ++t4) n2.push(e2[1].dims[t4]);
        const r2 = t3.pads.slice(), i3 = t3.outputShape.slice();
        ((t4, e3, n3, r3, i4, o3, a2, c2) => {
          const l2 = t4.length - 2, p2 = 0 === c2.length;
          for (let f2 = 0; f2 < l2; ++f2) {
            const d = p2 ? t4[f2 + 2] * o3[f2] : c2[f2], h = s(t4[f2 + 2], o3[f2], i4[f2], e3[f2], n3[f2], d);
            u(h, r3, i4, f2, f2 + l2), p2 && c2.push(o3[f2] * (t4[f2 + 2] - 1) + a2[f2] + (e3[f2] - 1) * n3[f2] + 1 - i4[f2] - i4[f2 + l2]);
          }
        })(e2[0].dims, n2, t3.dilations, t3.autoPad, r2, t3.strides, t3.outputPadding, i3);
        const o2 = Object.assign({}, t3);
        return Object.assign(o2, { kernelShape: n2, pads: r2, outputShape: i3, cacheKey: t3.cacheKey }), o2;
      };
      e.parseConvTransposeAttributes = (t3) => {
        const e2 = t3.attributes, n2 = (0, a.parseInternalActivationAttributes)(e2), i3 = e2.getString("auto_pad", "NOTSET"), o2 = e2.getInts("dilations", [1, 1]), s2 = e2.getInt("group", 1), u2 = e2.getInts("kernel_shape", []), c2 = e2.getInts("output_padding", [0, 0]), l2 = e2.getInts("output_shape", []), p2 = e2.getInts("pads", [0, 0, 0, 0]), f2 = e2.getInts("strides", [1, 1]);
        return (0, r.createAttributeWithCacheKey)(Object.assign({ autoPad: i3, dilations: o2, group: s2, kernelShape: u2, outputPadding: c2, outputShape: l2, pads: p2, strides: f2 }, n2));
      };
      const f = (t3, e2) => {
        if (!t3 || 2 !== t3.length && 3 !== t3.length) throw new Error("Conv requires 2 or 3 inputs");
        if (4 !== t3[0].dims.length || 4 !== t3[1].dims.length) throw new Error("currently only support 2-dimensional conv");
        if (t3[0].dims[1] !== t3[1].dims[0]) throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");
        const n2 = t3[1].dims[1] * e2.group;
        if (3 === t3.length && (1 !== t3[2].dims.length || t3[2].dims[0] !== n2)) throw new Error("invalid bias");
        const r2 = t3[0].dims.length - 2;
        if (e2.dilations.length !== r2) throw new Error(`dilations should be ${r2}D`);
        if (e2.strides.length !== r2) throw new Error(`strides should be ${r2}D`);
        if (e2.pads.length !== 2 * r2) throw new Error(`pads should be ${2 * r2}D`);
        if (e2.outputPadding.length !== r2) throw new Error(`output_padding should be ${r2}D`);
        if (0 !== e2.kernelShape.length && e2.kernelShape.length !== t3[1].dims.length - 2) throw new Error("invalid kernel shape");
        if (0 !== e2.outputShape.length && e2.outputShape.length !== t3[0].dims.length - 2) throw new Error("invalid output shape");
        if ("float32" !== t3[0].type || "float32" !== t3[1].type) throw new Error("ConvTranspose input(X,W) should be float tensor");
        if (3 === t3.length && "float32" !== t3[2].type) throw new Error("ConvTranspose input(bias) should be float tensor");
      };
    }, 8138: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseConvAttributes = e.conv = e.calculateOutputShape = void 0;
      const r = n(246), i2 = n(2517), o = n(4770), a = n(1386), s = n(9828), u = n(2823), c = n(3248), l = n(5623);
      e.calculateOutputShape = (t3, e2, n2, r2, i3) => {
        const o2 = t3[0], a2 = t3.slice(2), s2 = a2.length, u2 = e2[0], c2 = e2.slice(2).map((t4, e3) => t4 + (t4 - 1) * (n2[e3] - 1)), l2 = a2.map((t4, e3) => t4 + r2[e3] + r2[e3 + s2]), p2 = l2.map((t4, e3) => Math.floor((t4 - c2[e3] + i3[e3]) / i3[e3]));
        return [o2, u2].concat(...p2);
      }, e.conv = (t3, e2, n2) => (g(e2, n2), p(t3, e2, n2));
      const p = (t3, e2, n2) => {
        const r2 = h(n2, e2), i3 = t3.session.pack, s2 = 1 === r2.kernelShape[0] && 1 === r2.kernelShape[1];
        return r2.group > 1 ? [t3.run((0, o.createUnpackedGroupedConvProgramInfoLoader)(t3, e2, r2), e2)] : s2 && i3 ? [f(t3, e2, r2)] : i3 && 4 === e2[0].dims.length && 1 === e2[0].dims[0] && !s2 ? [(0, a.conv2DPacked)(t3, e2, r2)] : [d(t3, e2, r2)];
      }, f = (t3, n2, r2) => {
        const i3 = n2[0].dims, o2 = n2[1].dims, a2 = (0, e.calculateOutputShape)(i3, o2, r2.dilations, r2.pads, r2.strides), s2 = t3.reshapeUnpacked(n2[0], [i3[1], i3[2] * i3[3]]), u2 = t3.reshapeUnpacked(n2[1], [o2[0], o2[1]]), c2 = n2.length > 2 ? [u2, s2, n2[2]] : [u2, s2], p2 = t3.run((0, l.createMatmulProgramInfoLoader)(c2, r2), c2);
        return t3.reshapeUnpacked(p2, a2);
      }, d = (t3, n2, r2) => {
        const i3 = n2[0].dims, o2 = n2[1].dims, a2 = (0, e.calculateOutputShape)(i3, o2, r2.dilations, r2.pads, r2.strides), u2 = t3.run((0, c.createIm2ColProgramInfoLoader)(t3, n2[0], n2[1], a2, r2), [n2[0]]), l2 = 3 === n2.length ? [u2, n2[1], n2[2]] : [u2, n2[1]];
        return t3.run((0, s.createDotProductProgramInfoLoader)(t3, n2, a2, r2), l2);
      }, h = (t3, e2) => {
        const n2 = t3.kernelShape.slice();
        if (0 === t3.kernelShape.length) for (let t4 = 2; t4 < e2[1].dims.length; ++t4) n2.push(e2[1].dims[t4]);
        const r2 = t3.pads.slice();
        i2.PoolConvUtil.adjustPadsBasedOnAutoPad(e2[0].dims, t3.strides, t3.dilations, n2, r2, t3.autoPad);
        const o2 = Object.assign({}, t3);
        return Object.assign(o2, { kernelShape: n2, pads: r2, cacheKey: t3.cacheKey }), o2;
      };
      e.parseConvAttributes = (t3) => {
        const e2 = t3.attributes, n2 = (0, u.parseInternalActivationAttributes)(e2), i3 = e2.getString("auto_pad", "NOTSET"), o2 = e2.getInts("dilations", [1, 1]), a2 = e2.getInt("group", 1), s2 = e2.getInts("kernel_shape", []), c2 = e2.getInts("pads", [0, 0, 0, 0]), l2 = e2.getInts("strides", [1, 1]);
        return (0, r.createAttributeWithCacheKey)(Object.assign({ autoPad: i3, dilations: o2, group: a2, kernelShape: s2, pads: c2, strides: l2 }, n2));
      };
      const g = (t3, e2) => {
        if (!t3 || 2 !== t3.length && 3 !== t3.length) throw new Error("Conv requires 2 or 3 inputs");
        if (4 !== t3[0].dims.length || 4 !== t3[1].dims.length) throw new Error("currently only support 2-dimensional conv");
        if (t3[0].dims[1] !== t3[1].dims[1] * e2.group) throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");
        if (3 === t3.length && (1 !== t3[2].dims.length || t3[1].dims[0] !== t3[2].dims[0])) throw new Error("invalid bias");
        const n2 = t3[0].dims.length - 2;
        if (e2.dilations.length !== n2) throw new Error(`dilations should be ${n2}D`);
        if (e2.strides.length !== n2) throw new Error(`strides should be ${n2}D`);
        if (e2.pads.length !== 2 * n2) throw new Error(`pads should be ${2 * n2}D`);
        if (0 !== e2.kernelShape.length && e2.kernelShape.length !== t3[1].dims.length - 2) throw new Error("invalid kernel shape");
        if ("float32" !== t3[0].type || "float32" !== t3[1].type) throw new Error("Conv input(X,W) should be float tensor");
        if (3 === t3.length && "float32" !== t3[2].type) throw new Error("Conv input(bias) should be float tensor");
      };
    }, 5193: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseDepthToSpaceAttributes = e.depthToSpace = void 0;
      const r = n(3738);
      e.depthToSpace = (t3, e2, n2) => {
        i2(e2);
        const o = n2.blocksize, a = o * o, s = "DCR" === n2.mode ? [0, 3, 4, 1, 5, 2] : [0, 1, 4, 2, 5, 3], u = "DCR" === n2.mode ? [e2[0].dims[0], o, o, e2[0].dims[1] / a, e2[0].dims[2], e2[0].dims[3]] : [e2[0].dims[0], e2[0].dims[1] / a, o, o, e2[0].dims[2], e2[0].dims[3]], c = t3.reshapeUnpacked(e2[0], u), l = { perm: s, cacheKey: `${s}` }, [p] = (0, r.transpose)(t3, [c], l), f = [e2[0].dims[0], e2[0].dims[1] / a, e2[0].dims[2] * o, e2[0].dims[3] * o];
        return [t3.reshapeUnpacked(p, f)];
      }, e.parseDepthToSpaceAttributes = (t3) => {
        const e2 = t3.attributes.getInt("blocksize");
        if (e2 < 1) throw new Error(`blocksize must be >= 1, but got : ${e2} for DepthToSpace`);
        const n2 = t3.attributes.getString("mode", "DCR");
        if ("DCR" !== n2 && "CRD" !== n2) throw new Error(`unrecognized mode: ${n2} for DepthToSpace`);
        return { mode: n2, blocksize: e2 };
      };
      const i2 = (t3) => {
        if (1 !== t3.length) throw new Error(`DepthToSpace expect 1 inputs, but got ${t3.length}`);
        if ("string" === t3[0].type || 4 !== t3[0].dims.length) throw new TypeError("DepthToSpace input should be a 4-D numeric tensor");
      };
    }, 9828: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createDotProductProgramInfoLoader = void 0;
      const r = n(2517), i2 = n(5060), o = n(2039), a = n(2823), s = n(3248);
      e.createDotProductProgramInfoLoader = (t3, e2, n2, u) => {
        const c = ((t4, e3) => ({ name: "ConvDotProduct", inputNames: t4 ? ["Im2Col", "K", "B"] : ["Im2Col", "K"], inputTypes: t4 ? [o.TextureType.unpacked, o.TextureType.packedLastDimension, o.TextureType.unpacked] : [o.TextureType.unpacked, o.TextureType.packedLastDimension], cacheKey: e3.activationCacheKey }))(e2.length > 2, u);
        return Object.assign(Object.assign({}, c), { get: () => ((t4, e3, n3, u2, c2) => {
          const l = n3[0].dims, p = n3[1].dims, f = [p[0], Math.ceil(l[1] * p[2] * p[3] / 4)], d = (0, s.calculateIm2ColDims)(l, p, u2), [h, g] = t4.calculateTextureWidthAndHeight(f, o.TextureType.packedLastDimension), b = r.ShapeUtil.computeStrides(d), [m, y] = t4.calculateTextureWidthAndHeight(d, o.TextureType.packedLastDimension), _ = u2.length, v = n3.length < 3 ? "0.0" : "_B(b)", w = Math.ceil(l[1] * p[2] * p[3] / 4), { activationFunction: x, applyActivation: T } = (0, a.getActivationSnippet)(c2), S = (0, i2.getGlsl)(t4.session.backend.glContext.version), O = `
${x}
float process(int indices[${_}]) {
  int b[1];
  b[0] = indices[1];
  int im2col[4];
  im2col[0] = indices[0];
  im2col[1] = indices[2];
  im2col[2] = indices[3];
  int im2colOffset = im2col[0] * ${b[0]} + im2col[1] * ${b[1]} + im2col[2] * ${b[2]};
  int kernelOffset = indices[1] * ${f[1]};
  float value = ${v};
  for (int i = 0; i < ${w}; ++i) {
    vec2 im2colCoords = offsetToCoords(im2colOffset, ${m}, ${y});
    vec2 kernelCoords = offsetToCoords(kernelOffset, ${h}, ${g});
    value += dot(${S.texture2D}(Im2Col, im2colCoords), ${S.texture2D}(K, kernelCoords));
    ++im2colOffset;
    ++kernelOffset;
  }
  ${T}
  return value;
}`;
          return Object.assign(Object.assign({}, e3), { output: { dims: u2, type: n3[0].type, textureType: o.TextureType.unpacked }, shaderSource: O });
        })(t3, c, e2, n2, u) });
      };
    }, 7992: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseFlattenAttributes = e.flatten = void 0;
      const r = n(2517);
      e.flatten = (t3, e2, n2) => {
        i2(e2, n2);
        const o = r.ShapeUtil.flattenShape(e2[0].dims, n2);
        return [t3.reshapeUnpacked(e2[0], o)];
      }, e.parseFlattenAttributes = (t3) => t3.attributes.getInt("axis", 1);
      const i2 = (t3, e2) => {
        if (!t3 || 1 !== t3.length) throw new Error("Flatten requires 1 input.");
        const n2 = t3[0].dims.length;
        if (0 === n2) throw new Error("scalar tensor is not supported.");
        if (e2 < -n2 || e2 > n2) throw new Error("Invalid axis");
        if ("string" === t3[0].type) throw new Error("string tensor is not supported.");
      };
    }, 2823: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseInternalActivationAttributes = e.getActivationSnippet = void 0;
      const r = n(2517), i2 = n(4909);
      e.getActivationSnippet = function(t3) {
        let e2;
        switch (t3.activation) {
          case "Relu":
            e2 = (0, i2.glslRelu)();
            break;
          case "Sigmoid":
            e2 = (0, i2.glslSigmoid)();
            break;
          case "Clip":
            e2 = (0, i2.glslClip)(t3.clipMin, t3.clipMax);
            break;
          default:
            return { activationFunction: "", applyActivation: "" };
        }
        const n2 = e2.name;
        return { activationFunction: e2.body, applyActivation: `value = ${n2}_(value);` };
      }, e.parseInternalActivationAttributes = (t3) => {
        const e2 = t3.getString("activation", "");
        if ("Clip" === e2) {
          const [n2, i3] = t3.getFloats("activation_params", [r.MIN_CLIP, r.MAX_CLIP]);
          return { activation: e2, clipMax: i3, clipMin: n2, activationCacheKey: `${e2}:${n2},${i3}` };
        }
        return { activation: e2, activationCacheKey: e2 };
      };
    }, 1253: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseGatherAttributes = e.gather = void 0;
      const r = n(246), i2 = n(782), o = n(2517), a = n(2039);
      e.gather = (t3, e2, n2) => (c(e2, n2.axis), [t3.run(u(t3, e2, n2), e2)]), e.parseGatherAttributes = (t3) => (0, r.createAttributeWithCacheKey)({ axis: t3.attributes.getInt("axis", 0) });
      const s = { name: "Gather", inputNames: ["A", "B"], inputTypes: [a.TextureType.unpacked, a.TextureType.unpacked] }, u = (t3, e2, n2) => {
        const r2 = Object.assign(Object.assign({}, s), { cacheHint: n2.cacheKey });
        return Object.assign(Object.assign({}, r2), { get: () => ((t4, e3, n3, r3) => {
          const i3 = n3[0].dims.slice(), s2 = n3[1].dims.slice(), u2 = new Array(i3.length + s2.length - 1);
          r3 = o.ShapeUtil.normalizeAxis(r3, i3.length);
          const c2 = [];
          for (let t5 = 0; t5 < u2.length; t5++) t5 < r3 ? (u2[t5] = i3[t5], c2.push(`inputIdx[${t5}] = outputIdx[${t5}];`)) : t5 < r3 + s2.length ? (u2[t5] = s2[t5 - r3], c2.push(`indexDataIdx[${t5 - r3}] = outputIdx[${t5}];`)) : (u2[t5] = i3[t5 - s2.length + 1], c2.push(`inputIdx[${t5 - s2.length + 1}] = outputIdx[${t5}];`));
          const l = `
      float process(int outputIdx[${u2.length || 1}]) {
        int inputIdx[${i3.length}];
        int indexDataIdx[${s2.length || 1}];
        indexDataIdx[0] = 0;
        ${c2.join("\n        ")}
        int idx = int(_B(indexDataIdx));
        inputIdx[${r3}] = idx < 0 ? idx + ${i3[r3]} : idx;
        return _A(inputIdx);
      }`;
          return Object.assign(Object.assign({}, e3), { output: { dims: u2, type: n3[0].type, textureType: a.TextureType.unpacked }, shaderSource: l });
        })(0, r2, e2, n2.axis) });
      }, c = (t3, e2) => {
        if (!t3 || 2 !== t3.length) throw new Error("Gather requires 2 inputs.");
        const n2 = t3[0].dims.length;
        if (n2 < 1) throw new Error("Invalid input shape.");
        if (e2 < -n2 || e2 > n2 - 1) throw new Error("Invalid axis.");
        if (-1 === i2.NUMBER_TYPES.indexOf(t3[0].type)) throw new Error("Invaid input type.");
        if ("int32" !== t3[1].type && "int16" !== t3[1].type) throw new Error("Invaid input type.");
      };
    }, 4776: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseGemmAttributesV11 = e.parseGemmAttributesV7 = e.gemm = void 0;
      const r = n(246), i2 = n(2517), o = n(2039);
      e.gemm = (t3, e2, n2) => (c(e2, n2), [t3.run(s(e2, n2), e2)]);
      const a = (t3, e2) => {
        const n2 = 0 !== t3.attributes.getInt("transA", 0), i3 = 0 !== t3.attributes.getInt("transB", 0), o2 = t3.attributes.getFloat("alpha", 1), a2 = t3.attributes.getFloat("beta", 1);
        return (0, r.createAttributeWithCacheKey)({ transA: n2, transB: i3, alpha: o2, beta: a2, isOptionalC: e2 });
      };
      e.parseGemmAttributesV7 = (t3) => a(t3, false), e.parseGemmAttributesV11 = (t3) => a(t3, true);
      const s = (t3, e2) => {
        const n2 = { name: "Gemm", inputNames: 3 === t3.length ? ["A", "B", "C"] : ["A", "B"], inputTypes: 3 === t3.length ? [o.TextureType.unpacked, o.TextureType.unpacked, o.TextureType.unpacked] : [o.TextureType.unpacked, o.TextureType.unpacked], key: e2.cacheKey };
        return Object.assign(Object.assign({}, n2), { get: () => u(n2, t3, e2) });
      }, u = (t3, e2, n2) => {
        const r2 = e2[0].dims.slice(), a2 = e2[1].dims.slice(), [s2, u2] = i2.GemmUtil.getShapeOfGemmResult(r2, n2.transA, a2, n2.transB, 3 === e2.length ? e2[2].dims : void 0), c2 = [s2, u2];
        if (!c2) throw new Error("Can't use gemm on the given tensors");
        let l = r2[r2.length - 1], p = "";
        n2.transA && (l = r2[0]), n2.transA && n2.transB ? p = "value += _A_T(a) * _B_T(b);" : n2.transA && !n2.transB ? p = "value += _A_T(a) * _B(b);" : !n2.transA && n2.transB ? p = "value += _A(a) * _B_T(b);" : n2.transA || n2.transB || (p = "value += _A(a) * _B(b);");
        const f = c2.length, d = `
      float process(int indices[${f}]) {
          int a[${f}];
          int b[${f}];
          ${3 === e2.length ? `int c[${e2[2].dims.length}];` : ""}

          copyVec(indices, a);
          copyVec(indices, b);
          ${3 === e2.length ? "bcastIndices_C(indices, c);" : ""}

          float value = 0.0;
          for (int k=0; k<${l}; ++k) {
              a[${f - 1}] = k;
              b[${f - 2}] = k;
              ${p}
          }

          value = value * alpha;
          ${3 === e2.length ? "value += beta * _C(c);" : ""}
          return value;
      }`;
        return Object.assign(Object.assign({}, t3), { output: { dims: c2, type: e2[0].type, textureType: o.TextureType.unpacked }, variables: [{ name: "alpha", type: "float", data: n2.alpha }, { name: "beta", type: "float", data: n2.beta }], shaderSource: d });
      }, c = (t3, e2) => {
        if (!t3) throw new Error("Input is missing");
        if (e2.isOptionalC && (t3.length < 2 || t3.length > 3)) throw new Error("Invaid input shape.");
        if (!e2.isOptionalC && 3 !== t3.length) throw new Error("Gemm requires 3 inputs");
        if (3 === t3.length && 1 !== t3[2].dims.length && 2 !== t3[2].dims.length) throw new Error("Invalid input shape of C");
        if ("float32" !== t3[0].type && "float64" !== t3[0].type || "float32" !== t3[1].type && "float64" !== t3[1].type || 3 === t3.length && "float32" !== t3[2].type && "float64" !== t3[2].type) throw new Error("Invalid input type.");
        if (t3[0].type !== t3[1].type || 3 === t3.length && t3[0].type !== t3[2].type) throw new Error("Input types are mismatched");
      };
    }, 8555: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createPackedIm2ColProgramInfoLoader = void 0;
      const r = n(5060), i2 = n(2039), o = n(2827);
      e.createPackedIm2ColProgramInfoLoader = (t3, e2, n2, a, s) => {
        const u = (c = s.cacheKey, { name: "Im2Col (packed)", inputNames: ["A"], inputTypes: [i2.TextureType.packed], cacheHint: c });
        var c;
        return Object.assign(Object.assign({}, u), { get: () => ((t4, e3, n3, a2, s2, u2) => {
          const c2 = n3.dims, l = a2.dims, p = s2.length, f = [l[1] * l[2] * l[3], s2[2] * s2[3]], d = l[2] * l[3], h = (0, o.unpackFromChannel)(), g = (0, r.getGlsl)(t4.session.backend.glContext.version);
          let b = "";
          for (let t5 = 0; t5 <= 1; t5++) for (let e4 = 0; e4 <= 1; e4++) b += `
            blockIndex = rc.x + ${e4};
            pos = rc.y + ${t5};

            if(blockIndex < ${f[1]} && pos < ${f[0]}) {
              offsetY = int(blockIndex / (${s2[p - 1]})) * ${u2.strides[0]} -
                ${u2.pads[0]};
              d0 = offsetY + ${u2.dilations[0]} * (imod(pos, ${d}) / ${l[2]});

              if(d0 < ${c2[2]} && d0 >= 0) {
                offsetX = imod(blockIndex, ${s2[p - 1]}) * ${u2.strides[1]} -
                  ${u2.pads[1]};
                d1 = offsetX + ${u2.dilations[1]} * imod(imod(pos, ${d}), ${l[2]});

                if(d1 < ${c2[3]} && d1 >= 0) {

                  ch = int(float(pos)/ ${d}.);
                    innerDims = vec2(d0, d1);
                    result[${2 * t5 + e4}] = getChannel(
                      getA(0, ch, int(innerDims.x),
                      int(innerDims.y)), innerDims);
                }
              }
            }

          `;
          const m = `
      ${h}

      void main() {
        ivec2 rc = getOutputCoords();
          vec4 result = vec4(0.0);
          int blockIndex, pos, offsetY, d0, offsetX, d1, ch;
          vec2 innerDims;
          ${b}
          ${g.output} = result;
      }
            `;
          return Object.assign(Object.assign({}, e3), { output: { dims: f, type: n3.type, textureType: i2.TextureType.packed }, shaderSource: m, hasMain: true });
        })(t3, u, e2, n2, a, s) });
      };
    }, 3248: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.calculateIm2ColDims = e.createIm2ColProgramInfoLoader = void 0;
      const r = n(2039);
      e.createIm2ColProgramInfoLoader = (t3, n2, i2, o, a) => {
        const s = (u = a.cacheKey, { name: "Im2Col", inputNames: ["X"], inputTypes: [r.TextureType.unpacked], cacheHint: u });
        var u;
        return Object.assign(Object.assign({}, s), { get: () => ((t4, n3, i3, o2, a2, s2) => {
          const u2 = i3.dims, c = o2.dims, l = a2.length, p = (0, e.calculateIm2ColDims)(u2, c, a2, 4), f = `
        const int XC = ${u2[1]};
        const int XH = ${u2[2]};
        const int XW = ${u2[3]};
        const int KH = ${s2.kernelShape[0]};
        const int KW = ${s2.kernelShape[1]};
        const int dilationH = ${s2.dilations[0]};
        const int dilationW = ${s2.dilations[1]};
        const int strideH = ${s2.strides[0]};
        const int strideW = ${s2.strides[1]};
        const int padH = ${s2.pads[0]};
        const int padW = ${s2.pads[1]};
        const int KHKW = KH*KW;
        const int XCKHKW = XC * KHKW;
        const int outputChannels = 4;
        vec4 process(int indices[${l}]) {
          int b  = indices[0]; // batch size
          int oh = indices[1] * strideH - padH; //output height
          int ow = indices[2] * strideW - padW; //output width
          int p = indices[3] * outputChannels; //patch
          vec4 value = vec4(0.0);
          for(int i=0; i < outputChannels; ++i) {
            if(p < XCKHKW) {
              int patchC = p / KHKW;
              int patchH = (p - patchC*KHKW) / KW;
              int patchW = (p - patchC*KHKW) - patchH * KW;
              int xh2 = oh + patchH * dilationH;
              int xw2 = ow + patchW * dilationW;
              int x[${u2.length}];
              x[0] = b;
              x[1] = patchC;
              x[2] = xh2;
              x[3] = xw2;
              if(xh2 >= 0 &&
                  xh2 < XH &&
                  xw2 >= 0 &&
                  xw2 < XW) {
                value[i] = _X(x);
              }
            }
            ++p;
          }
          return value;
        }
        `;
          return Object.assign(Object.assign({}, n3), { output: { dims: p, type: i3.type, textureType: r.TextureType.packedLastDimension }, shaderSource: f });
        })(0, s, n2, i2, o, a) });
      }, e.calculateIm2ColDims = (t3, e2, n2, r2 = 4) => [n2[0], n2[2], n2[3], Math.ceil(t3[1] * e2[2] * e2[3] / r2)];
    }, 6572: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseImageScalerAttributes = e.imageScaler = void 0;
      const r = n(246), i2 = n(2039);
      e.imageScaler = (t3, e2, n2) => (u(e2), [t3.run(a(t3, e2, n2), e2)]), e.parseImageScalerAttributes = (t3) => {
        const e2 = t3.attributes.getFloat("scale"), n2 = t3.attributes.getFloats("bias");
        return (0, r.createAttributeWithCacheKey)({ scale: e2, bias: n2 });
      };
      const o = { name: "ImageScaler", inputNames: ["X"], inputTypes: [i2.TextureType.unpacked] }, a = (t3, e2, n2) => {
        const r2 = Object.assign(Object.assign({}, o), { cacheHint: n2.cacheKey });
        return Object.assign(Object.assign({}, r2), { get: () => ((t4, e3, n3, r3) => {
          const o2 = n3[0].dims.slice(), a2 = o2.length, u2 = `
      ${s(r3.bias.length)}
      float process(int indices[${a2}]) {
        return _X(indices) * scale + getBias(bias, indices[1]);
      }`;
          return Object.assign(Object.assign({}, e3), { output: { dims: o2, type: n3[0].type, textureType: i2.TextureType.unpacked }, variables: [{ name: "bias", type: "float", arrayLength: r3.bias.length, data: r3.bias }, { name: "scale", type: "float", data: r3.scale }], shaderSource: u2 });
        })(0, r2, e2, n2) });
      }, s = (t3) => {
        const e2 = [`float getBias(float bias[${t3}], int channel) {`];
        for (let n2 = 0; n2 < t3; ++n2) 0 === n2 ? e2.push(`	if (channel == ${n2}) { return bias[${n2}]; }`) : n2 === t3 - 1 ? e2.push(`	else { return bias[${n2}]; }`) : e2.push(`	else if (channel == ${n2}) { return bias[${n2}]; }`);
        return e2.push("	}"), e2.join("\n");
      }, u = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("ImageScaler requires 1 input.");
        if (4 !== t3[0].dims.length) throw new Error("Invalid input shape.");
        if ("float32" !== t3[0].type && "float64" !== t3[0].type) throw new Error("Invalid input type.");
      };
    }, 3346: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseInstanceNormalizationAttributes = e.instanceNormalization = void 0;
      const r = n(5060), i2 = n(2039);
      e.instanceNormalization = (t3, e2, n2) => {
        c(e2);
        const r2 = t3.run(a(e2[0]), e2);
        return [t3.run(u(t3, e2[0], n2, r2.dims), [e2[0], r2, e2[1], e2[2]])];
      }, e.parseInstanceNormalizationAttributes = (t3) => t3.attributes.getFloat("epsilon", 1e-5);
      const o = { name: "InstanceNormalization_MeanAndVariance", inputNames: ["X"], inputTypes: [i2.TextureType.unpacked] }, a = (t3) => Object.assign(Object.assign({}, o), { get: () => ((t4, e2) => {
        const n2 = e2.dims.slice(), r2 = n2[1], o2 = n2[2] * n2[3], a2 = [n2[0], r2], s2 = `
      vec4 process(int[2] indices) {
        vec4 v = vec4(0.0);
        int a[4];
        a[0] = indices[0];
        a[1] = indices[1];
        float temp = 0.0;
        for(int a2=0; a2<${n2[2]}; a2++) {
          a[2] = a2;
          for(int a3=0; a3<${n2[3]}; a3++) {
            a[3] = a3;
            float x = _X(a);
            temp += x;
          }
        }
        float mean = temp / float(${o2});
        temp = 0.0;
        for(int a2=0; a2<${n2[2]}; a2++) {
          a[2] = a2;
          for(int a3=0; a3<${n2[3]}; a3++) {
            a[3] = a3;
            float x = _X(a);
            temp += (x - mean) * (x - mean);
          }
        }
        v.r = mean;
        v.g = temp / float(${o2});

        return v;
      }`;
        return Object.assign(Object.assign({}, t4), { output: { dims: a2, type: e2.type, textureType: i2.TextureType.packedLastDimension }, shaderSource: s2 });
      })(o, t3) }), s = { name: "InstanceNormalization_ComputeOutput", inputNames: ["X", "MeanAndVariance", "Scale", "B"], inputTypes: [i2.TextureType.unpacked, i2.TextureType.packedLastDimension, i2.TextureType.unpacked, i2.TextureType.unpacked] }, u = (t3, e2, n2, o2) => {
        const a2 = Object.assign(Object.assign({}, s), { cacheHint: `${n2}` });
        return Object.assign(Object.assign({}, a2), { get: () => ((t4, e3, n3, o3, a3) => {
          const s2 = (0, r.getGlsl)(t4.session.backend.glContext.version), [u2, c2] = t4.calculateTextureWidthAndHeight(a3, i2.TextureType.packedLastDimension), [l, p] = [u2 / 4, c2], f = `
      vec4 get_MeanAndVariance(int[2] mv) {
        int offset = indicesToOffset_MeanAndVariance(mv);
        vec2 coords = offsetToCoords(offset, ${l}, ${p});
        return ${s2.texture2D}(MeanAndVariance, coords);
      }

      float process(int[4] indices) {
        int mv[2];
        mv[0] = indices[0];
        mv[1] = indices[1];
        vec4 mean_and_variance = get_MeanAndVariance(mv);
        float mean = mean_and_variance.r;
        float variance = mean_and_variance.g;

        int sb[1];
        sb[0] = indices[1];
        float scale = _Scale(sb);
        float b = _B(sb);

        return scale * (_X(indices) - mean) / sqrt(variance + epsilon) + b;
      }`;
          return Object.assign(Object.assign({}, e3), { output: { dims: n3.dims, type: n3.type, textureType: i2.TextureType.unpacked }, variables: [{ name: "epsilon", type: "float", data: o3 }], shaderSource: f });
        })(t3, a2, e2, n2, o2) });
      }, c = (t3) => {
        if (!t3 || 3 !== t3.length) throw new Error("InstanceNormalization requires 3 inputs.");
        const e2 = t3[0], n2 = t3[1], r2 = t3[2];
        if (e2.dims.length < 3 || 1 !== n2.dims.length || 1 !== r2.dims.length) throw new Error("Invalid input shape.");
        if (n2.dims[0] !== e2.dims[1] || r2.dims[0] !== e2.dims[1]) throw new Error("Input shapes are mismatched.");
        if ("float32" !== e2.type && "float64" !== e2.type || "float32" !== n2.type && "float64" !== n2.type || "float32" !== r2.type && "float64" !== r2.type) throw new Error("Invalid input type.");
        if (4 !== t3[0].dims.length) throw new Error("Only support 4-D input shape.");
      };
    }, 708: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createPackedMatmulProgramInfoLoader = void 0;
      const r = n(2517), i2 = n(5060), o = n(2039), a = n(9390), s = n(2823), u = n(5623);
      e.createPackedMatmulProgramInfoLoader = (t3, e2, n2) => {
        const c = (l = e2.length > 2, p = n2.activationCacheKey, { name: "MatMul (packed)", inputNames: l ? ["A", "B", "Bias"] : ["A", "B"], inputTypes: l ? [o.TextureType.packed, o.TextureType.packed, o.TextureType.packed] : [o.TextureType.packed, o.TextureType.packed], cacheHint: p });
        var l, p;
        return Object.assign(Object.assign({}, c), { get: () => ((t4, e3, n3, c2) => {
          const l2 = n3.length > 2, p2 = l2 ? "value += getBiasForMatmul();" : "", f = n3[0].dims, d = n3[1].dims, h = r.BroadcastUtil.calcShape(f, d, true), g = !r.ShapeUtil.areEqual(n3[0].dims, n3[1].dims);
          if (!h) throw new Error("Can't use matmul on the given tensors");
          const b = f[f.length - 1], m = Math.ceil(b / 2), y = f.length, _ = d.length, v = (0, i2.getGlsl)(t4.session.backend.glContext.version), w = (0, a.getCoordsDataType)(h.length), x = h.length, T = (0, a.getGlChannels)(), { activationFunction: S, applyActivation: O } = (0, s.getActivationSnippet)(c2), A = l2 ? `${(0, u.getBiasForMatmul)(w, T, n3[2].dims, h, true)}` : "", E = g ? `${function(t5, e4, n4, i3) {
            let o2 = [], a2 = [];
            const s2 = n4[0].dims, u2 = n4[1].dims, c3 = s2.length, l3 = u2.length, p3 = i3.length, f2 = p3 - c3, d2 = p3 - l3;
            o2 = s2.map((t6, n5) => `coords.${e4[n5 + f2]}`), o2[c3 - 1] = "i*2", o2.join(", "), a2 = u2.map((t6, n5) => `coords.${e4[n5 + d2]}`), a2[l3 - 2] = "i*2", a2.join(", ");
            const h2 = r.BroadcastUtil.getBroadcastDims(s2, i3), g2 = r.BroadcastUtil.getBroadcastDims(u2, i3), b2 = h2.map((t6) => `coords.${e4[t6 + f2]} = 0;`).join("\n"), m2 = g2.map((t6) => `coords.${e4[t6 + d2]} = 0;`).join("\n"), y2 = `int lastDim = coords.${e4[p3 - 1]};
  coords.${e4[p3 - 1]} = coords.${e4[p3 - 2]};
  coords.${e4[p3 - 2]} = lastDim;`;
            return `
vec4 getAAtOutCoordsMatmul(int i) {
  ${t5} coords = getOutputCoords();
  ${y2}
  ${b2}
  vec4 outputValue = getA(${o2});
  return outputValue;
}

vec4 getBAtOutCoordsMatmul(int i) {
  ${t5} coords = getOutputCoords();
  ${y2}
  ${m2}
  vec4 outputValue = getB(${a2});
  return outputValue;
}`;
          }(w, T, n3, h)}` : "", I = g ? "getAAtOutCoordsMatmul(i)" : `getA(${function(t5, e4) {
            let n4 = "";
            for (let r2 = 0; r2 < e4 - 2; r2++) n4 += `rc.${t5[r2]}, `;
            return n4 += `rc.${t5[e4 - 2]}, i*2`, n4;
          }(T, y)})`, P = g ? "getBAtOutCoordsMatmul(i)" : `getB(${function(t5, e4) {
            let n4 = "";
            for (let r2 = 0; r2 < e4 - 2; r2++) n4 += `rc.${t5[r2]}, `;
            return n4 += `i*2, rc.${t5[e4 - 1]}`, n4;
          }(T, _)})`, D = `
            ${E}
            ${A}
            ${S}
            void main() {
              ${g ? "" : `${w} rc =
          getOutputCoords(); int lastDim = rc.${T[x - 1]}; rc.${T[x - 1]} =
          rc.${T[x - 2]}; rc.${T[x - 2]} = lastDim;
      `}

              vec4 value = vec4(0);
              for (int i = 0; i < ${m}; i++) {
                vec4 a = ${I};
                vec4 b = ${P};

                value += (a.rrbb * b.rgrg);
                value += (a.ggaa * b.baba);
              }
              ${p2}
              ${O}
              ${v.output} = value;
            }`;
          return Object.assign(Object.assign({}, e3), { output: { dims: h, type: n3[0].type, textureType: o.TextureType.packed }, shaderSource: D, hasMain: true });
        })(t3, c, e2, n2) });
      };
    }, 5623: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.getBiasForMatmul = e.createMatmulProgramInfoLoader = e.parseMatMulAttributes = e.matMul = void 0;
      const r = n(2517), i2 = n(2039), o = n(9390), a = n(2823), s = n(708);
      function u(t3, e2) {
        const n2 = (s2 = t3.length > 2, u2 = e2.activationCacheKey, { name: "MatMul", inputNames: s2 ? ["A", "B", "Bias"] : ["A", "B"], inputTypes: s2 ? [i2.TextureType.unpacked, i2.TextureType.unpacked, i2.TextureType.unpacked] : [i2.TextureType.unpacked, i2.TextureType.unpacked], cacheHint: u2 });
        var s2, u2;
        return Object.assign(Object.assign({}, n2), { get: () => function(t4, e3, n3) {
          const s3 = e3[0].dims, u3 = e3[1].dims, c2 = r.BroadcastUtil.calcShape(s3, u3, true);
          if (!c2) throw new Error("Can't use matmul on the given tensors");
          const p = (0, o.getCoordsDataType)(c2.length), f = (0, o.getGlChannels)(), { activationFunction: d, applyActivation: h } = (0, a.getActivationSnippet)(n3), g = e3.length > 2, b = g ? "value += getBiasForMatmul();" : "", m = g ? `${l(p, f, e3[2].dims, c2, false)}` : "", y = c2.length, _ = s3.length, v = u3.length, w = `
    ${d}
    ${m}
    float process(int indices[${y}]) {
        int a[${_}];
        int b[${v}];
        bcastMatmulIndices_A(indices, a);
        bcastMatmulIndices_B(indices, b);

        float value;
        for (int k=0; k<${s3[s3.length - 1]}; ++k) {
            a[${_ - 1}] = k;
            b[${v - 2}] = k;
            value += _A(a) * _B(b);
        }
        ${b}
        ${h}
        return value;
    }`;
          return Object.assign(Object.assign({}, t4), { output: { dims: c2, type: e3[0].type, textureType: i2.TextureType.unpacked }, shaderSource: w });
        }(n2, t3, e2) });
      }
      e.matMul = (t3, e2, n2) => (c(e2), t3.session.pack ? [t3.run((0, s.createPackedMatmulProgramInfoLoader)(t3, e2, n2), e2)] : [t3.run(u(e2, n2), e2)]), e.parseMatMulAttributes = (t3) => (0, a.parseInternalActivationAttributes)(t3.attributes), e.createMatmulProgramInfoLoader = u;
      const c = (t3) => {
        if (!t3 || 2 !== t3.length) throw new Error("MatMul requires 2 inputs.");
        if (t3[0].dims[t3[0].dims.length - 1] !== t3[1].dims[t3[1].dims.length - 2]) throw new Error("shared dimension does not match.");
        if ("float32" !== t3[0].type && "float64" !== t3[0].type || "float32" !== t3[1].type && "float64" !== t3[1].type) throw new Error("inputs should be float type");
        if (t3[0].type !== t3[1].type) throw new Error("inputs types should match");
      };
      function l(t3, e2, n2, i3, o2) {
        let a2 = "";
        const s2 = n2.length, u2 = i3.length, c2 = u2 - s2;
        a2 = u2 < 2 && s2 > 0 ? "coords" : n2.map((t4, n3) => `coords.${e2[n3 + c2]}`).join(", ");
        const l2 = r.BroadcastUtil.getBroadcastDims(n2, i3).map((t4) => `coords.${e2[t4 + c2]} = 0;`).join("\n");
        let p = "vec4(outputValue.xx, outputValue.yy)";
        return 1 === r.ShapeUtil.size(n2) && (p = "vec4(outputValue.x)"), o2 ? `
vec4 getBiasForMatmul() {
  ${t3} coords = getOutputCoords();
  ${l2}
  vec4 outputValue = getBias(${a2});
  return ${p};
}` : `
float getBiasForMatmul() {
  ${t3} coords = getOutputCoords();
  ${l2}
  return getBias(coords.x);
}`;
      }
      e.getBiasForMatmul = l;
    }, 2403: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createPackProgramInfoLoader = void 0;
      const r = n(5060), i2 = n(2039), o = n(9390), a = n(2827), s = { name: "pack", inputNames: ["A"], inputTypes: [i2.TextureType.unpackedReversed] };
      e.createPackProgramInfoLoader = (t3, e2) => Object.assign(Object.assign({}, s), { get: () => ((t4, e3) => {
        const n2 = (0, r.getGlsl)(t4.session.backend.glContext.version), u = e3.dims, c = u.length, l = e3.dims.length, p = (0, o.getCoordsDataType)(l), f = (0, a.getChannels)("rc", l), d = (h = l, g = f, b = u[u.length - 2], m = u[u.length - 1], 0 === h || 1 === h ? "" : `
    int r = ${g[h - 2]};
    int c = ${g[h - 1]};
    int rp1 = ${g[h - 2]} + 1;
    int cp1 = ${g[h - 1]} + 1;
    bool rEdge = rp1 >= ${m};
    bool cEdge = cp1 >= ${b};
    `);
        var h, g, b, m;
        let y;
        y = 0 === c ? [1, 1] : 1 === c ? [u[0], 1] : [u[l - 1], u[l - 2]];
        const _ = function(t5, e4, n3) {
          if (0 === t5) return "false";
          if (1 === t5) return `rc > ${e4[0]}`;
          let r2 = "";
          for (let i3 = t5 - 2; i3 < t5; i3++) r2 += `${n3[i3]} >= ${e4[i3 - t5 + 2]}`, i3 < t5 - 1 && (r2 += "||");
          return r2;
        }(l, y, f), v = function(t5, e4) {
          const n3 = t5.length;
          if (0 === n3) return "getA(), 0, 0, 0";
          if (1 === n3) return `getA(rc),
            rc + 1 >= ${t5[0]} ? 0. : getA(rc + 1),
            0, 0`;
          let r2 = "";
          if (n3 > 2) for (let t6 = 0; t6 < n3 - 2; ++t6) r2 += `${e4[t6]},`;
          return `getA(${r2}r, c),
          rEdge ? 0. : getA(${r2}rp1, c),
          cEdge ? 0. : getA(${r2}r, cp1),
          rEdge || cEdge ? 0. : getA(${r2}rp1, cp1)`;
        }(u, f), w = `
        void main() {
          ${p} rc = getOutputCoords();

          if(${_}) {
            ${n2.output} = vec4(0);
          } else {
            ${d}

            ${n2.output} = vec4(${v});
          }
        }
      `;
        return Object.assign(Object.assign({}, s), { hasMain: true, output: { dims: e3.dims, type: e3.type, textureType: i2.TextureType.packed }, shaderSource: w });
      })(t3, e2) });
    }, 2827: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.unpackFromChannel = e.getChannels = e.getVecChannels = void 0;
      const r = n(9390);
      function i2(t3, e2) {
        return (0, r.getGlChannels)(e2).map((e3) => `${t3}.${e3}`);
      }
      e.getVecChannels = i2, e.getChannels = function(t3, e2) {
        return 1 === e2 ? [t3] : i2(t3, e2);
      }, e.unpackFromChannel = function() {
        return "\n    float getChannel(vec4 frag, int dim) {\n      int modCoord = imod(dim, 2);\n      return modCoord == 0 ? frag.r : frag.g;\n    }\n\n    float getChannel(vec4 frag, vec2 innerDims) {\n      vec2 modCoord = mod(innerDims, 2.);\n      return modCoord.x == 0. ?\n        (modCoord.y == 0. ? frag.r : frag.g) :\n        (modCoord.y == 0. ? frag.b : frag.a);\n    }\n  ";
      };
    }, 2870: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parsePadAttributesV11 = e.padV11 = e.parsePadAttributesV2 = e.padV2 = void 0;
      const r = n(246), i2 = n(2517), o = n(5060), a = n(2039), s = { name: "Pad", inputNames: ["A"], inputTypes: [a.TextureType.unpacked] };
      e.padV2 = (t3, e2, n2) => (l(e2), [t3.run(Object.assign(Object.assign({}, s), { cacheHint: n2.cacheKey, get: () => c(t3, e2[0], n2) }), e2)]), e.parsePadAttributesV2 = (t3) => {
        const e2 = t3.attributes.getString("mode", "constant"), n2 = t3.attributes.getFloat("value", 0), i3 = t3.attributes.getInts("pads");
        return (0, r.createAttributeWithCacheKey)({ mode: e2, value: n2, pads: i3 });
      }, e.padV11 = (t3, n2, r2) => {
        p(n2);
        const i3 = u(t3, n2, r2);
        return (0, e.padV2)(t3, [n2[0]], i3);
      }, e.parsePadAttributesV11 = (t3) => t3.attributes.getString("mode", "constant");
      const u = (t3, e2, n2) => {
        if (!t3.session.isInitializer(e2[1].dataId) || e2.length >= 3 && !t3.session.isInitializer(e2[2].dataId)) throw new Error("dynamic pad attributes are not allowed");
        const i3 = Array.from(e2[1].integerData), o2 = e2.length >= 3 ? e2[2].floatData[0] : 0;
        return (0, r.createAttributeWithCacheKey)({ mode: n2, pads: i3, value: o2 });
      }, c = (t3, e2, n2) => {
        const r2 = i2.ShapeUtil.padShape(e2.dims.slice(), n2.pads), o2 = r2.length, s2 = `
      ${f(t3, e2, n2)}
      float process(int[${o2}] indices) {
          return padA(indices);
      }`;
        return { name: "Pad", inputNames: ["A"], inputTypes: [a.TextureType.unpacked], output: { dims: r2, type: e2.type, textureType: a.TextureType.unpacked }, shaderSource: s2 };
      }, l = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Pad requires 1 input");
        if ("float32" !== t3[0].type && "float64" !== t3[0].type) throw new Error("Invalid input type.");
      }, p = (t3) => {
        if (!t3 || 2 !== t3.length && 3 !== t3.length) throw new Error("Pad requires 2 or 3 inputs");
        if ("int32" !== t3[1].type) throw new Error("Invalid input type.");
        if (t3.length >= 3 && "string" === t3[2].type) throw new Error("Invalid input type.");
      }, f = (t3, e2, n2) => {
        const r2 = (0, o.getGlsl)(t3.session.backend.glContext.version), [s2, u2] = t3.calculateTextureWidthAndHeight(e2.dims, a.TextureType.unpacked), c2 = i2.ShapeUtil.computeStrides(e2.dims);
        switch (n2.mode) {
          case "constant":
            return d(r2, e2.dims, c2, s2, u2, n2.pads, n2.value);
          case "reflect":
            return h(r2, e2.dims, c2, s2, u2, n2.pads);
          case "edge":
            return g(r2, e2.dims, c2, s2, u2, n2.pads);
          default:
            throw new Error("Invalid mode");
        }
      }, d = (t3, e2, n2, r2, i3, o2, a2) => {
        const s2 = e2.length;
        let u2 = "";
        for (let t4 = s2 - 1; t4 >= 0; --t4) u2 += `
        k = m[${t4}] - ${o2[t4]};
        if (k < 0)  return constant;
        if (k >= ${e2[t4]}) return constant;
        offset += k * ${n2[t4]};
        `;
        return `
      float padA(int m[${s2}]) {
        const float constant = float(${a2});
        int offset = 0;
        int k = 0;
        ${u2}
        vec2 coords = offsetToCoords(offset, ${r2}, ${i3});
        float value = getColorAsFloat(${t3.texture2D}(A, coords));
        return value;
      }
      `;
      }, h = (t3, e2, n2, r2, i3, o2) => {
        const a2 = e2.length;
        let s2 = "";
        for (let t4 = a2 - 1; t4 >= 0; --t4) s2 += `
        k = m[${t4}] - ${o2[t4]};
        if (k < 0) { k = -k; }
        {
          const int _2n_1 = ${2 * (e2[t4] - 1)};
          k = int( mod( float(k), float(_2n_1) ) ) ;
          if(k >= ${e2[t4]}) { k = _2n_1 - k; }
        }
        offset += k * ${n2[t4]};
        `;
        return `
      float padA(int m[${a2}]) {
        int offset = 0;
        int k = 0;
        ${s2}
        vec2 coords = offsetToCoords(offset, ${r2}, ${i3});
        float value = getColorAsFloat(${t3.texture2D}(A, coords));
        return value;
      }
      `;
      }, g = (t3, e2, n2, r2, i3, o2) => {
        const a2 = e2.length;
        let s2 = "";
        for (let t4 = a2 - 1; t4 >= 0; --t4) s2 += `
        k = m[${t4}] - ${o2[t4]};
        if (k < 0)  k = 0;
        if (k >= ${e2[t4]}) k = ${e2[t4] - 1};
        offset += k * ${n2[t4]};
      `;
        return `
      float padA(int m[${a2}]) {
        int offset = 0;
        int k = 0;
        ${s2}
        vec2 coords = offsetToCoords(offset, ${r2}, ${i3});
        float value = getColorAsFloat(${t3.texture2D}(A, coords));
        return value;
      }
      `;
      };
    }, 2143: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.globalMaxPool = e.parseMaxPoolAttributes = e.maxPool = e.parseGlobalAveragePoolAttributes = e.globalAveragePool = e.parseAveragePoolAttributes = e.averagePool = void 0;
      const r = n(246), i2 = n(2517), o = n(2039);
      e.averagePool = (t3, e2, n2) => {
        p(e2);
        const r2 = { name: "AveragePool", inputNames: ["X"], inputTypes: [o.TextureType.unpacked], cacheHint: n2.cacheKey };
        return [t3.run(Object.assign(Object.assign({}, r2), { get: () => a(e2, r2, false, n2) }), e2)];
      }, e.parseAveragePoolAttributes = (t3) => {
        const e2 = t3.attributes.getString("auto_pad", "NOTSET"), n2 = t3.attributes.getInt("ceil_mode", 0), i3 = 0 !== t3.attributes.getInt("count_include_pad", 0), o2 = t3.attributes.getInts("kernel_shape"), a2 = t3.attributes.getInts("strides", []), s2 = t3.attributes.getInts("pads", []);
        if (0 !== n2) throw new Error("using ceil() in shape computation is not yet supported for AveragePool");
        return (0, r.createAttributeWithCacheKey)({ autoPad: e2, ceilMode: n2, countIncludePad: i3, kernelShape: o2, strides: a2, pads: s2 });
      };
      const a = (t3, e2, n2, r2) => {
        const [a2, s2] = u(t3, r2, n2), c2 = i2.ShapeUtil.size(a2.kernelShape);
        let l2 = "";
        a2.countIncludePad ? l2 += `value /= float(${c2});` : l2 += `value /= float(${c2} - pad);`;
        const p2 = `
        ${f(t3[0].dims, a2, "value += _X(x);", l2, "0.0")}
      `;
        return Object.assign(Object.assign({}, e2), { output: { dims: s2, type: t3[0].type, textureType: o.TextureType.unpacked }, shaderSource: p2 });
      };
      e.globalAveragePool = (t3, e2, n2) => {
        p(e2);
        const r2 = { name: "GlobalAveragePool", inputNames: ["X"], inputTypes: [o.TextureType.unpacked], cacheHint: `${n2.countIncludePad}` };
        return [t3.run(Object.assign(Object.assign({}, r2), { get: () => a(e2, r2, true, n2) }), e2)];
      }, e.parseGlobalAveragePoolAttributes = (t3) => {
        const e2 = 0 !== t3.attributes.getInt("count_include_pad", 0);
        return (0, r.createAttributeWithCacheKey)({ autoPad: "", ceilMode: 0, countIncludePad: e2, kernelShape: [], strides: [], pads: [] });
      }, e.maxPool = (t3, e2, n2) => {
        p(e2);
        const r2 = { name: "MaxPool", inputNames: ["X"], inputTypes: [o.TextureType.unpacked], cacheHint: n2.cacheKey };
        return [t3.run(Object.assign(Object.assign({}, r2), { get: () => s(e2, r2, false, n2) }), e2)];
      }, e.parseMaxPoolAttributes = (t3) => {
        const e2 = t3.attributes.getString("auto_pad", "NOTSET"), n2 = t3.attributes.getInt("ceil_mode", 0), i3 = t3.attributes.getInts("kernel_shape"), o2 = t3.attributes.getInts("strides", []), a2 = t3.attributes.getInts("pads", []), s2 = t3.attributes.getInt("storage_order", 0), u2 = t3.attributes.getInts("dilations", []);
        if (0 !== s2) throw new Error("column major storage order is not yet supported for MaxPool");
        if (0 !== n2) throw new Error("using ceil() in shape computation is not yet supported for MaxPool");
        return (0, r.createAttributeWithCacheKey)({ autoPad: e2, ceilMode: n2, countIncludePad: false, kernelShape: i3, strides: o2, pads: a2, storageOrder: s2, dilations: u2 });
      };
      const s = (t3, e2, n2, r2) => {
        const [i3, a2] = u(t3, r2, n2), s2 = `
      ${f(t3[0].dims, i3, "\n      value = max(_X(x), value);\n    ", "", "-1e5")}
    `;
        return Object.assign(Object.assign({}, e2), { output: { dims: a2, type: t3[0].type, textureType: o.TextureType.unpacked }, shaderSource: s2 });
      }, u = (t3, e2, n2) => {
        const r2 = t3[0].dims.slice(), o2 = Object.hasOwnProperty.call(e2, "dilations"), a2 = e2.kernelShape.slice(), s2 = e2.strides.slice(), u2 = o2 ? e2.dilations.slice() : [], c2 = e2.pads.slice();
        i2.PoolConvUtil.adjustPoolAttributes(n2, r2, a2, s2, u2, c2);
        const l2 = i2.PoolConvUtil.computePoolOutputShape(n2, r2, s2, u2, a2, c2, e2.autoPad), p2 = Object.assign({}, e2);
        return o2 ? Object.assign(p2, { kernelShape: a2, strides: s2, pads: c2, dilations: u2, cacheKey: e2.cacheKey }) : Object.assign(p2, { kernelShape: a2, strides: s2, pads: c2, cacheKey: e2.cacheKey }), [p2, l2];
      }, c = { autoPad: "", ceilMode: 0, countIncludePad: false, kernelShape: [], strides: [], pads: [], storageOrder: 0, dilations: [], cacheKey: "" }, l = { name: "GlobalMaxPool", inputNames: ["X"], inputTypes: [o.TextureType.unpacked] };
      e.globalMaxPool = (t3, e2) => (p(e2), [t3.run(Object.assign(Object.assign({}, l), { get: () => s(e2, l, true, c) }), e2)]);
      const p = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Pool ops requires 1 input.");
        if ("float32" !== t3[0].type && "float64" !== t3[0].type) throw new Error("Invalid input type.");
      }, f = (t3, e2, n2, r2, o2) => {
        const a2 = t3.length;
        if (e2.kernelShape.length <= 2) {
          const i3 = e2.kernelShape[e2.kernelShape.length - 1], s2 = e2.strides[e2.strides.length - 1], u2 = e2.pads[e2.pads.length / 2 - 1], c2 = e2.pads[e2.pads.length - 1], l2 = t3[a2 - 1];
          let p2 = "", f2 = "", d2 = "";
          if (p2 = u2 + c2 !== 0 ? `
          for (int i = 0; i < ${i3}; i++) {
            x[${a2} - 1] = indices[${a2} - 1] * ${s2} - ${u2} + i;
            if (x[${a2} - 1] < 0 || x[${a2} - 1] >= ${l2}) {
              pad++;
              continue;
            }
            ${n2}
          }` : `
          for (int i = 0; i < ${i3}; i++) {
            x[${a2} - 1] = indices[${a2} - 1] * ${s2} - ${u2} + i;
            ${n2}
          }`, 2 === e2.kernelShape.length) {
            const n3 = e2.kernelShape[e2.kernelShape.length - 2], r3 = e2.strides[e2.strides.length - 2], o3 = e2.pads[e2.pads.length / 2 - 2], s3 = e2.pads[e2.pads.length - 2], u3 = t3[a2 - 2];
            f2 = o3 + s3 !== 0 ? `
            for (int j = 0; j < ${n3}; j++) {
              x[${a2} - 2] = indices[${a2} - 2] * ${r3} - ${o3} + j;
              if (x[${a2} - 2] < 0 || x[${a2} - 2] >= ${u3}) {
                pad+= ${i3};
                continue;
              }
          ` : `
            for (int j = 0; j < ${n3}; j++) {
              x[${a2} - 2] = indices[${a2} - 2] * ${r3} - ${o3} + j;
            `, d2 = "\n          }\n        ";
          }
          return `
        float process(int indices[${a2}]) {
          int x[${a2}];
          copyVec(indices, x);

          float value = ${o2};
          int pad = 0;
          ${f2}
          ${p2}
          ${d2}
          ${r2}
          return value;
        }
      `;
        }
        {
          const s2 = i2.ShapeUtil.size(e2.kernelShape), u2 = i2.ShapeUtil.computeStrides(e2.kernelShape), c2 = u2.length, l2 = e2.pads.length, p2 = h(c2), f2 = d(t3, "inputDims"), g = d(e2.pads, "pads"), b = d(u2, "kernelStrides"), m = d(e2.strides, "strides");
          let y = "";
          return y = e2.pads.reduce((t4, e3) => t4 + e3) ? `
            if (x[j] >= inputDims[j] || x[j] < 0) {
              pad++;
              isPad = true;
              break;
            }
          }
          if (!isPad) {
            ${n2}
          }` : `
          }
          ${n2}
        `, `
        ${p2}
        float process(int indices[${a2}]) {
          int x[${a2}];
          copyVec(indices, x);
          int offset[${c2}];
          int pads[${l2}];
          int inputDims[${a2}];
          int kernelStrides[${c2}];
          int strides[${c2}];
          ${g}
          ${f2}
          ${m}
          ${b}

          float value = ${o2};
          int pad = 0;
          bool isPad = false;
          for (int i = 0; i < ${s2}; i++) {
            offsetToIndices(i, kernelStrides, offset);
            isPad = false;
            for (int j = ${a2} - ${c2}; j < ${a2}; j++) {
              x[j] = indices[j] * strides[j - ${a2} + ${c2}]
                + offset[j - ${a2} + ${c2}] - pads[j - 2];
              ${y}
          }
          ${r2}

          return value;
        }
      `;
        }
      }, d = (t3, e2) => {
        let n2 = "";
        for (let r2 = 0; r2 < t3.length; r2++) n2 += `
      ${e2}[${r2}] = ${t3[r2]};
    `;
        return n2;
      }, h = (t3) => `
  void offsetToIndices(int offset, int[${t3}] strides, out int[${t3}] indices) {
    if (${t3} == 0) {
      return;
    }
    for (int i = 0; i < ${t3} - 1; ++i) {
      indices[i] = offset / strides[i];
      offset -= indices[i] * strides[i];
    }
    indices[${t3} - 1] = offset;
  }`;
    }, 4939: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.reduceLogSumSquare = e.reduceLogSum = e.reduceProd = e.reduceMin = e.reduceMax = e.reduceMean = e.reduceSum = e.parseReduceAttributes = void 0;
      const r = n(246), i2 = n(782), o = n(2517), a = n(2039), s = (t3, e2, n2, r2, i3) => {
        c(e2);
        const o2 = { name: r2, inputNames: ["A"], inputTypes: [a.TextureType.unpacked] };
        return [t3.run(Object.assign(Object.assign({}, o2), { cacheHint: n2.cacheKey, get: () => u(t3, e2, n2, r2, i3, o2) }), e2)];
      };
      e.parseReduceAttributes = (t3) => {
        const e2 = t3.attributes.getInts("axes", []), n2 = 1 === t3.attributes.getInt("keepdims", 1);
        return (0, r.createAttributeWithCacheKey)({ axes: e2, keepDims: n2 });
      };
      const u = (t3, e2, n2, r2, i3, s2) => {
        const u2 = [], c2 = e2[0].dims.length || 1, l = [], p = o.ShapeUtil.normalizeAxes(n2.axes, e2[0].dims.length), f = i3(e2, p);
        let d = f[1];
        for (let t4 = 0; t4 < e2[0].dims.length; t4++) p.indexOf(t4) >= 0 || 0 === p.length ? (n2.keepDims && u2.push(1), d = `
          for(int j${t4} = 0; j${t4} < ${e2[0].dims[t4]}; j${t4}++) {
            inputIdx[${t4}] = j${t4};
            ${d}
          }`) : (l.push(`inputIdx[${t4}] = outputIdx[${u2.length}];`), u2.push(e2[0].dims[t4]));
        const h = `
      float process(int outputIdx[${u2.length || 1}]) {
        float value;                 // final result
        int inputIdx[${c2}];      // addressing input data
        ${l.join("\n")}
        ${f[0]}       // init ops for reduce max/min
        ${d}
        ${f[2]}       // final computation for reduce mean
        return value;
      }`;
        return Object.assign(Object.assign({}, s2), { output: { dims: u2, type: e2[0].type, textureType: a.TextureType.unpacked }, shaderSource: h });
      }, c = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Reduce op requires 1 input.");
        if (-1 === i2.NUMBER_TYPES.indexOf(t3[0].type)) throw new Error("Invalid input type.");
      };
      e.reduceSum = (t3, e2, n2) => s(t3, e2, n2, "ReduceSum", () => ["value = 0.0;", "value += _A(inputIdx);", ""]), e.reduceMean = (t3, e2, n2) => s(t3, e2, n2, "ReduceMean", (t4, e3) => {
        let n3 = 1;
        for (let r2 = 0; r2 < t4[0].dims.length; r2++) (e3.indexOf(r2) >= 0 || 0 === e3.length) && (n3 *= t4[0].dims[r2]);
        return ["value = 0.0;", "value += _A(inputIdx);", `value /= ${n3}.;`];
      }), e.reduceMax = (t3, e2, n2) => s(t3, e2, n2, "ReduceMax", (t4, e3) => {
        const n3 = [];
        for (let r2 = 0; r2 < t4[0].dims.length; r2++) (e3.indexOf(r2) >= 0 || 0 === e3.length) && n3.push(`inputIdx[${r2}] = 0;`);
        return [`${n3.join("\n")}
value = _A(inputIdx);`, "value = max(value, _A(inputIdx));", ""];
      }), e.reduceMin = (t3, e2, n2) => s(t3, e2, n2, "ReduceMin", (t4, e3) => {
        const n3 = [];
        for (let r2 = 0; r2 < t4[0].dims.length; r2++) (e3.indexOf(r2) >= 0 || 0 === e3.length) && n3.push(`inputIdx[${r2}] = 0;`);
        return [`${n3.join("\n")}
value = _A(inputIdx);`, "value = min(value, _A(inputIdx));", ""];
      }), e.reduceProd = (t3, e2, n2) => s(t3, e2, n2, "ReduceProd", () => ["value = 1.0;", "value *= _A(inputIdx);", ""]), e.reduceLogSum = (t3, e2, n2) => s(t3, e2, n2, "ReduceLogSum", () => ["value = 0.0;", "value += _A(inputIdx);", "value = log(value);"]), e.reduceLogSumSquare = (t3, e2, n2) => s(t3, e2, n2, "ReduceLogSumSquare", () => ["float t; value = 0.0;", "t = _A(inputIdx); value += t * t;", ""]);
    }, 7019: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.isReshapeCheap = e.processDims3D = e.createPackedReshape3DProgramInfoLoader = void 0;
      const r = n(2517), i2 = n(5060), o = n(2039), a = n(2827);
      e.createPackedReshape3DProgramInfoLoader = (t3, e2, n2) => {
        const s = ((t4) => ({ name: "Reshape (packed)", inputTypes: [o.TextureType.packed], inputNames: ["A"], cacheHint: `${t4}` }))(n2);
        return Object.assign(Object.assign({}, s), { get: () => ((t4, e3, n3, s2) => {
          const u = e3.dims, c = s2;
          let l = "";
          for (let t5 = 0; t5 < 4; t5++) {
            let e4 = "";
            switch (t5) {
              case 0:
                e4 = "outputCoords = rc;";
                break;
              case 1:
                e4 = "outputCoords = ivec3(rc.x, rc.y+1, rc.z);";
                break;
              case 2:
                e4 = "outputCoords = ivec3(rc.x, rc.y, rc.z+1);";
                break;
              case 3:
                e4 = "outputCoords = ivec3(rc.x, rc.y+1, rc.z+1);";
                break;
              default:
                throw new Error();
            }
            l += `
        ${e4}
        ${t5 > 0 ? "if(outputCoords.y < rows && outputCoords.z < cols){" : ""}
          int flattenedIndex = getFlattenedIndex(outputCoords);

          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flattenedIndex);
          vec2 innerDims = vec2(float(inputRC.y),float(inputRC.z));

          result[${t5}] = getChannel(getA(inputRC.x, inputRC.y, inputRC.z), innerDims);

        ${t5 > 0 ? "}" : ""}
      `;
          }
          const p = (0, i2.getGlsl)(t4.session.backend.glContext.version), f = `
      ${function(t5) {
            const e4 = r.ShapeUtil.computeStrides(t5), n4 = ["b", "r", "c"], i3 = "index", o2 = e4.map((t6, r2) => `int ${n4[r2]} = ${i3} / ${t6}; ${r2 === e4.length - 1 ? `int ${n4[r2 + 1]} = ${i3} - ${n4[r2]} * ${t6}` : `index -= ${n4[r2]} * ${t6}`};`).join("");
            return `
    ivec3 inputCoordsFromReshapedOutCoords(int index) {
      ${o2}
      return ivec3(b, r, c);
    }
  `;
          }(u)}
      ${function(t5) {
            const e4 = r.ShapeUtil.computeStrides(t5);
            return `
  int getFlattenedIndex(ivec3 coords) {
    // reverse y, z order
    return coords.x * ${e4[0]} + coords.z * ${e4[1]} + coords.y;
  }
`;
          }(c)}
      ${(0, a.unpackFromChannel)()}

      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0.0);

        ivec3 outputCoords;
        int rows = ${c[2]};
        int cols = ${c[1]};

        ${l}
        ${p.output} = result;
      }
    `;
          return Object.assign(Object.assign({}, n3), { output: { dims: c, type: e3.type, textureType: o.TextureType.packed }, shaderSource: f, hasMain: true });
        })(t3, e2, s, n2) });
      }, e.processDims3D = function(t3) {
        if (0 === t3.length) return [1, 1, 1];
        let e2 = 1;
        for (let n2 = 0; n2 < t3.length - 2; ++n2) e2 *= t3[n2];
        return [e2, t3.length > 1 ? t3[t3.length - 2] : 1, t3[t3.length - 1]];
      }, e.isReshapeCheap = function(t3, e2) {
        let n2 = false;
        return n2 = 0 === t3.length || 0 === e2.length || (t3.length < 2 || e2.length < 2 ? t3[t3.length - 1] === e2[e2.length - 1] : t3[t3.length - 1] === e2[e2.length - 1] && t3[t3.length - 2] === e2[e2.length - 2]), n2;
      };
    }, 718: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.reshape = void 0;
      const r = n(2517);
      e.reshape = (t3, e2) => {
        const n2 = r.ShapeUtil.calculateReshapedDims(e2[0].dims, e2[1].integerData);
        return t3.session.pack ? [t3.reshapePacked(e2[0], n2)] : [t3.reshapeUnpacked(e2[0], n2)];
      };
    }, 2268: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseResizeAttributesV11 = e.parseResizeAttributesV10 = e.resize = void 0;
      const r = n(5060), i2 = n(2039), o = n(9390), a = n(2827), s = n(9793), u = { name: "Resize", inputNames: ["A"], inputTypes: [i2.TextureType.packed] };
      e.resize = (t3, e2, n2) => ((0, s.validateInputs)(e2, n2), [t3.run(Object.assign(Object.assign({}, u), { cacheHint: n2.cacheKey, get: () => c(t3, e2, n2) }), e2)]), e.parseResizeAttributesV10 = (t3) => (0, s.parseUpsampleAttributes)(t3, 10), e.parseResizeAttributesV11 = (t3) => (0, s.parseUpsampleAttributes)(t3, 11);
      const c = (t3, e2, n2) => {
        const s2 = (0, r.getGlsl)(t3.session.backend.glContext.version), [c2, p2] = l(e2, n2);
        if (c2.every((t4) => 1 === t4) && "tf_crop_and_resize" !== n2.coordinateTransformMode) return Object.assign(Object.assign({}, u), { output: { dims: p2, type: e2[0].type, textureType: i2.TextureType.packed }, hasMain: true, shaderSource: `void main() {
                    vec4 v = ${s2.texture2D}(X, TexCoords);
                    ${s2.output} = v;
                }` });
        const f2 = p2.length;
        if (f2 < 2) throw new Error(`output dimension should be at least 2, but got ${f2}`);
        const d = p2[f2 - 2], h = p2[f2 - 1], g = e2[0].dims;
        if (f2 !== g.length) throw new Error(`output dimension should match input ${g.length}, but got ${f2}`);
        const b = g[f2 - 2], m = g[f2 - 1], y = c2[f2 - 2], _ = c2[f2 - 1];
        let v = "";
        if ("linear" !== n2.mode) throw new Error(`resize (packed) does not support mode: '${n2.mode}'`);
        switch (n2.coordinateTransformMode) {
          case "asymmetric":
            v = "\n                    vec4 getSourceFracIndex(ivec4 coords) {\n                        return vec4(coords) / scaleWHWH;\n                    }\n                ";
            break;
          case "half_pixel":
            v = "\n                    vec4 getSourceFracIndex(ivec4 coords) {\n                        return (vec4(coords) + 0.5) / scaleWHWH - 0.5;\n                    }\n                ";
            break;
          case "pytorch_half_pixel":
            v = `
                    vec4 getSourceFracIndex(ivec4 coords) {
                        vec4 fcoords = vec4(coords);
                        return vec4(
                            ${h}.0 > 1.0 ? (fcoords.x + 0.5) / scaleWHWH.x - 0.5 : 0.0,
                            ${d}.0 > 1.0 ? (fcoords.y + 0.5) / scaleWHWH.y - 0.5 : 0.0,
                            ${h}.0 > 1.0 ? (fcoords.z + 0.5) / scaleWHWH.z - 0.5 : 0.0,
                            ${d}.0 > 1.0 ? (fcoords.w + 0.5) / scaleWHWH.w - 0.5 : 0.0
                          );
                    }
                `;
            break;
          case "align_corners":
            v = `
                    vec4 getSourceFracIndex(ivec4 coords) {
                        vec4 resized = vec4(${h}.0 - 1.0, ${d}.0 - 1.0, ${h}.0 - 1.0,
                            ${d}.0 - 1.0);
                        vec4 original = vec4(${m}.0 - 1.0, ${b}.0 - 1.0, ${m}.0 - 1.0,
                            ${b}.0 - 1.0);
                        vec4 new_scale = original / resized;
                        return vec4(coords) * new_scale;
                    }
                `;
            break;
          default:
            throw new Error(`resize (packed) does not support coordinateTransformMode:                                 '${n2.coordinateTransformMode}'`);
        }
        const w = (0, o.getCoordsDataType)(f2), x = `
            const vec2 inputWH = vec2(${b}.0, ${m}.0);
            const vec4 scaleWHWH = vec4(float(${y}), float(${_}), float(${y}), float(${_}));
            ${(0, a.unpackFromChannel)()}
            ${v}
            float getAValue(int x10, int r, int c, int d) {
                return getChannel(getA(x10, r, c, d), vec2(c, d));
            }
            void main() {
                ${w} rc = getOutputCoords();

                int batch = rc[0];
                int depth = rc[1];

                // retrieve the 4 coordinates that is used in the 4 packed output values.
                ivec4 coords = ivec4(rc.wz, rc.w + 1, rc.z + 1);

                // calculate the source index in fraction
                vec4 sourceFrac = getSourceFracIndex(coords);

                // get the lower and upper bound of the 4 values that will be packed into one texel.
                ivec4 x00 = ivec4(max(sourceFrac.xy, vec2(0.0)), min(inputWH - 1.0, ceil(sourceFrac.xy)));
                ivec4 x01 = ivec4(max(sourceFrac.xw, vec2(0.0)), min(inputWH - 1.0, ceil(sourceFrac.xw)));
                ivec4 x10 = ivec4(max(sourceFrac.zy, vec2(0.0)), min(inputWH - 1.0, ceil(sourceFrac.zy)));
                ivec4 x11 = ivec4(max(sourceFrac.zw, vec2(0.0)), min(inputWH - 1.0, ceil(sourceFrac.zw)));

                bool hasNextRow = rc.w < ${d - 1};
                bool hasNextCol = rc.z < ${h - 1};

                // pack x00, x01, x10, x11's top-left corner into one vec4 structure
                vec4 topLeft = vec4(
                    getAValue(batch, depth, x00.x, x00.y),
                    hasNextCol ? getAValue(batch, depth, x01.x, x01.y) : 0.0,
                    hasNextRow ? getAValue(batch, depth, x10.x, x10.y) : 0.0,
                    (hasNextRow && hasNextCol) ? getAValue(batch, depth, x11.x, x11.y) : 0.0);

                // pack x00, x01, x10, x11's top-right corner into one vec4 structure
                vec4 topRight = vec4(
                    getAValue(batch, depth, x00.x, x00.w),
                    hasNextCol ? getAValue(batch, depth, x01.x, x01.w) : 0.0,
                    hasNextRow ? getAValue(batch, depth, x10.x, x10.w) : 0.0,
                    (hasNextRow && hasNextCol) ? getAValue(batch, depth, x11.x, x11.w) : 0.0);

                // pack x00, x01, x10, x11's bottom-left corner into one vec4 structure
                vec4 bottomLeft = vec4(
                    getAValue(batch, depth, x00.z, x00.y),
                    hasNextCol ? getAValue(batch, depth, x01.z, x01.y) : 0.0,
                    hasNextRow ? getAValue(batch, depth, x10.z, x10.y) : 0.0,
                    (hasNextRow && hasNextCol) ? getAValue(batch, depth, x11.z, x11.y) : 0.0);

                // pack x00, x01, x10, x11's bottom-right corner into one vec4 structure
                vec4 bottomRight = vec4(
                    getAValue(batch, depth, x00.z, x00.w),
                    hasNextCol ? getAValue(batch, depth, x01.z, x01.w) : 0.0,
                    hasNextRow ? getAValue(batch, depth, x10.z, x10.w) : 0.0,
                    (hasNextRow && hasNextCol) ? getAValue(batch, depth, x11.z, x11.w) : 0.0);

                // calculate the interpolation fraction on u and v direction
                vec4 frac = vec4(sourceFrac) - floor(sourceFrac);
                vec4 clampFrac = clamp(frac, vec4(0.0), vec4(1.0));

                vec4 top = mix(topLeft, topRight, clampFrac.ywyw);
                vec4 bottom = mix(bottomLeft, bottomRight, clampFrac.ywyw);
                vec4 newValue = mix(top, bottom, clampFrac.xxzz);

                ${s2.output} = vec4(newValue);
            }
        `;
        return Object.assign(Object.assign({}, u), { output: { dims: p2, type: e2[0].type, textureType: i2.TextureType.packed }, hasMain: true, shaderSource: x });
      }, l = (t3, e2) => {
        const n2 = t3[0].dims;
        let r2, i3 = e2.scales;
        if (0 === i3.length) {
          const o3 = t3[e2.scalesInputIdx];
          if (o3 && 0 !== o3.size) {
            if (t3[e2.sizesInputIdx]) throw new Error("Only one of scales or sizes must be provided as input.");
            i3 = p(o3, e2.mode, e2.isResize);
          } else {
            const o4 = t3[e2.sizesInputIdx];
            if (!o4 || 0 === o4.size) throw new Error("Either scales or sizes MUST be provided as input.");
            r2 = Array.from(o4.integerData), i3 = f(r2, n2, e2.mode, e2.isResize);
          }
        } else if (t3[e2.sizesInputIdx]) throw new Error("Only one of scales or sizes must be provided as input.");
        const o2 = r2 || n2.map((t4, e3) => Math.floor(t4 * i3[e3]));
        return [i3, o2];
      }, p = (t3, e2, n2) => {
        const r2 = Array.from(t3.floatData);
        return (0, s.scalesValidation)(r2, e2, n2), r2;
      }, f = (t3, e2, n2, r2) => {
        const i3 = e2.length, o2 = new Array(i3);
        for (let n3 = 0, r3 = i3; n3 < r3; n3++) if (0 === e2[n3]) {
          if (0 !== t3[n3]) throw new Error("Input dim is zero but required output dim is non-zero.");
          o2[n3] = 1;
        } else o2[n3] = t3[n3] / e2[n3];
        return (0, s.scalesValidation)(o2, n2, r2), o2;
      };
    }, 8117: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.shape = void 0;
      const r = n(9162);
      e.shape = (t3, e2) => (i2(e2), [new r.Tensor([e2[0].dims.length], "int32", void 0, void 0, new Int32Array(e2[0].dims))]);
      const i2 = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Shape requires 1 input.");
      };
    }, 2278: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.sliceV10 = e.parseSliceAttributes = e.slice = void 0;
      const r = n(246), i2 = n(782), o = n(2517), a = n(2039), s = { name: "Slice", inputNames: ["A"], inputTypes: [a.TextureType.unpacked] };
      e.slice = (t3, e2, n2) => (c(e2), [t3.run(Object.assign(Object.assign({}, s), { cacheHint: n2.cacheKey, get: () => u(t3, e2[0], n2) }), e2)]), e.parseSliceAttributes = (t3) => {
        const e2 = t3.attributes.getInts("starts"), n2 = t3.attributes.getInts("ends"), i3 = t3.attributes.getInts("axes", []);
        return (0, r.createAttributeWithCacheKey)({ starts: e2, ends: n2, axes: i3 });
      };
      const u = (t3, e2, n2) => {
        const r2 = 0 === n2.axes.length ? e2.dims.slice(0).map((t4, e3) => e3) : n2.axes, i3 = o.ShapeUtil.normalizeAxes(r2, e2.dims.length), u2 = n2.starts.map((t4, n3) => t4 > e2.dims[i3[n3]] - 1 ? e2.dims[i3[n3]] : o.ShapeUtil.normalizeAxis(t4, e2.dims[i3[n3]])), c2 = n2.ends.map((t4, n3) => t4 > e2.dims[i3[n3]] - 1 ? e2.dims[i3[n3]] : o.ShapeUtil.normalizeAxis(t4, e2.dims[i3[n3]])), l2 = e2.dims.slice(), p2 = [];
        for (let t4 = 0; t4 < i3.length; t4++) l2[i3[t4]] = c2[t4] - u2[t4], u2[t4] > 0 && p2.push(`outputIdx[${i3[t4]}] += ${u2[t4]};`);
        const f = `
      float process(int outputIdx[${l2.length}]) {
        ${p2.join("\n      ")}
        return _A(outputIdx);
      }`;
        return Object.assign(Object.assign({}, s), { output: { dims: l2, type: e2.type, textureType: a.TextureType.unpacked }, shaderSource: f });
      }, c = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Slice requires 1 input.");
        if (-1 === i2.NUMBER_TYPES.indexOf(t3[0].type)) throw new Error("Invalid input type.");
      };
      e.sliceV10 = (t3, e2) => {
        p(e2);
        const n2 = l(t3, e2);
        return [t3.run(Object.assign(Object.assign({}, s), { cacheHint: n2.cacheKey, get: () => u(t3, e2[0], n2) }), [e2[0]])];
      };
      const l = (t3, e2) => {
        if (!t3.session.isInitializer(e2[1].dataId) || !t3.session.isInitializer(e2[2].dataId) || e2.length >= 4 && !t3.session.isInitializer(e2[3].dataId) || e2.length >= 5 && !t3.session.isInitializer(e2[4].dataId)) throw new Error("dynamic slice attributes are not allowed");
        if (e2.length >= 5 && e2[4].integerData.some((t4) => 1 !== t4)) throw new Error("currently non-1 steps is not supported for Slice");
        const n2 = Array.from(e2[1].integerData), r2 = Array.from(e2[2].integerData), i3 = e2.length >= 4 ? Array.from(e2[3].integerData) : [];
        return { starts: n2, ends: r2, axes: i3, cacheKey: `${i3};${n2};${r2}` };
      }, p = (t3) => {
        if (!t3 || t3.length < 3 || t3.length > 5) throw new Error("Invalid input number.");
        if ("int32" !== t3[1].type || 1 !== t3[1].dims.length) throw new Error("Invalid input type.");
        if ("int32" !== t3[2].type || 1 !== t3[2].dims.length) throw new Error("Invalid input type.");
        if (t3.length >= 4 && ("int32" !== t3[3].type || 1 !== t3[3].dims.length)) throw new Error("Invalid input type.");
        if (t3.length >= 5 && ("int32" !== t3[4].type || 1 !== t3[4].dims.length)) throw new Error("Invalid input type.");
      };
    }, 5524: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.softmaxV13 = e.parseSoftmaxAttributesV13 = e.parseSoftmaxAttributes = e.softmax = void 0;
      const r = n(246), i2 = n(2517), o = n(5060), a = n(2039), s = n(3738), u = { name: "SoftmaxComputeMax", inputNames: ["A"], inputTypes: [a.TextureType.unpacked] }, c = { name: "SoftmaxComputeScale", inputNames: ["A", "Max"], inputTypes: [a.TextureType.unpacked, a.TextureType.unpacked] }, l = { name: "SoftMax", inputNames: ["A", "Max", "Norm"], inputTypes: [a.TextureType.unpacked, a.TextureType.unpacked, a.TextureType.unpacked] };
      e.softmax = (t3, e2, n2) => {
        g(e2);
        const r2 = e2[0].dims.slice(), o2 = i2.ShapeUtil.normalizeAxis(n2.axis, r2.length), a2 = i2.ShapeUtil.sizeToDimension(r2, o2), s2 = i2.ShapeUtil.sizeFromDimension(r2, o2);
        return p(t3, e2, n2, a2, s2);
      }, e.parseSoftmaxAttributes = (t3) => (0, r.createAttributeWithCacheKey)({ axis: t3.attributes.getInt("axis", 1) }), e.parseSoftmaxAttributesV13 = (t3) => (0, r.createAttributeWithCacheKey)({ axis: t3.attributes.getInt("axis", -1) }), e.softmaxV13 = (t3, e2, n2) => {
        g(e2);
        const o2 = e2[0].dims.slice(), a2 = i2.ShapeUtil.normalizeAxis(n2.axis, o2.length), u2 = o2.length, c2 = a2 !== u2 - 1, l2 = [];
        let f2, d2 = [], h2 = [];
        c2 && (d2 = Array.from({ length: u2 }).map((t4, e3) => e3), d2[a2] = u2 - 1, d2[u2 - 1] = a2, d2.map((t4) => l2.push(o2[t4])), f2 = (0, r.createAttributeWithCacheKey)({ perm: d2 }), h2 = (0, s.transpose)(t3, e2, f2));
        const b = c2 ? i2.ShapeUtil.sizeToDimension(l2, u2 - 1) : i2.ShapeUtil.sizeToDimension(o2, u2 - 1), m = c2 ? i2.ShapeUtil.sizeFromDimension(l2, u2 - 1) : i2.ShapeUtil.sizeFromDimension(o2, u2 - 1), y = p(t3, c2 ? h2 : e2, n2, b, m);
        return c2 ? (0, s.transpose)(t3, y, f2) : y;
      };
      const p = (t3, e2, n2, r2, i3) => {
        const o2 = f(t3, e2[0], r2, i3, [r2]), a2 = t3.run(Object.assign(Object.assign({}, u), { cacheHint: n2.cacheKey, get: () => o2 }), e2), s2 = d(t3, e2[0], r2, i3, o2.output.dims, [r2]), p2 = t3.run(Object.assign(Object.assign({}, c), { cacheHint: n2.cacheKey, get: () => s2 }), [e2[0], a2]), g2 = h(t3, e2[0], r2, i3, o2.output.dims, s2.output.dims);
        return [t3.run(Object.assign(Object.assign({}, l), { cacheHint: n2.cacheKey, get: () => g2 }), [e2[0], a2, p2])];
      }, f = (t3, e2, n2, r2, i3) => {
        const [s2, c2] = t3.calculateTextureWidthAndHeight(e2.dims, a.TextureType.unpacked), l2 = i3.length;
        if (n2 < 1 || r2 < 1) throw new Error("Logical row count N and feature count D must be greater than or equal to 1");
        if (1 !== i3.length) throw new Error("Dimensionality of the output should be 1");
        if (i3[0] !== n2) throw new Error("Shape of the output should be equal to logical row count");
        const p2 = (0, o.getGlsl)(t3.session.backend.glContext.version), f2 = `
      float process(int[${l2}] indices) {
        int logical_row_start_offset = indices[0] * ${r2};

        float max = getColorAsFloat(${p2.texture2D}(A, offsetToCoords(logical_row_start_offset, ${s2},
        ${c2} )));
        for(int i=1; i<${r2}; ++i)
        {
          float current = getColorAsFloat(${p2.texture2D}(A, offsetToCoords(logical_row_start_offset + i,
            ${s2}, ${c2})));
          if(current > max)
          max = current;
        }

        return max;
      }`;
        return Object.assign(Object.assign({}, u), { output: { dims: i3, type: e2.type, textureType: a.TextureType.unpacked }, shaderSource: f2 });
      }, d = (t3, e2, n2, r2, i3, s2) => {
        const [u2, l2] = t3.calculateTextureWidthAndHeight(e2.dims, a.TextureType.unpacked), p2 = s2.length;
        if (n2 < 1 || r2 < 1) throw new Error("Logical row count N and feature count D must be greater than or equal to 1");
        if (1 !== s2.length) throw new Error("Dimensionality of the output should be 1");
        if (s2[0] !== n2) throw new Error("Shape of the output should be equal to logical row count");
        if (1 !== i3.length) throw new Error("Dimensionality of the intermediate results should be 1");
        if (i3[0] !== n2) throw new Error("Shape of the intermediate results should be equal to logical row count");
        const f2 = `
      float process(int[${p2}] indices) {
        int logical_row_start_offset = indices[0] * ${r2};

        float norm_factor = 0.0;
        float max = _Max(indices);
        for(int i=0; i<${r2}; ++i)
        {
          norm_factor += exp(getColorAsFloat(${(0, o.getGlsl)(t3.session.backend.glContext.version).texture2D}(A, offsetToCoords(logical_row_start_offset + i,
            ${u2}, ${l2}))) - max);
        }

        return norm_factor;
      }`;
        return Object.assign(Object.assign({}, c), { output: { dims: s2, type: e2.type, textureType: a.TextureType.unpacked }, shaderSource: f2 });
      }, h = (t3, e2, n2, r2, i3, o2) => {
        const [s2, u2] = t3.calculateTextureWidthAndHeight(e2.dims, a.TextureType.unpacked), c2 = e2.dims.length;
        if (n2 < 1 || r2 < 1) throw new Error("Logical row count N and feature count D must be greater than or equal to 1");
        if (1 !== i3.length || 1 !== o2.length) throw new Error("Dimensionality of the intermediate results should be 1");
        if (i3[0] !== n2 || o2[0] !== n2) throw new Error("Shape of the intermediate results should be equal to logical row count");
        const p2 = `
      float process(int[${c2}] indices) {

      // get offset of current logical tensor index from the 2-D texture coordinates (TexCoords)
      int offset = coordsToOffset(TexCoords, ${s2}, ${u2});

      //determine the logical row for this index
      int logical_row_index[1];
      logical_row_index[0] = offset / ${r2};

      float norm_factor = _Norm(logical_row_index);

      // avoid possible division by 0
      // if norm_facor is 0, all elements are zero
      // if so, return 0
      if(norm_factor == 0.0)
        return 0.0;

      return exp(_A(indices) - _Max(logical_row_index)) / norm_factor;
    }`;
        return Object.assign(Object.assign({}, l), { output: { dims: e2.dims, type: e2.type, textureType: a.TextureType.unpacked }, shaderSource: p2 });
      }, g = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Softmax requires 1 input.");
        if ("float32" !== t3[0].type && "float64" !== t3[0].type) throw new Error("Invalid input type");
      };
    }, 5975: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseSplitAttributes = e.split = void 0;
      const r = n(246), i2 = n(2517), o = n(2039), a = { name: "Split", inputNames: ["A"], inputTypes: [o.TextureType.unpacked] };
      e.split = (t3, e2, n2) => {
        c(e2);
        const r2 = i2.ShapeUtil.normalizeAxis(n2.axis, e2[0].dims.length), o2 = s(t3, e2, r2, n2), l = [];
        for (let i3 = 0; i3 < o2; ++i3) l.push(t3.run(Object.assign(Object.assign({}, a), { cacheHint: `${n2.cacheKey};${i3}`, get: () => u(t3, e2[0], n2, r2, i3) }), e2));
        return l;
      }, e.parseSplitAttributes = (t3) => {
        const e2 = t3.attributes.getInt("axis", 0), n2 = t3.attributes.getInts("split", []), i3 = t3.outputs.length;
        return (0, r.createAttributeWithCacheKey)({ axis: e2, split: n2, numOutputs: i3 });
      };
      const s = (t3, e2, n2, r2) => {
        const [, o2] = i2.SplitUtil.splitShape(e2[0].dims, n2, r2.split, r2.numOutputs);
        return o2.length;
      }, u = (t3, e2, n2, r2, s2) => {
        const [u2, c2] = i2.SplitUtil.splitShape(e2.dims, r2, n2.split, n2.numOutputs), l = c2[s2], p = u2[s2], f = `
      float process(int indices[${p.length}]) {
        indices[${r2}] += ${l};
        return _A(indices);
      }
    `;
        return Object.assign(Object.assign({}, a), { cacheHint: `${n2.cacheKey}:${s2}`, output: { dims: p, type: e2.type, textureType: o.TextureType.unpacked }, shaderSource: f });
      }, c = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Split requires one input.");
        if ("int8" !== t3[0].type && "uint8" !== t3[0].type && "int16" !== t3[0].type && "uint16" !== t3[0].type && "int32" !== t3[0].type && "uint32" !== t3[0].type && "float32" !== t3[0].type && "float64" !== t3[0].type && "bool" !== t3[0].type) throw new Error("Invalid input type.");
      };
    }, 3933: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseSqueezeAttributes = e.squeezeV13 = e.squeeze = void 0;
      const r = n(2517);
      e.squeeze = (t3, e2, n2) => {
        i2(e2);
        const o2 = r.ShapeUtil.squeezeShape(e2[0].dims, n2);
        return [t3.reshapeUnpacked(e2[0], o2)];
      }, e.squeezeV13 = (t3, n2) => (o(n2), (0, e.squeeze)(t3, [n2[0]], Array.from(n2[1].integerData))), e.parseSqueezeAttributes = (t3) => t3.attributes.getInts("axes");
      const i2 = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Squeeze requires 1 input.");
        if ("string" === t3[0].type) throw new Error("invalid input tensor types.");
      }, o = (t3) => {
        if (!t3 || 2 !== t3.length) throw new Error("Squeeze requires 2 inputs.");
        if ("int32" !== t3[1].type) throw new Error("Invalid input type.");
      };
    }, 6558: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.sum = void 0;
      const r = n(5060), i2 = n(2039);
      e.sum = (t3, e2) => {
        a(e2);
        const n2 = { name: "Sum", inputNames: e2.map((t4, e3) => `X${e3}`), inputTypes: new Array(e2.length).fill(i2.TextureType.unpacked) };
        return [t3.run(Object.assign(Object.assign({}, n2), { get: () => o(t3, e2, n2) }), e2)];
      };
      const o = (t3, e2, n2) => {
        const o2 = (0, r.getGlsl)(t3.session.backend.glContext.version), a2 = e2[0].dims.slice(), s = e2.map((t4, e3) => `${o2.texture2D}(X${e3},TexCoords)`).join(" + "), u = `
      void main() {
        vec4 result = ${s};
        ${o2.output} = result;
      }
    `;
        return Object.assign(Object.assign({}, n2), { output: { dims: a2, type: e2[0].type, textureType: i2.TextureType.unpacked }, hasMain: true, shaderSource: u });
      }, a = (t3) => {
        if (!t3 || 0 === t3.length) throw new Error("Sum requires inputs.");
        const e2 = t3[0].dims.length;
        for (let n2 = 1; n2 < t3.length; n2++) {
          if (e2 !== t3[n2].dims.length) throw new Error("Input shapes are mismatched.");
          for (let r2 = 0; r2 < e2; r2++) if (t3[0].dims[r2] !== t3[n2].dims[r2]) throw new Error("Input shapes are not matched.");
        }
        if ("float32" !== t3[0].type && "float64" !== t3[0].type) throw new Error("Invalid input type.");
        for (let e3 = 1; e3 < t3.length; e3++) if (t3[0].type !== t3[e3].type) throw new Error("Input types are not matched.");
      };
    }, 5723: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.tile = void 0;
      const r = n(782), i2 = n(2039);
      e.tile = (t3, e2) => {
        a(e2);
        const n2 = { name: "Tile", inputNames: ["A"], inputTypes: [i2.TextureType.unpacked] };
        return [t3.run(Object.assign(Object.assign({}, n2), { get: () => o(t3, e2, n2) }), e2)];
      };
      const o = (t3, e2, n2) => {
        const r2 = e2[0].dims.slice(), o2 = new Array(r2.length), a2 = [];
        for (let t4 = 0; t4 < r2.length; t4++) o2[t4] = r2[t4] * e2[1].numberData[t4], a2.push(`inputIdx[${t4}] = int(mod(float(outputIdx[${t4}]), ${r2[t4]}.));`);
        const s = o2.length, u = `
      float process(int outputIdx[${s}]) {
        int inputIdx[${s}];
        ${a2.join("\n")}
        return _A(inputIdx);
      }
    `;
        return Object.assign(Object.assign({}, n2), { output: { dims: o2, type: e2[0].type, textureType: i2.TextureType.unpacked }, shaderSource: u });
      }, a = (t3) => {
        if (!t3 || 2 !== t3.length) throw new Error("Tile requires 2 input.");
        if (1 !== t3[1].dims.length) throw new Error("The second input shape must 1 dimension.");
        if (t3[1].dims[0] !== t3[0].dims.length) throw new Error("Invalid input shape.");
        if (-1 === r.NUMBER_TYPES.indexOf(t3[0].type)) throw new Error("Invalid input type.");
        if ("int32" !== t3[1].type && "int16" !== t3[1].type) throw new Error("Invalid repeat type.");
      };
    }, 3738: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseTransposeAttributes = e.transpose = void 0;
      const r = n(246), i2 = n(2517), o = n(2039), a = { name: "Transpose", inputNames: ["A"], inputTypes: [o.TextureType.unpacked] };
      e.transpose = (t3, e2, n2) => (p(e2), [t3.run(Object.assign(Object.assign({}, a), { cacheHint: n2.cacheKey, get: () => s(t3, e2[0], n2.perm) }), e2)]), e.parseTransposeAttributes = (t3) => (0, r.createAttributeWithCacheKey)({ perm: t3.attributes.getInts("perm", []) });
      const s = (t3, e2, n2) => {
        const r2 = e2.dims;
        n2 = u(r2, n2);
        const i3 = c(r2, n2), s2 = r2.length, p2 = `
      ${l("perm", n2, s2)}
      float process(int indices[${s2}]) {
        int a[${s2}];
        perm(a, indices);
        return _A(a);
      }`;
        return Object.assign(Object.assign({}, a), { output: { dims: i3, type: e2.type, textureType: o.TextureType.unpacked }, shaderSource: p2 });
      }, u = (t3, e2) => (e2 && e2.length !== t3.length && (e2 = [...t3.keys()].reverse()), e2), c = (t3, e2) => (e2 = u(t3, e2), i2.ShapeUtil.sortBasedOnPerm(t3, e2)), l = (t3, e2, n2) => {
        const r2 = [];
        r2.push(`void ${t3}(out int a[${n2}], int src[${n2}]) {`);
        for (let t4 = 0; t4 < n2; ++t4) r2.push(`	a[${e2[t4]}]=src[${t4}];`);
        return r2.push("	}"), r2.join("\n");
      }, p = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Transpose requires 1 input.");
        if ("float32" !== t3[0].type && "float64" !== t3[0].type) throw new Error("input should be float tensor");
      };
    }, 8710: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.encodeAsUint8 = void 0;
      const r = n(5060), i2 = n(2039);
      e.encodeAsUint8 = (t3, e2) => {
        const n2 = e2.shape, o = (0, r.getGlsl)(t3.session.backend.glContext.version), a = `
    const float FLOAT_MAX = 1.70141184e38;
    const float FLOAT_MIN = 1.17549435e-38;

    bool isNaN(float val) {
      return (val < 1.0 || 0.0 < val || val == 0.0) ? false : true;
    }

    highp vec4 encodeAsUint8(highp float v) {
      if (isNaN(v)) {
        return vec4(255, 255, 255, 255);
      }

      highp float av = abs(v);

      if(av < FLOAT_MIN) {
        return vec4(0.0, 0.0, 0.0, 0.0);
      } else if(v > FLOAT_MAX) {
        return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;
      } else if(v < -FLOAT_MAX) {
        return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;
      }

      highp vec4 c = vec4(0,0,0,0);

      highp float e = floor(log2(av));
      highp float m = exp2(fract(log2(av))) - 1.0;

      c[2] = floor(128.0 * m);
      m -= c[2] / 128.0;
      c[1] = floor(32768.0 * m);
      m -= c[1] / 32768.0;
      c[0] = floor(8388608.0 * m);

      highp float ebias = e + 127.0;
      c[3] = floor(ebias / 2.0);
      ebias -= c[3] * 2.0;
      c[2] += floor(ebias) * 128.0;

      c[3] += 128.0 * step(0.0, -v);

      return c / 255.0;
    }

    void main() {
      float value = ${o.texture2D}(X,TexCoords).r;
      ${o.output} = encodeAsUint8(value);
    }`, s = { name: "Uint8Encode", inputTypes: [i2.TextureType.unpacked], inputNames: ["X"], output: { dims: n2, type: e2.tensor.type, textureType: i2.TextureType.downloadUint8AsFloat }, shaderSource: a, hasMain: true };
        return t3.executeProgram(s, [e2.tensor]);
      };
    }, 4909: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.tanh = e.tan = e.sqrt = e.sin = e.sigmoid = e.relu = e.not = e.neg = e.log = e.parseLeakyReluAttributes = e.leakyRelu = e.identity = e.floor = e.exp = e.parseEluAttributes = e.elu = e.cos = e.ceil = e.clipV11 = e.parseClipAttributes = e.clip = e.atan = e.asin = e.acos = e.abs = e.glslTanh = e.glslTan = e.glslSqrt = e.glslSigmoid = e.glslRelu = e.glslSin = e.glslNot = e.glslNeg = e.glslLog = e.glslLeakyRelu = e.glslIdentity = e.glslClip = e.glslFloor = e.glslExp = e.glslElu = e.glslCos = e.glslCeil = e.glslAtan = e.glslAsin = e.glslAcos = e.glslAbs = void 0;
      const r = n(246), i2 = n(2517), o = n(8520), a = n(5060), s = n(2039);
      function u() {
        return P("abs");
      }
      function c() {
        return P("acos");
      }
      function l() {
        return P("asin");
      }
      function p() {
        return P("atan");
      }
      function f() {
        return P("ceil");
      }
      function d() {
        return P("cos");
      }
      function h(t3) {
        const e2 = "elu";
        return { body: `
  const float alpha = float(${t3});

  float ${e2}_(float a) {
    return a >= 0.0 ? a: (exp(a) - 1.0) * alpha;
  }
  vec4 ${e2}_(vec4 v) {
    return vec4(${e2}_(v.x), ${e2}_(v.y), ${e2}_(v.z), ${e2}_(v.w));
  }
  `, name: e2, type: o.FunctionType.ValueBased };
      }
      function g() {
        return P("exp");
      }
      function b() {
        return P("floor");
      }
      function m(t3, e2) {
        const n2 = "clip";
        return { body: `
  const float min = float(${t3});
  const float max = float(${e2});

  float ${n2}_(float a) {
    return clamp(a, min, max);
  }
  vec4 ${n2}_(vec4 v) {
    return clamp(v, min, max);
  }
  `, name: n2, type: o.FunctionType.ValueBased };
      }
      function y() {
        const t3 = "indentity";
        return { body: `
  float ${t3}_(float a) {
    return a;
  }
  vec4 ${t3}_(vec4 v) {
    return v;
  }
  `, name: t3, type: o.FunctionType.ValueBased };
      }
      function _(t3) {
        const e2 = "leakyRelu";
        return { body: `
  const float alpha = float(${t3});

  float ${e2}_(float a) {
    return a < 0.0 ? a * alpha : a;
  }
  vec4 ${e2}_(vec4 v) {
    return vec4(${e2}_(v.x), ${e2}_(v.y), ${e2}_(v.z), ${e2}_(v.w));
  }
  `, name: e2, type: o.FunctionType.ValueBased };
      }
      function v() {
        return P("log");
      }
      function w() {
        const t3 = "neg";
        return { body: `
  float ${t3}_(float a) {
    return -a;
  }
  vec4 ${t3}_(vec4 v) {
    return -v;
  }
  `, name: t3, type: o.FunctionType.ValueBased };
      }
      function x() {
        const t3 = "not";
        return { body: `
  float ${t3}_(float a) {
    return float( ! bool(a) );
  }
  bool ${t3}_(bool a) {
    return !a;
  }
  vec4 ${t3}_(vec4 v) {
    return vec4(!bool(v.x), !bool(v.y), !bool(v.z), !bool(v.w));
  }
  bvec4 ${t3}_(bvec4 v) {
    return bvec4(!v.x, !v.y, !v.z, !v.w);
  }
  `, name: t3, type: o.FunctionType.ValueBased };
      }
      function T() {
        return P("sin");
      }
      function S() {
        const t3 = "relu";
        return { body: `
  float ${t3}_(float a) {
    return max( a, 0.0 );
  }
  vec4 ${t3}_(vec4 v) {
    return max( v, 0.0 );
  }
  `, name: t3, type: o.FunctionType.ValueBased };
      }
      function O() {
        const t3 = "sigmoid";
        return { body: `
  float ${t3}_(float a) {
    return 1.0 / (1.0 + exp(-a));
  }
  vec4 ${t3}_(vec4 v) {
    return 1.0 / (1.0 + exp(-v));
  }
  `, name: t3, type: o.FunctionType.ValueBased };
      }
      function A() {
        return P("sqrt");
      }
      function E() {
        return P("tan");
      }
      function I() {
        const t3 = "tanh";
        return { body: `
  float ${t3}_(float a) {
    a = clamp(a, -10., 10.);
    a = exp(2.*a);
    return (a - 1.) / (a + 1.);
  }
  vec4 ${t3}_(vec4 v) {
    v = clamp(v, -10., 10.);
    v = exp(2.*v);
    return (v - 1.) / (v + 1.);
  }
  `, name: t3, type: o.FunctionType.ValueBased };
      }
      function P(t3) {
        return { body: `
  float ${t3}_(float a) {
    return ${t3}(a);
  }
  vec4 ${t3}_(vec4 v) {
    return ${t3}(v);
  }
  `, name: t3, type: o.FunctionType.ValueBased };
      }
      e.glslAbs = u, e.glslAcos = c, e.glslAsin = l, e.glslAtan = p, e.glslCeil = f, e.glslCos = d, e.glslElu = h, e.glslExp = g, e.glslFloor = b, e.glslClip = m, e.glslIdentity = y, e.glslLeakyRelu = _, e.glslLog = v, e.glslNeg = w, e.glslNot = x, e.glslSin = T, e.glslRelu = S, e.glslSigmoid = O, e.glslSqrt = A, e.glslTan = E, e.glslTanh = I;
      const D = (t3, e2, n2, r2) => {
        const i3 = t3.session.pack ? s.TextureType.packed : s.TextureType.unpacked, o2 = { name: n2.name, inputTypes: [i3], inputNames: ["A"], cacheHint: r2 };
        return Object.assign(Object.assign({}, o2), { get: () => ((t4, e3, n3, r3) => {
          const i4 = t4.session.pack ? s.TextureType.packed : s.TextureType.unpacked, o3 = (0, a.getGlsl)(t4.session.backend.glContext.version);
          return Object.assign(Object.assign({}, e3), { output: { dims: n3.dims, type: n3.type, textureType: i4 }, shaderSource: `
     ${r3.body}
     void main() {
       vec4 v = ${o3.texture2D}(A, TexCoords);
       v = ${r3.name}_(v);
       ${o3.output} = v;
     }
     `, hasMain: true });
        })(t3, o2, e2, n2) });
      };
      e.abs = (t3, e2) => [t3.run(D(t3, e2[0], u()), e2)], e.acos = (t3, e2) => [t3.run(D(t3, e2[0], c()), e2)], e.asin = (t3, e2) => [t3.run(D(t3, e2[0], l()), e2)], e.atan = (t3, e2) => [t3.run(D(t3, e2[0], p()), e2)], e.clip = (t3, e2, n2) => [t3.run(D(t3, e2[0], m(n2.min, n2.max), n2.cacheKey), e2)], e.parseClipAttributes = (t3) => (0, r.createAttributeWithCacheKey)({ min: t3.attributes.getFloat("min", i2.MIN_CLIP), max: t3.attributes.getFloat("max", i2.MAX_CLIP) }), e.clipV11 = (t3, n2) => {
        const r2 = $(t3, n2);
        return (0, e.clip)(t3, [n2[0]], r2);
      };
      const $ = (t3, e2) => {
        if (e2.length >= 3 && (!t3.session.isInitializer(e2[1].dataId) || !t3.session.isInitializer(e2[2].dataId))) throw new Error("dynamic clip attributes are not allowed");
        const n2 = e2.length >= 3 ? e2[1].numberData[0] : i2.MIN_CLIP, o2 = e2.length >= 3 ? e2[2].numberData[0] : i2.MAX_CLIP;
        return (0, r.createAttributeWithCacheKey)({ min: n2, max: o2 });
      };
      e.ceil = (t3, e2) => [t3.run(D(t3, e2[0], f()), e2)], e.cos = (t3, e2) => [t3.run(D(t3, e2[0], d()), e2)], e.elu = (t3, e2, n2) => [t3.run(D(t3, e2[0], h(n2.alpha), n2.cacheKey), e2)], e.parseEluAttributes = (t3) => (0, r.createAttributeWithCacheKey)({ alpha: t3.attributes.getFloat("alpha", 1) }), e.exp = (t3, e2) => [t3.run(D(t3, e2[0], g()), e2)], e.floor = (t3, e2) => [t3.run(D(t3, e2[0], b()), e2)], e.identity = (t3, e2) => [t3.run(D(t3, e2[0], y()), e2)], e.leakyRelu = (t3, e2, n2) => [t3.run(D(t3, e2[0], _(n2.alpha), n2.cacheKey), e2)], e.parseLeakyReluAttributes = (t3) => (0, r.createAttributeWithCacheKey)({ alpha: t3.attributes.getFloat("alpha", 0.01) }), e.log = (t3, e2) => [t3.run(D(t3, e2[0], v()), e2)], e.neg = (t3, e2) => [t3.run(D(t3, e2[0], w()), e2)], e.not = (t3, e2) => [t3.run(D(t3, e2[0], x()), e2)], e.relu = (t3, e2) => [t3.run(D(t3, e2[0], S()), e2)], e.sigmoid = (t3, e2) => [t3.run(D(t3, e2[0], O()), e2)], e.sin = (t3, e2) => [t3.run(D(t3, e2[0], T()), e2)], e.sqrt = (t3, e2) => [t3.run(D(t3, e2[0], A()), e2)], e.tan = (t3, e2) => [t3.run(D(t3, e2[0], E()), e2)], e.tanh = (t3, e2) => [t3.run(D(t3, e2[0], I()), e2)];
    }, 5611: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createUnpackProgramInfoLoader = e.createUnpackProgramInfo = void 0;
      const r = n(5060), i2 = n(2039), o = n(9390), a = n(2827), s = { name: "unpack", inputNames: ["A"], inputTypes: [i2.TextureType.packed] };
      e.createUnpackProgramInfo = (t3, e2) => {
        const n2 = e2.dims.length, u = (0, a.getChannels)("rc", n2), c = u.slice(-2), l = (0, o.getCoordsDataType)(n2), p = (0, a.unpackFromChannel)(), f = 0 === e2.dims.length ? "" : function(t4, e3) {
          if (1 === t4) return "rc";
          let n3 = "";
          for (let r2 = 0; r2 < t4; r2++) n3 += e3[r2], r2 < t4 - 1 && (n3 += ",");
          return n3;
        }(n2, u), d = n2 <= 1 ? "rc" : `vec2(${c.join(",")})`, h = `
    ${p}
    void main() {
      ${l} rc = getOutputCoords();

       // Sample the texture with the coords to get the rgba channel value.
       vec4 packedInput = getA(${f});

       ${(0, r.getGlsl)(t3.session.backend.glContext.version).output} = vec4(getChannel(packedInput, ${d}), 0, 0, 0);
     }
   `;
        return Object.assign(Object.assign({}, s), { hasMain: true, output: { dims: e2.dims, type: e2.type, textureType: i2.TextureType.unpacked }, shaderSource: h });
      }, e.createUnpackProgramInfoLoader = (t3, n2) => Object.assign(Object.assign({}, s), { get: () => (0, e.createUnpackProgramInfo)(t3, n2) });
    }, 8428: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.parseUnsqueezeAttributes = e.unsqueezeV13 = e.unsqueeze = void 0;
      const r = n(2517);
      e.unsqueeze = (t3, e2, n2) => {
        i2(e2);
        const o2 = r.ShapeUtil.unsqueezeShape(e2[0].dims, n2);
        return [t3.reshapeUnpacked(e2[0], o2)];
      }, e.unsqueezeV13 = (t3, n2) => (o(n2), (0, e.unsqueeze)(t3, [n2[0]], Array.from(n2[1].integerData))), e.parseUnsqueezeAttributes = (t3) => t3.attributes.getInts("axes");
      const i2 = (t3) => {
        if (!t3 || 1 !== t3.length) throw new Error("Unsqueeze requires 1 input.");
        if ("string" === t3[0].type) throw new Error("invalid input tensor types.");
      }, o = (t3) => {
        if (!t3 || 2 !== t3.length) throw new Error("Unsqueeze requires 2 inputs.");
        if ("int32" !== t3[1].type) throw new Error("Invalid input type.");
      };
    }, 9793: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.scalesValidation = e.validateInputs = e.parseUpsampleAttributes = e.parseUpsampleAttributesV9 = e.parseUpsampleAttributesV7 = e.upsample = void 0;
      const r = n(246), i2 = n(5060), o = n(2039), a = { name: "Upsample", inputNames: ["X"], inputTypes: [o.TextureType.unpacked] };
      e.upsample = (t3, n2, r2) => ((0, e.validateInputs)(n2, r2), [t3.run(Object.assign(Object.assign({}, a), { cacheHint: r2.cacheKey, get: () => s(t3, n2, r2) }), n2)]), e.parseUpsampleAttributesV7 = (t3) => (0, e.parseUpsampleAttributes)(t3, 7), e.parseUpsampleAttributesV9 = (t3) => (0, e.parseUpsampleAttributes)(t3, 9), e.parseUpsampleAttributes = (t3, n2) => {
        const i3 = n2 >= 10, o2 = t3.attributes.getString("mode", "nearest");
        if ("nearest" !== o2 && "linear" !== o2 && (n2 < 11 || "cubic" !== o2)) throw new Error(`unrecognized mode: ${o2}`);
        let a2 = [];
        n2 < 9 && (a2 = t3.attributes.getFloats("scales"), (0, e.scalesValidation)(a2, o2, i3));
        const s2 = t3.attributes.getFloat("extrapolation_value", 0), u = n2 > 10 ? t3.attributes.getString("coordinate_transformation_mode", "half_pixel") : "asymmetric";
        if (-1 === ["asymmetric", "pytorch_half_pixel", "tf_half_pixel_for_nn", "align_corners", "tf_crop_and_resize", "half_pixel"].indexOf(u)) throw new Error(`coordinate_transform_mode '${u}' is not supported`);
        const c = "tf_crop_and_resize" === u, l = c, p = "nearest" === o2 && n2 >= 11 ? t3.attributes.getString("nearest_mode", "round_prefer_floor") : "";
        if (-1 === ["round_prefer_floor", "round_prefer_ceil", "floor", "ceil", ""].indexOf(p)) throw new Error(`nearest_mode '${p}' is not supported`);
        const f = t3.attributes.getFloat("cubic_coeff_a", -0.75), d = 0 !== t3.attributes.getInt("exclude_outside", 0);
        if (d && "cubic" !== o2) throw new Error("exclude_outside can be set to 1 only when mode is CUBIC.");
        const h = n2 < 11 || "nearest" === o2 && "asymmetric" === u && "floor" === p;
        let g = 0, b = 0, m = 0;
        return n2 > 10 ? t3.inputs.length > 2 ? (g = 1, b = 2, m = 3) : (b = 1, m = 2) : 9 === n2 && (b = 1), (0, r.createAttributeWithCacheKey)({ opset: n2, isResize: i3, mode: o2, scales: a2, extrapolationValue: s2, coordinateTransformMode: u, useExtrapolation: l, needRoiInput: c, nearestMode: p, cubicCoefficientA: f, excludeOutside: d, useNearest2xOptimization: h, roiInputIdx: g, scalesInputIdx: b, sizesInputIdx: m });
      };
      const s = (t3, e2, n2) => {
        const r2 = (0, i2.getGlsl)(t3.session.backend.glContext.version), [s2, u] = t3.calculateTextureWidthAndHeight(e2[0].dims, o.TextureType.unpacked), c = e2[0].dims.map((t4, e3) => Math.floor(t4 * n2.scales[e3])), [l, p] = t3.calculateTextureWidthAndHeight(c, o.TextureType.unpacked), f = c.length, d = new Array(f), h = new Array(f);
        let g = `
      int output_pitches[${f}];
      int input_pitches[${f}];
      `;
        for (let t4 = f - 1; t4 >= 0; t4--) d[t4] = t4 === f - 1 ? 1 : d[t4 + 1] * c[t4 + 1], h[t4] = t4 === f - 1 ? 1 : h[t4 + 1] * e2[0].dims[t4 + 1], g += `
        output_pitches[${t4}] = ${d[t4]};
        input_pitches[${t4}] = ${h[t4]};
        `;
        const b = `
      float getInputFloat(int index) {
        vec2 coords = offsetToCoords(index, ${s2}, ${u});
        float value = getColorAsFloat(${r2.texture2D}(X, coords));
        return value;
      }
      `, m = "nearest" === n2.mode ? `
    ${b}
    float process(int indices[${f}]) {
      int input_index = 0;
      int output_index = coordsToOffset(TexCoords, ${l}, ${p});

      ${g}

      int d, m;
      for (int dim = 0; dim < ${f}; ++dim) {
        d = output_index / output_pitches[dim];
        m = output_index - d * output_pitches[dim];
        output_index = m;

        if (scales[dim] != 1 && d > 0) {
          int d2 = d / scales[dim];
          m = d - d2 * scales[dim];
          d = d2;
        }
        input_index += input_pitches[dim] * d;
      }

      return getInputFloat(input_index);
    }` : 4 === f ? `
    ${b}
    float process(int indices[4]) {
      int input_index = 0;
      int output_index = coordsToOffset(TexCoords, ${l}, ${p});

      ${g}

      int m;
      int index_of_dim0, index_of_dim1, index_of_dim2, index_of_dim3;
      index_of_dim0 = output_index / output_pitches[0];
      m = output_index - index_of_dim0 * output_pitches[0];
      index_of_dim1 = m / output_pitches[1];
      m = m - index_of_dim1 * output_pitches[1];
      index_of_dim2 = m / output_pitches[2];
      m = m - index_of_dim2 * output_pitches[2];
      index_of_dim3 = m;

      int index_of_input_dim2, index_of_input_dim3, x_offset, y_offset;
      index_of_input_dim2 = index_of_dim2 / scales[2];
      y_offset = index_of_dim2 - index_of_input_dim2 * scales[2];
      index_of_input_dim3 = index_of_dim3 / scales[3];
      x_offset = index_of_dim3 - index_of_input_dim3 * scales[3];

      input_index = index_of_dim0 * input_pitches[0] +
            index_of_dim1 * input_pitches[1] +
            index_of_input_dim2 * input_pitches[2] +
            index_of_input_dim3;

      float x00 = getInputFloat(input_index);
      float x10, x01, x11;

      bool end_of_dim2 = false;
      if (index_of_input_dim2 == (${e2[0].dims[2]} - 1)) {
        // It's the end in dimension 2
        x01 = x00;
        end_of_dim2 = true;
      } else {
        x01 = getInputFloat(input_index + input_pitches[2]);
      }

      if (index_of_input_dim3 == (input_pitches[2] - 1)) {
        // It's the end in dimension 3
        x10 = x00;
        x11 = x01;
      }
      else {
        x10 = getInputFloat(input_index + 1);
        x11 = end_of_dim2 ? x10 : getInputFloat(input_index + input_pitches[2] + 1);
      }

      float y0 = x00 + float(y_offset) * (x01 - x00) / float(scales[2]);
      float y1 = x10 + float(y_offset) * (x11 - x10) / float(scales[2]);
      return y0 + float(x_offset) * (y1 - y0) / float(scales[3]);
    }` : `
    ${b}
    float process(int indices[2]) {
      int input_index = 0;
      int output_index = coordsToOffset(TexCoords, ${l}, ${p});

      ${g}

      int m;
      int index_of_dim0, index_of_dim1;
      index_of_dim0 = output_index / output_pitches[0];
      m = output_index - index_of_dim0 * output_pitches[0];
      index_of_dim1 = m;

      int index_of_input_dim0, index_of_input_dim1, x_offset, y_offset;
      index_of_input_dim0 = index_of_dim0 / scales[0];
      y_offset = index_of_dim0 - index_of_input_dim0 * scales[0];
      index_of_input_dim1 = index_of_dim1 / scales[1];
      x_offset = index_of_dim1 - index_of_input_dim1 * scales[1];

      input_index = index_of_input_dim0 * input_pitches[0] + index_of_input_dim1;

      float x00 = getInputFloat(input_index);
      float x10, x01, x11;

      bool end_of_dim0 = false;
      if (index_of_input_dim0 == (${e2[0].dims[0]} - 1)) {
        // It's the end in dimension 0
        x01 = x00;
        end_of_dim0 = true;
      } else {
        x01 = getInputFloat(input_index + input_pitches[0]);
      }

      if (index_of_input_dim1 == (input_pitches[0] - 1)) {
        // It's the end in dimension 1
        x10 = x00;
        x11 = x01;
      }
      else {
        x10 = getInputFloat(input_index + 1);
        x11 = end_of_dim0 ? x10 : getInputFloat(input_index + input_pitches[0] + 1);
      }

      float y0 = x00 + float(y_offset) * (x01 - x00) / float(scales[0]);
      float y1 = x10 + float(y_offset) * (x11 - x10) / float(scales[0]);
      return y0 + float(x_offset) * (y1 - y0) / float(scales[1]);
    }`;
        return Object.assign(Object.assign({}, a), { output: { dims: c, type: e2[0].type, textureType: o.TextureType.unpacked }, shaderSource: m, variables: [{ name: "scales", type: "int", arrayLength: n2.scales.length, data: n2.scales.map((t4) => Math.ceil(t4)) }] });
      };
      e.validateInputs = (t3, e2) => {
        if (!t3 || e2.opset < 9 && 1 !== t3.length || e2.opset >= 9 && e2.opset < 11 && 2 !== t3.length || e2.opset >= 11 && t3.length < 2) throw new Error("invalid inputs.");
        if (e2.scales.length > 0 && t3[0].dims.length !== e2.scales.length) throw new Error("Invalid input shape.");
        if ("string" === t3[0].type) throw new Error("Invalid input tensor types.");
      }, e.scalesValidation = (t3, e2, n2) => {
        if (n2) {
          for (const e3 of t3) if (e3 <= 0) throw new Error("Scale value should be greater than 0.");
        } else for (const e3 of t3) if (e3 < 1) throw new Error("Scale value should be greater than or equal to 1.");
        if (!("linear" !== e2 && "cubic" !== e2 || 2 === t3.length || 4 === t3.length && 1 === t3[0] && 1 === t3[1])) throw new Error(`'Linear' mode and 'Cubic' mode only support 2-D inputs ('Bilinear', 'Bicubic')         or 4-D inputs with the corresponding outermost 2 scale values being 1         in the ${n2 ? "Resize" : "Upsample"} opeartor.`);
      };
    }, 1958: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.ProgramManager = void 0;
      const r = n(6207), i2 = n(3694), o = n(8879), a = n(5060);
      e.ProgramManager = class {
        constructor(t3, e2, n2) {
          this.profiler = t3, this.glContext = e2, this.textureLayoutStrategy = n2, this.repo = /* @__PURE__ */ new Map(), this.attributesBound = false;
        }
        getArtifact(t3) {
          return this.repo.get(t3);
        }
        setArtifact(t3, e2) {
          this.repo.set(t3, e2);
        }
        run(t3, e2, n2) {
          var r2;
          this.profiler.event("op", `ProgramManager.run ${null !== (r2 = t3.programInfo.name) && void 0 !== r2 ? r2 : "unknown kernel"}`, () => {
            var r3;
            const o2 = this.glContext.gl, a2 = t3.program;
            o2.useProgram(a2);
            try {
              this.bindOutput(n2), this.attributesBound || this.bindAttributes(t3.attribLocations), this.bindUniforms(t3.uniformLocations, null !== (r3 = t3.programInfo.variables) && void 0 !== r3 ? r3 : [], e2);
            } catch (e3) {
              throw i2.Logger.error("ProgramManager", t3.programInfo.shaderSource), e3;
            }
            this.profiler.event("backend", "GlContext.draw()", () => {
              this.glContext.draw();
            });
          }, this.glContext);
        }
        dispose() {
          this.vertexShader && this.glContext.deleteShader(this.vertexShader), this.repo.forEach((t3) => this.glContext.deleteProgram(t3.program));
        }
        build(t3, e2, n2) {
          return this.profiler.event("backend", "ProgramManager.build", () => {
            const r2 = new o.GlslPreprocessor(this.glContext, t3, e2, n2), i3 = r2.preprocess(), a2 = this.compile(i3);
            return { programInfo: t3, program: a2, uniformLocations: this.getUniformLocations(a2, r2.context.programInfo.inputNames, r2.context.programInfo.variables), attribLocations: this.getAttribLocations(a2) };
          });
        }
        compile(t3) {
          if (!this.vertexShader) {
            i2.Logger.verbose("ProrgramManager", "Compiling and caching Vertex shader for the first time");
            const t4 = (0, a.getVertexShaderSource)(this.glContext.version);
            this.vertexShader = this.glContext.compileShader(t4, this.glContext.gl.VERTEX_SHADER);
          }
          r.env.debug && i2.Logger.verbose("ProrgramManager", `FragShader:
${t3}
`);
          const e2 = this.glContext.compileShader(t3, this.glContext.gl.FRAGMENT_SHADER), n2 = this.glContext.createProgram(this.vertexShader, e2);
          return this.glContext.deleteShader(e2), n2;
        }
        bindOutput(t3) {
          const e2 = t3.width, n2 = t3.height;
          i2.Logger.verbose("ProrgramManager", `Binding output texture to Framebuffer: w/h=${e2}/${n2}, shape=${t3.shape}, type=${t3.tensor.type}`), this.glContext.attachFramebuffer(t3.texture, e2, n2);
        }
        bindAttributes(t3) {
          const e2 = t3.position, n2 = t3.textureCoord;
          this.glContext.setVertexAttributes(e2, n2), this.attributesBound = true;
        }
        bindUniforms(t3, e2, n2) {
          var r2;
          const i3 = this.glContext.gl;
          let o2 = 0;
          for (const { name: a2, type: s, location: u, arrayLength: c } of t3) {
            const t4 = null === (r2 = e2.find((t5) => t5.name === a2)) || void 0 === r2 ? void 0 : r2.data;
            if ("sampler2D" !== s && !t4) throw new Error(`variable '${a2}' does not have data defined in program info`);
            switch (s) {
              case "sampler2D":
                this.bindTexture(n2[o2], u, o2), o2++;
                break;
              case "float":
                c ? i3.uniform1fv(u, t4) : i3.uniform1f(u, t4);
                break;
              case "int":
                c ? i3.uniform1iv(u, t4) : i3.uniform1i(u, t4);
                break;
              default:
                throw new Error(`Uniform not implemented: ${s}`);
            }
          }
        }
        bindTexture(t3, e2, n2) {
          this.glContext.bindTextureToUniform(t3.texture, n2, e2);
        }
        getAttribLocations(t3) {
          return { position: this.getAttribLocation(t3, "position"), textureCoord: this.getAttribLocation(t3, "textureCoord") };
        }
        getUniformLocations(t3, e2, n2) {
          const r2 = [];
          if (e2) for (const n3 of e2) r2.push({ name: n3, type: "sampler2D", location: this.getUniformLocation(t3, n3) });
          if (n2) for (const e3 of n2) r2.push(Object.assign(Object.assign({}, e3), { location: this.getUniformLocation(t3, e3.name) }));
          return r2;
        }
        getUniformLocation(t3, e2) {
          const n2 = this.glContext.gl.getUniformLocation(t3, e2);
          if (null === n2) throw new Error(`Uniform ${e2} not found.`);
          return n2;
        }
        getAttribLocation(t3, e2) {
          return this.glContext.gl.getAttribLocation(t3, e2);
        }
      };
    }, 6416: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.WebGLSessionHandler = void 0;
      const r = n(3694), i2 = n(1047), o = n(8316), a = n(1640), s = n(1958), u = n(7859), c = n(5702);
      e.WebGLSessionHandler = class {
        constructor(t3, e2) {
          this.backend = t3, this.context = e2, this.layoutStrategy = new u.PreferLogicalStrategy(t3.glContext.maxTextureSize), this.programManager = new s.ProgramManager(this.context.profiler, t3.glContext, this.layoutStrategy), this.textureManager = new c.TextureManager(t3.glContext, this.layoutStrategy, this.context.profiler, { reuseTextures: "full" === t3.textureCacheMode }), this.packedTextureDataCache = /* @__PURE__ */ new Map(), this.unpackedTextureDataCache = /* @__PURE__ */ new Map(), this.pack = t3.pack, this.pack2unpackMap = /* @__PURE__ */ new Map(), this.unpack2packMap = /* @__PURE__ */ new Map();
        }
        createInferenceHandler() {
          return new o.WebGLInferenceHandler(this);
        }
        onGraphInitialized(t3) {
          const e2 = t3.getValues().filter((t4) => -1 === t4.from && t4.tensor).map((t4) => t4.tensor.dataId);
          this.initializers = new Set(e2);
        }
        isInitializer(t3) {
          return !!this.initializers && this.initializers.has(t3);
        }
        addInitializer(t3) {
          this.initializers.add(t3);
        }
        getTextureData(t3, e2) {
          return e2 ? this.packedTextureDataCache.get(t3) : this.unpackedTextureDataCache.get(t3);
        }
        setTextureData(t3, e2, n2 = false) {
          r.Logger.verbose("WebGLSessionHandler", "Storing Texture data in cache"), n2 ? this.packedTextureDataCache.set(t3, e2) : this.unpackedTextureDataCache.set(t3, e2);
        }
        dispose() {
          this.programManager.dispose(), this.textureManager.clearActiveTextures(), this.packedTextureDataCache.forEach((t3) => this.textureManager.releaseTexture(t3, true)), this.packedTextureDataCache = /* @__PURE__ */ new Map(), this.unpackedTextureDataCache.forEach((t3) => this.textureManager.releaseTexture(t3, true)), this.unpackedTextureDataCache = /* @__PURE__ */ new Map();
        }
        resolve(t3, e2, n2) {
          const r2 = (0, i2.resolveOperator)(t3, e2, a.WEBGL_OP_RESOLVE_RULES);
          return { impl: r2.opImpl, context: r2.opInit ? r2.opInit(t3, n2) : t3 };
        }
      };
    }, 7769: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.Uint8DataEncoder = e.RGBAFloatDataEncoder = e.RedFloat32DataEncoder = void 0;
      const r = n(3694);
      e.RedFloat32DataEncoder = class {
        constructor(t3, e2 = 1) {
          if (1 === e2) this.internalFormat = t3.R32F, this.format = t3.RED, this.textureType = t3.FLOAT, this.channelSize = e2;
          else {
            if (4 !== e2) throw new Error(`Invalid number of channels: ${e2}`);
            this.internalFormat = t3.RGBA32F, this.format = t3.RGBA, this.textureType = t3.FLOAT, this.channelSize = e2;
          }
        }
        encode(t3, e2) {
          let n2, i2;
          return t3.constructor !== Float32Array && (r.Logger.warning("Encoder", "data was not of type Float32; creating new Float32Array"), i2 = new Float32Array(t3)), e2 * this.channelSize > t3.length ? (r.Logger.warning("Encoder", "Source data too small. Allocating larger array"), i2 = t3, n2 = this.allocate(e2 * this.channelSize), i2.forEach((t4, e3) => n2[e3] = t4)) : (i2 = t3, n2 = i2), n2;
        }
        allocate(t3) {
          return new Float32Array(4 * t3);
        }
        decode(t3, e2) {
          return 1 === this.channelSize ? t3.filter((t4, e3) => e3 % 4 == 0).subarray(0, e2) : t3.subarray(0, e2);
        }
      }, e.RGBAFloatDataEncoder = class {
        constructor(t3, e2 = 1, n2) {
          if (1 !== e2 && 4 !== e2) throw new Error(`Invalid number of channels: ${e2}`);
          this.internalFormat = t3.RGBA, this.format = t3.RGBA, this.channelSize = e2, this.textureType = n2 || t3.FLOAT;
        }
        encode(t3, e2) {
          let n2 = t3;
          return 1 === this.channelSize && (r.Logger.verbose("Encoder", "Exploding into a larger array"), n2 = this.allocate(e2), t3.forEach((t4, e3) => n2[4 * e3] = t4)), n2;
        }
        allocate(t3) {
          return new Float32Array(4 * t3);
        }
        decode(t3, e2) {
          return 1 === this.channelSize ? t3.filter((t4, e3) => e3 % 4 == 0).subarray(0, e2) : t3.subarray(0, e2);
        }
      }, e.Uint8DataEncoder = class {
        constructor(t3, e2 = 1) {
          if (this.channelSize = 4, 1 === e2) this.internalFormat = t3.ALPHA, this.format = t3.ALPHA, this.textureType = t3.UNSIGNED_BYTE, this.channelSize = e2;
          else {
            if (4 !== e2) throw new Error(`Invalid number of channels: ${e2}`);
            this.internalFormat = t3.RGBA, this.format = t3.RGBA, this.textureType = t3.UNSIGNED_BYTE, this.channelSize = e2;
          }
        }
        encode(t3, e2) {
          return new Uint8Array(t3.buffer, t3.byteOffset, t3.byteLength);
        }
        allocate(t3) {
          return new Uint8Array(t3 * this.channelSize);
        }
        decode(t3, e2) {
          if (t3 instanceof Uint8Array) return t3.subarray(0, e2);
          throw new Error(`Invalid array type: ${t3.constructor}`);
        }
      };
    }, 7859: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.getBatchDim = e.sizeToSquarishShape = e.getRowsCols = e.sizeFromShape = e.isInt = e.parseAxisParam = e.squeezeShape = e.PreferLogicalStrategy = e.AlwaysKeepOriginalSizeStrategy = void 0;
      const r = n(3694), i2 = n(2517);
      function o(t3, e2) {
        const n2 = [], r2 = [], i3 = null != e2 && Array.isArray(e2) && 0 === e2.length, o2 = null == e2 || i3 ? null : a(e2, t3).sort();
        let s2 = 0;
        for (let e3 = 0; e3 < t3.length; ++e3) {
          if (null != o2) {
            if (o2[s2] === e3 && 1 !== t3[e3]) throw new Error(`Can't squeeze axis ${e3} since its dim '${t3[e3]}' is not 1`);
            (null == o2[s2] || o2[s2] > e3) && 1 === t3[e3] && (n2.push(t3[e3]), r2.push(e3)), o2[s2] <= e3 && s2++;
          }
          1 !== t3[e3] && (n2.push(t3[e3]), r2.push(e3));
        }
        return { newShape: n2, keptDims: r2 };
      }
      function a(t3, e2) {
        const n2 = e2.length;
        return t3 = null == t3 ? e2.map((t4, e3) => e3) : [].concat(t3), (0, i2.assert)(t3.every((t4) => t4 >= -n2 && t4 < n2), () => `All values in axis param must be in range [-${n2}, ${n2}) but got axis ${t3}`), (0, i2.assert)(t3.every(s), () => `All values in axis param must be integers but got axis ${t3}`), t3.map((t4) => t4 < 0 ? n2 + t4 : t4);
      }
      function s(t3) {
        return t3 % 1 == 0;
      }
      function u(t3) {
        if (0 === t3.length) return 1;
        let e2 = t3[0];
        for (let n2 = 1; n2 < t3.length; n2++) e2 *= t3[n2];
        return e2;
      }
      function c(t3) {
        const e2 = Math.ceil(Math.sqrt(t3));
        return [e2, Math.ceil(t3 / e2)];
      }
      e.AlwaysKeepOriginalSizeStrategy = class {
        constructor(t3) {
          this.maxTextureSize = t3;
        }
        computeTextureWH(t3, e2) {
          if (0 === t3.length) return [1, 1];
          const n2 = this.maxTextureSize;
          if (e2 && void 0 !== e2.breakAxis) {
            const i4 = e2.breakAxis >= t3.length ? 1 : t3.slice(e2.breakAxis).reduce((t4, e3) => t4 * e3), o3 = e2.breakAxis <= 0 ? 1 : t3.slice(0, e2.breakAxis).reduce((t4, e3) => t4 * e3);
            if (!(i4 > n2 || o3 > n2)) return [i4, o3];
            r.Logger.verbose("TextureLayout", `Given width/height preferences were unattainable: shape:${t3}, breakAxis:${e2.breakAxis}`);
          }
          const i3 = t3.reduce((t4, e3) => t4 * e3);
          let o2 = Math.floor(Math.sqrt(i3));
          for (; o2 < n2 && o2 < i3 && i3 % o2 != 0; o2++) ;
          if (o2 >= n2 || i3 % o2 != 0) throw new Error(`The given dimensions are outside this GPU's boundaries: ${t3}`);
          return [o2, i3 / o2];
        }
      }, e.PreferLogicalStrategy = class {
        constructor(t3) {
          this.maxTextureSize = t3;
        }
        computeTextureWH(t3, e2) {
          const n2 = this.computeTexture(t3, e2);
          return e2 && e2.isPacked && (n2[0] /= 2, n2[1] /= 2), e2 && e2.reverseWH ? [n2[1], n2[0]] : n2;
        }
        computeTexture(t3, e2) {
          const n2 = e2 && e2.isPacked;
          if (0 === t3.length) return n2 ? [2, 2] : [1, 1];
          let i3 = this.maxTextureSize;
          if (e2 && void 0 !== e2.breakAxis) {
            const n3 = e2.breakAxis >= t3.length ? 1 : t3.slice(e2.breakAxis).reduce((t4, e3) => t4 * e3), o2 = e2.breakAxis <= 0 ? 1 : t3.slice(0, e2.breakAxis).reduce((t4, e3) => t4 * e3);
            if (!(n3 > i3 || o2 > i3)) return [n3, o2];
            r.Logger.verbose("TextureLayout", `Given width/height preferences were unattainable: shape:${t3}, breakAxis:${e2.breakAxis}`);
          }
          let a2 = t3.slice(0);
          if (n2 && (i3 *= 2, a2 = a2.map((t4, e3) => e3 >= a2.length - 2 ? a2[e3] % 2 == 0 ? a2[e3] : a2[e3] + 1 : a2[e3]), 1 === a2.length && (a2 = [2, a2[0]])), 2 !== a2.length) {
            const t4 = o(a2);
            a2 = t4.newShape;
          }
          const s2 = u(a2);
          return a2.length <= 1 && s2 <= i3 ? [1, s2] : 2 === a2.length && a2[0] <= i3 && a2[1] <= i3 ? a2 : 3 === a2.length && a2[0] * a2[1] <= i3 && a2[2] <= i3 ? [a2[0] * a2[1], a2[2]] : 3 === a2.length && a2[0] <= i3 && a2[1] * a2[2] <= i3 ? [a2[0], a2[1] * a2[2]] : 4 === a2.length && a2[0] * a2[1] * a2[2] <= i3 && a2[3] <= i3 ? [a2[0] * a2[1] * a2[2], a2[3]] : 4 === a2.length && a2[0] <= i3 && a2[1] * a2[2] * a2[3] <= i3 ? [a2[0], a2[1] * a2[2] * a2[3]] : n2 ? c(s2 / 4).map((t4) => 2 * t4) : c(s2);
        }
      }, e.squeezeShape = o, e.parseAxisParam = a, e.isInt = s, e.sizeFromShape = u, e.getRowsCols = function(t3) {
        if (0 === t3.length) throw Error("Cannot get rows and columns of an empty shape array.");
        return [t3.length > 1 ? t3[t3.length - 2] : 1, t3[t3.length - 1]];
      }, e.sizeToSquarishShape = c, e.getBatchDim = function(t3, e2 = 2) {
        return u(t3.slice(0, t3.length - e2));
      };
    }, 4057: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createTextureLayoutFromShape = e.calculateTextureWidthAndHeight = e.createTextureLayoutFromTextureType = void 0;
      const r = n(2517), i2 = n(2039);
      e.createTextureLayoutFromTextureType = (t3, n2, r2) => {
        const o = r2 === i2.TextureType.unpacked || r2 === i2.TextureType.unpackedReversed ? 1 : 4, a = r2 === i2.TextureType.packed, s = r2 === i2.TextureType.unpackedReversed || r2 === i2.TextureType.packed, u = r2 === i2.TextureType.packedLastDimension ? n2.length - 1 : void 0, c = r2 === i2.TextureType.packedLastDimension ? n2.map((t4, e2) => e2 === n2.length - 1 ? 4 * t4 : t4) : void 0;
        return (0, e.createTextureLayoutFromShape)(t3, n2, o, c, { isPacked: a, reverseWH: s, breakAxis: u });
      }, e.calculateTextureWidthAndHeight = (t3, n2, r2) => {
        const i3 = (0, e.createTextureLayoutFromTextureType)(t3, n2, r2);
        return [i3.width, i3.height];
      }, e.createTextureLayoutFromShape = (t3, e2, n2 = 1, i3, o) => {
        const a = !(!o || !o.isPacked), [s, u] = t3.computeTextureWH(a && i3 || e2, o), c = e2.length;
        let l = e2.slice(0);
        if (0 === c && (l = [1]), 1 === n2) i3 = e2;
        else if (a) {
          if (4 !== n2) throw new Error("a packed texture must be 4-channel");
          i3 = e2, c > 0 && (l[c - 1] = Math.ceil(l[c - 1] / 2)), c > 1 && (l[c - 2] = Math.ceil(l[c - 2] / 2));
        } else if (!i3) throw new Error("Unpacked shape is needed when using channels > 1");
        return { width: s, height: u, channels: n2, isPacked: a, shape: l, strides: r.ShapeUtil.computeStrides(l), unpackedShape: i3, reversedWH: o && o.reverseWH };
      };
    }, 5702: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.TextureManager = void 0;
      const r = n(3694);
      e.TextureManager = class {
        constructor(t3, e2, n2, r2) {
          this.glContext = t3, this.layoutStrategy = e2, this.profiler = n2, this.config = r2, this.pendingRead = /* @__PURE__ */ new Map(), r2.reuseTextures && (this.inUseTextures = /* @__PURE__ */ new Map(), this.idleTextures = /* @__PURE__ */ new Map(), this.textureLookup = /* @__PURE__ */ new Map());
        }
        createTextureFromLayout(t3, e2, n2, i2) {
          const o = this.toEncoderType(t3), a = this.glContext.getEncoder(o, e2.channels || 1, i2);
          if (e2.isPacked && 1 === i2) throw new Error("not implemented");
          const s = e2.width, u = e2.height;
          let c, l;
          if (this.config.reuseTextures) {
            c = `${s}x${u}_${a.format}_${a.internalFormat}_${a.textureType}`, l = this.inUseTextures.get(c), l || (l = [], this.inUseTextures.set(c, l));
            const e3 = this.idleTextures.get(c);
            if (e3 && e3.length > 0) {
              const r2 = e3.pop();
              return l.push(r2), 1 === i2 && this.glContext.updateTexture(r2, s, u, a, this.toTextureData(t3, n2)), r2;
            }
          }
          r.Logger.verbose("TextureManager", `Creating new texture of size ${e2.width}x${e2.height}`);
          const p = this.glContext.allocateTexture(s, u, a, this.toTextureData(t3, n2));
          return this.config.reuseTextures && (l.push(p), this.textureLookup.set(p, c)), p;
        }
        readTexture(t3, e2, n2) {
          return n2 || (n2 = 1), this.profiler.event("backend", "TextureManager.readTexture", () => {
            const r2 = t3.shape.reduce((t4, e3) => t4 * e3) * n2, i2 = this.glContext.readTexture(t3.texture, t3.width, t3.height, r2, this.toEncoderType(e2), n2);
            return this.toTensorData(e2, i2);
          });
        }
        async readTextureAsync(t3, e2, n2) {
          const r2 = t3.tensor.dataId;
          if (n2 || (n2 = 1), this.pendingRead.has(r2)) {
            const t4 = this.pendingRead.get(r2);
            return new Promise((e3) => null == t4 ? void 0 : t4.push(e3));
          }
          return this.profiler.event("backend", "TextureManager.readTextureAsync", async () => {
            this.pendingRead.set(r2, []);
            const i2 = t3.shape.reduce((t4, e3) => t4 * e3) * n2;
            await this.glContext.createAndWaitForFence();
            const o = this.glContext.readTexture(t3.texture, t3.width, t3.height, i2, this.toEncoderType(e2), n2), a = this.toTensorData(e2, o), s = this.pendingRead.get(r2);
            return this.pendingRead.delete(r2), null == s || s.forEach((t4) => t4(a)), a;
          });
        }
        readUint8TextureAsFloat(t3) {
          return this.profiler.event("backend", "TextureManager.readUint8TextureAsFloat", () => {
            const e2 = t3.shape.reduce((t4, e3) => t4 * e3), n2 = this.glContext.readTexture(t3.texture, t3.width, t3.height, 4 * e2, "byte", 4);
            return new Float32Array(n2.buffer, n2.byteOffset, e2);
          });
        }
        releaseTexture(t3, e2) {
          let n2;
          if (this.config.reuseTextures && (n2 = this.textureLookup.get(t3.texture), n2)) {
            e2 && this.textureLookup.delete(n2);
            const r2 = this.inUseTextures.get(n2);
            if (r2) {
              const e3 = r2.indexOf(t3.texture);
              if (-1 !== e3) {
                r2.splice(e3, 1);
                let i2 = this.idleTextures.get(n2);
                i2 || (i2 = [], this.idleTextures.set(n2, i2)), i2.push(t3.texture);
              }
            }
          }
          n2 && !e2 || (r.Logger.verbose("TextureManager", `Deleting texture of size ${t3.width}x${t3.height}`), this.glContext.deleteTexture(t3.texture));
        }
        toTensorData(t3, e2) {
          switch (t3) {
            case "int16":
              return e2 instanceof Int16Array ? e2 : Int16Array.from(e2);
            case "int32":
              return e2 instanceof Int32Array ? e2 : Int32Array.from(e2);
            case "int8":
              return e2 instanceof Int8Array ? e2 : Int8Array.from(e2);
            case "uint16":
              return e2 instanceof Uint16Array ? e2 : Uint16Array.from(e2);
            case "uint32":
              return e2 instanceof Uint32Array ? e2 : Uint32Array.from(e2);
            case "uint8":
            case "bool":
              return e2 instanceof Uint8Array ? e2 : Uint8Array.from(e2);
            case "float32":
              return e2 instanceof Float32Array ? e2 : Float32Array.from(e2);
            case "float64":
              return e2 instanceof Float64Array ? e2 : Float64Array.from(e2);
            default:
              throw new Error(`TensorData type ${t3} is not supported`);
          }
        }
        toTextureData(t3, e2) {
          if (e2) return e2 instanceof Float32Array ? e2 : new Float32Array(e2);
        }
        toEncoderType(t3) {
          return "float";
        }
        clearActiveTextures() {
          this.glContext.clearActiveTextures();
        }
      };
    }, 2039: (t2, e) => {
      var n;
      Object.defineProperty(e, "__esModule", { value: true }), e.TextureType = void 0, (n = e.TextureType || (e.TextureType = {}))[n.unpacked = 0] = "unpacked", n[n.unpackedReversed = 1] = "unpackedReversed", n[n.packed = 2] = "packed", n[n.downloadUint8AsFloat = 3] = "downloadUint8AsFloat", n[n.packedLastDimension = 4] = "packedLastDimension";
    }, 9390: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.getGlChannels = e.getCoordsDataType = e.getSqueezedParams = e.squeezeInputShape = e.generateShaderFuncNameFromInputSamplerNameAtOutCoords = e.generateShaderFuncNameFromInputSamplerName = e.repeatedTry = e.getPackedShape = void 0;
      const r = n(2517);
      e.getPackedShape = function(t3) {
        const e2 = t3.length;
        return t3.slice(0, e2 - 1).concat(t3[e2 - 1] / 4);
      }, e.repeatedTry = async function(t3, e2 = (t4) => 0, n2) {
        return new Promise((r2, i2) => {
          let o = 0;
          const a = () => {
            if (t3()) return void r2();
            o++;
            const s = e2(o);
            null != n2 && o >= n2 ? i2() : setTimeout(a, s);
          };
          a();
        });
      }, e.generateShaderFuncNameFromInputSamplerName = function(t3) {
        return (0, r.assert)(void 0 !== t3 && 0 !== t3.length, () => "empty string found for sampler name"), "get" + t3.charAt(0).toUpperCase() + t3.slice(1);
      }, e.generateShaderFuncNameFromInputSamplerNameAtOutCoords = function(t3) {
        return (0, r.assert)(void 0 !== t3 && 0 !== t3.length, () => "empty string found for sampler name"), "get" + t3.charAt(0).toUpperCase() + t3.slice(1) + "AtOutCoords";
      }, e.squeezeInputShape = function(t3, e2) {
        let n2 = JSON.parse(JSON.stringify(t3));
        return n2 = e2, n2;
      }, e.getSqueezedParams = function(t3, e2) {
        return e2.map((e3) => t3[e3]).join(", ");
      }, e.getCoordsDataType = function(t3) {
        if (t3 <= 1) return "int";
        if (2 === t3) return "ivec2";
        if (3 === t3) return "ivec3";
        if (4 === t3) return "ivec4";
        if (5 === t3) return "ivec5";
        if (6 === t3) return "ivec6";
        throw Error(`GPU for rank ${t3} is not yet supported`);
      }, e.getGlChannels = function(t3 = 6) {
        return ["x", "y", "z", "w", "u", "v"].slice(0, t3);
      };
    }, 7305: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.createNewWebGLContext = e.createWebGLContext = void 0;
      const r = n(3694), i2 = n(1713), o = {};
      function a(t3) {
        const e2 = function() {
          if ("undefined" == typeof document) {
            if ("undefined" == typeof OffscreenCanvas) throw new TypeError("failed to create canvas: OffscreenCanvas is not supported");
            return new OffscreenCanvas(1, 1);
          }
          const t4 = document.createElement("canvas");
          return t4.width = 1, t4.height = 1, t4;
        }();
        let n2;
        const o2 = { alpha: false, depth: false, antialias: false, stencil: false, preserveDrawingBuffer: false, premultipliedAlpha: false, failIfMajorPerformanceCaveat: false };
        if ((!t3 || "webgl2" === t3) && (n2 = e2.getContext("webgl2", o2), n2)) try {
          return new i2.WebGLContext(n2, 2);
        } catch (t4) {
          r.Logger.warning("GlContextFactory", `failed to create WebGLContext using contextId 'webgl2'. Error: ${t4}`);
        }
        if ((!t3 || "webgl" === t3) && (n2 = e2.getContext("webgl", o2) || e2.getContext("experimental-webgl", o2), n2)) try {
          return new i2.WebGLContext(n2, 1);
        } catch (t4) {
          r.Logger.warning("GlContextFactory", `failed to create WebGLContext using contextId 'webgl' or 'experimental-webgl'. Error: ${t4}`);
        }
        throw new Error("WebGL is not supported");
      }
      e.createWebGLContext = function t3(e2) {
        let n2;
        e2 && "webgl2" !== e2 || !("webgl2" in o) ? e2 && "webgl" !== e2 || !("webgl" in o) || (n2 = o.webgl) : n2 = o.webgl2, n2 = n2 || a(e2), e2 = e2 || 1 === n2.version ? "webgl" : "webgl2";
        const r2 = n2.gl;
        return o[e2] = n2, r2.isContextLost() ? (delete o[e2], t3(e2)) : (r2.disable(r2.DEPTH_TEST), r2.disable(r2.STENCIL_TEST), r2.disable(r2.BLEND), r2.disable(r2.DITHER), r2.disable(r2.POLYGON_OFFSET_FILL), r2.disable(r2.SAMPLE_COVERAGE), r2.enable(r2.SCISSOR_TEST), r2.enable(r2.CULL_FACE), r2.cullFace(r2.BACK), n2);
      }, e.createNewWebGLContext = a;
    }, 1713: function(t2, e, n) {
      var r = this && this.__createBinding || (Object.create ? function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2);
        var i3 = Object.getOwnPropertyDescriptor(e2, n2);
        i3 && !("get" in i3 ? !e2.__esModule : i3.writable || i3.configurable) || (i3 = { enumerable: true, get: function() {
          return e2[n2];
        } }), Object.defineProperty(t3, r2, i3);
      } : function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2), t3[r2] = e2[n2];
      }), i2 = this && this.__setModuleDefault || (Object.create ? function(t3, e2) {
        Object.defineProperty(t3, "default", { enumerable: true, value: e2 });
      } : function(t3, e2) {
        t3.default = e2;
      }), o = this && this.__importStar || function(t3) {
        if (t3 && t3.__esModule) return t3;
        var e2 = {};
        if (null != t3) for (var n2 in t3) "default" !== n2 && Object.prototype.hasOwnProperty.call(t3, n2) && r(e2, t3, n2);
        return i2(e2, t3), e2;
      };
      Object.defineProperty(e, "__esModule", { value: true }), e.WebGLContext = e.linearSearchLastTrue = void 0;
      const a = n(6207), s = o(n(7769)), u = n(9390);
      function c(t3) {
        let e2 = 0;
        for (; e2 < t3.length && t3[e2](); ++e2) ;
        return e2 - 1;
      }
      e.linearSearchLastTrue = c, e.WebGLContext = class {
        constructor(t3, e2) {
          this.frameBufferBound = false, this.itemsToPoll = [], this.gl = t3, this.version = e2, this.getExtensions(), this.vertexbuffer = this.createVertexbuffer(), this.framebuffer = this.createFramebuffer(), this.queryVitalParameters();
        }
        allocateTexture(t3, e2, n2, r2) {
          const i3 = this.gl, o2 = i3.createTexture();
          i3.bindTexture(i3.TEXTURE_2D, o2), i3.texParameteri(i3.TEXTURE_2D, i3.TEXTURE_MIN_FILTER, i3.NEAREST), i3.texParameteri(i3.TEXTURE_2D, i3.TEXTURE_MAG_FILTER, i3.NEAREST), i3.texParameteri(i3.TEXTURE_2D, i3.TEXTURE_WRAP_S, i3.CLAMP_TO_EDGE), i3.texParameteri(i3.TEXTURE_2D, i3.TEXTURE_WRAP_T, i3.CLAMP_TO_EDGE);
          const a2 = r2 ? n2.encode(r2, t3 * e2) : null;
          return i3.texImage2D(i3.TEXTURE_2D, 0, n2.internalFormat, t3, e2, 0, n2.format, n2.textureType, a2), this.checkError(), o2;
        }
        updateTexture(t3, e2, n2, r2, i3) {
          const o2 = this.gl;
          o2.bindTexture(o2.TEXTURE_2D, t3);
          const a2 = r2.encode(i3, e2 * n2);
          o2.texSubImage2D(o2.TEXTURE_2D, 0, 0, 0, e2, n2, r2.format, r2.textureType, a2), this.checkError();
        }
        attachFramebuffer(t3, e2, n2) {
          const r2 = this.gl;
          r2.bindTexture(r2.TEXTURE_2D, t3), r2.bindFramebuffer(r2.FRAMEBUFFER, this.framebuffer), r2.framebufferTexture2D(r2.FRAMEBUFFER, r2.COLOR_ATTACHMENT0, r2.TEXTURE_2D, t3, 0), this.checkError(), r2.viewport(0, 0, e2, n2), r2.scissor(0, 0, e2, n2);
        }
        readTexture(t3, e2, n2, r2, i3, o2) {
          const a2 = this.gl;
          o2 || (o2 = 1), this.frameBufferBound || this.attachFramebuffer(t3, e2, n2);
          const s2 = this.getEncoder(i3, o2), u2 = s2.allocate(e2 * n2);
          return a2.bindTexture(a2.TEXTURE_2D, t3), a2.framebufferTexture2D(a2.FRAMEBUFFER, a2.COLOR_ATTACHMENT0, a2.TEXTURE_2D, t3, 0), a2.readPixels(0, 0, e2, n2, a2.RGBA, s2.textureType, u2), this.checkError(), s2.decode(u2, r2);
        }
        isFramebufferReady() {
          return true;
        }
        getActiveTexture() {
          const t3 = this.gl;
          return "TEXTURE" + (t3.getParameter(this.gl.ACTIVE_TEXTURE) - t3.TEXTURE0);
        }
        getTextureBinding() {
          return this.gl.getParameter(this.gl.TEXTURE_BINDING_2D);
        }
        getFramebufferBinding() {
          return this.gl.getParameter(this.gl.FRAMEBUFFER_BINDING);
        }
        setVertexAttributes(t3, e2) {
          const n2 = this.gl;
          n2.vertexAttribPointer(t3, 3, n2.FLOAT, false, 20, 0), n2.enableVertexAttribArray(t3), -1 !== e2 && (n2.vertexAttribPointer(e2, 2, n2.FLOAT, false, 20, 12), n2.enableVertexAttribArray(e2)), this.checkError();
        }
        createProgram(t3, e2) {
          const n2 = this.gl, r2 = n2.createProgram();
          return n2.attachShader(r2, t3), n2.attachShader(r2, e2), n2.linkProgram(r2), r2;
        }
        compileShader(t3, e2) {
          const n2 = this.gl, r2 = n2.createShader(e2);
          if (!r2) throw new Error(`createShader() returned null with type ${e2}`);
          if (n2.shaderSource(r2, t3), n2.compileShader(r2), false === n2.getShaderParameter(r2, n2.COMPILE_STATUS)) throw new Error(`Failed to compile shader: ${n2.getShaderInfoLog(r2)}
Shader source:
${t3}`);
          return r2;
        }
        deleteShader(t3) {
          this.gl.deleteShader(t3);
        }
        bindTextureToUniform(t3, e2, n2) {
          const r2 = this.gl;
          r2.activeTexture(r2.TEXTURE0 + e2), this.checkError(), r2.bindTexture(r2.TEXTURE_2D, t3), this.checkError(), r2.uniform1i(n2, e2), this.checkError();
        }
        draw() {
          this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4), this.checkError();
        }
        checkError() {
          if (a.env.debug) {
            const t3 = this.gl, e2 = t3.getError();
            let n2 = "";
            switch (e2) {
              case t3.NO_ERROR:
                return;
              case t3.INVALID_ENUM:
                n2 = "INVALID_ENUM";
                break;
              case t3.INVALID_VALUE:
                n2 = "INVALID_VALUE";
                break;
              case t3.INVALID_OPERATION:
                n2 = "INVALID_OPERATION";
                break;
              case t3.INVALID_FRAMEBUFFER_OPERATION:
                n2 = "INVALID_FRAMEBUFFER_OPERATION";
                break;
              case t3.OUT_OF_MEMORY:
                n2 = "OUT_OF_MEMORY";
                break;
              case t3.CONTEXT_LOST_WEBGL:
                n2 = "CONTEXT_LOST_WEBGL";
                break;
              default:
                n2 = `Unknown WebGL Error: ${e2.toString(16)}`;
            }
            throw new Error(n2);
          }
        }
        deleteTexture(t3) {
          this.gl.deleteTexture(t3);
        }
        deleteProgram(t3) {
          this.gl.deleteProgram(t3);
        }
        getEncoder(t3, e2, n2 = 0) {
          if (2 === this.version) return new s.RedFloat32DataEncoder(this.gl, e2);
          switch (t3) {
            case "float":
              return 1 === n2 || this.isRenderFloat32Supported ? new s.RGBAFloatDataEncoder(this.gl, e2) : new s.RGBAFloatDataEncoder(this.gl, e2, this.textureHalfFloatExtension.HALF_FLOAT_OES);
            case "int":
              throw new Error("not implemented");
            case "byte":
              return new s.Uint8DataEncoder(this.gl, e2);
            default:
              throw new Error(`Invalid dataType: ${t3}`);
          }
        }
        clearActiveTextures() {
          const t3 = this.gl;
          for (let e2 = 0; e2 < this.maxTextureImageUnits; ++e2) t3.activeTexture(t3.TEXTURE0 + e2), t3.bindTexture(t3.TEXTURE_2D, null);
        }
        dispose() {
          if (this.disposed) return;
          const t3 = this.gl;
          t3.bindFramebuffer(t3.FRAMEBUFFER, null), t3.deleteFramebuffer(this.framebuffer), t3.bindBuffer(t3.ARRAY_BUFFER, null), t3.deleteBuffer(this.vertexbuffer), t3.bindBuffer(t3.ELEMENT_ARRAY_BUFFER, null), t3.finish(), this.disposed = true;
        }
        createDefaultGeometry() {
          return new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);
        }
        createVertexbuffer() {
          const t3 = this.gl, e2 = t3.createBuffer();
          if (!e2) throw new Error("createBuffer() returned null");
          const n2 = this.createDefaultGeometry();
          return t3.bindBuffer(t3.ARRAY_BUFFER, e2), t3.bufferData(t3.ARRAY_BUFFER, n2, t3.STATIC_DRAW), this.checkError(), e2;
        }
        createFramebuffer() {
          const t3 = this.gl.createFramebuffer();
          if (!t3) throw new Error("createFramebuffer returned null");
          return t3;
        }
        queryVitalParameters() {
          const t3 = this.gl;
          if (this.isFloatTextureAttachableToFrameBuffer = this.checkFloatTextureAttachableToFrameBuffer(), this.isRenderFloat32Supported = this.checkRenderFloat32(), this.isFloat32DownloadSupported = this.checkFloat32Download(), 1 === this.version && !this.textureHalfFloatExtension && !this.isRenderFloat32Supported) throw new Error("both float32 and float16 TextureType are not supported");
          this.isBlendSupported = !this.isRenderFloat32Supported || this.checkFloat32Blend(), this.maxTextureSize = t3.getParameter(t3.MAX_TEXTURE_SIZE), this.maxTextureImageUnits = t3.getParameter(t3.MAX_TEXTURE_IMAGE_UNITS), this.version;
        }
        getExtensions() {
          2 === this.version ? (this.colorBufferFloatExtension = this.gl.getExtension("EXT_color_buffer_float"), this.disjointTimerQueryWebgl2Extension = this.gl.getExtension("EXT_disjoint_timer_query_webgl2")) : (this.textureFloatExtension = this.gl.getExtension("OES_texture_float"), this.textureHalfFloatExtension = this.gl.getExtension("OES_texture_half_float"));
        }
        checkFloatTextureAttachableToFrameBuffer() {
          const t3 = this.gl, e2 = t3.createTexture();
          t3.bindTexture(t3.TEXTURE_2D, e2);
          const n2 = 2 === this.version ? t3.RGBA32F : t3.RGBA;
          t3.texImage2D(t3.TEXTURE_2D, 0, n2, 1, 1, 0, t3.RGBA, t3.FLOAT, null);
          const r2 = t3.createFramebuffer();
          t3.bindFramebuffer(t3.FRAMEBUFFER, r2), t3.framebufferTexture2D(t3.FRAMEBUFFER, t3.COLOR_ATTACHMENT0, t3.TEXTURE_2D, e2, 0);
          const i3 = t3.checkFramebufferStatus(t3.FRAMEBUFFER) === t3.FRAMEBUFFER_COMPLETE;
          return t3.bindTexture(t3.TEXTURE_2D, null), t3.bindFramebuffer(t3.FRAMEBUFFER, null), t3.deleteTexture(e2), t3.deleteFramebuffer(r2), i3;
        }
        checkRenderFloat32() {
          if (2 === this.version) {
            if (!this.colorBufferFloatExtension) return false;
          } else if (!this.textureFloatExtension) return false;
          return this.isFloatTextureAttachableToFrameBuffer;
        }
        checkFloat32Download() {
          if (2 === this.version) {
            if (!this.colorBufferFloatExtension) return false;
          } else {
            if (!this.textureFloatExtension) return false;
            if (!this.gl.getExtension("WEBGL_color_buffer_float")) return false;
          }
          return this.isFloatTextureAttachableToFrameBuffer;
        }
        checkFloat32Blend() {
          const t3 = this.gl;
          let e2, n2, r2, i3, o2;
          try {
            e2 = t3.createTexture(), n2 = t3.createFramebuffer(), t3.bindTexture(t3.TEXTURE_2D, e2);
            const a2 = 2 === this.version ? t3.RGBA32F : t3.RGBA;
            return t3.texImage2D(t3.TEXTURE_2D, 0, a2, 1, 1, 0, t3.RGBA, t3.FLOAT, null), t3.bindFramebuffer(t3.FRAMEBUFFER, n2), t3.framebufferTexture2D(t3.FRAMEBUFFER, t3.COLOR_ATTACHMENT0, t3.TEXTURE_2D, e2, 0), t3.enable(t3.BLEND), r2 = t3.createShader(t3.VERTEX_SHADER), !!r2 && (t3.shaderSource(r2, "void main(){}"), t3.compileShader(r2), i3 = t3.createShader(t3.FRAGMENT_SHADER), !!i3 && (t3.shaderSource(i3, "precision highp float;void main(){gl_FragColor=vec4(0.5);}"), t3.compileShader(i3), o2 = t3.createProgram(), !!o2 && (t3.attachShader(o2, r2), t3.attachShader(o2, i3), t3.linkProgram(o2), t3.useProgram(o2), t3.drawArrays(t3.POINTS, 0, 1), t3.getError() === t3.NO_ERROR)));
          } finally {
            t3.disable(t3.BLEND), o2 && t3.deleteProgram(o2), r2 && t3.deleteShader(r2), i3 && t3.deleteShader(i3), n2 && (t3.bindFramebuffer(t3.FRAMEBUFFER, null), t3.deleteFramebuffer(n2)), e2 && (t3.bindTexture(t3.TEXTURE_2D, null), t3.deleteTexture(e2));
          }
        }
        beginTimer() {
          if (2 === this.version && this.disjointTimerQueryWebgl2Extension) {
            const t3 = this.gl, e2 = this.disjointTimerQueryWebgl2Extension, n2 = t3.createQuery();
            return t3.beginQuery(e2.TIME_ELAPSED_EXT, n2), n2;
          }
          throw new Error("WebGL1 profiling currently not supported.");
        }
        endTimer() {
          if (2 !== this.version || !this.disjointTimerQueryWebgl2Extension) throw new Error("WebGL1 profiling currently not supported");
          {
            const t3 = this.gl, e2 = this.disjointTimerQueryWebgl2Extension;
            t3.endQuery(e2.TIME_ELAPSED_EXT);
          }
        }
        isTimerResultAvailable(t3) {
          let e2 = false, n2 = false;
          if (2 !== this.version || !this.disjointTimerQueryWebgl2Extension) throw new Error("WebGL1 profiling currently not supported");
          {
            const r2 = this.gl, i3 = this.disjointTimerQueryWebgl2Extension;
            e2 = r2.getQueryParameter(t3, r2.QUERY_RESULT_AVAILABLE), n2 = r2.getParameter(i3.GPU_DISJOINT_EXT);
          }
          return e2 && !n2;
        }
        getTimerResult(t3) {
          let e2 = 0;
          if (2 !== this.version) throw new Error("WebGL1 profiling currently not supported");
          {
            const n2 = this.gl;
            e2 = n2.getQueryParameter(t3, n2.QUERY_RESULT), n2.deleteQuery(t3);
          }
          return e2 / 1e6;
        }
        async waitForQueryAndGetTime(t3) {
          return await (0, u.repeatedTry)(() => this.isTimerResultAvailable(t3)), this.getTimerResult(t3);
        }
        async createAndWaitForFence() {
          const t3 = this.createFence(this.gl);
          return this.pollFence(t3);
        }
        createFence(t3) {
          let e2;
          const n2 = t3, r2 = n2.fenceSync(n2.SYNC_GPU_COMMANDS_COMPLETE, 0);
          return t3.flush(), e2 = null === r2 ? () => true : () => {
            const t4 = n2.clientWaitSync(r2, 0, 0);
            return t4 === n2.ALREADY_SIGNALED || t4 === n2.CONDITION_SATISFIED;
          }, { query: r2, isFencePassed: e2 };
        }
        async pollFence(t3) {
          return new Promise((e2) => {
            this.addItemToPoll(() => t3.isFencePassed(), () => e2());
          });
        }
        pollItems() {
          const t3 = c(this.itemsToPoll.map((t4) => t4.isDoneFn));
          for (let e2 = 0; e2 <= t3; ++e2) {
            const { resolveFn: t4 } = this.itemsToPoll[e2];
            t4();
          }
          this.itemsToPoll = this.itemsToPoll.slice(t3 + 1);
        }
        async addItemToPoll(t3, e2) {
          this.itemsToPoll.push({ isDoneFn: t3, resolveFn: e2 }), this.itemsToPoll.length > 1 || await (0, u.repeatedTry)(() => (this.pollItems(), 0 === this.itemsToPoll.length));
        }
      };
    }, 1036: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.ExecutionPlan = void 0;
      const r = n(3694);
      class i2 {
        constructor(t3, e2) {
          this.op = t3, this.node = e2;
        }
      }
      e.ExecutionPlan = class {
        constructor(t3, e2, n2) {
          this.graph = t3, this.profiler = n2, this.initialize(e2);
        }
        initialize(t3) {
          this.profiler.event("session", "ExecutionPlan.initialize", () => {
            const e2 = this.graph.getNodes();
            if (e2.length !== t3.length) throw new Error("The size of nodes and OPs do not match.");
            this._ops = t3.map((t4, n2) => new i2(t4, e2[n2])), this.reset(), this._starter = [], this._ops.forEach((t4, e3) => {
              let n2 = true;
              for (const e4 of t4.node.inputs) if (!this._values[e4] && -1 === this.graph.getInputIndices().indexOf(e4)) {
                n2 = false;
                break;
              }
              n2 && this._starter.push(e3);
            });
          });
        }
        reset() {
          this._values = this.graph.getValues().map((t3) => t3.tensor);
        }
        async execute(t3, e2) {
          return this.profiler.event("session", "ExecutionPlan.execute", async () => {
            this.reset();
            const n2 = t3.createInferenceHandler(), i3 = this.graph.getInputIndices();
            if (e2.length !== i3.length) throw new Error(`number of input tensors don't match the number of inputs to the model: actual: ${e2.length} expected: ${i3.length}`);
            e2.forEach((t4, e3) => {
              const n3 = i3[e3];
              this._values[n3] = t4;
            });
            const o = this._starter.slice(0), a = this.graph.getValues(), s = this.graph.getNodes();
            let u = 0;
            for (; u < o.length; ) {
              const t4 = o[u++], e3 = this._ops[t4], i4 = e3.node.inputs.map((t5) => this._values[t5]);
              if (-1 !== i4.indexOf(void 0)) throw new Error(`unresolved input detected: op: ${e3.node}`);
              const c2 = i4;
              r.Logger.verbose("ExecPlan", `Runing op:${e3.node.name} (${c2.map((t5, n3) => `'${e3.node.inputs[n3]}': ${t5.type}[${t5.dims.join(",")}]`).join(", ")})`);
              const l = await this.profiler.event("node", e3.node.name, async () => e3.op.impl(n2, c2, e3.op.context));
              if (l.length !== e3.node.outputs.length) throw new Error("the size of output does not match model definition.");
              l.forEach((t5, n3) => {
                const r2 = e3.node.outputs[n3];
                if (this._values[r2]) throw new Error(`output [${r2}] already has value: op:${e3.node.name}`);
                this._values[r2] = t5;
              });
              const p = /* @__PURE__ */ new Set();
              l.forEach((t5, n3) => {
                const r2 = e3.node.outputs[n3];
                for (const t6 of a[r2].to) {
                  const e4 = s[t6];
                  let n4 = true;
                  for (const t7 of e4.inputs) if (!this._values[t7]) {
                    n4 = false;
                    break;
                  }
                  n4 && p.add(t6);
                }
              }), o.push(...p);
            }
            const c = [];
            for (let t4 = 0; t4 < this.graph.getOutputIndices().length; t4++) {
              const e3 = this.graph.getOutputIndices()[t4], n3 = this._values[e3];
              if (void 0 === n3) throw new Error(`required output [${e3}] does not have value`);
              0 === e3 ? await n3.getData() : n3.data, c.push(n3);
            }
            return r.Logger.verbose("ExecPlan", "disposing of inferenceHandler"), n2.dispose(), c;
          });
        }
      };
    }, 7070: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.Graph = void 0;
      const r = n(1446), i2 = n(7778), o = n(9395), a = n(9162), s = n(2517);
      var u = o.onnxruntime.experimental.fbs;
      e.Graph = { from: (t3, e2) => new p(t3, e2) };
      class c {
        constructor(t3) {
          this._from = void 0, this._to = [], this.tensor = void 0, this.type = void 0, t3 && (this.type = s.ProtoUtil.tensorValueTypeFromProto(t3.type.tensorType));
        }
        get from() {
          return this._from;
        }
        get to() {
          return this._to;
        }
      }
      class l {
        constructor(t3, e2) {
          t3 instanceof r.onnx.NodeProto ? (this.name = t3.name, this.opType = t3.opType, this.attributes = new i2.Attribute(t3.attribute)) : t3 instanceof u.Node && (this.name = null != e2 ? e2 : t3.name(), this.opType = t3.opType(), this.attributes = new i2.Attribute(s.ProtoUtil.tensorAttributesFromORTFormat(t3))), this.inputs = [], this.outputs = [], this.executeNode = true;
        }
      }
      class p {
        constructor(t3, e2) {
          if (!t3) throw new TypeError("graph is empty");
          this.buildGraph(t3), this.transformGraph(e2), this.checkIsAcyclic();
        }
        getInputIndices() {
          return this._allInputIndices;
        }
        getInputNames() {
          return this._allInputNames;
        }
        getOutputIndices() {
          return this._allOutputIndices;
        }
        getOutputNames() {
          return this._allOutputNames;
        }
        getValues() {
          return this._allData;
        }
        getNodes() {
          return this._nodes;
        }
        buildGraph(t3) {
          if (t3 instanceof r.onnx.GraphProto) this.buildGraphFromOnnxFormat(t3);
          else {
            if (!(t3 instanceof u.Graph)) throw new TypeError("Graph type is not supported.");
            this.buildGraphFromOrtFormat(t3);
          }
        }
        buildGraphFromOnnxFormat(t3) {
          const e2 = /* @__PURE__ */ new Map();
          this._allData = [], this._allInputIndices = [], this._allInputNames = [], this._allOutputIndices = [], this._allOutputNames = [], this._nodes = [];
          const n2 = /* @__PURE__ */ new Map();
          if (!t3.input) throw new Error("missing information in graph: input");
          const r2 = [];
          for (const n3 of t3.input) {
            if (e2.has(n3.name)) throw new Error(`duplicated input name: ${n3.name}`);
            const t4 = this._allData.push(new c(n3)) - 1;
            e2.set(n3.name, t4), r2.push(n3.name);
          }
          if (!t3.initializer) throw new Error("missing information in graph: initializer");
          for (const n3 of t3.initializer) {
            let t4 = e2.get(n3.name);
            if (void 0 === t4) {
              const r3 = new c();
              r3.type = { shape: { dims: s.ProtoUtil.tensorDimsFromProto(n3.dims) }, tensorType: s.ProtoUtil.tensorDataTypeFromProto(n3.dataType) }, t4 = this._allData.push(r3) - 1, e2.set(n3.name, t4);
            }
            this._allData[t4]._from = -1, this._allData[t4].tensor = a.Tensor.fromProto(n3);
          }
          for (let t4 = 0; t4 < this._allData.length; t4++) this._allData[t4].tensor || (this._allInputIndices.push(t4), this._allInputNames.push(r2[t4]));
          if (!t3.output) throw new Error("missing information in graph: output");
          for (const n3 of t3.output) {
            if (e2.has(n3.name)) throw new Error(`duplicated output name: ${n3.name}`);
            const t4 = this._allData.push(new c(n3)) - 1;
            e2.set(n3.name, t4), this._allOutputIndices.push(t4), this._allOutputNames.push(n3.name);
          }
          if (!t3.node) throw new Error("missing information in graph: node");
          for (const e3 of t3.node) {
            if (!e3.name) for (let t5 = 0; ; t5++) {
              const r3 = `unnamed_${e3.opType}_${t5}`;
              if (!n2.has(r3)) {
                e3.name = r3;
                break;
              }
            }
            if (n2.has(e3.name)) throw new Error(`duplicated node name: ${e3.name}`);
            const t4 = this._nodes.push(new l(e3)) - 1;
            n2.set(e3.name, t4);
          }
          for (let n3 = 0; n3 < this._nodes.length; n3++) {
            const r3 = this._nodes[n3], i3 = t3.node[n3];
            if (!i3.output) throw new Error(`missing output for node: ${i3.name}`);
            for (const t4 of i3.output) {
              let o2 = e2.get(t4);
              if (void 0 === o2 && (o2 = this._allData.push(new c()) - 1, e2.set(t4, o2)), r3.outputs.push(o2), void 0 !== this._allData[o2]._from) throw new Error(`multiple nodes output to one data value: ${o2}`);
              if (this._allData[o2]._from = n3, "Constant" === i3.opType) {
                if (!i3.attribute || 1 !== i3.attribute.length || !i3.attribute[0].t) throw new Error("missing attributes or missing tensor value in attributes for this Constant operator");
                if (!i3.output || 1 !== i3.output.length) throw new Error("missing output or incorrect number of outputs for this Constant operator");
                r3.outputs.pop(), r3.executeNode = false, this._allData[o2]._from = -1, this._allData[o2].tensor = a.Tensor.fromProto(i3.attribute[0].t);
              }
            }
          }
          for (let n3 = 0; n3 < this._nodes.length; n3++) {
            const r3 = this._nodes[n3], i3 = t3.node[n3];
            if (!i3.input) throw new Error(`missing input for node: ${i3.name}`);
            for (const t4 of i3.input) {
              const o2 = e2.get(t4);
              if (void 0 === o2) {
                if ("" === t4 && 3 === i3.input.length && "Resize" === i3.opType) continue;
                throw new Error(`unrecognized input '${t4}' for node: ${i3.name}`);
              }
              r3.inputs.push(o2), this._allData[o2]._to.push(n3);
            }
          }
          return true;
        }
        buildGraphFromOrtFormat(t3) {
          var e2, n2, r2;
          const i3 = /* @__PURE__ */ new Map();
          this._allData = [], this._allInputIndices = [], this._allInputNames = [], this._allOutputIndices = [], this._allOutputNames = [], this._nodes = [];
          const o2 = /* @__PURE__ */ new Map(), p2 = [];
          for (let o3 = 0; o3 < t3.inputsLength(); o3++) {
            const a2 = t3.inputs(o3);
            if (i3.has(a2)) throw new Error(`duplicated input name: ${a2}`);
            for (let o4 = 0; o4 < t3.nodeArgsLength(); o4++) if ((null === (e2 = t3.nodeArgs(o4)) || void 0 === e2 ? void 0 : e2.name()) === a2) {
              const e3 = new c();
              if ((null === (r2 = null === (n2 = t3.nodeArgs(o4)) || void 0 === n2 ? void 0 : n2.type()) || void 0 === r2 ? void 0 : r2.valueType()) !== u.TypeInfoValue.tensor_type) throw new Error("Unexpected value type for the nodeArg.");
              const l2 = t3.nodeArgs(o4).type().value(new u.TensorTypeAndShape()), f = s.ProtoUtil.tensorDataTypeFromProto(l2.elemType()), d = l2.shape(), h = [];
              for (let t4 = 0; t4 < d.dimLength(); t4++) h.push(s.LongUtil.longToNumber(d.dim(t4).value().dimValue()));
              e3.type = { shape: { dims: h }, tensorType: f };
              const g = this._allData.push(e3) - 1;
              i3.set(a2, g), p2.push(a2);
            }
          }
          for (let e3 = 0; e3 < t3.initializersLength(); e3++) {
            const n3 = t3.initializers(e3);
            let r3 = i3.get(n3.name());
            if (void 0 === r3) {
              const t4 = new c(), e4 = s.ProtoUtil.tensorDimsFromORTFormat(n3), o3 = s.ProtoUtil.tensorDataTypeFromProto(n3.dataType());
              t4.type = { shape: { dims: e4 }, tensorType: o3 }, r3 = this._allData.push(t4) - 1, i3.set(n3.name(), r3);
            }
            this._allData[r3]._from = -1, this._allData[r3].tensor = a.Tensor.fromOrtTensor(n3);
          }
          for (let t4 = 0; t4 < this._allData.length; t4++) this._allData[t4].tensor || (this._allInputIndices.push(t4), this._allInputNames.push(p2[t4]));
          for (let e3 = 0; e3 < t3.outputsLength(); e3++) {
            const n3 = t3.outputs(e3);
            if (i3.has(n3)) throw new Error(`duplicated output name: ${n3}`);
            const r3 = this._allData.push(new c()) - 1;
            i3.set(n3, r3), this._allOutputIndices.push(r3), this._allOutputNames.push(n3);
          }
          if (!t3.nodes) throw new Error("missing information in graph: node");
          for (let e3 = 0; e3 < t3.nodesLength(); e3++) {
            const n3 = t3.nodes(e3);
            let r3 = n3.name();
            if (!r3) for (let t4 = 0; r3 = `unnamed_${n3.opType()}_${t4}`, o2.has(r3); t4++) ;
            if (o2.has(r3)) throw new Error(`duplicated node name: ${r3}`);
            const i4 = this._nodes.push(new l(n3, r3)) - 1;
            o2.set(r3, i4);
          }
          for (let e3 = 0; e3 < this._nodes.length; e3++) {
            const n3 = this._nodes[e3], r3 = t3.nodes(e3);
            if (null == r3) throw new Error(`No node exists at index ${e3}`);
            if (0 === (null == r3 ? void 0 : r3.outputsLength())) throw new Error(`missing output for node: ${r3.name}`);
            for (let t4 = 0; t4 < (null == r3 ? void 0 : r3.outputsLength()); t4++) {
              const o3 = null == r3 ? void 0 : r3.outputs(t4);
              let s2 = i3.get(o3);
              if (void 0 === s2 && (s2 = this._allData.push(new c()) - 1, i3.set(o3, s2)), n3.outputs.push(s2), void 0 !== this._allData[s2]._from) throw new Error(`multiple nodes output to one data value: ${s2}`);
              if (this._allData[s2]._from = e3, "Constant" === r3.opType()) {
                if (1 !== r3.attributesLength() || !r3.attributes(0).t()) throw new Error("missing attributes or missing tensor value in attributes for this Constant operator");
                if (1 !== r3.outputsLength()) throw new Error("missing output or incorrect number of outputs for this Constant operator");
                n3.outputs.pop(), n3.executeNode = false, this._allData[s2]._from = -1, this._allData[s2].tensor = a.Tensor.fromOrtTensor(r3.attributes(0).t());
              }
            }
          }
          for (let e3 = 0; e3 < this._nodes.length; e3++) {
            const n3 = this._nodes[e3], r3 = t3.nodes(e3);
            if (0 === r3.inputsLength()) throw new Error(`missing input for node: ${r3.name}`);
            for (let t4 = 0; t4 < r3.inputsLength(); t4++) {
              const o3 = r3.inputs(t4), a2 = i3.get(o3);
              if (void 0 === a2) throw new Error(`unrecognized input '${o3}' for node: ${r3.name()}`);
              n3.inputs.push(a2), this._allData[a2]._to.push(e3);
            }
          }
        }
        checkIsAcyclic() {
          const t3 = /* @__PURE__ */ new Set();
          this._allInputIndices.forEach((e3) => {
            this._allData[e3]._to.forEach((e4) => {
              t3.add(e4);
            });
          });
          const e2 = Array.from(t3), n2 = new Array(this._nodes.length).fill("white");
          for (; e2.length > 0; ) {
            const t4 = e2.pop();
            "gray" === n2[t4] ? n2[t4] = "black" : (e2.push(t4), n2[t4] = "gray", this._nodes[t4].outputs.forEach((r2) => {
              const i3 = this._allData[r2];
              if (void 0 !== i3.tensor) throw new Error("node outputs should not be initialized");
              if (i3._from !== t4) throw new Error("from property of the Value object doesn't match index of Node being processed");
              i3._to.forEach((t5) => {
                if ("gray" === n2[t5]) throw new Error("model graph is cyclic");
                "white" === n2[t5] && e2.push(t5);
              });
            }));
          }
        }
        transformGraph(t3) {
          this.removeAllIdentityNodes(), this.removeAllDropoutNodes(), this.fuseConvActivationNodes(), t3 && t3.transformGraph(this), this.finalizeGraph();
        }
        finalizeGraph() {
          let t3 = 0;
          for (let e2 = 0; e2 < this._nodes.length; e2++) this._nodes[e2].executeNode ? t3 > 0 && (this._nodes[e2].inputs.forEach((n2) => {
            const r2 = this._allData[n2]._to.indexOf(e2 + t3);
            -1 !== r2 && (this._allData[n2]._to[r2] = e2);
          }), this._nodes[e2].outputs.forEach((n2) => {
            this._allData[n2]._from && this._allData[n2]._from === e2 + t3 && (this._allData[n2]._from = e2);
          })) : (t3++, this._nodes[e2].outputs.forEach((t4) => {
            this._allData[t4]._from = -2;
          }), this._nodes.splice(e2, 1), e2--);
          t3 = 0;
          for (let e2 = 0; e2 < this._allData.length; e2++) if (-2 !== this._allData[e2].from || -1 !== this._allOutputIndices.indexOf(e2 + t3)) {
            if (t3 > 0) {
              let n2 = -1;
              void 0 !== this._allData[e2].from && -1 !== this._allData[e2].from ? (n2 = this._nodes[this._allData[e2].from].outputs.indexOf(e2 + t3), -1 !== n2 && (this._nodes[this._allData[e2].from].outputs[n2] = e2)) : (n2 = this._allInputIndices.indexOf(e2 + t3), -1 !== n2 && (this._allInputIndices[n2] = e2)), this._allData[e2].to.forEach((r2) => {
                n2 = this._nodes[r2].inputs.indexOf(e2 + t3), -1 !== n2 && (this._nodes[r2].inputs[n2] = e2);
              }), 0 === this._allData[e2].to.length && (n2 = this._allOutputIndices.indexOf(e2 + t3), -1 !== n2 && (this._allOutputIndices[n2] = e2));
            }
          } else t3++, this._allData.splice(e2, 1), e2--;
        }
        deleteNode(t3) {
          const e2 = this._nodes[t3];
          if (e2.outputs.length > 1) {
            for (let t4 = 1; t4 < e2.outputs.length; t4++) if (this._allData[e2.outputs[t4]].to.length > 0) throw new Error("Node deletion with more than one output connected to other nodes is not supported. ");
          }
          e2.executeNode = false;
          const n2 = e2.inputs[0], r2 = e2.outputs[0], i3 = this._allData[r2].to, o2 = this._allData[n2].to.indexOf(t3);
          if (-1 === o2) throw new Error("The Value object doesn't have the current Node in it's 'to' property ");
          this._allData[n2].to.splice(o2, 1), this._allData[r2]._to = [];
          const a2 = this._allOutputIndices.indexOf(r2);
          if (-1 !== a2 && (this._allOutputIndices[a2] = n2), i3 && i3.length > 0) for (const t4 of i3) {
            const e3 = this._nodes[t4].inputs.indexOf(r2);
            if (-1 === e3) throw new Error("The Node object doesn't have the output Value in it's 'inputs' property ");
            this._nodes[t4].inputs[e3] = n2, this._allData[n2].to.push(t4);
          }
        }
        removeAllDropoutNodes() {
          let t3 = 0;
          for (const e2 of this._nodes) {
            if ("Dropout" === e2.opType) {
              if (1 !== e2.inputs.length) throw new Error("Dropout nodes should only contain one input. ");
              if (1 !== e2.outputs.length && 2 !== e2.outputs.length) throw new Error("Dropout nodes should contain either 1 or 2 output(s)");
              if (2 === e2.outputs.length && 0 !== this._allData[e2.outputs[1]]._to.length) throw new Error("Dropout nodes's second output should not be referenced by other nodes");
              this.deleteNode(t3);
            }
            t3++;
          }
        }
        removeAllIdentityNodes() {
          let t3 = 0;
          for (const e2 of this._nodes) "Identity" === e2.opType && this.deleteNode(t3), t3++;
        }
        isActivation(t3) {
          switch (t3.opType) {
            case "Relu":
            case "Sigmoid":
            case "Clip":
              return true;
            default:
              return false;
          }
        }
        fuseConvActivationNodes() {
          for (const t3 of this._nodes) if ("Conv" === t3.opType) {
            const e2 = this._allData[t3.outputs[0]]._to;
            if (1 === e2.length && this.isActivation(this._nodes[e2[0]])) {
              const n2 = this._nodes[e2[0]];
              if ("Clip" === n2.opType) if (1 === n2.inputs.length) try {
                t3.attributes.set("activation_params", "floats", [n2.attributes.getFloat("min"), n2.attributes.getFloat("max")]);
              } catch (e3) {
                t3.attributes.set("activation_params", "floats", [s.MIN_CLIP, s.MAX_CLIP]);
              }
              else {
                if (!(n2.inputs.length >= 3 && void 0 !== this._allData[n2.inputs[1]].tensor && void 0 !== this._allData[n2.inputs[2]].tensor)) continue;
                t3.attributes.set("activation_params", "floats", [this._allData[n2.inputs[1]].tensor.floatData[0], this._allData[n2.inputs[2]].tensor.floatData[0]]);
              }
              t3.attributes.set("activation", "string", n2.opType), this.deleteNode(e2[0]);
            }
          }
        }
      }
    }, 3694: (t2, e) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.now = e.Profiler = e.Logger = void 0;
      const n = { verbose: 1e3, info: 2e3, warning: 4e3, error: 5e3, fatal: 6e3 }, r = { none: new class {
        log(t3, e2, n2) {
        }
      }(), console: new class {
        log(t3, e2, n2) {
          console.log(`${this.color(t3)} ${n2 ? "\x1B[35m" + n2 + "\x1B[0m " : ""}${e2}`);
        }
        color(t3) {
          switch (t3) {
            case "verbose":
              return "\x1B[34;40mv\x1B[0m";
            case "info":
              return "\x1B[32mi\x1B[0m";
            case "warning":
              return "\x1B[30;43mw\x1B[0m";
            case "error":
              return "\x1B[31;40me\x1B[0m";
            case "fatal":
              return "\x1B[101mf\x1B[0m";
            default:
              throw new Error(`unsupported severity: ${t3}`);
          }
        }
      }() }, i2 = { provider: "console", minimalSeverity: "warning", logDateTime: true, logSourceLocation: false };
      let o = { "": i2 };
      function a(t3, e2, n2, r2) {
        if (void 0 === e2) return i3 = t3, { verbose: a.verbose.bind(null, i3), info: a.info.bind(null, i3), warning: a.warning.bind(null, i3), error: a.error.bind(null, i3), fatal: a.fatal.bind(null, i3) };
        if (void 0 === n2) s(t3, e2);
        else if ("number" == typeof n2 && void 0 === r2) s(t3, e2);
        else if ("string" == typeof n2 && void 0 === r2) s(t3, n2, 0, e2);
        else {
          if ("string" != typeof n2 || "number" != typeof r2) throw new TypeError("input is valid");
          s(t3, n2, 0, e2);
        }
        var i3;
      }
      function s(t3, e2, i3, a2) {
        const s2 = o[a2 || ""] || o[""];
        n[t3] < n[s2.minimalSeverity] || (s2.logDateTime && (e2 = `${(/* @__PURE__ */ new Date()).toISOString()}|${e2}`), s2.logSourceLocation, r[s2.provider].log(t3, e2, a2));
      }
      !function(t3) {
        function e2(t4) {
          o = {}, n2("", t4 || {});
        }
        function n2(t4, n3) {
          if ("*" === t4) e2(n3);
          else {
            const e3 = o[t4] || i2;
            o[t4] = { provider: n3.provider || e3.provider, minimalSeverity: n3.minimalSeverity || e3.minimalSeverity, logDateTime: void 0 === n3.logDateTime ? e3.logDateTime : n3.logDateTime, logSourceLocation: void 0 === n3.logSourceLocation ? e3.logSourceLocation : n3.logSourceLocation };
          }
        }
        t3.verbose = function(e3, n3) {
          t3("verbose", e3, n3);
        }, t3.info = function(e3, n3) {
          t3("info", e3, n3);
        }, t3.warning = function(e3, n3) {
          t3("warning", e3, n3);
        }, t3.error = function(e3, n3) {
          t3("error", e3, n3);
        }, t3.fatal = function(e3, n3) {
          t3("fatal", e3, n3);
        }, t3.reset = e2, t3.set = n2, t3.setWithEnv = function(t4) {
          const e3 = {};
          t4.logLevel && (e3.minimalSeverity = t4.logLevel), n2("", e3);
        };
      }(a || (a = {})), e.Logger = a;
      class u {
        constructor(t3, e2, n2, r2, i3, o2) {
          this.category = t3, this.name = e2, this.startTime = n2, this.endCallback = r2, this.timer = i3, this.ctx = o2;
        }
        end() {
          return this.endCallback(this);
        }
        async checkTimer() {
          if (void 0 === this.ctx || void 0 === this.timer) throw new Error("No webgl timer found");
          return this.ctx.endTimer(), this.ctx.waitForQueryAndGetTime(this.timer);
        }
      }
      class c {
        constructor(t3, e2, n2, r2) {
          this.category = t3, this.name = e2, this.startTime = n2, this.endTime = r2;
        }
      }
      e.Profiler = class {
        static create(t3) {
          return void 0 === t3 ? new this() : new this(t3.maxNumberEvents, t3.flushBatchSize, t3.flushIntervalInMilliseconds);
        }
        constructor(t3, e2, n2) {
          this._started = false, this._flushPointer = 0, this._started = false, this._maxNumberEvents = void 0 === t3 ? 1e4 : t3, this._flushBatchSize = void 0 === e2 ? 10 : e2, this._flushIntervalInMilliseconds = void 0 === n2 ? 5e3 : n2;
        }
        start() {
          this._started = true, this._timingEvents = [], this._flushTime = (0, e.now)(), this._flushPointer = 0;
        }
        stop() {
          for (this._started = false; this._flushPointer < this._timingEvents.length; this._flushPointer++) this.logOneEvent(this._timingEvents[this._flushPointer]);
        }
        event(t3, e2, n2, r2) {
          const i3 = this._started ? this.begin(t3, e2, r2) : void 0;
          let o2 = false;
          const a2 = n2();
          if (a2 && "function" == typeof a2.then) return o2 = true, new Promise((t4, e3) => {
            a2.then(async (e4) => {
              i3 && await i3.end(), t4(e4);
            }, async (t5) => {
              i3 && await i3.end(), e3(t5);
            });
          });
          if (!o2 && i3) {
            const t4 = i3.end();
            if (t4 && "function" == typeof t4.then) return new Promise((e3, n3) => {
              t4.then(() => {
                e3(a2);
              }, (t5) => {
                n3(t5);
              });
            });
          }
          return a2;
        }
        begin(t3, n2, r2) {
          if (!this._started) throw new Error("profiler is not started yet");
          if (void 0 === r2) {
            const r3 = (0, e.now)();
            return this.flush(r3), new u(t3, n2, r3, (t4) => this.endSync(t4));
          }
          {
            const e2 = r2.beginTimer();
            return new u(t3, n2, 0, async (t4) => this.end(t4), e2, r2);
          }
        }
        async end(t3) {
          const e2 = await t3.checkTimer();
          this._timingEvents.length < this._maxNumberEvents && (this._timingEvents.push(new c(t3.category, t3.name, t3.startTime, e2)), this.flush(e2));
        }
        endSync(t3) {
          const n2 = (0, e.now)();
          this._timingEvents.length < this._maxNumberEvents && (this._timingEvents.push(new c(t3.category, t3.name, t3.startTime, n2)), this.flush(n2));
        }
        logOneEvent(t3) {
          e.Logger.verbose(`Profiler.${t3.category}`, `${(t3.endTime - t3.startTime).toFixed(2)}ms on event '${t3.name}' at ${t3.endTime.toFixed(2)}`);
        }
        flush(t3) {
          if (this._timingEvents.length - this._flushPointer >= this._flushBatchSize || t3 - this._flushTime >= this._flushIntervalInMilliseconds) {
            for (const t4 = this._flushPointer; this._flushPointer < t4 + this._flushBatchSize && this._flushPointer < this._timingEvents.length; this._flushPointer++) this.logOneEvent(this._timingEvents[this._flushPointer]);
            this._flushTime = (0, e.now)();
          }
        }
        get started() {
          return this._started;
        }
      }, e.now = "undefined" != typeof performance && performance.now ? () => performance.now() : Date.now;
    }, 2644: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.Model = void 0;
      const r = n(5686), i2 = n(1446), o = n(7070), a = n(9395), s = n(2517);
      var u = a.onnxruntime.experimental.fbs;
      e.Model = class {
        constructor() {
        }
        load(t3, e2, n2) {
          if (!n2) try {
            return void this.loadFromOnnxFormat(t3, e2);
          } catch (t4) {
            if (void 0 !== n2) throw t4;
          }
          this.loadFromOrtFormat(t3, e2);
        }
        loadFromOnnxFormat(t3, e2) {
          const n2 = i2.onnx.ModelProto.decode(t3);
          if (s.LongUtil.longToNumber(n2.irVersion) < 3) throw new Error("only support ONNX model with IR_VERSION>=3");
          this._opsets = n2.opsetImport.map((t4) => ({ domain: t4.domain, version: s.LongUtil.longToNumber(t4.version) })), this._graph = o.Graph.from(n2.graph, e2);
        }
        loadFromOrtFormat(t3, e2) {
          const n2 = new r.flatbuffers.ByteBuffer(t3), i3 = u.InferenceSession.getRootAsInferenceSession(n2).model();
          if (s.LongUtil.longToNumber(i3.irVersion()) < 3) throw new Error("only support ONNX model with IR_VERSION>=3");
          this._opsets = [];
          for (let t4 = 0; t4 < i3.opsetImportLength(); t4++) {
            const e3 = i3.opsetImport(t4);
            this._opsets.push({ domain: null == e3 ? void 0 : e3.domain(), version: s.LongUtil.longToNumber(e3.version()) });
          }
          this._graph = o.Graph.from(i3.graph(), e2);
        }
        get graph() {
          return this._graph;
        }
        get opsets() {
          return this._opsets;
        }
      };
    }, 782: (t2, e) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.FLOAT_TYPES = e.INT_TYPES = e.NUMBER_TYPES = void 0, e.NUMBER_TYPES = ["float32", "float64", "int32", "int16", "int8", "uint16", "uint32", "uint8"], e.INT_TYPES = ["int32", "int16", "int8", "uint16", "uint32", "uint8"], e.FLOAT_TYPES = ["float32", "float64"];
    }, 1047: (t2, e) => {
      function n(t3, e2) {
        if (e2.endsWith("+")) {
          const n2 = Number.parseInt(e2.substring(0, e2.length - 1), 10);
          return !isNaN(n2) && n2 <= t3;
        }
        if (2 === e2.split("-").length) {
          const n2 = e2.split("-"), r = Number.parseInt(n2[0], 10), i2 = Number.parseInt(n2[1], 10);
          return !isNaN(r) && !isNaN(i2) && r <= t3 && t3 <= i2;
        }
        return Number.parseInt(e2, 10) === t3;
      }
      Object.defineProperty(e, "__esModule", { value: true }), e.resolveOperator = void 0, e.resolveOperator = function(t3, e2, r) {
        for (const i2 of r) {
          const r2 = i2[0], o = i2[1], a = i2[2], s = i2[3], u = i2[4];
          if (t3.opType === r2) {
            for (const t4 of e2) if ((t4.domain === o || "ai.onnx" === t4.domain && "" === o) && n(t4.version, a)) return { opImpl: s, opInit: u };
          }
        }
        throw new TypeError(`cannot resolve operator '${t3.opType}' with opsets: ${e2.map((t4) => `${t4.domain || "ai.onnx"} v${t4.version}`).join(", ")}`);
      };
    }, 9395: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.onnxruntime = void 0;
      const r = n(5686);
      var i2, o;
      i2 = e.onnxruntime || (e.onnxruntime = {}), function(t3) {
        !function(t4) {
          t4[t4.UNDEFINED = 0] = "UNDEFINED", t4[t4.FLOAT = 1] = "FLOAT", t4[t4.INT = 2] = "INT", t4[t4.STRING = 3] = "STRING", t4[t4.TENSOR = 4] = "TENSOR", t4[t4.GRAPH = 5] = "GRAPH", t4[t4.FLOATS = 6] = "FLOATS", t4[t4.INTS = 7] = "INTS", t4[t4.STRINGS = 8] = "STRINGS", t4[t4.TENSORS = 9] = "TENSORS", t4[t4.GRAPHS = 10] = "GRAPHS", t4[t4.SPARSE_TENSOR = 11] = "SPARSE_TENSOR", t4[t4.SPARSE_TENSORS = 12] = "SPARSE_TENSORS";
        }(t3.AttributeType || (t3.AttributeType = {}));
      }((o = i2.experimental || (i2.experimental = {})).fbs || (o.fbs = {})), function(t3) {
        !function(t4) {
          !function(t5) {
            !function(t6) {
              t6[t6.UNKNOWN = 0] = "UNKNOWN", t6[t6.VALUE = 1] = "VALUE", t6[t6.PARAM = 2] = "PARAM";
            }(t5.DimensionValueType || (t5.DimensionValueType = {}));
          }(t4.fbs || (t4.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(t4) {
          !function(t5) {
            !function(t6) {
              t6[t6.UNDEFINED = 0] = "UNDEFINED", t6[t6.FLOAT = 1] = "FLOAT", t6[t6.UINT8 = 2] = "UINT8", t6[t6.INT8 = 3] = "INT8", t6[t6.UINT16 = 4] = "UINT16", t6[t6.INT16 = 5] = "INT16", t6[t6.INT32 = 6] = "INT32", t6[t6.INT64 = 7] = "INT64", t6[t6.STRING = 8] = "STRING", t6[t6.BOOL = 9] = "BOOL", t6[t6.FLOAT16 = 10] = "FLOAT16", t6[t6.DOUBLE = 11] = "DOUBLE", t6[t6.UINT32 = 12] = "UINT32", t6[t6.UINT64 = 13] = "UINT64", t6[t6.COMPLEX64 = 14] = "COMPLEX64", t6[t6.COMPLEX128 = 15] = "COMPLEX128", t6[t6.BFLOAT16 = 16] = "BFLOAT16";
            }(t5.TensorDataType || (t5.TensorDataType = {}));
          }(t4.fbs || (t4.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(t4) {
          !function(t5) {
            !function(t6) {
              t6[t6.Primitive = 0] = "Primitive", t6[t6.Fused = 1] = "Fused";
            }(t5.NodeType || (t5.NodeType = {}));
          }(t4.fbs || (t4.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(t4) {
          !function(t5) {
            !function(t6) {
              t6[t6.NONE = 0] = "NONE", t6[t6.tensor_type = 1] = "tensor_type", t6[t6.sequence_type = 2] = "sequence_type", t6[t6.map_type = 3] = "map_type";
            }(t5.TypeInfoValue || (t5.TypeInfoValue = {}));
          }(t4.fbs || (t4.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsShape(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsShape(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              dim(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 4);
                return r2 ? (n3 || new t3.experimental.fbs.Dimension()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              dimLength() {
                let t4 = this.bb.__offset(this.bb_pos, 4);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              static startShape(t4) {
                t4.startObject(1);
              }
              static addDim(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static createDimVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startDimVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static endShape(t4) {
                return t4.endObject();
              }
              static createShape(t4, e4) {
                return n2.startShape(t4), n2.addDim(t4, e4), n2.endShape(t4);
              }
            }
            e3.Shape = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsDimension(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsDimension(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              value(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 4);
                return n3 ? (e4 || new t3.experimental.fbs.DimensionValue()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              denotation(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 6);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              static startDimension(t4) {
                t4.startObject(2);
              }
              static addValue(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addDenotation(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static endDimension(t4) {
                return t4.endObject();
              }
              static createDimension(t4, e4, r2) {
                return n2.startDimension(t4), n2.addValue(t4, e4), n2.addDenotation(t4, r2), n2.endDimension(t4);
              }
            }
            e3.Dimension = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsDimensionValue(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsDimensionValue(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              dimType() {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.readInt8(this.bb_pos + e4) : t3.experimental.fbs.DimensionValueType.UNKNOWN;
              }
              dimValue() {
                let t4 = this.bb.__offset(this.bb_pos, 6);
                return t4 ? this.bb.readInt64(this.bb_pos + t4) : this.bb.createLong(0, 0);
              }
              dimParam(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 8);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              static startDimensionValue(t4) {
                t4.startObject(3);
              }
              static addDimType(e4, n3) {
                e4.addFieldInt8(0, n3, t3.experimental.fbs.DimensionValueType.UNKNOWN);
              }
              static addDimValue(t4, e4) {
                t4.addFieldInt64(1, e4, t4.createLong(0, 0));
              }
              static addDimParam(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static endDimensionValue(t4) {
                return t4.endObject();
              }
              static createDimensionValue(t4, e4, r2, i3) {
                return n2.startDimensionValue(t4), n2.addDimType(t4, e4), n2.addDimValue(t4, r2), n2.addDimParam(t4, i3), n2.endDimensionValue(t4);
              }
            }
            e3.DimensionValue = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsTensorTypeAndShape(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsTensorTypeAndShape(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              elemType() {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.readInt32(this.bb_pos + e4) : t3.experimental.fbs.TensorDataType.UNDEFINED;
              }
              shape(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 6);
                return n3 ? (e4 || new t3.experimental.fbs.Shape()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              static startTensorTypeAndShape(t4) {
                t4.startObject(2);
              }
              static addElemType(e4, n3) {
                e4.addFieldInt32(0, n3, t3.experimental.fbs.TensorDataType.UNDEFINED);
              }
              static addShape(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static endTensorTypeAndShape(t4) {
                return t4.endObject();
              }
              static createTensorTypeAndShape(t4, e4, r2) {
                return n2.startTensorTypeAndShape(t4), n2.addElemType(t4, e4), n2.addShape(t4, r2), n2.endTensorTypeAndShape(t4);
              }
            }
            e3.TensorTypeAndShape = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsMapType(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsMapType(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              keyType() {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.readInt32(this.bb_pos + e4) : t3.experimental.fbs.TensorDataType.UNDEFINED;
              }
              valueType(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 6);
                return n3 ? (e4 || new t3.experimental.fbs.TypeInfo()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              static startMapType(t4) {
                t4.startObject(2);
              }
              static addKeyType(e4, n3) {
                e4.addFieldInt32(0, n3, t3.experimental.fbs.TensorDataType.UNDEFINED);
              }
              static addValueType(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static endMapType(t4) {
                return t4.endObject();
              }
              static createMapType(t4, e4, r2) {
                return n2.startMapType(t4), n2.addKeyType(t4, e4), n2.addValueType(t4, r2), n2.endMapType(t4);
              }
            }
            e3.MapType = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsSequenceType(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsSequenceType(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              elemType(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 4);
                return n3 ? (e4 || new t3.experimental.fbs.TypeInfo()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              static startSequenceType(t4) {
                t4.startObject(1);
              }
              static addElemType(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static endSequenceType(t4) {
                return t4.endObject();
              }
              static createSequenceType(t4, e4) {
                return n2.startSequenceType(t4), n2.addElemType(t4, e4), n2.endSequenceType(t4);
              }
            }
            e3.SequenceType = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(t4) {
          (t4.fbs || (t4.fbs = {})).EdgeEnd = class {
            constructor() {
              this.bb = null, this.bb_pos = 0;
            }
            __init(t5, e2) {
              return this.bb_pos = t5, this.bb = e2, this;
            }
            nodeIndex() {
              return this.bb.readUint32(this.bb_pos);
            }
            srcArgIndex() {
              return this.bb.readInt32(this.bb_pos + 4);
            }
            dstArgIndex() {
              return this.bb.readInt32(this.bb_pos + 8);
            }
            static createEdgeEnd(t5, e2, n2, r2) {
              return t5.prep(4, 12), t5.writeInt32(r2), t5.writeInt32(n2), t5.writeInt32(e2), t5.offset();
            }
          };
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsNodeEdge(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsNodeEdge(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              nodeIndex() {
                let t4 = this.bb.__offset(this.bb_pos, 4);
                return t4 ? this.bb.readUint32(this.bb_pos + t4) : 0;
              }
              inputEdges(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 6);
                return r2 ? (n3 || new t3.experimental.fbs.EdgeEnd()).__init(this.bb.__vector(this.bb_pos + r2) + 12 * e4, this.bb) : null;
              }
              inputEdgesLength() {
                let t4 = this.bb.__offset(this.bb_pos, 6);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              outputEdges(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 8);
                return r2 ? (n3 || new t3.experimental.fbs.EdgeEnd()).__init(this.bb.__vector(this.bb_pos + r2) + 12 * e4, this.bb) : null;
              }
              outputEdgesLength() {
                let t4 = this.bb.__offset(this.bb_pos, 8);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              static startNodeEdge(t4) {
                t4.startObject(3);
              }
              static addNodeIndex(t4, e4) {
                t4.addFieldInt32(0, e4, 0);
              }
              static addInputEdges(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static startInputEdgesVector(t4, e4) {
                t4.startVector(12, e4, 4);
              }
              static addOutputEdges(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static startOutputEdgesVector(t4, e4) {
                t4.startVector(12, e4, 4);
              }
              static endNodeEdge(t4) {
                return t4.endObject();
              }
              static createNodeEdge(t4, e4, r2, i3) {
                return n2.startNodeEdge(t4), n2.addNodeIndex(t4, e4), n2.addInputEdges(t4, r2), n2.addOutputEdges(t4, i3), n2.endNodeEdge(t4);
              }
            }
            e3.NodeEdge = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsNode(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsNode(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              name(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              docString(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 6);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              domain(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 8);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              sinceVersion() {
                let t4 = this.bb.__offset(this.bb_pos, 10);
                return t4 ? this.bb.readInt32(this.bb_pos + t4) : 0;
              }
              index() {
                let t4 = this.bb.__offset(this.bb_pos, 12);
                return t4 ? this.bb.readUint32(this.bb_pos + t4) : 0;
              }
              opType(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 14);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              type() {
                let e4 = this.bb.__offset(this.bb_pos, 16);
                return e4 ? this.bb.readInt32(this.bb_pos + e4) : t3.experimental.fbs.NodeType.Primitive;
              }
              executionProviderType(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 18);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              inputs(t4, e4) {
                let n3 = this.bb.__offset(this.bb_pos, 20);
                return n3 ? this.bb.__string(this.bb.__vector(this.bb_pos + n3) + 4 * t4, e4) : null;
              }
              inputsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 20);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              outputs(t4, e4) {
                let n3 = this.bb.__offset(this.bb_pos, 22);
                return n3 ? this.bb.__string(this.bb.__vector(this.bb_pos + n3) + 4 * t4, e4) : null;
              }
              outputsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 22);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              attributes(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 24);
                return r2 ? (n3 || new t3.experimental.fbs.Attribute()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              attributesLength() {
                let t4 = this.bb.__offset(this.bb_pos, 24);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              inputArgCounts(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 26);
                return e4 ? this.bb.readInt32(this.bb.__vector(this.bb_pos + e4) + 4 * t4) : 0;
              }
              inputArgCountsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 26);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              inputArgCountsArray() {
                let t4 = this.bb.__offset(this.bb_pos, 26);
                return t4 ? new Int32Array(this.bb.bytes().buffer, this.bb.bytes().byteOffset + this.bb.__vector(this.bb_pos + t4), this.bb.__vector_len(this.bb_pos + t4)) : null;
              }
              implicitInputs(t4, e4) {
                let n3 = this.bb.__offset(this.bb_pos, 28);
                return n3 ? this.bb.__string(this.bb.__vector(this.bb_pos + n3) + 4 * t4, e4) : null;
              }
              implicitInputsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 28);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              static startNode(t4) {
                t4.startObject(13);
              }
              static addName(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addDocString(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static addDomain(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static addSinceVersion(t4, e4) {
                t4.addFieldInt32(3, e4, 0);
              }
              static addIndex(t4, e4) {
                t4.addFieldInt32(4, e4, 0);
              }
              static addOpType(t4, e4) {
                t4.addFieldOffset(5, e4, 0);
              }
              static addType(e4, n3) {
                e4.addFieldInt32(6, n3, t3.experimental.fbs.NodeType.Primitive);
              }
              static addExecutionProviderType(t4, e4) {
                t4.addFieldOffset(7, e4, 0);
              }
              static addInputs(t4, e4) {
                t4.addFieldOffset(8, e4, 0);
              }
              static createInputsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startInputsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addOutputs(t4, e4) {
                t4.addFieldOffset(9, e4, 0);
              }
              static createOutputsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startOutputsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addAttributes(t4, e4) {
                t4.addFieldOffset(10, e4, 0);
              }
              static createAttributesVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startAttributesVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addInputArgCounts(t4, e4) {
                t4.addFieldOffset(11, e4, 0);
              }
              static createInputArgCountsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addInt32(e4[n3]);
                return t4.endVector();
              }
              static startInputArgCountsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addImplicitInputs(t4, e4) {
                t4.addFieldOffset(12, e4, 0);
              }
              static createImplicitInputsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startImplicitInputsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static endNode(t4) {
                return t4.endObject();
              }
              static createNode(t4, e4, r2, i3, o2, a, s, u, c, l, p, f, d, h) {
                return n2.startNode(t4), n2.addName(t4, e4), n2.addDocString(t4, r2), n2.addDomain(t4, i3), n2.addSinceVersion(t4, o2), n2.addIndex(t4, a), n2.addOpType(t4, s), n2.addType(t4, u), n2.addExecutionProviderType(t4, c), n2.addInputs(t4, l), n2.addOutputs(t4, p), n2.addAttributes(t4, f), n2.addInputArgCounts(t4, d), n2.addImplicitInputs(t4, h), n2.endNode(t4);
              }
            }
            e3.Node = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsValueInfo(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsValueInfo(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              name(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              docString(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 6);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              type(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 8);
                return n3 ? (e4 || new t3.experimental.fbs.TypeInfo()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              static startValueInfo(t4) {
                t4.startObject(3);
              }
              static addName(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addDocString(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static addType(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static endValueInfo(t4) {
                return t4.endObject();
              }
              static createValueInfo(t4, e4, r2, i3) {
                return n2.startValueInfo(t4), n2.addName(t4, e4), n2.addDocString(t4, r2), n2.addType(t4, i3), n2.endValueInfo(t4);
              }
            }
            e3.ValueInfo = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsTypeInfo(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsTypeInfo(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              denotation(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              valueType() {
                let e4 = this.bb.__offset(this.bb_pos, 6);
                return e4 ? this.bb.readUint8(this.bb_pos + e4) : t3.experimental.fbs.TypeInfoValue.NONE;
              }
              value(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 8);
                return e4 ? this.bb.__union(t4, this.bb_pos + e4) : null;
              }
              static startTypeInfo(t4) {
                t4.startObject(3);
              }
              static addDenotation(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addValueType(e4, n3) {
                e4.addFieldInt8(1, n3, t3.experimental.fbs.TypeInfoValue.NONE);
              }
              static addValue(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static endTypeInfo(t4) {
                return t4.endObject();
              }
              static createTypeInfo(t4, e4, r2, i3) {
                return n2.startTypeInfo(t4), n2.addDenotation(t4, e4), n2.addValueType(t4, r2), n2.addValue(t4, i3), n2.endTypeInfo(t4);
              }
            }
            e3.TypeInfo = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(t4) {
          !function(t5) {
            class e2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t6, e3) {
                return this.bb_pos = t6, this.bb = e3, this;
              }
              static getRootAsOperatorSetId(t6, n2) {
                return (n2 || new e2()).__init(t6.readInt32(t6.position()) + t6.position(), t6);
              }
              static getSizePrefixedRootAsOperatorSetId(t6, n2) {
                return t6.setPosition(t6.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (n2 || new e2()).__init(t6.readInt32(t6.position()) + t6.position(), t6);
              }
              domain(t6) {
                let e3 = this.bb.__offset(this.bb_pos, 4);
                return e3 ? this.bb.__string(this.bb_pos + e3, t6) : null;
              }
              version() {
                let t6 = this.bb.__offset(this.bb_pos, 6);
                return t6 ? this.bb.readInt64(this.bb_pos + t6) : this.bb.createLong(0, 0);
              }
              static startOperatorSetId(t6) {
                t6.startObject(2);
              }
              static addDomain(t6, e3) {
                t6.addFieldOffset(0, e3, 0);
              }
              static addVersion(t6, e3) {
                t6.addFieldInt64(1, e3, t6.createLong(0, 0));
              }
              static endOperatorSetId(t6) {
                return t6.endObject();
              }
              static createOperatorSetId(t6, n2, r2) {
                return e2.startOperatorSetId(t6), e2.addDomain(t6, n2), e2.addVersion(t6, r2), e2.endOperatorSetId(t6);
              }
            }
            t5.OperatorSetId = e2;
          }(t4.fbs || (t4.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsTensor(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsTensor(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              name(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              docString(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 6);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              dims(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 8);
                return e4 ? this.bb.readInt64(this.bb.__vector(this.bb_pos + e4) + 8 * t4) : this.bb.createLong(0, 0);
              }
              dimsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 8);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              dataType() {
                let e4 = this.bb.__offset(this.bb_pos, 10);
                return e4 ? this.bb.readInt32(this.bb_pos + e4) : t3.experimental.fbs.TensorDataType.UNDEFINED;
              }
              rawData(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 12);
                return e4 ? this.bb.readUint8(this.bb.__vector(this.bb_pos + e4) + t4) : 0;
              }
              rawDataLength() {
                let t4 = this.bb.__offset(this.bb_pos, 12);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              rawDataArray() {
                let t4 = this.bb.__offset(this.bb_pos, 12);
                return t4 ? new Uint8Array(this.bb.bytes().buffer, this.bb.bytes().byteOffset + this.bb.__vector(this.bb_pos + t4), this.bb.__vector_len(this.bb_pos + t4)) : null;
              }
              stringData(t4, e4) {
                let n3 = this.bb.__offset(this.bb_pos, 14);
                return n3 ? this.bb.__string(this.bb.__vector(this.bb_pos + n3) + 4 * t4, e4) : null;
              }
              stringDataLength() {
                let t4 = this.bb.__offset(this.bb_pos, 14);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              static startTensor(t4) {
                t4.startObject(6);
              }
              static addName(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addDocString(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static addDims(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static createDimsVector(t4, e4) {
                t4.startVector(8, e4.length, 8);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addInt64(e4[n3]);
                return t4.endVector();
              }
              static startDimsVector(t4, e4) {
                t4.startVector(8, e4, 8);
              }
              static addDataType(e4, n3) {
                e4.addFieldInt32(3, n3, t3.experimental.fbs.TensorDataType.UNDEFINED);
              }
              static addRawData(t4, e4) {
                t4.addFieldOffset(4, e4, 0);
              }
              static createRawDataVector(t4, e4) {
                t4.startVector(1, e4.length, 1);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addInt8(e4[n3]);
                return t4.endVector();
              }
              static startRawDataVector(t4, e4) {
                t4.startVector(1, e4, 1);
              }
              static addStringData(t4, e4) {
                t4.addFieldOffset(5, e4, 0);
              }
              static createStringDataVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startStringDataVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static endTensor(t4) {
                return t4.endObject();
              }
              static createTensor(t4, e4, r2, i3, o2, a, s) {
                return n2.startTensor(t4), n2.addName(t4, e4), n2.addDocString(t4, r2), n2.addDims(t4, i3), n2.addDataType(t4, o2), n2.addRawData(t4, a), n2.addStringData(t4, s), n2.endTensor(t4);
              }
            }
            e3.Tensor = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsSparseTensor(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsSparseTensor(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              values(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 4);
                return n3 ? (e4 || new t3.experimental.fbs.Tensor()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              indices(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 6);
                return n3 ? (e4 || new t3.experimental.fbs.Tensor()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              dims(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 8);
                return e4 ? this.bb.readInt64(this.bb.__vector(this.bb_pos + e4) + 8 * t4) : this.bb.createLong(0, 0);
              }
              dimsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 8);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              static startSparseTensor(t4) {
                t4.startObject(3);
              }
              static addValues(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addIndices(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static addDims(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static createDimsVector(t4, e4) {
                t4.startVector(8, e4.length, 8);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addInt64(e4[n3]);
                return t4.endVector();
              }
              static startDimsVector(t4, e4) {
                t4.startVector(8, e4, 8);
              }
              static endSparseTensor(t4) {
                return t4.endObject();
              }
              static createSparseTensor(t4, e4, r2, i3) {
                return n2.startSparseTensor(t4), n2.addValues(t4, e4), n2.addIndices(t4, r2), n2.addDims(t4, i3), n2.endSparseTensor(t4);
              }
            }
            e3.SparseTensor = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsAttribute(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsAttribute(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              name(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              docString(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 6);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              type() {
                let e4 = this.bb.__offset(this.bb_pos, 8);
                return e4 ? this.bb.readInt32(this.bb_pos + e4) : t3.experimental.fbs.AttributeType.UNDEFINED;
              }
              f() {
                let t4 = this.bb.__offset(this.bb_pos, 10);
                return t4 ? this.bb.readFloat32(this.bb_pos + t4) : 0;
              }
              i() {
                let t4 = this.bb.__offset(this.bb_pos, 12);
                return t4 ? this.bb.readInt64(this.bb_pos + t4) : this.bb.createLong(0, 0);
              }
              s(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 14);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              t(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 16);
                return n3 ? (e4 || new t3.experimental.fbs.Tensor()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              g(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 18);
                return n3 ? (e4 || new t3.experimental.fbs.Graph()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              floats(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 20);
                return e4 ? this.bb.readFloat32(this.bb.__vector(this.bb_pos + e4) + 4 * t4) : 0;
              }
              floatsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 20);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              floatsArray() {
                let t4 = this.bb.__offset(this.bb_pos, 20);
                return t4 ? new Float32Array(this.bb.bytes().buffer, this.bb.bytes().byteOffset + this.bb.__vector(this.bb_pos + t4), this.bb.__vector_len(this.bb_pos + t4)) : null;
              }
              ints(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 22);
                return e4 ? this.bb.readInt64(this.bb.__vector(this.bb_pos + e4) + 8 * t4) : this.bb.createLong(0, 0);
              }
              intsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 22);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              strings(t4, e4) {
                let n3 = this.bb.__offset(this.bb_pos, 24);
                return n3 ? this.bb.__string(this.bb.__vector(this.bb_pos + n3) + 4 * t4, e4) : null;
              }
              stringsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 24);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              tensors(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 26);
                return r2 ? (n3 || new t3.experimental.fbs.Tensor()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              tensorsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 26);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              graphs(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 28);
                return r2 ? (n3 || new t3.experimental.fbs.Graph()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              graphsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 28);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              static startAttribute(t4) {
                t4.startObject(13);
              }
              static addName(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addDocString(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static addType(e4, n3) {
                e4.addFieldInt32(2, n3, t3.experimental.fbs.AttributeType.UNDEFINED);
              }
              static addF(t4, e4) {
                t4.addFieldFloat32(3, e4, 0);
              }
              static addI(t4, e4) {
                t4.addFieldInt64(4, e4, t4.createLong(0, 0));
              }
              static addS(t4, e4) {
                t4.addFieldOffset(5, e4, 0);
              }
              static addT(t4, e4) {
                t4.addFieldOffset(6, e4, 0);
              }
              static addG(t4, e4) {
                t4.addFieldOffset(7, e4, 0);
              }
              static addFloats(t4, e4) {
                t4.addFieldOffset(8, e4, 0);
              }
              static createFloatsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addFloat32(e4[n3]);
                return t4.endVector();
              }
              static startFloatsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addInts(t4, e4) {
                t4.addFieldOffset(9, e4, 0);
              }
              static createIntsVector(t4, e4) {
                t4.startVector(8, e4.length, 8);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addInt64(e4[n3]);
                return t4.endVector();
              }
              static startIntsVector(t4, e4) {
                t4.startVector(8, e4, 8);
              }
              static addStrings(t4, e4) {
                t4.addFieldOffset(10, e4, 0);
              }
              static createStringsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startStringsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addTensors(t4, e4) {
                t4.addFieldOffset(11, e4, 0);
              }
              static createTensorsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startTensorsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addGraphs(t4, e4) {
                t4.addFieldOffset(12, e4, 0);
              }
              static createGraphsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startGraphsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static endAttribute(t4) {
                return t4.endObject();
              }
              static createAttribute(t4, e4, r2, i3, o2, a, s, u, c, l, p, f, d, h) {
                return n2.startAttribute(t4), n2.addName(t4, e4), n2.addDocString(t4, r2), n2.addType(t4, i3), n2.addF(t4, o2), n2.addI(t4, a), n2.addS(t4, s), n2.addT(t4, u), n2.addG(t4, c), n2.addFloats(t4, l), n2.addInts(t4, p), n2.addStrings(t4, f), n2.addTensors(t4, d), n2.addGraphs(t4, h), n2.endAttribute(t4);
              }
            }
            e3.Attribute = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsGraph(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsGraph(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              initializers(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 4);
                return r2 ? (n3 || new t3.experimental.fbs.Tensor()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              initializersLength() {
                let t4 = this.bb.__offset(this.bb_pos, 4);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              nodeArgs(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 6);
                return r2 ? (n3 || new t3.experimental.fbs.ValueInfo()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              nodeArgsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 6);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              nodes(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 8);
                return r2 ? (n3 || new t3.experimental.fbs.Node()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              nodesLength() {
                let t4 = this.bb.__offset(this.bb_pos, 8);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              maxNodeIndex() {
                let t4 = this.bb.__offset(this.bb_pos, 10);
                return t4 ? this.bb.readUint32(this.bb_pos + t4) : 0;
              }
              nodeEdges(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 12);
                return r2 ? (n3 || new t3.experimental.fbs.NodeEdge()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              nodeEdgesLength() {
                let t4 = this.bb.__offset(this.bb_pos, 12);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              inputs(t4, e4) {
                let n3 = this.bb.__offset(this.bb_pos, 14);
                return n3 ? this.bb.__string(this.bb.__vector(this.bb_pos + n3) + 4 * t4, e4) : null;
              }
              inputsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 14);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              outputs(t4, e4) {
                let n3 = this.bb.__offset(this.bb_pos, 16);
                return n3 ? this.bb.__string(this.bb.__vector(this.bb_pos + n3) + 4 * t4, e4) : null;
              }
              outputsLength() {
                let t4 = this.bb.__offset(this.bb_pos, 16);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              sparseInitializers(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 18);
                return r2 ? (n3 || new t3.experimental.fbs.SparseTensor()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              sparseInitializersLength() {
                let t4 = this.bb.__offset(this.bb_pos, 18);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              static startGraph(t4) {
                t4.startObject(8);
              }
              static addInitializers(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static createInitializersVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startInitializersVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addNodeArgs(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static createNodeArgsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startNodeArgsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addNodes(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static createNodesVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startNodesVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addMaxNodeIndex(t4, e4) {
                t4.addFieldInt32(3, e4, 0);
              }
              static addNodeEdges(t4, e4) {
                t4.addFieldOffset(4, e4, 0);
              }
              static createNodeEdgesVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startNodeEdgesVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addInputs(t4, e4) {
                t4.addFieldOffset(5, e4, 0);
              }
              static createInputsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startInputsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addOutputs(t4, e4) {
                t4.addFieldOffset(6, e4, 0);
              }
              static createOutputsVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startOutputsVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addSparseInitializers(t4, e4) {
                t4.addFieldOffset(7, e4, 0);
              }
              static createSparseInitializersVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startSparseInitializersVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static endGraph(t4) {
                return t4.endObject();
              }
              static createGraph(t4, e4, r2, i3, o2, a, s, u, c) {
                return n2.startGraph(t4), n2.addInitializers(t4, e4), n2.addNodeArgs(t4, r2), n2.addNodes(t4, i3), n2.addMaxNodeIndex(t4, o2), n2.addNodeEdges(t4, a), n2.addInputs(t4, s), n2.addOutputs(t4, u), n2.addSparseInitializers(t4, c), n2.endGraph(t4);
              }
            }
            e3.Graph = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsModel(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsModel(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              irVersion() {
                let t4 = this.bb.__offset(this.bb_pos, 4);
                return t4 ? this.bb.readInt64(this.bb_pos + t4) : this.bb.createLong(0, 0);
              }
              opsetImport(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 6);
                return r2 ? (n3 || new t3.experimental.fbs.OperatorSetId()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              opsetImportLength() {
                let t4 = this.bb.__offset(this.bb_pos, 6);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              producerName(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 8);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              producerVersion(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 10);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              domain(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 12);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              modelVersion() {
                let t4 = this.bb.__offset(this.bb_pos, 14);
                return t4 ? this.bb.readInt64(this.bb_pos + t4) : this.bb.createLong(0, 0);
              }
              docString(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 16);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              graph(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 18);
                return n3 ? (e4 || new t3.experimental.fbs.Graph()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              graphDocString(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 20);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              static startModel(t4) {
                t4.startObject(9);
              }
              static addIrVersion(t4, e4) {
                t4.addFieldInt64(0, e4, t4.createLong(0, 0));
              }
              static addOpsetImport(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static createOpsetImportVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startOpsetImportVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static addProducerName(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static addProducerVersion(t4, e4) {
                t4.addFieldOffset(3, e4, 0);
              }
              static addDomain(t4, e4) {
                t4.addFieldOffset(4, e4, 0);
              }
              static addModelVersion(t4, e4) {
                t4.addFieldInt64(5, e4, t4.createLong(0, 0));
              }
              static addDocString(t4, e4) {
                t4.addFieldOffset(6, e4, 0);
              }
              static addGraph(t4, e4) {
                t4.addFieldOffset(7, e4, 0);
              }
              static addGraphDocString(t4, e4) {
                t4.addFieldOffset(8, e4, 0);
              }
              static endModel(t4) {
                return t4.endObject();
              }
              static createModel(t4, e4, r2, i3, o2, a, s, u, c, l) {
                return n2.startModel(t4), n2.addIrVersion(t4, e4), n2.addOpsetImport(t4, r2), n2.addProducerName(t4, i3), n2.addProducerVersion(t4, o2), n2.addDomain(t4, a), n2.addModelVersion(t4, s), n2.addDocString(t4, u), n2.addGraph(t4, c), n2.addGraphDocString(t4, l), n2.endModel(t4);
              }
            }
            e3.Model = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(t4) {
          !function(t5) {
            class e2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t6, e3) {
                return this.bb_pos = t6, this.bb = e3, this;
              }
              static getRootAsKernelCreateInfos(t6, n2) {
                return (n2 || new e2()).__init(t6.readInt32(t6.position()) + t6.position(), t6);
              }
              static getSizePrefixedRootAsKernelCreateInfos(t6, n2) {
                return t6.setPosition(t6.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (n2 || new e2()).__init(t6.readInt32(t6.position()) + t6.position(), t6);
              }
              nodeIndices(t6) {
                let e3 = this.bb.__offset(this.bb_pos, 4);
                return e3 ? this.bb.readUint32(this.bb.__vector(this.bb_pos + e3) + 4 * t6) : 0;
              }
              nodeIndicesLength() {
                let t6 = this.bb.__offset(this.bb_pos, 4);
                return t6 ? this.bb.__vector_len(this.bb_pos + t6) : 0;
              }
              nodeIndicesArray() {
                let t6 = this.bb.__offset(this.bb_pos, 4);
                return t6 ? new Uint32Array(this.bb.bytes().buffer, this.bb.bytes().byteOffset + this.bb.__vector(this.bb_pos + t6), this.bb.__vector_len(this.bb_pos + t6)) : null;
              }
              kernelDefHashes(t6) {
                let e3 = this.bb.__offset(this.bb_pos, 6);
                return e3 ? this.bb.readUint64(this.bb.__vector(this.bb_pos + e3) + 8 * t6) : this.bb.createLong(0, 0);
              }
              kernelDefHashesLength() {
                let t6 = this.bb.__offset(this.bb_pos, 6);
                return t6 ? this.bb.__vector_len(this.bb_pos + t6) : 0;
              }
              static startKernelCreateInfos(t6) {
                t6.startObject(2);
              }
              static addNodeIndices(t6, e3) {
                t6.addFieldOffset(0, e3, 0);
              }
              static createNodeIndicesVector(t6, e3) {
                t6.startVector(4, e3.length, 4);
                for (let n2 = e3.length - 1; n2 >= 0; n2--) t6.addInt32(e3[n2]);
                return t6.endVector();
              }
              static startNodeIndicesVector(t6, e3) {
                t6.startVector(4, e3, 4);
              }
              static addKernelDefHashes(t6, e3) {
                t6.addFieldOffset(1, e3, 0);
              }
              static createKernelDefHashesVector(t6, e3) {
                t6.startVector(8, e3.length, 8);
                for (let n2 = e3.length - 1; n2 >= 0; n2--) t6.addInt64(e3[n2]);
                return t6.endVector();
              }
              static startKernelDefHashesVector(t6, e3) {
                t6.startVector(8, e3, 8);
              }
              static endKernelCreateInfos(t6) {
                return t6.endObject();
              }
              static createKernelCreateInfos(t6, n2, r2) {
                return e2.startKernelCreateInfos(t6), e2.addNodeIndices(t6, n2), e2.addKernelDefHashes(t6, r2), e2.endKernelCreateInfos(t6);
              }
            }
            t5.KernelCreateInfos = e2;
          }(t4.fbs || (t4.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsSubGraphSessionState(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsSubGraphSessionState(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              graphId(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              sessionState(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 6);
                return n3 ? (e4 || new t3.experimental.fbs.SessionState()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              static startSubGraphSessionState(t4) {
                t4.startObject(2);
              }
              static addGraphId(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addSessionState(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static endSubGraphSessionState(t4) {
                let e4 = t4.endObject();
                return t4.requiredField(e4, 4), e4;
              }
              static createSubGraphSessionState(t4, e4, r2) {
                return n2.startSubGraphSessionState(t4), n2.addGraphId(t4, e4), n2.addSessionState(t4, r2), n2.endSubGraphSessionState(t4);
              }
            }
            e3.SubGraphSessionState = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsSessionState(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsSessionState(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              kernels(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 4);
                return n3 ? (e4 || new t3.experimental.fbs.KernelCreateInfos()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              subGraphSessionStates(e4, n3) {
                let r2 = this.bb.__offset(this.bb_pos, 6);
                return r2 ? (n3 || new t3.experimental.fbs.SubGraphSessionState()).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + r2) + 4 * e4), this.bb) : null;
              }
              subGraphSessionStatesLength() {
                let t4 = this.bb.__offset(this.bb_pos, 6);
                return t4 ? this.bb.__vector_len(this.bb_pos + t4) : 0;
              }
              static startSessionState(t4) {
                t4.startObject(2);
              }
              static addKernels(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addSubGraphSessionStates(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static createSubGraphSessionStatesVector(t4, e4) {
                t4.startVector(4, e4.length, 4);
                for (let n3 = e4.length - 1; n3 >= 0; n3--) t4.addOffset(e4[n3]);
                return t4.endVector();
              }
              static startSubGraphSessionStatesVector(t4, e4) {
                t4.startVector(4, e4, 4);
              }
              static endSessionState(t4) {
                return t4.endObject();
              }
              static createSessionState(t4, e4, r2) {
                return n2.startSessionState(t4), n2.addKernels(t4, e4), n2.addSubGraphSessionStates(t4, r2), n2.endSessionState(t4);
              }
            }
            e3.SessionState = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {})), function(t3) {
        !function(e2) {
          !function(e3) {
            class n2 {
              constructor() {
                this.bb = null, this.bb_pos = 0;
              }
              __init(t4, e4) {
                return this.bb_pos = t4, this.bb = e4, this;
              }
              static getRootAsInferenceSession(t4, e4) {
                return (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static getSizePrefixedRootAsInferenceSession(t4, e4) {
                return t4.setPosition(t4.position() + r.flatbuffers.SIZE_PREFIX_LENGTH), (e4 || new n2()).__init(t4.readInt32(t4.position()) + t4.position(), t4);
              }
              static bufferHasIdentifier(t4) {
                return t4.__has_identifier("ORTM");
              }
              ortVersion(t4) {
                let e4 = this.bb.__offset(this.bb_pos, 4);
                return e4 ? this.bb.__string(this.bb_pos + e4, t4) : null;
              }
              model(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 6);
                return n3 ? (e4 || new t3.experimental.fbs.Model()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              sessionState(e4) {
                let n3 = this.bb.__offset(this.bb_pos, 8);
                return n3 ? (e4 || new t3.experimental.fbs.SessionState()).__init(this.bb.__indirect(this.bb_pos + n3), this.bb) : null;
              }
              static startInferenceSession(t4) {
                t4.startObject(3);
              }
              static addOrtVersion(t4, e4) {
                t4.addFieldOffset(0, e4, 0);
              }
              static addModel(t4, e4) {
                t4.addFieldOffset(1, e4, 0);
              }
              static addSessionState(t4, e4) {
                t4.addFieldOffset(2, e4, 0);
              }
              static endInferenceSession(t4) {
                return t4.endObject();
              }
              static finishInferenceSessionBuffer(t4, e4) {
                t4.finish(e4, "ORTM");
              }
              static finishSizePrefixedInferenceSessionBuffer(t4, e4) {
                t4.finish(e4, "ORTM", true);
              }
              static createInferenceSession(t4, e4, r2, i3) {
                return n2.startInferenceSession(t4), n2.addOrtVersion(t4, e4), n2.addModel(t4, r2), n2.addSessionState(t4, i3), n2.endInferenceSession(t4);
              }
            }
            e3.InferenceSession = n2;
          }(e2.fbs || (e2.fbs = {}));
        }(t3.experimental || (t3.experimental = {}));
      }(e.onnxruntime || (e.onnxruntime = {}));
    }, 7448: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.OnnxjsSessionHandler = void 0;
      const r = n(6207), i2 = n(9162);
      e.OnnxjsSessionHandler = class {
        constructor(t3) {
          this.session = t3, this.inputNames = this.session.inputNames, this.outputNames = this.session.outputNames;
        }
        async dispose() {
        }
        async run(t3, e2, n2) {
          const o = /* @__PURE__ */ new Map();
          for (const e3 in t3) if (Object.hasOwnProperty.call(t3, e3)) {
            const n3 = t3[e3];
            o.set(e3, new i2.Tensor(n3.dims, n3.type, void 0, void 0, n3.data));
          }
          const a = await this.session.run(o), s = {};
          return a.forEach((t4, e3) => {
            s[e3] = new r.Tensor(t4.type, t4.data, t4.dims);
          }), s;
        }
        startProfiling() {
          this.session.startProfiling();
        }
        endProfiling() {
          this.session.endProfiling();
        }
      };
    }, 6919: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.Session = void 0;
      const r = n(6231), i2 = n(6464), o = n(7091), a = n(1036), s = n(3694), u = n(2644);
      e.Session = class {
        constructor(t3 = {}) {
          this._initialized = false, this.backendHint = t3.backendHint, this.profiler = s.Profiler.create(t3.profiler), this.context = { profiler: this.profiler, graphInputTypes: [], graphInputDims: [] };
        }
        get inputNames() {
          return this._model.graph.getInputNames();
        }
        get outputNames() {
          return this._model.graph.getOutputNames();
        }
        startProfiling() {
          this.profiler.start();
        }
        endProfiling() {
          this.profiler.stop();
        }
        async loadModel(t3, e2, n2) {
          await this.profiler.event("session", "Session.loadModel", async () => {
            const a2 = await (0, o.resolveBackend)(this.backendHint);
            if (this.sessionHandler = a2.createSessionHandler(this.context), this._model = new u.Model(), "string" == typeof t3) {
              const e3 = t3.endsWith(".ort");
              if ("undefined" == typeof fetch) {
                const n3 = await (0, i2.promisify)(r.readFile)(t3);
                this.initialize(n3, e3);
              } else {
                const n3 = await fetch(t3), r2 = await n3.arrayBuffer();
                this.initialize(new Uint8Array(r2), e3);
              }
            } else if (ArrayBuffer.isView(t3)) this.initialize(t3);
            else {
              const r2 = new Uint8Array(t3, e2 || 0, n2 || t3.byteLength);
              this.initialize(r2);
            }
          });
        }
        initialize(t3, e2) {
          if (this._initialized) throw new Error("already initialized");
          this.profiler.event("session", "Session.initialize", () => {
            const n2 = this.sessionHandler.transformGraph ? this.sessionHandler : void 0;
            this._model.load(t3, n2, e2), this.sessionHandler.onGraphInitialized && this.sessionHandler.onGraphInitialized(this._model.graph), this.initializeOps(this._model.graph), this._executionPlan = new a.ExecutionPlan(this._model.graph, this._ops, this.profiler);
          }), this._initialized = true;
        }
        async run(t3) {
          if (!this._initialized) throw new Error("session not initialized yet");
          return this.profiler.event("session", "Session.run", async () => {
            const e2 = this.normalizeAndValidateInputs(t3), n2 = await this._executionPlan.execute(this.sessionHandler, e2);
            return this.createOutput(n2);
          });
        }
        normalizeAndValidateInputs(t3) {
          const e2 = this._model.graph.getInputNames();
          if (Array.isArray(t3)) {
            if (t3.length !== e2.length) throw new Error(`incorrect input array length: expected ${e2.length} but got ${t3.length}`);
          } else {
            if (t3.size !== e2.length) throw new Error(`incorrect input map size: expected ${e2.length} but got ${t3.size}`);
            const n2 = new Array(t3.size);
            let r2 = 0;
            for (let i3 = 0; i3 < e2.length; ++i3) {
              const o2 = t3.get(e2[i3]);
              if (!o2) throw new Error(`missing input tensor for: '${name}'`);
              n2[r2++] = o2;
            }
            t3 = n2;
          }
          if (this.context.graphInputTypes && 0 !== this.context.graphInputTypes.length && this.context.graphInputDims && 0 !== this.context.graphInputDims.length) this.validateInputTensorDims(this.context.graphInputDims, t3, false);
          else {
            const e3 = this._model.graph.getInputIndices(), n2 = this._model.graph.getValues(), r2 = new Array(e3.length);
            for (let i3 = 0; i3 < e3.length; ++i3) {
              const o2 = n2[e3[i3]];
              r2[i3] = o2.type.shape.dims, this.context.graphInputTypes.push(o2.type.tensorType), this.context.graphInputDims.push(t3[i3].dims);
            }
            this.validateInputTensorDims(r2, t3, true);
          }
          return this.validateInputTensorTypes(this.context.graphInputTypes, t3), t3;
        }
        validateInputTensorTypes(t3, e2) {
          for (let n2 = 0; n2 < e2.length; n2++) {
            const r2 = t3[n2], i3 = e2[n2].type;
            if (r2 !== i3) throw new Error(`input tensor[${n2}] check failed: expected type '${r2}' but got ${i3}`);
          }
        }
        validateInputTensorDims(t3, e2, n2) {
          for (let r2 = 0; r2 < e2.length; r2++) {
            const i3 = t3[r2], o2 = e2[r2].dims;
            if (!this.compareTensorDims(i3, o2, n2)) throw new Error(`input tensor[${r2}] check failed: expected shape '[${i3.join(",")}]' but got [${o2.join(",")}]`);
          }
        }
        compareTensorDims(t3, e2, n2) {
          if (t3.length !== e2.length) return false;
          for (let r2 = 0; r2 < t3.length; ++r2) if (t3[r2] !== e2[r2] && (!n2 || 0 !== t3[r2])) return false;
          return true;
        }
        createOutput(t3) {
          const e2 = this._model.graph.getOutputNames();
          if (t3.length !== e2.length) throw new Error("expected number of outputs do not match number of generated outputs");
          const n2 = /* @__PURE__ */ new Map();
          for (let r2 = 0; r2 < e2.length; ++r2) n2.set(e2[r2], t3[r2]);
          return n2;
        }
        initializeOps(t3) {
          const e2 = t3.getNodes();
          this._ops = new Array(e2.length);
          for (let n2 = 0; n2 < e2.length; n2++) this._ops[n2] = this.sessionHandler.resolve(e2[n2], this._model.opsets, t3);
        }
      };
    }, 9162: function(t2, e, n) {
      var r = this && this.__importDefault || function(t3) {
        return t3 && t3.__esModule ? t3 : { default: t3 };
      };
      Object.defineProperty(e, "__esModule", { value: true }), e.Tensor = void 0;
      const i2 = n(3442), o = r(n(3720)), a = n(1446), s = n(9395), u = n(2517);
      var c = s.onnxruntime.experimental.fbs;
      class l {
        get data() {
          if (void 0 === this.cache) {
            const t3 = this.dataProvider(this.dataId);
            if (t3.length !== this.size) throw new Error("Length of data provided by the Data Provider is inconsistent with the dims of this Tensor.");
            this.cache = t3;
          }
          return this.cache;
        }
        get stringData() {
          if ("string" !== this.type) throw new TypeError("data type is not string");
          return this.data;
        }
        get integerData() {
          switch (this.type) {
            case "uint8":
            case "int8":
            case "uint16":
            case "int16":
            case "int32":
            case "uint32":
            case "bool":
              return this.data;
            default:
              throw new TypeError("data type is not integer (uint8, int8, uint16, int16, int32, uint32, bool)");
          }
        }
        get floatData() {
          switch (this.type) {
            case "float32":
            case "float64":
              return this.data;
            default:
              throw new TypeError("data type is not float (float32, float64)");
          }
        }
        get numberData() {
          if ("string" !== this.type) return this.data;
          throw new TypeError("type cannot be non-number (string)");
        }
        get(t3) {
          return this.data[u.ShapeUtil.indicesToOffset(t3, this.strides)];
        }
        set(t3, e2) {
          this.data[u.ShapeUtil.indicesToOffset(t3, this.strides)] = e2;
        }
        async getData() {
          return void 0 === this.cache && (this.cache = await this.asyncDataProvider(this.dataId)), this.cache;
        }
        get strides() {
          return this._strides || (this._strides = u.ShapeUtil.computeStrides(this.dims)), this._strides;
        }
        constructor(t3, e2, n2, r2, o2, a2 = i2.Guid.create()) {
          this.dims = t3, this.type = e2, this.dataProvider = n2, this.asyncDataProvider = r2, this.cache = o2, this.dataId = a2, this.size = u.ShapeUtil.validateDimsAndCalcSize(t3);
          const s2 = this.size, c2 = void 0 === n2 && void 0 === r2 && void 0 === o2;
          if (void 0 !== o2 && o2.length !== s2) throw new RangeError("Input dims doesn't match data length.");
          if ("string" === e2) {
            if (!(void 0 === o2 || Array.isArray(o2) && o2.every((t4) => "string" == typeof t4))) throw new TypeError("cache should be a string array");
            c2 && (this.cache = new Array(s2));
          } else {
            if (void 0 !== o2) {
              const t4 = f(e2);
              if (!(o2 instanceof t4)) throw new TypeError(`cache should be type ${t4.name}`);
            }
            if (c2) {
              const t4 = new ArrayBuffer(s2 * function(t5) {
                switch (t5) {
                  case "bool":
                  case "int8":
                  case "uint8":
                    return 1;
                  case "int16":
                  case "uint16":
                    return 2;
                  case "int32":
                  case "uint32":
                  case "float32":
                    return 4;
                  case "float64":
                    return 8;
                  default:
                    throw new Error(`cannot calculate sizeof() on type ${t5}`);
                }
              }(e2));
              this.cache = function(t5, e3) {
                return new (f(e3))(t5);
              }(t4, e2);
            }
          }
        }
        static fromProto(t3) {
          if (!t3) throw new Error("cannot construct Value from an empty tensor");
          const e2 = u.ProtoUtil.tensorDataTypeFromProto(t3.dataType), n2 = u.ProtoUtil.tensorDimsFromProto(t3.dims), r2 = new l(n2, e2);
          if ("string" === e2) t3.stringData.forEach((t4, e3) => {
            r2.data[e3] = (0, u.decodeUtf8String)(t4);
          });
          else if (t3.rawData && "number" == typeof t3.rawData.byteLength && t3.rawData.byteLength > 0) {
            const e3 = r2.data, n3 = new DataView(t3.rawData.buffer, t3.rawData.byteOffset, t3.rawData.byteLength), i3 = p(t3.dataType), o2 = t3.rawData.byteLength / i3;
            if (t3.rawData.byteLength % i3 != 0) throw new Error("invalid buffer length");
            if (e3.length !== o2) throw new Error("buffer length mismatch");
            for (let r3 = 0; r3 < o2; r3++) {
              const o3 = h(n3, t3.dataType, r3 * i3);
              e3[r3] = o3;
            }
          } else {
            let e3;
            switch (t3.dataType) {
              case a.onnx.TensorProto.DataType.FLOAT:
                e3 = t3.floatData;
                break;
              case a.onnx.TensorProto.DataType.INT32:
              case a.onnx.TensorProto.DataType.INT16:
              case a.onnx.TensorProto.DataType.UINT16:
              case a.onnx.TensorProto.DataType.INT8:
              case a.onnx.TensorProto.DataType.UINT8:
              case a.onnx.TensorProto.DataType.BOOL:
                e3 = t3.int32Data;
                break;
              case a.onnx.TensorProto.DataType.INT64:
                e3 = t3.int64Data;
                break;
              case a.onnx.TensorProto.DataType.DOUBLE:
                e3 = t3.doubleData;
                break;
              case a.onnx.TensorProto.DataType.UINT32:
              case a.onnx.TensorProto.DataType.UINT64:
                e3 = t3.uint64Data;
                break;
              default:
                throw new Error("unspecific error");
            }
            if (null == e3) throw new Error("failed to populate data from a tensorproto value");
            const n3 = r2.data;
            if (n3.length !== e3.length) throw new Error("array length mismatch");
            for (let r3 = 0; r3 < e3.length; r3++) {
              const i3 = e3[r3];
              o.default.isLong(i3) ? n3[r3] = d(i3, t3.dataType) : n3[r3] = i3;
            }
          }
          return r2;
        }
        static fromData(t3, e2, n2) {
          return new l(e2, n2, void 0, void 0, t3);
        }
        static fromOrtTensor(t3) {
          if (!t3) throw new Error("cannot construct Value from an empty tensor");
          const e2 = u.ProtoUtil.tensorDimsFromORTFormat(t3), n2 = u.ProtoUtil.tensorDataTypeFromProto(t3.dataType()), r2 = new l(e2, n2);
          if ("string" === n2) for (let e3 = 0; e3 < t3.stringDataLength(); e3++) r2.data[e3] = t3.stringData(e3);
          else if (t3.rawDataArray() && "number" == typeof t3.rawDataLength() && t3.rawDataLength() > 0) {
            const e3 = r2.data, n3 = new DataView(t3.rawDataArray().buffer, t3.rawDataArray().byteOffset, t3.rawDataLength()), i3 = p(t3.dataType()), o2 = t3.rawDataLength() / i3;
            if (t3.rawDataLength() % i3 != 0) throw new Error("invalid buffer length");
            if (e3.length !== o2) throw new Error("buffer length mismatch");
            for (let r3 = 0; r3 < o2; r3++) {
              const o3 = h(n3, t3.dataType(), r3 * i3);
              e3[r3] = o3;
            }
          }
          return r2;
        }
      }
      function p(t3) {
        switch (t3) {
          case a.onnx.TensorProto.DataType.UINT8:
          case a.onnx.TensorProto.DataType.INT8:
          case a.onnx.TensorProto.DataType.BOOL:
            return 1;
          case a.onnx.TensorProto.DataType.UINT16:
          case a.onnx.TensorProto.DataType.INT16:
            return 2;
          case a.onnx.TensorProto.DataType.FLOAT:
          case a.onnx.TensorProto.DataType.INT32:
          case a.onnx.TensorProto.DataType.UINT32:
            return 4;
          case a.onnx.TensorProto.DataType.INT64:
          case a.onnx.TensorProto.DataType.DOUBLE:
          case a.onnx.TensorProto.DataType.UINT64:
            return 8;
          default:
            throw new Error(`cannot calculate sizeof() on type ${a.onnx.TensorProto.DataType[t3]}`);
        }
      }
      function f(t3) {
        switch (t3) {
          case "bool":
          case "uint8":
            return Uint8Array;
          case "int8":
            return Int8Array;
          case "int16":
            return Int16Array;
          case "uint16":
            return Uint16Array;
          case "int32":
            return Int32Array;
          case "uint32":
            return Uint32Array;
          case "float32":
            return Float32Array;
          case "float64":
            return Float64Array;
          default:
            throw new Error("unspecified error");
        }
      }
      function d(t3, e2) {
        if (e2 === a.onnx.TensorProto.DataType.INT64 || e2 === c.TensorDataType.INT64) {
          if (t3.greaterThanOrEqual(2147483648) || t3.lessThan(-2147483648)) throw new TypeError("int64 is not supported");
        } else {
          if (e2 !== a.onnx.TensorProto.DataType.UINT32 && e2 !== c.TensorDataType.UINT32 && e2 !== a.onnx.TensorProto.DataType.UINT64 && e2 !== c.TensorDataType.UINT64) throw new TypeError(`not a LONG type: ${a.onnx.TensorProto.DataType[e2]}`);
          if (t3.greaterThanOrEqual(4294967296) || t3.lessThan(0)) throw new TypeError("uint64 is not supported");
        }
        return t3.toNumber();
      }
      function h(t3, e2, n2) {
        switch (e2) {
          case a.onnx.TensorProto.DataType.BOOL:
          case a.onnx.TensorProto.DataType.UINT8:
            return t3.getUint8(n2);
          case a.onnx.TensorProto.DataType.INT8:
            return t3.getInt8(n2);
          case a.onnx.TensorProto.DataType.UINT16:
            return t3.getUint16(n2, true);
          case a.onnx.TensorProto.DataType.INT16:
            return t3.getInt16(n2, true);
          case a.onnx.TensorProto.DataType.FLOAT:
            return t3.getFloat32(n2, true);
          case a.onnx.TensorProto.DataType.INT32:
            return t3.getInt32(n2, true);
          case a.onnx.TensorProto.DataType.UINT32:
            return t3.getUint32(n2, true);
          case a.onnx.TensorProto.DataType.INT64:
            return d(o.default.fromBits(t3.getUint32(n2, true), t3.getUint32(n2 + 4, true), false), e2);
          case a.onnx.TensorProto.DataType.DOUBLE:
            return t3.getFloat64(n2, true);
          case a.onnx.TensorProto.DataType.UINT64:
            return d(o.default.fromBits(t3.getUint32(n2, true), t3.getUint32(n2 + 4, true), true), e2);
          default:
            throw new Error(`cannot read from DataView for type ${a.onnx.TensorProto.DataType[e2]}`);
        }
      }
      e.Tensor = l;
    }, 2517: function(t2, e, n) {
      var r = this && this.__importDefault || function(t3) {
        return t3 && t3.__esModule ? t3 : { default: t3 };
      };
      Object.defineProperty(e, "__esModule", { value: true }), e.decodeUtf8String = e.MAX_CLIP = e.MIN_CLIP = e.PoolConvUtil = e.ReduceUtil = e.SplitUtil = e.MathUtil = e.ShapeUtil = e.LongUtil = e.ProtoUtil = e.GemmUtil = e.arrayCopyHelper = e.BroadcastUtil = e.MatMulUtil = e.ArrayUtil = e.assert = e.checkInputsShape = void 0;
      const i2 = n(5686), o = r(n(3720)), a = n(1446), s = n(9162);
      e.checkInputsShape = function(t3, ...e2) {
        if (!t3 || t3.length !== e2.length) return false;
        for (let n2 = 0; n2 < t3.length; n2++) if (!t3[n2].dims || t3[n2].dims.length !== e2[n2]) return false;
        return true;
      }, e.assert = function(t3, e2) {
        if (!t3) throw new Error("string" == typeof e2 ? e2 : e2());
      }, e.ArrayUtil = class {
        static arraysEqual(t3, e2) {
          if (t3.length !== e2.length) return false;
          for (let n2 = 0; n2 < t3.length; n2++) if (t3[n2] !== e2[n2]) return false;
          return true;
        }
      };
      class u {
        static preprocessInputShapes(t3, e2) {
          return [1 === t3.length ? [1, t3[0]] : t3, 1 === e2.length ? [e2[0], 1] : e2];
        }
        static postprocessOutputShape(t3, e2, n2) {
          1 === e2 && t3.splice(t3.length - 2, 1), 1 === n2 && t3.pop();
        }
        static calcMatMulShape(t3, e2) {
          return t3[1] !== e2[0] ? void 0 : [t3[0], e2[1]];
        }
      }
      e.MatMulUtil = u;
      class c {
        static calcShape(t3, e2, n2 = false) {
          const r2 = t3.length, i3 = e2.length;
          if (0 === r2) return e2;
          if (0 === i3) return t3;
          const o2 = Math.max(t3.length, e2.length), a2 = new Array(o2);
          if (n2) {
            if (r2 < 2 || i3 < 2) return;
            const n3 = u.calcMatMulShape([t3[r2 - 2], t3[r2 - 1]], [e2[i3 - 2], e2[i3 - 1]]);
            if (void 0 === n3) return;
            [a2[o2 - 2], a2[o2 - 1]] = n3;
          }
          for (let s2 = n2 ? 3 : 1; s2 <= o2; s2++) {
            const n3 = r2 - s2 < 0 ? 1 : t3[r2 - s2], u2 = i3 - s2 < 0 ? 1 : e2[i3 - s2];
            if (n3 !== u2 && n3 > 1 && u2 > 1) return;
            a2[o2 - s2] = Math.max(n3, u2);
          }
          return a2;
        }
        static index(t3, e2) {
          const n2 = new Array(e2.length);
          return c.fillIndex(t3, e2, n2), n2;
        }
        static fillIndex(t3, e2, n2) {
          const r2 = t3.length - e2.length;
          for (let i3 = 0; i3 < e2.length; i3++) n2[i3] = t3[r2 + i3] % e2[i3];
        }
        static calc(t3, e2, n2, r2, i3) {
          const o2 = c.calcShape(t3.dims, e2.dims);
          if (o2) {
            if (r2 && !f.areEqual(o2, t3.dims)) return;
            const a2 = f.size(o2), u2 = r2 ? t3 : new s.Tensor(o2, i3 || t3.type);
            if (0 === o2.length) u2.set([], n2(t3.get([]), e2.get([])));
            else {
              const r3 = new Array(o2.length), i4 = new Array(t3.dims.length), s2 = new Array(e2.dims.length);
              let l2, p2 = 0, f2 = 0, d2 = false, h2 = false;
              0 === t3.dims.length && (p2 = t3.get([]), d2 = true), 0 === e2.dims.length && (f2 = e2.get([]), h2 = true);
              for (let g2 = 0; g2 < a2; g2++) {
                l2 = g2;
                for (let t4 = o2.length - 1; t4 >= 0; t4--) r3[t4] = l2 % o2[t4], l2 = Math.floor(l2 / o2[t4]);
                d2 || (c.fillIndex(r3, t3.dims, i4), p2 = t3.get(i4)), h2 || (c.fillIndex(r3, e2.dims, s2), f2 = e2.get(s2)), u2.set(r3, n2(p2, f2));
              }
            }
            return u2;
          }
        }
        static isValidBroadcast(t3, e2) {
          const n2 = t3.length, r2 = e2.length;
          if (n2 > r2) return false;
          for (let i3 = 1; i3 <= n2; i3++) if (1 !== t3[n2 - i3] && t3[n2 - i3] !== e2[r2 - i3]) return false;
          return true;
        }
        static getBroadcastDims(t3, e2) {
          const n2 = t3.length, r2 = [];
          for (let i3 = 0; i3 < n2; i3++) {
            const o2 = n2 - 1 - i3, a2 = t3[o2] || 1;
            (e2[e2.length - 1 - i3] || 1) > 1 && 1 === a2 && r2.unshift(o2);
          }
          return r2;
        }
      }
      e.BroadcastUtil = c, e.arrayCopyHelper = function(t3, e2, n2, r2, i3) {
        if (r2 < 0 || r2 >= e2.length) throw new Error("sourceIndex out of bounds");
        if (n2 < 0 || n2 >= t3.length) throw new Error("targetIndex out of bounds");
        if (r2 + i3 > e2.length) throw new Error("source indices to be copied are outside bounds");
        if (n2 + i3 > t3.length) throw new Error("target array is too small to hold result");
        for (let o2 = 0; o2 < i3; o2++) t3[n2 + o2] = e2[r2 + o2];
      }, e.GemmUtil = class {
        static getShapeOfGemmResult(t3, e2, n2, r2, i3) {
          if (2 !== t3.length || 2 !== n2.length) throw new Error("shape need to be of size 2");
          let o2, a2, s2;
          e2 ? (o2 = t3[1], a2 = t3[0]) : (o2 = t3[0], a2 = t3[1]);
          let u2 = -1;
          if (r2 ? (s2 = n2[0], u2 = 1) : (s2 = n2[1], u2 = 0), n2[u2] !== a2) throw new Error("dimension mismatch");
          if (o2 <= 0 || s2 <= 0 || a2 <= 0) throw new Error("invalid shape specified");
          if (i3 && !c.isValidBroadcast(i3, [o2, s2])) throw new Error("gemm: invalid bias shape for broadcast");
          return [o2, s2, a2];
        }
      };
      class l {
        static tensorDataTypeFromProto(t3) {
          switch (t3) {
            case a.onnx.TensorProto.DataType.INT8:
              return "int8";
            case a.onnx.TensorProto.DataType.UINT8:
              return "uint8";
            case a.onnx.TensorProto.DataType.BOOL:
              return "bool";
            case a.onnx.TensorProto.DataType.INT16:
              return "int16";
            case a.onnx.TensorProto.DataType.UINT16:
              return "uint16";
            case a.onnx.TensorProto.DataType.INT32:
              return "int32";
            case a.onnx.TensorProto.DataType.UINT32:
              return "uint32";
            case a.onnx.TensorProto.DataType.FLOAT:
              return "float32";
            case a.onnx.TensorProto.DataType.DOUBLE:
              return "float64";
            case a.onnx.TensorProto.DataType.STRING:
              return "string";
            case a.onnx.TensorProto.DataType.INT64:
              return "int32";
            case a.onnx.TensorProto.DataType.UINT64:
              return "uint32";
            default:
              throw new Error(`unsupported data type: ${a.onnx.TensorProto.DataType[t3]}`);
          }
        }
        static tensorDataTypeStringToEnum(t3) {
          switch (t3) {
            case "int8":
              return a.onnx.TensorProto.DataType.INT8;
            case "uint8":
              return a.onnx.TensorProto.DataType.UINT8;
            case "bool":
              return a.onnx.TensorProto.DataType.BOOL;
            case "int16":
              return a.onnx.TensorProto.DataType.INT16;
            case "uint16":
              return a.onnx.TensorProto.DataType.UINT16;
            case "int32":
              return a.onnx.TensorProto.DataType.INT32;
            case "uint32":
              return a.onnx.TensorProto.DataType.UINT32;
            case "float32":
              return a.onnx.TensorProto.DataType.FLOAT;
            case "float64":
              return a.onnx.TensorProto.DataType.DOUBLE;
            case "string":
              return a.onnx.TensorProto.DataType.STRING;
            case "int64":
              return a.onnx.TensorProto.DataType.INT64;
            case "uint64":
              return a.onnx.TensorProto.DataType.UINT64;
            default:
              throw new Error(`unsupported data type: ${t3}`);
          }
        }
        static tensorDimsFromProto(t3) {
          return t3.map((t4) => o.default.isLong(t4) ? t4.toNumber() : t4);
        }
        static tensorValueTypeFromProto(t3) {
          return { tensorType: l.tensorDataTypeFromProto(t3.elemType), shape: { dims: l.tensorDimsFromProto(t3.shape.dim.map((t4) => t4.dimValue)) } };
        }
        static tensorDimsFromORTFormat(t3) {
          const e2 = [];
          for (let n2 = 0; n2 < t3.dimsLength(); n2++) e2.push(p.longToNumber(t3.dims(n2)));
          return e2;
        }
        static tensorAttributesFromORTFormat(t3) {
          const e2 = [];
          for (let n2 = 0; n2 < t3.attributesLength(); n2++) e2.push(t3.attributes(n2));
          return e2;
        }
      }
      e.ProtoUtil = l;
      class p {
        static longToNumber(t3, e2) {
          return o.default.isLong(t3) ? t3.toNumber() : t3 instanceof i2.flatbuffers.Long ? o.default.fromValue({ low: t3.low, high: t3.high, unsigned: null != e2 && e2 }).toNumber() : t3;
        }
        static isLong(t3) {
          return o.default.isLong(t3) || t3 instanceof i2.flatbuffers.Long;
        }
      }
      e.LongUtil = p;
      class f {
        static size(t3) {
          return f.getSizeFromDimensionRange(t3, 0, t3.length);
        }
        static sizeFromDimension(t3, e2) {
          if (e2 < 0 || e2 > t3.length) throw new Error(`invalid dimension of ${e2} for sizeFromDimension as Tensor has ${t3.length} dimensions.`);
          return f.getSizeFromDimensionRange(t3, e2, t3.length);
        }
        static sizeToDimension(t3, e2) {
          if (e2 < 0 || e2 > t3.length) throw new Error(`invalid dimension of ${e2} for sizeToDimension as Tensor has ${t3.length} dimensions.`);
          return f.getSizeFromDimensionRange(t3, 0, e2);
        }
        static getSizeFromDimensionRange(t3, e2, n2) {
          let r2 = 1;
          for (let i3 = e2; i3 < n2; i3++) {
            if (t3[i3] <= 0) throw new Error("cannot get valid size from specified dimension range. Most likely the range contains 0 or negative values in them.");
            r2 *= t3[i3];
          }
          return r2;
        }
        static computeStrides(t3) {
          const e2 = t3.length;
          if (0 === e2) return [];
          if (1 === e2) return [1];
          const n2 = new Array(e2);
          n2[e2 - 1] = 1, n2[e2 - 2] = t3[e2 - 1];
          for (let r2 = e2 - 3; r2 >= 0; --r2) n2[r2] = n2[r2 + 1] * t3[r2 + 1];
          return n2;
        }
        static transpose(t3) {
          return t3.slice().reverse();
        }
        static indicesToOffset(t3, e2, n2) {
          void 0 === n2 && (n2 = t3.length);
          let r2 = 0;
          for (let i3 = 0; i3 < n2; ++i3) r2 += e2[i3] * t3[i3];
          return r2;
        }
        static offsetToIndices(t3, e2) {
          const n2 = e2.length;
          if (0 === n2) return [];
          if (1 === n2) return [t3 * e2[0]];
          const r2 = new Array(e2.length);
          for (let n3 = 0; n3 < r2.length - 1; ++n3) r2[n3] = Math.floor(t3 / e2[n3]), t3 -= r2[n3] * e2[n3];
          return r2[r2.length - 1] = t3, r2;
        }
        static normalizeAxis(t3, e2) {
          if (t3 < -e2 && t3 >= e2) throw new Error("unsupported axis for this operation.");
          return t3 < 0 ? t3 + e2 : t3;
        }
        static normalizeAxes(t3, e2) {
          return t3.map((t4) => this.normalizeAxis(t4, e2));
        }
        static incrementIndex(t3, e2, n2) {
          if (0 === e2.length || 0 === t3.length) throw new Error("Index incrementing unsupported for scalar Tensor");
          if (void 0 === n2) n2 = e2.length;
          else if (n2 <= 0 || n2 > e2.length) throw new Error("Incorrect axis to increment on");
          for (let r2 = n2 - 1; r2 >= 0 && (t3[r2]++, !(t3[r2] < e2[r2])); --r2) t3[r2] = 0;
        }
        static calculateReshapedDims(t3, e2) {
          if (0 === e2.length) {
            if (0 === t3.length || 1 === f.size(t3)) return [];
            throw new Error("cannot reshape to a scalar Tensor");
          }
          const n2 = e2.length, r2 = new Array(n2);
          let i3 = -1, o2 = 1;
          for (let a3 = 0; a3 < n2; a3++) {
            if (e2[a3] < -1) throw new Error("a dimension in shape hints cannot be less than -1");
            if (-1 === e2[a3]) {
              if (-1 !== i3) throw new Error("at most one dimension in shape hints can be -1");
              i3 = a3;
            } else {
              if (0 === e2[a3]) {
                if (a3 >= t3.length) throw new Error("the dimension with value zero exceeds the dimension size of the input tensor");
                r2[a3] = t3[a3];
              } else r2[a3] = e2[a3];
              o2 *= r2[a3];
            }
          }
          const a2 = f.size(t3);
          if (-1 !== i3) {
            if (a2 % o2 != 0) throw new Error(`the input tensor cannot be reshaped to the requested shape. Input shape: [${t3}] Output shape: [${e2}]`);
            r2[i3] = a2 / o2;
          } else if (o2 !== a2) throw new Error("reshapedDims and originalDims don't have matching sizes");
          return r2;
        }
        static sortBasedOnPerm(t3, e2) {
          return e2 ? e2.map((e3) => t3[e3]) : t3.slice().reverse();
        }
        static padShape(t3, e2) {
          const n2 = t3.length;
          return t3.map((t4, r2) => t4 + e2[r2] + e2[r2 + n2]);
        }
        static areEqual(t3, e2) {
          return t3.length === e2.length && t3.every((t4, n2) => t4 === e2[n2]);
        }
        static validateDimsAndCalcSize(t3) {
          if (t3.length > 6) throw new TypeError("Only rank 0 to 6 is supported for tensor shape.");
          let e2 = 1;
          for (const n2 of t3) {
            if (!Number.isInteger(n2)) throw new TypeError(`Invalid shape: ${n2} is not an integer`);
            if (n2 < 0 || n2 > 2147483647) throw new TypeError(`Invalid shape: length ${n2} is not allowed`);
            e2 *= n2;
          }
          return e2;
        }
        static flattenShape(t3, e2) {
          e2 < 0 && (e2 += t3.length);
          const n2 = t3.reduce((t4, e3) => t4 * e3, 1), r2 = t3.slice(e2).reduce((t4, e3) => t4 * e3, 1);
          return [n2 / r2, r2];
        }
        static squeezeShape(t3, e2) {
          const n2 = new Array();
          e2 = f.normalizeAxes(e2, t3.length);
          for (let r2 = 0; r2 < t3.length; r2++) {
            const i3 = e2.indexOf(r2) >= 0;
            if (i3 && 1 !== t3[r2]) throw new Error("squeeze an axis of size different than 1");
            (0 === e2.length && t3[r2] > 1 || e2.length > 0 && !i3) && n2.push(t3[r2]);
          }
          return n2;
        }
        static unsqueezeShape(t3, e2) {
          const n2 = new Array(t3.length + e2.length);
          n2.fill(0);
          for (let t4 = 0; t4 < e2.length; t4++) {
            const r3 = f.normalizeAxis(e2[t4], n2.length);
            if (r3 >= n2.length) throw new Error("'axes' has an out of range axis");
            if (0 !== n2[r3]) throw new Error("'axes' has a duplicate axis");
            n2[r3] = 1;
          }
          let r2 = 0;
          for (let e3 = 0; e3 < n2.length; e3++) 0 === n2[e3] && (n2[e3] = t3[r2++]);
          if (r2 !== t3.length) throw new Error("the unsqueezed dimension could not be established");
          return n2;
        }
      }
      e.ShapeUtil = f, e.MathUtil = class {
        static sqr(t3, e2, n2, r2, i3) {
          if (r2 < 0 || r2 >= e2.length) throw new Error("sourceIndex out of bounds");
          if (n2 < 0 || n2 >= t3.length) throw new Error("targetIndex out of bounds");
          if (r2 + i3 > e2.length) throw new Error("source indices to be copied are outside bounds");
          if (n2 + i3 > t3.length) throw new Error("target array is too small to hold result");
          for (let o2 = 0; o2 < i3; o2++) t3[n2 + o2] += Math.pow(e2[r2 + o2], 2);
        }
        static axpy(t3, e2, n2, r2, i3, o2) {
          if (r2 < 0 || r2 >= e2.length) throw new Error("sourceIndex out of bounds");
          if (n2 < 0 || n2 >= t3.length) throw new Error("targetIndex out of bounds");
          if (r2 + i3 > e2.length) throw new Error("source indices to be copied are outside bounds");
          if (n2 + i3 > t3.length) throw new Error("target array is too small to hold result");
          for (let a2 = 0; a2 < i3; a2++) t3[n2 + a2] += o2 * e2[r2 + a2];
        }
        static powx(t3, e2, n2, r2, i3, o2) {
          if (r2 < 0 || r2 >= e2.length) throw new Error("sourceIndex out of bounds");
          if (n2 < 0 || n2 >= t3.length) throw new Error("targetIndex out of bounds");
          if (r2 + i3 > e2.length) throw new Error("source indices to be copied are outside bounds");
          if (n2 + i3 > t3.length) throw new Error("target array is too small to hold result");
          for (let a2 = 0; a2 < i3; a2++) t3[n2 + a2] = Math.pow(e2[r2 + a2], o2);
        }
        static mul(t3, e2, n2, r2, i3) {
          if (r2 < 0 || r2 >= e2.length) throw new Error("sourceIndex out of bounds");
          if (n2 < 0 || n2 >= t3.length) throw new Error("targetIndex out of bounds");
          if (r2 + i3 > e2.length) throw new Error("source indices to be copied are outside bounds");
          if (n2 + i3 > t3.length) throw new Error("target array is too small to hold result");
          for (let o2 = 0; o2 < i3; o2++) t3[n2 + o2] = e2[r2 + o2] * t3[n2 + o2];
        }
      };
      class d {
        static splitShape(t3, e2, n2, r2) {
          if (0 === n2.length) {
            if (!r2) throw new Error("need to know number of outputs when the 'split' attribute is not specified");
            d.determineSplit(t3[e2], r2, n2);
          }
          const i3 = [], o2 = [0];
          for (let r3 = 0; r3 < n2.length; ++r3) {
            0 !== r3 && o2.push(o2[r3 - 1] + n2[r3 - 1]);
            const a2 = t3.slice();
            a2[e2] = n2[r3], i3.push(a2);
          }
          return [i3, o2];
        }
        static determineSplit(t3, e2, n2) {
          if (t3 % e2 != 0) throw new Error("cannot split tensor to equal sized parts");
          for (let r2 = 0; r2 < e2; ++r2) n2.push(t3 / e2);
        }
      }
      e.SplitUtil = d;
      class h {
        static calcReduce(t3, e2, n2, r2, i3) {
          const o2 = t3.dims.slice(0);
          0 === e2.length && o2.forEach((t4, n3) => e2.push(n3));
          const a2 = h.calcReduceShape(o2, e2, true), u2 = f.size(a2), l2 = new s.Tensor(a2, t3.type), p2 = f.computeStrides(a2), d2 = f.computeStrides(o2), g2 = new Array(o2.length);
          for (let n3 = 0; n3 < u2; n3++) {
            const a3 = f.offsetToIndices(n3, p2);
            c.fillIndex(a3, o2, g2), l2.set(a3, h.calcReduceByAxis(t3.numberData, e2, o2, 0, f.indicesToOffset(g2, d2), r2, i3));
          }
          return n2 ? l2 : new s.Tensor(h.calcReduceShape(o2, e2, n2), l2.type, void 0, void 0, l2.data, l2.dataId);
        }
        static calcReduceByAxis(t3, e2, n2, r2, i3, o2, a2) {
          let s2 = 0;
          if (r2 >= e2.length) return o2(t3[i3]);
          const u2 = e2[r2], c2 = u2 >= n2.length ? 1 : f.size(n2.slice(u2 + 1));
          for (let l2 = 0; l2 < n2[u2]; l2++) s2 = 0 === l2 ? h.calcReduceByAxis(t3, e2, n2, r2 + 1, i3, o2, a2) : a2(s2, h.calcReduceByAxis(t3, e2, n2, r2 + 1, i3, o2, a2)), i3 += c2;
          return s2;
        }
        static calcReduceShape(t3, e2, n2) {
          const r2 = t3.slice();
          for (let t4 = 0; t4 < e2.length; t4++) r2[e2[t4]] = n2 ? 1 : 0;
          return r2.filter((t4) => 0 !== t4);
        }
      }
      e.ReduceUtil = h;
      class g {
        static adjustPoolAttributes(t3, e2, n2, r2, i3, o2) {
          if (!t3 && n2.length !== e2.length - 2) throw new Error("length of specified kernel shapes should be 2 less than length of input dimensions");
          if (t3) for (let t4 = 0; t4 < e2.length - 2; t4++) t4 >= n2.length ? n2.push(e2[t4 + 2]) : n2[t4] = e2[t4 + 2];
          for (let t4 = 0; t4 < n2.length; t4++) if (t4 < r2.length) {
            if (r2[t4] < 0) throw new Error("strides should be greater than or equal to 1");
          } else r2.push(1);
          for (let t4 = 0; t4 < n2.length; t4++) if (t4 < i3.length) {
            if (i3[t4] < 0) throw new Error("dilations should be greater than or equal to 1");
          } else i3.push(1);
          for (let t4 = 0; t4 < 2 * n2.length; t4++) if (t4 < o2.length) {
            if (o2[t4] < 0) throw new Error("pad should be greater than or equal to 1");
          } else o2.push(0);
          for (let t4 = 0; t4 < n2.length; t4++) {
            if (n2[t4] <= 0) throw new Error("kernel shapes need to be greater than 0");
            if (o2[t4] >= n2[t4] || o2[t4 + n2.length] >= n2[t4]) throw new Error("pads should be smaller than kernel");
          }
        }
        static adjustPadsBasedOnAutoPad(t3, e2, n2, r2, i3, o2) {
          if (o2) {
            if (i3.length !== 2 * (t3.length - 2)) throw new Error("length of pads should be twice the length of data dimensions");
            if (e2.length !== t3.length - 2) throw new Error("length of strides should be the length of data dimensions");
            if (r2.length !== t3.length - 2) throw new Error("length of kernel shapes should be the length of data dimensions");
            for (let a2 = 0; a2 < t3.length - 2; a2++) g.adjustPadAndReturnShape(t3[a2 + 2], e2[a2], n2[a2], r2[a2], i3, a2, a2 + t3.length - 2, o2);
          }
        }
        static computePoolOutputShape(t3, e2, n2, r2, i3, o2, a2) {
          if (e2.length <= 0) throw new Error("input shape must be of size greater than 0");
          const s2 = [e2[0], e2[1]];
          return g.computeShapeHelper(t3, e2, s2, n2, r2, i3, o2, a2), s2;
        }
        static computeConvOutputShape(t3, e2, n2, r2, i3, o2, a2) {
          if (t3.length <= 0 || e2.length <= 0) throw new Error("invalid input tensor dims or invalid filter tensor dims");
          const s2 = [t3[0], e2[0]];
          return g.computeShapeHelper(false, t3, s2, n2, r2, i3, o2, a2), s2;
        }
        static computeShapeHelper(t3, e2, n2, r2, i3, o2, a2, s2) {
          if (t3) for (let t4 = 0; t4 < e2.length - 2; t4++) n2.push(1);
          else for (let t4 = 0; t4 < e2.length - 2; t4++) n2.push(g.adjustPadAndReturnShape(e2[t4 + 2], r2[t4], i3[t4], o2[t4], a2, t4, t4 + e2.length - 2, s2));
        }
        static adjustPadAndReturnShape(t3, e2, n2, r2, i3, o2, a2, s2) {
          const u2 = n2 * (r2 - 1) + 1;
          if (!s2 || "NOTSET" === s2) return Math.floor((t3 + i3[o2] + i3[a2] - u2) / e2 + 1);
          switch (s2) {
            case "VALID":
              return i3[o2] = 0, i3[a2] = 0, Math.floor((t3 - u2) / e2 + 1);
            case "SAME_LOWER":
            case "SAME_UPPER":
              if (1 !== n2) throw new Error("Dilation not supported for SAME_UPPER or SAME_LOWER");
              {
                const n3 = ((t3 + e2 - 1) / e2 - 1) * e2 + r2 - t3;
                return i3[o2] = "SAME_LOWER" === s2 ? Math.floor((n3 + 1) / 2) : Math.floor(n3 / 2), i3[a2] = n3 - i3[o2], Math.floor((t3 + n3 - r2) / e2 + 1);
              }
            default:
              throw new Error("Unsupported AutoPad type");
          }
        }
      }
      e.PoolConvUtil = g, e.MIN_CLIP = -34028234663852886e22, e.MAX_CLIP = 34028234663852886e22, e.decodeUtf8String = function(t3) {
        return new TextDecoder().decode(t3);
      };
    }, 7967: (t2, e) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.iterateExtraOptions = void 0, e.iterateExtraOptions = (t3, n, r, i2) => {
        if ("object" == typeof t3 && null !== t3) {
          if (r.has(t3)) throw new Error("Circular reference in options");
          r.add(t3);
        }
        Object.entries(t3).forEach(([t4, o]) => {
          const a = n ? n + t4 : t4;
          if ("object" == typeof o) (0, e.iterateExtraOptions)(o, a + ".", r, i2);
          else if ("string" == typeof o || "number" == typeof o) i2(a, o.toString());
          else {
            if ("boolean" != typeof o) throw new Error("Can't handle extra config type: " + typeof o);
            i2(a, o ? "1" : "0");
          }
        });
      };
    }, 2157: function(t2, e, n) {
      var r, i2 = this && this.__createBinding || (Object.create ? function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2);
        var i3 = Object.getOwnPropertyDescriptor(e2, n2);
        i3 && !("get" in i3 ? !e2.__esModule : i3.writable || i3.configurable) || (i3 = { enumerable: true, get: function() {
          return e2[n2];
        } }), Object.defineProperty(t3, r2, i3);
      } : function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2), t3[r2] = e2[n2];
      }), o = this && this.__setModuleDefault || (Object.create ? function(t3, e2) {
        Object.defineProperty(t3, "default", { enumerable: true, value: e2 });
      } : function(t3, e2) {
        t3.default = e2;
      }), a = this && this.__importStar || function(t3) {
        if (t3 && t3.__esModule) return t3;
        var e2 = {};
        if (null != t3) for (var n2 in t3) "default" !== n2 && Object.prototype.hasOwnProperty.call(t3, n2) && i2(e2, t3, n2);
        return o(e2, t3), e2;
      };
      Object.defineProperty(e, "__esModule", { value: true }), e.endProfiling = e.run = e.releaseSession = e.createSession = e.createSessionFinalize = e.createSessionAllocate = e.initOrt = e.initWasm = void 0;
      const s = n(6207), u = a(n(349)), c = n(6361), l = () => !!s.env.wasm.proxy && "undefined" != typeof document;
      let p, f, d, h = false, g = false, b = false;
      const m = [], y = [], _ = [], v = [], w = [], x = [], T = () => {
        if (h || !g || b || !p) throw new Error("worker not ready");
      }, S = (t3) => {
        switch (t3.data.type) {
          case "init-wasm":
            h = false, t3.data.err ? (b = true, f[1](t3.data.err)) : (g = true, f[0]());
            break;
          case "init-ort":
            t3.data.err ? d[1](t3.data.err) : d[0]();
            break;
          case "create_allocate":
            t3.data.err ? m.shift()[1](t3.data.err) : m.shift()[0](t3.data.out);
            break;
          case "create_finalize":
            t3.data.err ? y.shift()[1](t3.data.err) : y.shift()[0](t3.data.out);
            break;
          case "create":
            t3.data.err ? _.shift()[1](t3.data.err) : _.shift()[0](t3.data.out);
            break;
          case "release":
            t3.data.err ? v.shift()[1](t3.data.err) : v.shift()[0]();
            break;
          case "run":
            t3.data.err ? w.shift()[1](t3.data.err) : w.shift()[0](t3.data.out);
            break;
          case "end-profiling":
            t3.data.err ? x.shift()[1](t3.data.err) : x.shift()[0]();
        }
      }, O = "undefined" != typeof document ? null === (r = null === document || void 0 === document ? void 0 : document.currentScript) || void 0 === r ? void 0 : r.src : void 0;
      e.initWasm = async () => {
        if (l()) {
          if (g) return;
          if (h) throw new Error("multiple calls to 'initWasm()' detected.");
          if (b) throw new Error("previous call to 'initWasm()' failed.");
          return h = true, void 0 === s.env.wasm.wasmPaths && O && 0 !== O.indexOf("blob:") && (s.env.wasm.wasmPaths = O.substr(0, +O.lastIndexOf("/") + 1)), new Promise((t3, e2) => {
            null == p || p.terminate(), p = n(9710).Z(), p.onmessage = S, f = [t3, e2];
            const r2 = { type: "init-wasm", in: s.env.wasm };
            p.postMessage(r2);
          });
        }
        return (0, c.initializeWebAssembly)(s.env.wasm);
      }, e.initOrt = async (t3, e2) => {
        if (l()) return T(), new Promise((n2, r2) => {
          d = [n2, r2];
          const i3 = { type: "init-ort", in: { numThreads: t3, loggingLevel: e2 } };
          p.postMessage(i3);
        });
        u.initOrt(t3, e2);
      }, e.createSessionAllocate = async (t3) => l() ? (T(), new Promise((e2, n2) => {
        m.push([e2, n2]);
        const r2 = { type: "create_allocate", in: { model: t3 } };
        p.postMessage(r2, [t3.buffer]);
      })) : u.createSessionAllocate(t3), e.createSessionFinalize = async (t3, e2) => l() ? (T(), new Promise((n2, r2) => {
        y.push([n2, r2]);
        const i3 = { type: "create_finalize", in: { modeldata: t3, options: e2 } };
        p.postMessage(i3);
      })) : u.createSessionFinalize(t3, e2), e.createSession = async (t3, e2) => l() ? (T(), new Promise((n2, r2) => {
        _.push([n2, r2]);
        const i3 = { type: "create", in: { model: t3, options: e2 } };
        p.postMessage(i3, [t3.buffer]);
      })) : u.createSession(t3, e2), e.releaseSession = async (t3) => {
        if (l()) return T(), new Promise((e2, n2) => {
          v.push([e2, n2]);
          const r2 = { type: "release", in: t3 };
          p.postMessage(r2);
        });
        u.releaseSession(t3);
      }, e.run = async (t3, e2, n2, r2, i3) => l() ? (T(), new Promise((o2, a2) => {
        w.push([o2, a2]);
        const s2 = { type: "run", in: { sessionId: t3, inputIndices: e2, inputs: n2, outputIndices: r2, options: i3 } };
        p.postMessage(s2, u.extractTransferableBuffers(n2));
      })) : u.run(t3, e2, n2, r2, i3), e.endProfiling = async (t3) => {
        if (l()) return T(), new Promise((e2, n2) => {
          x.push([e2, n2]);
          const r2 = { type: "end-profiling", in: t3 };
          p.postMessage(r2);
        });
        u.endProfiling(t3);
      };
    }, 586: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.setRunOptions = void 0;
      const r = n(7967), i2 = n(4983), o = n(6361);
      e.setRunOptions = (t3) => {
        const e2 = (0, o.getInstance)();
        let n2 = 0;
        const a = [], s = t3 || {};
        try {
          if (void 0 === (null == t3 ? void 0 : t3.logSeverityLevel)) s.logSeverityLevel = 2;
          else if ("number" != typeof t3.logSeverityLevel || !Number.isInteger(t3.logSeverityLevel) || t3.logSeverityLevel < 0 || t3.logSeverityLevel > 4) throw new Error(`log serverity level is not valid: ${t3.logSeverityLevel}`);
          if (void 0 === (null == t3 ? void 0 : t3.logVerbosityLevel)) s.logVerbosityLevel = 0;
          else if ("number" != typeof t3.logVerbosityLevel || !Number.isInteger(t3.logVerbosityLevel)) throw new Error(`log verbosity level is not valid: ${t3.logVerbosityLevel}`);
          void 0 === (null == t3 ? void 0 : t3.terminate) && (s.terminate = false);
          let o2 = 0;
          if (void 0 !== (null == t3 ? void 0 : t3.tag) && (o2 = (0, i2.allocWasmString)(t3.tag, a)), n2 = e2._OrtCreateRunOptions(s.logSeverityLevel, s.logVerbosityLevel, !!s.terminate, o2), 0 === n2) throw new Error("Can't create run options");
          return void 0 !== (null == t3 ? void 0 : t3.extra) && (0, r.iterateExtraOptions)(t3.extra, "", /* @__PURE__ */ new WeakSet(), (t4, r2) => {
            const o3 = (0, i2.allocWasmString)(t4, a), s2 = (0, i2.allocWasmString)(r2, a);
            if (0 !== e2._OrtAddRunConfigEntry(n2, o3, s2)) throw new Error(`Can't set a run config entry: ${t4} - ${r2}`);
          }), [n2, a];
        } catch (t4) {
          throw 0 !== n2 && e2._OrtReleaseRunOptions(n2), a.forEach(e2._free), t4;
        }
      };
    }, 2306: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.OnnxruntimeWebAssemblySessionHandler = void 0;
      const r = n(6231), i2 = n(6207), o = n(6464), a = n(2157);
      let s;
      e.OnnxruntimeWebAssemblySessionHandler = class {
        async createSessionAllocate(t3) {
          const e2 = await fetch(t3), n2 = await e2.arrayBuffer();
          return (0, a.createSessionAllocate)(new Uint8Array(n2));
        }
        async loadModel(t3, e2) {
          if (s || (await (0, a.initOrt)(i2.env.wasm.numThreads, ((t4) => {
            switch (t4) {
              case "verbose":
                return 0;
              case "info":
                return 1;
              case "warning":
                return 2;
              case "error":
                return 3;
              case "fatal":
                return 4;
              default:
                throw new Error(`unsupported logging level: ${t4}`);
            }
          })(i2.env.logLevel)), s = true), "string" == typeof t3) if ("undefined" == typeof fetch) {
            const n2 = await (0, o.promisify)(r.readFile)(t3);
            [this.sessionId, this.inputNames, this.outputNames] = await (0, a.createSession)(n2, e2);
          } else {
            const n2 = await this.createSessionAllocate(t3);
            [this.sessionId, this.inputNames, this.outputNames] = await (0, a.createSessionFinalize)(n2, e2);
          }
          else [this.sessionId, this.inputNames, this.outputNames] = await (0, a.createSession)(t3, e2);
        }
        async dispose() {
          return (0, a.releaseSession)(this.sessionId);
        }
        async run(t3, e2, n2) {
          const r2 = [], o2 = [];
          Object.entries(t3).forEach((t4) => {
            const e3 = t4[0], n3 = t4[1], i3 = this.inputNames.indexOf(e3);
            if (-1 === i3) throw new Error(`invalid input '${e3}'`);
            r2.push(n3), o2.push(i3);
          });
          const s2 = [];
          Object.entries(e2).forEach((t4) => {
            const e3 = t4[0], n3 = this.outputNames.indexOf(e3);
            if (-1 === n3) throw new Error(`invalid output '${e3}'`);
            s2.push(n3);
          });
          const u = await (0, a.run)(this.sessionId, o2, r2.map((t4) => [t4.type, t4.dims, t4.data]), s2, n2), c = {};
          for (let t4 = 0; t4 < u.length; t4++) c[this.outputNames[s2[t4]]] = new i2.Tensor(u[t4][0], u[t4][2], u[t4][1]);
          return c;
        }
        startProfiling() {
        }
        endProfiling() {
          (0, a.endProfiling)(this.sessionId);
        }
      };
    }, 4919: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.setSessionOptions = void 0;
      const r = n(7967), i2 = n(4983), o = n(6361);
      e.setSessionOptions = (t3) => {
        const e2 = (0, o.getInstance)();
        let n2 = 0;
        const a = [], s = t3 || {};
        ((t4) => {
          t4.extra || (t4.extra = {}), t4.extra.session || (t4.extra.session = {});
          const e3 = t4.extra.session;
          e3.use_ort_model_bytes_directly || (e3.use_ort_model_bytes_directly = "1");
        })(s);
        try {
          void 0 === (null == t3 ? void 0 : t3.graphOptimizationLevel) && (s.graphOptimizationLevel = "all");
          const u = ((t4) => {
            switch (t4) {
              case "disabled":
                return 0;
              case "basic":
                return 1;
              case "extended":
                return 2;
              case "all":
                return 99;
              default:
                throw new Error(`unsupported graph optimization level: ${t4}`);
            }
          })(s.graphOptimizationLevel);
          void 0 === (null == t3 ? void 0 : t3.enableCpuMemArena) && (s.enableCpuMemArena = true), void 0 === (null == t3 ? void 0 : t3.enableMemPattern) && (s.enableMemPattern = true), void 0 === (null == t3 ? void 0 : t3.executionMode) && (s.executionMode = "sequential");
          const c = ((t4) => {
            switch (t4) {
              case "sequential":
                return 0;
              case "parallel":
                return 1;
              default:
                throw new Error(`unsupported execution mode: ${t4}`);
            }
          })(s.executionMode);
          let l = 0;
          if (void 0 !== (null == t3 ? void 0 : t3.logId) && (l = (0, i2.allocWasmString)(t3.logId, a)), void 0 === (null == t3 ? void 0 : t3.logSeverityLevel)) s.logSeverityLevel = 2;
          else if ("number" != typeof t3.logSeverityLevel || !Number.isInteger(t3.logSeverityLevel) || t3.logSeverityLevel < 0 || t3.logSeverityLevel > 4) throw new Error(`log serverity level is not valid: ${t3.logSeverityLevel}`);
          if (void 0 === (null == t3 ? void 0 : t3.logVerbosityLevel)) s.logVerbosityLevel = 0;
          else if ("number" != typeof t3.logVerbosityLevel || !Number.isInteger(t3.logVerbosityLevel)) throw new Error(`log verbosity level is not valid: ${t3.logVerbosityLevel}`);
          if (void 0 === (null == t3 ? void 0 : t3.enableProfiling) && (s.enableProfiling = false), n2 = e2._OrtCreateSessionOptions(u, !!s.enableCpuMemArena, !!s.enableMemPattern, c, !!s.enableProfiling, 0, l, s.logSeverityLevel, s.logVerbosityLevel), 0 === n2) throw new Error("Can't create session options");
          return (null == t3 ? void 0 : t3.executionProviders) && ((t4, e3, n3) => {
            for (const r2 of e3) {
              let e4 = "string" == typeof r2 ? r2 : r2.name;
              switch (e4) {
                case "xnnpack":
                  e4 = "XNNPACK";
                  break;
                case "wasm":
                case "cpu":
                  continue;
                default:
                  throw new Error(`not supported EP: ${e4}`);
              }
              const a2 = (0, i2.allocWasmString)(e4, n3);
              if (0 !== (0, o.getInstance)()._OrtAppendExecutionProvider(t4, a2)) throw new Error(`Can't append execution provider: ${e4}`);
            }
          })(n2, t3.executionProviders, a), void 0 !== (null == t3 ? void 0 : t3.extra) && (0, r.iterateExtraOptions)(t3.extra, "", /* @__PURE__ */ new WeakSet(), (t4, r2) => {
            const o2 = (0, i2.allocWasmString)(t4, a), s2 = (0, i2.allocWasmString)(r2, a);
            if (0 !== e2._OrtAddSessionConfigEntry(n2, o2, s2)) throw new Error(`Can't set a session config entry: ${t4} - ${r2}`);
          }), [n2, a];
        } catch (t4) {
          throw 0 !== n2 && e2._OrtReleaseSessionOptions(n2), a.forEach(e2._free), t4;
        }
      };
    }, 4983: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.allocWasmString = void 0;
      const r = n(6361);
      e.allocWasmString = (t3, e2) => {
        const n2 = (0, r.getInstance)(), i2 = n2.lengthBytesUTF8(t3) + 1, o = n2._malloc(i2);
        return n2.stringToUTF8(t3, o, i2), e2.push(o), o;
      };
    }, 349: (t2, e, n) => {
      Object.defineProperty(e, "__esModule", { value: true }), e.extractTransferableBuffers = e.endProfiling = e.run = e.releaseSession = e.createSession = e.createSessionFinalize = e.createSessionAllocate = e.initOrt = void 0;
      const r = n(586), i2 = n(4919), o = n(4983), a = n(6361);
      e.initOrt = (t3, e2) => {
        const n2 = (0, a.getInstance)()._OrtInit(t3, e2);
        if (0 !== n2) throw new Error(`Can't initialize onnxruntime. error code = ${n2}`);
      };
      const s = /* @__PURE__ */ new Map();
      e.createSessionAllocate = (t3) => {
        const e2 = (0, a.getInstance)(), n2 = e2._malloc(t3.byteLength);
        return e2.HEAPU8.set(t3, n2), [n2, t3.byteLength];
      }, e.createSessionFinalize = (t3, e2) => {
        const n2 = (0, a.getInstance)();
        let r2 = 0, o2 = 0, u2 = [];
        try {
          if ([o2, u2] = (0, i2.setSessionOptions)(e2), r2 = n2._OrtCreateSession(t3[0], t3[1], o2), 0 === r2) throw new Error("Can't create a session");
        } finally {
          n2._free(t3[0]), n2._OrtReleaseSessionOptions(o2), u2.forEach(n2._free);
        }
        const c2 = n2._OrtGetInputCount(r2), l2 = n2._OrtGetOutputCount(r2), p = [], f = [], d = [], h = [];
        for (let t4 = 0; t4 < c2; t4++) {
          const e3 = n2._OrtGetInputName(r2, t4);
          if (0 === e3) throw new Error("Can't get an input name");
          f.push(e3), p.push(n2.UTF8ToString(e3));
        }
        for (let t4 = 0; t4 < l2; t4++) {
          const e3 = n2._OrtGetOutputName(r2, t4);
          if (0 === e3) throw new Error("Can't get an output name");
          h.push(e3), d.push(n2.UTF8ToString(e3));
        }
        return s.set(r2, [r2, f, h]), [r2, p, d];
      }, e.createSession = (t3, n2) => {
        const r2 = (0, e.createSessionAllocate)(t3);
        return (0, e.createSessionFinalize)(r2, n2);
      }, e.releaseSession = (t3) => {
        const e2 = (0, a.getInstance)(), n2 = s.get(t3);
        if (!n2) throw new Error("invalid session id");
        const r2 = n2[0], i3 = n2[1], o2 = n2[2];
        i3.forEach(e2._OrtFree), o2.forEach(e2._OrtFree), e2._OrtReleaseSession(r2), s.delete(t3);
      };
      const u = (t3) => {
        switch (t3) {
          case "int8":
            return 3;
          case "uint8":
            return 2;
          case "bool":
            return 9;
          case "int16":
            return 5;
          case "uint16":
            return 4;
          case "int32":
            return 6;
          case "uint32":
            return 12;
          case "float32":
            return 1;
          case "float64":
            return 11;
          case "string":
            return 8;
          case "int64":
            return 7;
          case "uint64":
            return 13;
          default:
            throw new Error(`unsupported data type: ${t3}`);
        }
      }, c = (t3) => {
        switch (t3) {
          case 3:
            return "int8";
          case 2:
            return "uint8";
          case 9:
            return "bool";
          case 5:
            return "int16";
          case 4:
            return "uint16";
          case 6:
            return "int32";
          case 12:
            return "uint32";
          case 1:
            return "float32";
          case 11:
            return "float64";
          case 8:
            return "string";
          case 7:
            return "int64";
          case 13:
            return "uint64";
          default:
            throw new Error(`unsupported data type: ${t3}`);
        }
      }, l = (t3) => {
        switch (t3) {
          case "float32":
            return Float32Array;
          case "uint8":
          case "bool":
            return Uint8Array;
          case "int8":
            return Int8Array;
          case "uint16":
            return Uint16Array;
          case "int16":
            return Int16Array;
          case "int32":
            return Int32Array;
          case "float64":
            return Float64Array;
          case "uint32":
            return Uint32Array;
          case "int64":
            return BigInt64Array;
          case "uint64":
            return BigUint64Array;
          default:
            throw new Error(`unsupported type: ${t3}`);
        }
      };
      e.run = (t3, e2, n2, i3, p) => {
        const f = (0, a.getInstance)(), d = s.get(t3);
        if (!d) throw new Error("invalid session id");
        const h = d[0], g = d[1], b = d[2], m = e2.length, y = i3.length;
        let _ = 0, v = [];
        const w = [], x = [];
        try {
          [_, v] = (0, r.setRunOptions)(p);
          for (let t5 = 0; t5 < m; t5++) {
            const e3 = n2[t5][0], r2 = n2[t5][1], i4 = n2[t5][2];
            let a3, s3;
            if (Array.isArray(i4)) {
              s3 = 4 * i4.length, a3 = f._malloc(s3), x.push(a3);
              let t6 = a3 / 4;
              for (let e4 = 0; e4 < i4.length; e4++) {
                if ("string" != typeof i4[e4]) throw new TypeError(`tensor data at index ${e4} is not a string`);
                f.HEAPU32[t6++] = (0, o.allocWasmString)(i4[e4], x);
              }
            } else s3 = i4.byteLength, a3 = f._malloc(s3), x.push(a3), f.HEAPU8.set(new Uint8Array(i4.buffer, i4.byteOffset, s3), a3);
            const c2 = f.stackSave(), l2 = f.stackAlloc(4 * r2.length);
            try {
              let t6 = l2 / 4;
              r2.forEach((e4) => f.HEAP32[t6++] = e4);
              const n3 = f._OrtCreateTensor(u(e3), a3, s3, l2, r2.length);
              if (0 === n3) throw new Error("Can't create a tensor");
              w.push(n3);
            } finally {
              f.stackRestore(c2);
            }
          }
          const t4 = f.stackSave(), a2 = f.stackAlloc(4 * m), s2 = f.stackAlloc(4 * m), d2 = f.stackAlloc(4 * y), T = f.stackAlloc(4 * y);
          try {
            let n3 = a2 / 4, r2 = s2 / 4, o2 = d2 / 4, u2 = T / 4;
            for (let t5 = 0; t5 < m; t5++) f.HEAPU32[n3++] = w[t5], f.HEAPU32[r2++] = g[e2[t5]];
            for (let t5 = 0; t5 < y; t5++) f.HEAPU32[o2++] = 0, f.HEAPU32[u2++] = b[i3[t5]];
            let p2 = f._OrtRun(h, s2, a2, m, T, y, d2, _);
            const v2 = [];
            if (0 === p2) for (let t5 = 0; t5 < y; t5++) {
              const e3 = f.HEAPU32[d2 / 4 + t5], n4 = f.stackSave(), r3 = f.stackAlloc(16);
              let i4, o3 = 0;
              try {
                if (p2 = f._OrtGetTensorData(e3, r3, r3 + 4, r3 + 8, r3 + 12), 0 !== p2) throw new Error(`Can't access output tensor data. error code = ${p2}`);
                let t6 = r3 / 4;
                const a3 = f.HEAPU32[t6++];
                o3 = f.HEAPU32[t6++];
                const s3 = f.HEAPU32[t6++], u3 = f.HEAPU32[t6++], d3 = [];
                for (let t7 = 0; t7 < u3; t7++) d3.push(f.HEAPU32[s3 / 4 + t7]);
                f._OrtFree(s3);
                const h2 = 0 === d3.length ? 1 : d3.reduce((t7, e4) => t7 * e4);
                if (i4 = c(a3), "string" === i4) {
                  const t7 = [];
                  let e4 = o3 / 4;
                  for (let n5 = 0; n5 < h2; n5++) {
                    const r4 = f.HEAPU32[e4++], i5 = n5 === h2 - 1 ? void 0 : f.HEAPU32[e4] - r4;
                    t7.push(f.UTF8ToString(r4, i5));
                  }
                  v2.push([i4, d3, t7]);
                } else {
                  const t7 = new (l(i4))(h2);
                  new Uint8Array(t7.buffer, t7.byteOffset, t7.byteLength).set(f.HEAPU8.subarray(o3, o3 + t7.byteLength)), v2.push([i4, d3, t7]);
                }
              } finally {
                f.stackRestore(n4), "string" === i4 && o3 && f._free(o3), f._OrtReleaseTensor(e3);
              }
            }
            if (0 === p2) return v2;
            throw new Error(`failed to call OrtRun(). error code = ${p2}.`);
          } finally {
            f.stackRestore(t4);
          }
        } finally {
          w.forEach(f._OrtReleaseTensor), x.forEach(f._free), f._OrtReleaseRunOptions(_), v.forEach(f._free);
        }
      }, e.endProfiling = (t3) => {
        const e2 = (0, a.getInstance)(), n2 = s.get(t3);
        if (!n2) throw new Error("invalid session id");
        const r2 = n2[0], i3 = e2._OrtEndProfiling(r2);
        if (0 === i3) throw new Error("Can't get an profile file name");
        e2._OrtFree(i3);
      }, e.extractTransferableBuffers = (t3) => {
        const e2 = [];
        for (const n2 of t3) {
          const t4 = n2[2];
          !Array.isArray(t4) && t4.buffer && e2.push(t4.buffer);
        }
        return e2;
      };
    }, 6361: function(t2, e, n) {
      var r = this && this.__createBinding || (Object.create ? function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2);
        var i3 = Object.getOwnPropertyDescriptor(e2, n2);
        i3 && !("get" in i3 ? !e2.__esModule : i3.writable || i3.configurable) || (i3 = { enumerable: true, get: function() {
          return e2[n2];
        } }), Object.defineProperty(t3, r2, i3);
      } : function(t3, e2, n2, r2) {
        void 0 === r2 && (r2 = n2), t3[r2] = e2[n2];
      }), i2 = this && this.__setModuleDefault || (Object.create ? function(t3, e2) {
        Object.defineProperty(t3, "default", { enumerable: true, value: e2 });
      } : function(t3, e2) {
        t3.default = e2;
      }), o = this && this.__importStar || function(t3) {
        if (t3 && t3.__esModule) return t3;
        var e2 = {};
        if (null != t3) for (var n2 in t3) "default" !== n2 && Object.prototype.hasOwnProperty.call(t3, n2) && r(e2, t3, n2);
        return i2(e2, t3), e2;
      }, a = this && this.__importDefault || function(t3) {
        return t3 && t3.__esModule ? t3 : { default: t3 };
      };
      Object.defineProperty(e, "__esModule", { value: true }), e.dispose = e.getInstance = e.initializeWebAssembly = void 0;
      const s = o(n(1423)), u = a(n(932)), c = n(3474);
      let l, p = false, f = false, d = false;
      const h = (t3, e2) => e2 ? t3 ? "ort-wasm-simd-threaded.wasm" : "ort-wasm-threaded.wasm" : t3 ? "ort-wasm-simd.wasm" : "ort-wasm.wasm";
      e.initializeWebAssembly = async (t3) => {
        if (p) return Promise.resolve();
        if (f) throw new Error("multiple calls to 'initializeWebAssembly()' detected.");
        if (d) throw new Error("previous call to 'initializeWebAssembly()' failed.");
        f = true;
        const e2 = t3.initTimeout, r2 = t3.numThreads, i3 = t3.simd, o2 = r2 > 1 && (() => {
          try {
            return "undefined" != typeof SharedArrayBuffer && ("undefined" != typeof MessageChannel && new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)), WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 5, 4, 1, 3, 1, 1, 10, 11, 1, 9, 0, 65, 0, 254, 16, 2, 0, 26, 11])));
          } catch (t4) {
            return false;
          }
        })(), a2 = i3 && (() => {
          try {
            return WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1, 28, 0, 65, 0, 253, 15, 253, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 186, 1, 26, 11]));
          } catch (t4) {
            return false;
          }
        })(), g = "string" == typeof t3.wasmPaths ? t3.wasmPaths : void 0, b = h(false, o2), m = h(a2, o2), y = "object" == typeof t3.wasmPaths ? t3.wasmPaths[m] : void 0;
        let _ = false;
        const v = [];
        if (e2 > 0 && v.push(new Promise((t4) => {
          setTimeout(() => {
            _ = true, t4();
          }, e2);
        })), v.push(new Promise((t4, e3) => {
          const r3 = o2 ? c : u.default, i4 = { locateFile: (t5, e4) => o2 && t5.endsWith(".worker.js") && "undefined" != typeof Blob ? URL.createObjectURL(new Blob([n(4154)], { type: "text/javascript" })) : t5 === b ? null != y ? y : (null != g ? g : e4) + m : e4 + t5 };
          if (o2) if ("undefined" == typeof Blob) i4.mainScriptUrlOrBlob = s.join(__dirname, "ort-wasm-threaded.js");
          else {
            const t5 = `var ortWasmThreaded=(function(){var _scriptDir;return ${r3.toString()}})();`;
            i4.mainScriptUrlOrBlob = new Blob([t5], { type: "text/javascript" });
          }
          r3(i4).then((e4) => {
            f = false, p = true, l = e4, t4();
          }, (t5) => {
            f = false, d = true, e3(t5);
          });
        })), await Promise.race(v), _) throw new Error(`WebAssembly backend initializing failed due to timeout: ${e2}ms`);
      }, e.getInstance = () => {
        if (p && l) return l;
        throw new Error("WebAssembly is not initialized yet.");
      }, e.dispose = () => {
        var t3;
        !p || f || d || (f = true, null === (t3 = l.PThread) || void 0 === t3 || t3.terminateAllThreads(), l = void 0, f = false, p = false, d = true);
      };
    }, 9710: (t2, e, n) => {
      n.d(e, { Z: () => o });
      var r = n(477), i2 = n.n(r);
      function o() {
        return i2()('/*!\n* ONNX Runtime Web v1.14.0\n* Copyright (c) Microsoft Corporation. All rights reserved.\n* Licensed under the MIT License.\n*/\n(()=>{var t={474:(t,e,n)=>{var _scriptDir,r=(_scriptDir=(_scriptDir="undefined"!=typeof document&&document.currentScript?document.currentScript.src:void 0)||__filename,function(t){function e(){return k.buffer!=D&&N(k.buffer),P}function r(){return k.buffer!=D&&N(k.buffer),U}function a(){return k.buffer!=D&&N(k.buffer),F}function i(){return k.buffer!=D&&N(k.buffer),I}function o(){return k.buffer!=D&&N(k.buffer),W}var u,s,c;t=t||{},u||(u=void 0!==t?t:{}),u.ready=new Promise((function(t,e){s=t,c=e}));var l,f,p,h,d,y,b=Object.assign({},u),m="./this.program",g=(t,e)=>{throw e},v="object"==typeof window,_="function"==typeof importScripts,w="object"==typeof process&&"object"==typeof process.versions&&"string"==typeof process.versions.node,O=u.ENVIRONMENT_IS_PTHREAD||!1,A="";function S(t){return u.locateFile?u.locateFile(t,A):A+t}if(w){let e;A=_?n(17).dirname(A)+"/":__dirname+"/",y=()=>{d||(h=n(147),d=n(17))},l=function(t,e){return y(),t=d.normalize(t),h.readFileSync(t,e?void 0:"utf8")},p=t=>((t=l(t,!0)).buffer||(t=new Uint8Array(t)),t),f=(t,e,n)=>{y(),t=d.normalize(t),h.readFile(t,(function(t,r){t?n(t):e(r.buffer)}))},1<process.argv.length&&(m=process.argv[1].replace(/\\\\/g,"/")),process.argv.slice(2),process.on("uncaughtException",(function(t){if(!(t instanceof st))throw t})),process.on("unhandledRejection",(function(t){throw t})),g=(t,e)=>{if(Q())throw process.exitCode=t,e;e instanceof st||x("exiting due to exception: "+e),process.exit(t)},u.inspect=function(){return"[Emscripten Module object]"};try{e=n(267)}catch(t){throw console.error(\'The "worker_threads" module is not supported in this node.js build - perhaps a newer version is needed?\'),t}global.Worker=e.Worker}else(v||_)&&(_?A=self.location.href:"undefined"!=typeof document&&document.currentScript&&(A=document.currentScript.src),_scriptDir&&(A=_scriptDir),A=0!==A.indexOf("blob:")?A.substr(0,A.replace(/[?#].*/,"").lastIndexOf("/")+1):"",w||(l=t=>{var e=new XMLHttpRequest;return e.open("GET",t,!1),e.send(null),e.responseText},_&&(p=t=>{var e=new XMLHttpRequest;return e.open("GET",t,!1),e.responseType="arraybuffer",e.send(null),new Uint8Array(e.response)}),f=(t,e,n)=>{var r=new XMLHttpRequest;r.open("GET",t,!0),r.responseType="arraybuffer",r.onload=()=>{200==r.status||0==r.status&&r.response?e(r.response):n()},r.onerror=n,r.send(null)}));w&&"undefined"==typeof performance&&(global.performance=n(74).performance);var T=console.log.bind(console),E=console.warn.bind(console);w&&(y(),T=t=>h.writeSync(1,t+"\\n"),E=t=>h.writeSync(2,t+"\\n"));var M,C=u.print||T,x=u.printErr||E;Object.assign(u,b),b=null,u.thisProgram&&(m=u.thisProgram),u.quit&&(g=u.quit),u.wasmBinary&&(M=u.wasmBinary);var R=u.noExitRuntime||!1;"object"!=typeof WebAssembly&&at("no native wasm support detected");var k,j,D,P,U,F,I,W,H=!1,z="undefined"!=typeof TextDecoder?new TextDecoder("utf8"):void 0;function L(t,e,n){var r=(e>>>=0)+n;for(n=e;t[n]&&!(n>=r);)++n;if(16<n-e&&t.buffer&&z)return z.decode(t.buffer instanceof SharedArrayBuffer?t.slice(e,n):t.subarray(e,n));for(r="";e<n;){var a=t[e++];if(128&a){var i=63&t[e++];if(192==(224&a))r+=String.fromCharCode((31&a)<<6|i);else{var o=63&t[e++];65536>(a=224==(240&a)?(15&a)<<12|i<<6|o:(7&a)<<18|i<<12|o<<6|63&t[e++])?r+=String.fromCharCode(a):(a-=65536,r+=String.fromCharCode(55296|a>>10,56320|1023&a))}}else r+=String.fromCharCode(a)}return r}function Y(t,e){return(t>>>=0)?L(r(),t,e):""}function B(t,e,n,r){if(!(0<r))return 0;var a=n>>>=0;r=n+r-1;for(var i=0;i<t.length;++i){var o=t.charCodeAt(i);if(55296<=o&&57343>=o&&(o=65536+((1023&o)<<10)|1023&t.charCodeAt(++i)),127>=o){if(n>=r)break;e[n++>>>0]=o}else{if(2047>=o){if(n+1>=r)break;e[n++>>>0]=192|o>>6}else{if(65535>=o){if(n+2>=r)break;e[n++>>>0]=224|o>>12}else{if(n+3>=r)break;e[n++>>>0]=240|o>>18,e[n++>>>0]=128|o>>12&63}e[n++>>>0]=128|o>>6&63}e[n++>>>0]=128|63&o}}return e[n>>>0]=0,n-a}function G(t){for(var e=0,n=0;n<t.length;++n){var r=t.charCodeAt(n);127>=r?e++:2047>=r?e+=2:55296<=r&&57343>=r?(e+=4,++n):e+=3}return e}function N(t){D=t,u.HEAP8=P=new Int8Array(t),u.HEAP16=new Int16Array(t),u.HEAP32=F=new Int32Array(t),u.HEAPU8=U=new Uint8Array(t),u.HEAPU16=new Uint16Array(t),u.HEAPU32=I=new Uint32Array(t),u.HEAPF32=new Float32Array(t),u.HEAPF64=W=new Float64Array(t)}O&&(D=u.buffer);var V=u.INITIAL_MEMORY||16777216;if(O)k=u.wasmMemory,D=u.buffer;else if(u.wasmMemory)k=u.wasmMemory;else if(!((k=new WebAssembly.Memory({initial:V/65536,maximum:65536,shared:!0})).buffer instanceof SharedArrayBuffer))throw x("requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag"),w&&console.log("(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and also use a recent version)"),Error("bad memory");k&&(D=k.buffer),V=D.byteLength,N(D);var q,$=[],X=[],J=[],Z=[];function Q(){return R||!1}function K(){var t=u.preRun.shift();$.unshift(t)}var tt,et=0,nt=null,rt=null;function at(t){throw O?postMessage({cmd:"onAbort",arg:t}):u.onAbort&&u.onAbort(t),x(t="Aborted("+t+")"),H=!0,t=new WebAssembly.RuntimeError(t+". Build with -sASSERTIONS for more info."),c(t),t}function it(){return tt.startsWith("data:application/octet-stream;base64,")}function ot(){var t=tt;try{if(t==tt&&M)return new Uint8Array(M);if(p)return p(t);throw"both async and sync fetching of the wasm failed"}catch(t){at(t)}}tt="ort-wasm-threaded.wasm",it()||(tt=S(tt));var ut={};function st(t){this.name="ExitStatus",this.message="Program terminated with exit("+t+")",this.status=t}function ct(t){(t=ht.Vb[t])||at(),ht.mc(t)}function lt(t){var e=ht.Cc();if(!e)return 6;ht.ac.push(e),ht.Vb[t.Ub]=e,e.Ub=t.Ub;var n={cmd:"run",start_routine:t.Ic,arg:t.zc,pthread_ptr:t.Ub};return e.$b=()=>{n.time=performance.now(),e.postMessage(n,t.Nc)},e.loaded&&(e.$b(),delete e.$b),0}function ft(t){if(O)return qt(1,1,t);Q()||(ht.oc(),u.onExit&&u.onExit(t),H=!0),g(t,new st(t))}function pt(t,e){if(!e&&O)throw bt(t),"unwind";Q()||O||(me(),dt(J),be(0),re[1].length&&ae(1,10),re[2].length&&ae(2,10),ht.oc()),ft(t)}var ht={Yb:[],ac:[],qc:[],Vb:{},fc:function(){O&&ht.Ec()},Pc:function(){},Ec:function(){ht.receiveObjectTransfer=ht.Gc,ht.threadInitTLS=ht.pc,ht.setExitStatus=ht.nc,R=!1},nc:function(){},oc:function(){for(var t of Object.values(ht.Vb))ht.mc(t);for(t of ht.Yb)t.terminate();ht.Yb=[]},mc:function(t){var e=t.Ub;delete ht.Vb[e],ht.Yb.push(t),ht.ac.splice(ht.ac.indexOf(t),1),t.Ub=0,Oe(e)},Gc:function(){},pc:function(){ht.qc.forEach((t=>t()))},Fc:function(t,e){t.onmessage=n=>{var r=(n=n.data).cmd;if(t.Ub&&(ht.Bc=t.Ub),n.targetThread&&n.targetThread!=he()){var a=ht.Vb[n.Qc];a?a.postMessage(n,n.transferList):x(\'Internal error! Worker sent a message "\'+r+\'" to target pthread \'+n.targetThread+", but that thread no longer exists!")}else"processProxyingQueue"===r?Lt(n.queue):"spawnThread"===r?lt(n):"cleanupThread"===r?ct(n.thread):"killThread"===r?(n=n.thread,r=ht.Vb[n],delete ht.Vb[n],r.terminate(),Oe(n),ht.ac.splice(ht.ac.indexOf(r),1),r.Ub=0):"cancelThread"===r?ht.Vb[n.thread].postMessage({cmd:"cancel"}):"loaded"===r?(t.loaded=!0,e&&e(t),t.$b&&(t.$b(),delete t.$b)):"print"===r?C("Thread "+n.threadId+": "+n.text):"printErr"===r?x("Thread "+n.threadId+": "+n.text):"alert"===r?alert("Thread "+n.threadId+": "+n.text):"setimmediate"===n.target?t.postMessage(n):"onAbort"===r?u.onAbort&&u.onAbort(n.arg):r&&x("worker sent an unknown command "+r);ht.Bc=void 0},t.onerror=t=>{throw x("worker sent an error! "+t.filename+":"+t.lineno+": "+t.message),t},w&&(t.on("message",(function(e){t.onmessage({data:e})})),t.on("error",(function(e){t.onerror(e)})),t.on("detachedExit",(function(){}))),t.postMessage({cmd:"load",urlOrBlob:u.mainScriptUrlOrBlob||_scriptDir,wasmMemory:k,wasmModule:j})},yc:function(){var t=S("ort-wasm-threaded.worker.js");ht.Yb.push(new Worker(t))},Cc:function(){return 0==ht.Yb.length&&(ht.yc(),ht.Fc(ht.Yb[0])),ht.Yb.pop()}};function dt(t){for(;0<t.length;)t.shift()(u)}function yt(t){var e=Ee();return t=t(),Me(e),t}function bt(t){if(O)return qt(2,0,t);try{pt(t)}catch(t){t instanceof st||"unwind"==t||g(1,t)}}u.PThread=ht,u.establishStackSpace=function(){var t=he(),e=a()[t+44>>2>>>0];t=a()[t+48>>2>>>0],Te(e,e-t),Me(e)};var mt=[];function gt(t){var e=mt[t];return e||(t>=mt.length&&(mt.length=t+1),mt[t]=e=q.get(t)),e}u.invokeEntryPoint=function(t,e){t=gt(t)(e),Q()?ht.nc(t):Ae(t)};var vt,_t,wt=[],Ot=0,At=0;function St(t){this.Zb=t,this.Sb=t-24,this.xc=function(t){i()[this.Sb+4>>2>>>0]=t},this.bc=function(){return i()[this.Sb+4>>2>>>0]},this.wc=function(t){i()[this.Sb+8>>2>>>0]=t},this.Dc=function(){return i()[this.Sb+8>>2>>>0]},this.rc=function(){a()[this.Sb>>2>>>0]=0},this.hc=function(t){t=t?1:0,e()[this.Sb+12>>0>>>0]=t},this.uc=function(){return 0!=e()[this.Sb+12>>0>>>0]},this.ic=function(t){t=t?1:0,e()[this.Sb+13>>0>>>0]=t},this.kc=function(){return 0!=e()[this.Sb+13>>0>>>0]},this.fc=function(t,e){this.cc(0),this.xc(t),this.wc(e),this.rc(),this.hc(!1),this.ic(!1)},this.sc=function(){Atomics.add(a(),this.Sb>>2,1)},this.Hc=function(){return 1===Atomics.sub(a(),this.Sb>>2,1)},this.cc=function(t){i()[this.Sb+16>>2>>>0]=t},this.tc=function(){return i()[this.Sb+16>>2>>>0]},this.vc=function(){if(Re(this.bc()))return i()[this.Zb>>2>>>0];var t=this.tc();return 0!==t?t:this.Zb}}function Tt(t){return ye(new St(t).Sb)}function Et(t,e,n,r){return O?qt(3,1,t,e,n,r):Mt(t,e,n,r)}function Mt(t,e,n,r){if("undefined"==typeof SharedArrayBuffer)return x("Current environment does not support SharedArrayBuffer, pthreads are not available!"),6;var a=[];return O&&0===a.length?Et(t,e,n,r):(t={Ic:n,Ub:t,zc:r,Nc:a},O?(t.Oc="spawnThread",postMessage(t,a),0):lt(t))}function Ct(t,e,n){return O?qt(4,1,t,e,n):0}function xt(t,e){if(O)return qt(5,1,t,e)}function Rt(t,e){if(O)return qt(6,1,t,e)}function kt(t,e,n){if(O)return qt(7,1,t,e,n)}function jt(t,e,n){return O?qt(8,1,t,e,n):0}function Dt(t,e){if(O)return qt(9,1,t,e)}function Pt(t,e,n){if(O)return qt(10,1,t,e,n)}function Ut(t,e,n,r){if(O)return qt(11,1,t,e,n,r)}function Ft(t,e,n,r){if(O)return qt(12,1,t,e,n,r)}function It(t,e,n,r){if(O)return qt(13,1,t,e,n,r)}function Wt(t){if(O)return qt(14,1,t)}function Ht(t,e){if(O)return qt(15,1,t,e)}function zt(t,e,n){if(O)return qt(16,1,t,e,n)}function Lt(t){Atomics.store(a(),t>>2,1),he()&&we(t),Atomics.compareExchange(a(),t>>2,1,0)}function Yt(t){return i()[t>>>2]+4294967296*a()[t+4>>>2]}function Bt(t,e,n,r,a,i){return O?qt(17,1,t,e,n,r,a,i):-52}function Gt(t,e,n,r,a,i){if(O)return qt(18,1,t,e,n,r,a,i)}function Nt(t){var n=G(t)+1,r=de(n);return r&&B(t,e(),r,n),r}function Vt(t,e,n){function r(t){return(t=t.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?t[1]:"GMT"}if(O)return qt(19,1,t,e,n);var o=(new Date).getFullYear(),u=new Date(o,0,1),s=new Date(o,6,1);o=u.getTimezoneOffset();var c=s.getTimezoneOffset(),l=Math.max(o,c);a()[t>>2>>>0]=60*l,a()[e>>2>>>0]=Number(o!=c),t=r(u),e=r(s),t=Nt(t),e=Nt(e),c<o?(i()[n>>2>>>0]=t,i()[n+4>>2>>>0]=e):(i()[n>>2>>>0]=e,i()[n+4>>2>>>0]=t)}function qt(t,e){var n=arguments.length-2,r=arguments;return yt((()=>{for(var a=Ce(8*n),i=a>>3,u=0;u<n;u++){var s=r[2+u];o()[i+u>>>0]=s}return _e(t,n,a,e)}))}u.executeNotifiedProxyingQueue=Lt,_t=w?()=>{var t=process.hrtime();return 1e3*t[0]+t[1]/1e6}:O?()=>performance.now()-u.__performance_now_clock_drift:()=>performance.now();var $t,Xt=[],Jt={};function Zt(){if(!$t){var t,e={USER:"web_user",LOGNAME:"web_user",PATH:"/",PWD:"/",HOME:"/home/web_user",LANG:("object"==typeof navigator&&navigator.languages&&navigator.languages[0]||"C").replace("-","_")+".UTF-8",_:m||"./this.program"};for(t in Jt)void 0===Jt[t]?delete e[t]:e[t]=Jt[t];var n=[];for(t in e)n.push(t+"="+e[t]);$t=n}return $t}function Qt(t,n){if(O)return qt(20,1,t,n);var r=0;return Zt().forEach((function(a,o){var u=n+r;for(o=i()[t+4*o>>2>>>0]=u,u=0;u<a.length;++u)e()[o++>>0>>>0]=a.charCodeAt(u);e()[o>>0>>>0]=0,r+=a.length+1})),0}function Kt(t,e){if(O)return qt(21,1,t,e);var n=Zt();i()[t>>2>>>0]=n.length;var r=0;return n.forEach((function(t){r+=t.length+1})),i()[e>>2>>>0]=r,0}function te(t){return O?qt(22,1,t):52}function ee(t,e,n,r){return O?qt(23,1,t,e,n,r):52}function ne(t,e,n,r,a){return O?qt(24,1,t,e,n,r,a):70}var re=[null,[],[]];function ae(t,e){var n=re[t];0===e||10===e?((1===t?C:x)(L(n,0)),n.length=0):n.push(e)}function ie(t,e,n,a){if(O)return qt(25,1,t,e,n,a);for(var o=0,u=0;u<n;u++){var s=i()[e>>2>>>0],c=i()[e+4>>2>>>0];e+=8;for(var l=0;l<c;l++)ae(t,r()[s+l>>>0]);o+=c}return i()[a>>2>>>0]=o,0}var oe=0;function ue(t){return 0==t%4&&(0!=t%100||0==t%400)}var se=[31,29,31,30,31,30,31,31,30,31,30,31],ce=[31,28,31,30,31,30,31,31,30,31,30,31];function le(t,n,r,i){function o(t,e,n){for(t="number"==typeof t?t.toString():t||"";t.length<e;)t=n[0]+t;return t}function u(t,e){return o(t,e,"0")}function s(t,e){function n(t){return 0>t?-1:0<t?1:0}var r;return 0===(r=n(t.getFullYear()-e.getFullYear()))&&0===(r=n(t.getMonth()-e.getMonth()))&&(r=n(t.getDate()-e.getDate())),r}function c(t){switch(t.getDay()){case 0:return new Date(t.getFullYear()-1,11,29);case 1:return t;case 2:return new Date(t.getFullYear(),0,3);case 3:return new Date(t.getFullYear(),0,2);case 4:return new Date(t.getFullYear(),0,1);case 5:return new Date(t.getFullYear()-1,11,31);case 6:return new Date(t.getFullYear()-1,11,30)}}function l(t){var e=t.Wb;for(t=new Date(new Date(t.Xb+1900,0,1).getTime());0<e;){var n=t.getMonth(),r=(ue(t.getFullYear())?se:ce)[n];if(!(e>r-t.getDate())){t.setDate(t.getDate()+e);break}e-=r-t.getDate()+1,t.setDate(1),11>n?t.setMonth(n+1):(t.setMonth(0),t.setFullYear(t.getFullYear()+1))}return n=new Date(t.getFullYear()+1,0,4),e=c(new Date(t.getFullYear(),0,4)),n=c(n),0>=s(e,t)?0>=s(n,t)?t.getFullYear()+1:t.getFullYear():t.getFullYear()-1}var f=a()[i+40>>2>>>0];for(var p in i={Lc:a()[i>>2>>>0],Kc:a()[i+4>>2>>>0],dc:a()[i+8>>2>>>0],jc:a()[i+12>>2>>>0],ec:a()[i+16>>2>>>0],Xb:a()[i+20>>2>>>0],Tb:a()[i+24>>2>>>0],Wb:a()[i+28>>2>>>0],Rc:a()[i+32>>2>>>0],Jc:a()[i+36>>2>>>0],Mc:f?Y(f):""},r=Y(r),f={"%c":"%a %b %d %H:%M:%S %Y","%D":"%m/%d/%y","%F":"%Y-%m-%d","%h":"%b","%r":"%I:%M:%S %p","%R":"%H:%M","%T":"%H:%M:%S","%x":"%m/%d/%y","%X":"%H:%M:%S","%Ec":"%c","%EC":"%C","%Ex":"%m/%d/%y","%EX":"%H:%M:%S","%Ey":"%y","%EY":"%Y","%Od":"%d","%Oe":"%e","%OH":"%H","%OI":"%I","%Om":"%m","%OM":"%M","%OS":"%S","%Ou":"%u","%OU":"%U","%OV":"%V","%Ow":"%w","%OW":"%W","%Oy":"%y"})r=r.replace(new RegExp(p,"g"),f[p]);var h="Sunday Monday Tuesday Wednesday Thursday Friday Saturday".split(" "),d="January February March April May June July August September October November December".split(" ");for(p in f={"%a":function(t){return h[t.Tb].substring(0,3)},"%A":function(t){return h[t.Tb]},"%b":function(t){return d[t.ec].substring(0,3)},"%B":function(t){return d[t.ec]},"%C":function(t){return u((t.Xb+1900)/100|0,2)},"%d":function(t){return u(t.jc,2)},"%e":function(t){return o(t.jc,2," ")},"%g":function(t){return l(t).toString().substring(2)},"%G":function(t){return l(t)},"%H":function(t){return u(t.dc,2)},"%I":function(t){return 0==(t=t.dc)?t=12:12<t&&(t-=12),u(t,2)},"%j":function(t){for(var e=0,n=0;n<=t.ec-1;e+=(ue(t.Xb+1900)?se:ce)[n++]);return u(t.jc+e,3)},"%m":function(t){return u(t.ec+1,2)},"%M":function(t){return u(t.Kc,2)},"%n":function(){return"\\n"},"%p":function(t){return 0<=t.dc&&12>t.dc?"AM":"PM"},"%S":function(t){return u(t.Lc,2)},"%t":function(){return"\\t"},"%u":function(t){return t.Tb||7},"%U":function(t){return u(Math.floor((t.Wb+7-t.Tb)/7),2)},"%V":function(t){var e=Math.floor((t.Wb+7-(t.Tb+6)%7)/7);if(2>=(t.Tb+371-t.Wb-2)%7&&e++,e)53==e&&(4==(n=(t.Tb+371-t.Wb)%7)||3==n&&ue(t.Xb)||(e=1));else{e=52;var n=(t.Tb+7-t.Wb-1)%7;(4==n||5==n&&ue(t.Xb%400-1))&&e++}return u(e,2)},"%w":function(t){return t.Tb},"%W":function(t){return u(Math.floor((t.Wb+7-(t.Tb+6)%7)/7),2)},"%y":function(t){return(t.Xb+1900).toString().substring(2)},"%Y":function(t){return t.Xb+1900},"%z":function(t){var e=0<=(t=t.Jc);return t=Math.abs(t)/60,(e?"+":"-")+String("0000"+(t/60*100+t%60)).slice(-4)},"%Z":function(t){return t.Mc},"%%":function(){return"%"}},r=r.replace(/%%/g,"\\0\\0"),f)r.includes(p)&&(r=r.replace(new RegExp(p,"g"),f[p](i)));return p=function(t){var e=Array(G(t)+1);return B(t,e,0,e.length),e}(r=r.replace(/\\0\\0/g,"%")),p.length>n?0:(function(t,n){e().set(t,n>>>0)}(p,t),p.length-1)}ht.fc();var fe=[null,ft,bt,Et,Ct,xt,Rt,kt,jt,Dt,Pt,Ut,Ft,It,Wt,Ht,zt,Bt,Gt,Vt,Qt,Kt,te,ee,ne,ie],pe={b:function(t){return de(t+24)+24},n:function(t){return(t=new St(t)).uc()||(t.hc(!0),Ot--),t.ic(!1),wt.push(t),t.sc(),t.vc()},ma:function(t){throw x("Unexpected exception thrown, this is not properly supported - aborting"),H=!0,t},x:function(){Se(0);var t=wt.pop();if(t.Hc()&&!t.kc()){var e=t.Dc();e&&gt(e)(t.Zb),Tt(t.Zb)}At=0},e:function(){var t=At;if(!t)return oe=0;var e=new St(t);e.cc(t);var n=e.bc();if(!n)return oe=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(xe(i,n,e.Sb+16))return oe=i,t}return oe=n,t},l:function(){var t=At;if(!t)return oe=0;var e=new St(t);e.cc(t);var n=e.bc();if(!n)return oe=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(xe(i,n,e.Sb+16))return oe=i,t}return oe=n,t},h:function(){var t=At;if(!t)return oe=0;var e=new St(t);e.cc(t);var n=e.bc();if(!n)return oe=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(xe(i,n,e.Sb+16))return oe=i,t}return oe=n,t},t:Tt,M:function(){var t=wt.pop();t||at("no exception to throw");var e=t.Zb;throw t.kc()||(wt.push(t),t.ic(!0),t.hc(!1),Ot++),At=e,e},c:function(t,e,n){throw new St(t).fc(e,n),At=t,Ot++,t},pa:function(){return Ot},Fa:function(t){ge(t,!_,1,!v),ht.pc()},T:function(t){O?postMessage({cmd:"cleanupThread",thread:t}):ct(t)},xa:Mt,j:function(t){throw At||(At=t),t},H:Ct,Ma:xt,ua:Rt,wa:kt,oa:jt,Ka:Dt,Ca:Pt,Ja:Ut,V:Ft,va:It,sa:Wt,La:Ht,ta:zt,Ta:function(){},X:function(){at("To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking")},Ua:function(){at("To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking")},W:function(){return Date.now()},ya:function(){return 2097152},Oa:function(){return!0},za:function(t,e,n,r){if(t==e)setTimeout((()=>Lt(r)));else if(O)postMessage({targetThread:t,cmd:"processProxyingQueue",queue:r});else{if(!(t=ht.Vb[t]))return;t.postMessage({cmd:"processProxyingQueue",queue:r})}return 1},Ea:function(){return-1},Pa:function(t,e){t=new Date(1e3*Yt(t)),a()[e>>2>>>0]=t.getUTCSeconds(),a()[e+4>>2>>>0]=t.getUTCMinutes(),a()[e+8>>2>>>0]=t.getUTCHours(),a()[e+12>>2>>>0]=t.getUTCDate(),a()[e+16>>2>>>0]=t.getUTCMonth(),a()[e+20>>2>>>0]=t.getUTCFullYear()-1900,a()[e+24>>2>>>0]=t.getUTCDay(),t=(t.getTime()-Date.UTC(t.getUTCFullYear(),0,1,0,0,0,0))/864e5|0,a()[e+28>>2>>>0]=t},Qa:function(t,e){t=new Date(1e3*Yt(t)),a()[e>>2>>>0]=t.getSeconds(),a()[e+4>>2>>>0]=t.getMinutes(),a()[e+8>>2>>>0]=t.getHours(),a()[e+12>>2>>>0]=t.getDate(),a()[e+16>>2>>>0]=t.getMonth(),a()[e+20>>2>>>0]=t.getFullYear()-1900,a()[e+24>>2>>>0]=t.getDay();var n=new Date(t.getFullYear(),0,1),r=(t.getTime()-n.getTime())/864e5|0;a()[e+28>>2>>>0]=r,a()[e+36>>2>>>0]=-60*t.getTimezoneOffset(),r=new Date(t.getFullYear(),6,1).getTimezoneOffset(),t=0|(r!=(n=n.getTimezoneOffset())&&t.getTimezoneOffset()==Math.min(n,r)),a()[e+32>>2>>>0]=t},Ra:function(t){var e=new Date(a()[t+20>>2>>>0]+1900,a()[t+16>>2>>>0],a()[t+12>>2>>>0],a()[t+8>>2>>>0],a()[t+4>>2>>>0],a()[t>>2>>>0],0),n=a()[t+32>>2>>>0],r=e.getTimezoneOffset(),i=new Date(e.getFullYear(),0,1),o=new Date(e.getFullYear(),6,1).getTimezoneOffset(),u=i.getTimezoneOffset(),s=Math.min(u,o);return 0>n?a()[t+32>>2>>>0]=Number(o!=u&&s==r):0<n!=(s==r)&&(o=Math.max(u,o),e.setTime(e.getTime()+6e4*((0<n?s:o)-r))),a()[t+24>>2>>>0]=e.getDay(),n=(e.getTime()-i.getTime())/864e5|0,a()[t+28>>2>>>0]=n,a()[t>>2>>>0]=e.getSeconds(),a()[t+4>>2>>>0]=e.getMinutes(),a()[t+8>>2>>>0]=e.getHours(),a()[t+12>>2>>>0]=e.getDate(),a()[t+16>>2>>>0]=e.getMonth(),e.getTime()/1e3|0},Aa:Bt,Ba:Gt,Sa:function t(e,n,r){t.Ac||(t.Ac=!0,Vt(e,n,r))},y:function(){at("")},U:function(){if(!w&&!_){var t="Blocking on the main thread is very dangerous, see https://emscripten.org/docs/porting/pthreads.html#blocking-on-the-main-browser-thread";vt||(vt={}),vt[t]||(vt[t]=1,w&&(t="warning: "+t),x(t))}},ra:function(){return 4294901760},B:_t,Ia:function(t,e,n){r().copyWithin(t>>>0,e>>>0,e+n>>>0)},F:function(){return w?n(37).cpus().length:navigator.hardwareConcurrency},Da:function(t,e,n){Xt.length=e,n>>=3;for(var r=0;r<e;r++)Xt[r]=o()[n+r>>>0];return(0>t?ut[-t-1]:fe[t]).apply(null,Xt)},qa:function(t){var e=r().length;if((t>>>=0)<=e||4294901760<t)return!1;for(var n=1;4>=n;n*=2){var a=e*(1+.2/n);a=Math.min(a,t+100663296);var i=Math;a=Math.max(t,a),i=i.min.call(i,4294901760,a+(65536-a%65536)%65536);t:{try{k.grow(i-D.byteLength+65535>>>16),N(k.buffer);var o=1;break t}catch(t){}o=void 0}if(o)return!0}return!1},Na:function(){throw"unwind"},Ga:Qt,Ha:Kt,J:pt,I:te,S:ee,ga:ne,R:ie,d:function(){return oe},na:function t(r,a){t.lc||(t.lc=function(){if("object"==typeof crypto&&"function"==typeof crypto.getRandomValues){var t=new Uint8Array(1);return()=>(crypto.getRandomValues(t),t[0])}if(w)try{var e=n(113);return()=>e.randomBytes(1)[0]}catch(t){}return()=>at("randomDevice")}());for(var i=0;i<a;i++)e()[r+i>>0>>>0]=t.lc();return 0},ia:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},ja:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},K:function(t){var e=Ee();try{return gt(t)()}catch(t){if(Me(e),t!==t+0)throw t;Se(1,0)}},f:function(t,e){var n=Ee();try{return gt(t)(e)}catch(t){if(Me(n),t!==t+0)throw t;Se(1,0)}},P:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},Q:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},k:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},p:function(t,e,n,r){var a=Ee();try{return gt(t)(e,n,r)}catch(t){if(Me(a),t!==t+0)throw t;Se(1,0)}},q:function(t,e,n,r,a){var i=Ee();try{return gt(t)(e,n,r,a)}catch(t){if(Me(i),t!==t+0)throw t;Se(1,0)}},N:function(t,e,n,r,a,i){var o=Ee();try{return gt(t)(e,n,r,a,i)}catch(t){if(Me(o),t!==t+0)throw t;Se(1,0)}},s:function(t,e,n,r,a,i){var o=Ee();try{return gt(t)(e,n,r,a,i)}catch(t){if(Me(o),t!==t+0)throw t;Se(1,0)}},w:function(t,e,n,r,a,i,o){var u=Ee();try{return gt(t)(e,n,r,a,i,o)}catch(t){if(Me(u),t!==t+0)throw t;Se(1,0)}},L:function(t,e,n,r,a,i,o,u){var s=Ee();try{return gt(t)(e,n,r,a,i,o,u)}catch(t){if(Me(s),t!==t+0)throw t;Se(1,0)}},E:function(t,e,n,r,a,i,o,u,s,c,l,f){var p=Ee();try{return gt(t)(e,n,r,a,i,o,u,s,c,l,f)}catch(t){if(Me(p),t!==t+0)throw t;Se(1,0)}},aa:function(t,e,n,r,a,i,o,u){var s=Ee();try{return He(t,e,n,r,a,i,o,u)}catch(t){if(Me(s),t!==t+0)throw t;Se(1,0)}},_:function(t,e,n,r,a,i,o){var u=Ee();try{return je(t,e,n,r,a,i,o)}catch(t){if(Me(u),t!==t+0)throw t;Se(1,0)}},Z:function(t,e,n,r,a){var i=Ee();try{return ze(t,e,n,r,a)}catch(t){if(Me(i),t!==t+0)throw t;Se(1,0)}},ca:function(t,e,n,r){var a=Ee();try{return Ie(t,e,n,r)}catch(t){if(Me(a),t!==t+0)throw t;Se(1,0)}},$:function(t){var e=Ee();try{return ke(t)}catch(t){if(Me(e),t!==t+0)throw t;Se(1,0)}},ba:function(t,e){var n=Ee();try{return We(t,e)}catch(t){if(Me(n),t!==t+0)throw t;Se(1,0)}},Y:function(t,e,n){var r=Ee();try{return De(t,e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},g:function(t){var e=Ee();try{gt(t)()}catch(t){if(Me(e),t!==t+0)throw t;Se(1,0)}},r:function(t,e){var n=Ee();try{gt(t)(e)}catch(t){if(Me(n),t!==t+0)throw t;Se(1,0)}},i:function(t,e,n){var r=Ee();try{gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},ha:function(t,e,n,r){var a=Ee();try{gt(t)(e,n,r)}catch(t){if(Me(a),t!==t+0)throw t;Se(1,0)}},m:function(t,e,n,r){var a=Ee();try{gt(t)(e,n,r)}catch(t){if(Me(a),t!==t+0)throw t;Se(1,0)}},v:function(t,e,n,r,a){var i=Ee();try{gt(t)(e,n,r,a)}catch(t){if(Me(i),t!==t+0)throw t;Se(1,0)}},u:function(t,e,n,r,a,i){var o=Ee();try{gt(t)(e,n,r,a,i)}catch(t){if(Me(o),t!==t+0)throw t;Se(1,0)}},O:function(t,e,n,r,a,i,o){var u=Ee();try{gt(t)(e,n,r,a,i,o)}catch(t){if(Me(u),t!==t+0)throw t;Se(1,0)}},A:function(t,e,n,r,a,i,o,u){var s=Ee();try{gt(t)(e,n,r,a,i,o,u)}catch(t){if(Me(s),t!==t+0)throw t;Se(1,0)}},ka:function(t,e,n,r,a,i,o,u,s){var c=Ee();try{gt(t)(e,n,r,a,i,o,u,s)}catch(t){if(Me(c),t!==t+0)throw t;Se(1,0)}},C:function(t,e,n,r,a,i,o,u,s,c,l){var f=Ee();try{gt(t)(e,n,r,a,i,o,u,s,c,l)}catch(t){if(Me(f),t!==t+0)throw t;Se(1,0)}},D:function(t,e,n,r,a,i,o,u,s,c,l,f,p,h,d,y){var b=Ee();try{gt(t)(e,n,r,a,i,o,u,s,c,l,f,p,h,d,y)}catch(t){if(Me(b),t!==t+0)throw t;Se(1,0)}},fa:function(t,e,n,r,a,i,o,u){var s=Ee();try{Pe(t,e,n,r,a,i,o,u)}catch(t){if(Me(s),t!==t+0)throw t;Se(1,0)}},da:function(t,e,n,r,a,i,o,u,s,c,l,f){var p=Ee();try{Fe(t,e,n,r,a,i,o,u,s,c,l,f)}catch(t){if(Me(p),t!==t+0)throw t;Se(1,0)}},ea:function(t,e,n,r,a,i){var o=Ee();try{Ue(t,e,n,r,a,i)}catch(t){if(Me(o),t!==t+0)throw t;Se(1,0)}},o:function(t){return t},a:k||u.wasmMemory,G:function(t){oe=t},la:le,z:function(t,e,n,r){return le(t,e,n,r)}};!function(){function t(t,e){u.asm=t.exports,ht.qc.push(u.asm.sb),q=u.asm.ub,X.unshift(u.asm.Va),j=e,O||(et--,u.monitorRunDependencies&&u.monitorRunDependencies(et),0==et&&(null!==nt&&(clearInterval(nt),nt=null),rt&&(t=rt,rt=null,t())))}function e(e){t(e.instance,e.module)}function n(t){return function(){if(!M&&(v||_)){if("function"==typeof fetch&&!tt.startsWith("file://"))return fetch(tt,{credentials:"same-origin"}).then((function(t){if(!t.ok)throw"failed to load wasm binary file at \'"+tt+"\'";return t.arrayBuffer()})).catch((function(){return ot()}));if(f)return new Promise((function(t,e){f(tt,(function(e){t(new Uint8Array(e))}),e)}))}return Promise.resolve().then((function(){return ot()}))}().then((function(t){return WebAssembly.instantiate(t,r)})).then((function(t){return t})).then(t,(function(t){x("failed to asynchronously prepare wasm: "+t),at(t)}))}var r={a:pe};if(O||(et++,u.monitorRunDependencies&&u.monitorRunDependencies(et)),u.instantiateWasm)try{return u.instantiateWasm(r,t)}catch(t){return x("Module.instantiateWasm callback failed with error: "+t),!1}(M||"function"!=typeof WebAssembly.instantiateStreaming||it()||tt.startsWith("file://")||w||"function"!=typeof fetch?n(e):fetch(tt,{credentials:"same-origin"}).then((function(t){return WebAssembly.instantiateStreaming(t,r).then(e,(function(t){return x("wasm streaming compile failed: "+t),x("falling back to ArrayBuffer instantiation"),n(e)}))}))).catch(c)}(),u.___wasm_call_ctors=function(){return(u.___wasm_call_ctors=u.asm.Va).apply(null,arguments)},u._OrtInit=function(){return(u._OrtInit=u.asm.Wa).apply(null,arguments)},u._OrtCreateSessionOptions=function(){return(u._OrtCreateSessionOptions=u.asm.Xa).apply(null,arguments)},u._OrtAppendExecutionProvider=function(){return(u._OrtAppendExecutionProvider=u.asm.Ya).apply(null,arguments)},u._OrtAddSessionConfigEntry=function(){return(u._OrtAddSessionConfigEntry=u.asm.Za).apply(null,arguments)},u._OrtReleaseSessionOptions=function(){return(u._OrtReleaseSessionOptions=u.asm._a).apply(null,arguments)},u._OrtCreateSession=function(){return(u._OrtCreateSession=u.asm.$a).apply(null,arguments)},u._OrtReleaseSession=function(){return(u._OrtReleaseSession=u.asm.ab).apply(null,arguments)},u._OrtGetInputCount=function(){return(u._OrtGetInputCount=u.asm.bb).apply(null,arguments)},u._OrtGetOutputCount=function(){return(u._OrtGetOutputCount=u.asm.cb).apply(null,arguments)},u._OrtGetInputName=function(){return(u._OrtGetInputName=u.asm.db).apply(null,arguments)},u._OrtGetOutputName=function(){return(u._OrtGetOutputName=u.asm.eb).apply(null,arguments)},u._OrtFree=function(){return(u._OrtFree=u.asm.fb).apply(null,arguments)},u._OrtCreateTensor=function(){return(u._OrtCreateTensor=u.asm.gb).apply(null,arguments)},u._OrtGetTensorData=function(){return(u._OrtGetTensorData=u.asm.hb).apply(null,arguments)},u._OrtReleaseTensor=function(){return(u._OrtReleaseTensor=u.asm.ib).apply(null,arguments)},u._OrtCreateRunOptions=function(){return(u._OrtCreateRunOptions=u.asm.jb).apply(null,arguments)},u._OrtAddRunConfigEntry=function(){return(u._OrtAddRunConfigEntry=u.asm.kb).apply(null,arguments)},u._OrtReleaseRunOptions=function(){return(u._OrtReleaseRunOptions=u.asm.lb).apply(null,arguments)},u._OrtRun=function(){return(u._OrtRun=u.asm.mb).apply(null,arguments)},u._OrtEndProfiling=function(){return(u._OrtEndProfiling=u.asm.nb).apply(null,arguments)};var he=u._pthread_self=function(){return(he=u._pthread_self=u.asm.ob).apply(null,arguments)},de=u._malloc=function(){return(de=u._malloc=u.asm.pb).apply(null,arguments)},ye=u._free=function(){return(ye=u._free=u.asm.qb).apply(null,arguments)},be=u._fflush=function(){return(be=u._fflush=u.asm.rb).apply(null,arguments)};u.__emscripten_tls_init=function(){return(u.__emscripten_tls_init=u.asm.sb).apply(null,arguments)};var me=u.___funcs_on_exit=function(){return(me=u.___funcs_on_exit=u.asm.tb).apply(null,arguments)},ge=u.__emscripten_thread_init=function(){return(ge=u.__emscripten_thread_init=u.asm.vb).apply(null,arguments)};u.__emscripten_thread_crashed=function(){return(u.__emscripten_thread_crashed=u.asm.wb).apply(null,arguments)};var ve,_e=u._emscripten_run_in_main_runtime_thread_js=function(){return(_e=u._emscripten_run_in_main_runtime_thread_js=u.asm.xb).apply(null,arguments)},we=u.__emscripten_proxy_execute_task_queue=function(){return(we=u.__emscripten_proxy_execute_task_queue=u.asm.yb).apply(null,arguments)},Oe=u.__emscripten_thread_free_data=function(){return(Oe=u.__emscripten_thread_free_data=u.asm.zb).apply(null,arguments)},Ae=u.__emscripten_thread_exit=function(){return(Ae=u.__emscripten_thread_exit=u.asm.Ab).apply(null,arguments)},Se=u._setThrew=function(){return(Se=u._setThrew=u.asm.Bb).apply(null,arguments)},Te=u._emscripten_stack_set_limits=function(){return(Te=u._emscripten_stack_set_limits=u.asm.Cb).apply(null,arguments)},Ee=u.stackSave=function(){return(Ee=u.stackSave=u.asm.Db).apply(null,arguments)},Me=u.stackRestore=function(){return(Me=u.stackRestore=u.asm.Eb).apply(null,arguments)},Ce=u.stackAlloc=function(){return(Ce=u.stackAlloc=u.asm.Fb).apply(null,arguments)},xe=u.___cxa_can_catch=function(){return(xe=u.___cxa_can_catch=u.asm.Gb).apply(null,arguments)},Re=u.___cxa_is_pointer_type=function(){return(Re=u.___cxa_is_pointer_type=u.asm.Hb).apply(null,arguments)},ke=u.dynCall_j=function(){return(ke=u.dynCall_j=u.asm.Ib).apply(null,arguments)},je=u.dynCall_iiiiij=function(){return(je=u.dynCall_iiiiij=u.asm.Jb).apply(null,arguments)},De=u.dynCall_jii=function(){return(De=u.dynCall_jii=u.asm.Kb).apply(null,arguments)},Pe=u.dynCall_viiiiij=function(){return(Pe=u.dynCall_viiiiij=u.asm.Lb).apply(null,arguments)},Ue=u.dynCall_vjji=function(){return(Ue=u.dynCall_vjji=u.asm.Mb).apply(null,arguments)},Fe=u.dynCall_viiijjjii=function(){return(Fe=u.dynCall_viiijjjii=u.asm.Nb).apply(null,arguments)},Ie=u.dynCall_iij=function(){return(Ie=u.dynCall_iij=u.asm.Ob).apply(null,arguments)},We=u.dynCall_ji=function(){return(We=u.dynCall_ji=u.asm.Pb).apply(null,arguments)},He=u.dynCall_iiiiiij=function(){return(He=u.dynCall_iiiiiij=u.asm.Qb).apply(null,arguments)},ze=u.dynCall_iiij=function(){return(ze=u.dynCall_iiij=u.asm.Rb).apply(null,arguments)};function Le(){function t(){if(!ve&&(ve=!0,u.calledRun=!0,!H)&&(O||dt(X),s(u),u.onRuntimeInitialized&&u.onRuntimeInitialized(),!O)){if(u.postRun)for("function"==typeof u.postRun&&(u.postRun=[u.postRun]);u.postRun.length;){var t=u.postRun.shift();Z.unshift(t)}dt(Z)}}if(!(0<et))if(O)s(u),O||dt(X),postMessage({cmd:"loaded"});else{if(u.preRun)for("function"==typeof u.preRun&&(u.preRun=[u.preRun]);u.preRun.length;)K();dt($),0<et||(u.setStatus?(u.setStatus("Running..."),setTimeout((function(){setTimeout((function(){u.setStatus("")}),1),t()}),1)):t())}}if(u.UTF8ToString=Y,u.stringToUTF8=function(t,e,n){return B(t,r(),e,n)},u.lengthBytesUTF8=G,u.keepRuntimeAlive=Q,u.wasmMemory=k,u.stackSave=Ee,u.stackRestore=Me,u.stackAlloc=Ce,u.ExitStatus=st,u.PThread=ht,rt=function t(){ve||Le(),ve||(rt=t)},u.preInit)for("function"==typeof u.preInit&&(u.preInit=[u.preInit]);0<u.preInit.length;)u.preInit.pop()();return Le(),t.ready});t.exports=r},932:(t,e,n)=>{var _scriptDir,r=(_scriptDir=(_scriptDir="undefined"!=typeof document&&document.currentScript?document.currentScript.src:void 0)||__filename,function(t){var e,r,a;t=t||{},e||(e=void 0!==t?t:{}),e.ready=new Promise((function(t,e){r=t,a=e}));var i,o,u,s,c,l,f=Object.assign({},e),p="./this.program",h=(t,e)=>{throw e},d="object"==typeof window,y="function"==typeof importScripts,b="object"==typeof process&&"object"==typeof process.versions&&"string"==typeof process.versions.node,m="";b?(m=y?n(17).dirname(m)+"/":__dirname+"/",l=()=>{c||(s=n(147),c=n(17))},i=function(t,e){return l(),t=c.normalize(t),s.readFileSync(t,e?void 0:"utf8")},u=t=>((t=i(t,!0)).buffer||(t=new Uint8Array(t)),t),o=(t,e,n)=>{l(),t=c.normalize(t),s.readFile(t,(function(t,r){t?n(t):e(r.buffer)}))},1<process.argv.length&&(p=process.argv[1].replace(/\\\\/g,"/")),process.argv.slice(2),process.on("uncaughtException",(function(t){if(!(t instanceof J))throw t})),process.on("unhandledRejection",(function(t){throw t})),h=(t,e)=>{if(w||0<z)throw process.exitCode=t,e;e instanceof J||_("exiting due to exception: "+e),process.exit(t)},e.inspect=function(){return"[Emscripten Module object]"}):(d||y)&&(y?m=self.location.href:"undefined"!=typeof document&&document.currentScript&&(m=document.currentScript.src),_scriptDir&&(m=_scriptDir),m=0!==m.indexOf("blob:")?m.substr(0,m.replace(/[?#].*/,"").lastIndexOf("/")+1):"",i=t=>{var e=new XMLHttpRequest;return e.open("GET",t,!1),e.send(null),e.responseText},y&&(u=t=>{var e=new XMLHttpRequest;return e.open("GET",t,!1),e.responseType="arraybuffer",e.send(null),new Uint8Array(e.response)}),o=(t,e,n)=>{var r=new XMLHttpRequest;r.open("GET",t,!0),r.responseType="arraybuffer",r.onload=()=>{200==r.status||0==r.status&&r.response?e(r.response):n()},r.onerror=n,r.send(null)});var g,v=e.print||console.log.bind(console),_=e.printErr||console.warn.bind(console);Object.assign(e,f),f=null,e.thisProgram&&(p=e.thisProgram),e.quit&&(h=e.quit),e.wasmBinary&&(g=e.wasmBinary);var w=e.noExitRuntime||!1;"object"!=typeof WebAssembly&&V("no native wasm support detected");var O,A,S,T,E,M,C=!1,x="undefined"!=typeof TextDecoder?new TextDecoder("utf8"):void 0;function R(t,e,n){var r=(e>>>=0)+n;for(n=e;t[n]&&!(n>=r);)++n;if(16<n-e&&t.buffer&&x)return x.decode(t.subarray(e,n));for(r="";e<n;){var a=t[e++];if(128&a){var i=63&t[e++];if(192==(224&a))r+=String.fromCharCode((31&a)<<6|i);else{var o=63&t[e++];65536>(a=224==(240&a)?(15&a)<<12|i<<6|o:(7&a)<<18|i<<12|o<<6|63&t[e++])?r+=String.fromCharCode(a):(a-=65536,r+=String.fromCharCode(55296|a>>10,56320|1023&a))}}else r+=String.fromCharCode(a)}return r}function k(t,e){return(t>>>=0)?R(T,t,e):""}function j(t,e,n,r){if(!(0<r))return 0;var a=n>>>=0;r=n+r-1;for(var i=0;i<t.length;++i){var o=t.charCodeAt(i);if(55296<=o&&57343>=o&&(o=65536+((1023&o)<<10)|1023&t.charCodeAt(++i)),127>=o){if(n>=r)break;e[n++>>>0]=o}else{if(2047>=o){if(n+1>=r)break;e[n++>>>0]=192|o>>6}else{if(65535>=o){if(n+2>=r)break;e[n++>>>0]=224|o>>12}else{if(n+3>=r)break;e[n++>>>0]=240|o>>18,e[n++>>>0]=128|o>>12&63}e[n++>>>0]=128|o>>6&63}e[n++>>>0]=128|63&o}}return e[n>>>0]=0,n-a}function D(t){for(var e=0,n=0;n<t.length;++n){var r=t.charCodeAt(n);127>=r?e++:2047>=r?e+=2:55296<=r&&57343>=r?(e+=4,++n):e+=3}return e}function P(){var t=O.buffer;A=t,e.HEAP8=S=new Int8Array(t),e.HEAP16=new Int16Array(t),e.HEAP32=E=new Int32Array(t),e.HEAPU8=T=new Uint8Array(t),e.HEAPU16=new Uint16Array(t),e.HEAPU32=M=new Uint32Array(t),e.HEAPF32=new Float32Array(t),e.HEAPF64=new Float64Array(t)}var U,F=[],I=[],W=[],H=[],z=0;function L(){var t=e.preRun.shift();F.unshift(t)}var Y,B=0,G=null,N=null;function V(t){throw e.onAbort&&e.onAbort(t),_(t="Aborted("+t+")"),C=!0,t=new WebAssembly.RuntimeError(t+". Build with -sASSERTIONS for more info."),a(t),t}function q(){return Y.startsWith("data:application/octet-stream;base64,")}if(Y="ort-wasm.wasm",!q()){var $=Y;Y=e.locateFile?e.locateFile($,m):m+$}function X(){var t=Y;try{if(t==Y&&g)return new Uint8Array(g);if(u)return u(t);throw"both async and sync fetching of the wasm failed"}catch(t){V(t)}}function J(t){this.name="ExitStatus",this.message="Program terminated with exit("+t+")",this.status=t}function Z(t){for(;0<t.length;)t.shift()(e)}var Q=[],K=0,tt=0;function et(t){this.Db=t,this.zb=t-24,this.Ub=function(t){M[this.zb+4>>2>>>0]=t},this.Eb=function(){return M[this.zb+4>>2>>>0]},this.Sb=function(t){M[this.zb+8>>2>>>0]=t},this.Wb=function(){return M[this.zb+8>>2>>>0]},this.Tb=function(){E[this.zb>>2>>>0]=0},this.Ib=function(t){S[this.zb+12>>0>>>0]=t?1:0},this.Pb=function(){return 0!=S[this.zb+12>>0>>>0]},this.Jb=function(t){S[this.zb+13>>0>>>0]=t?1:0},this.Lb=function(){return 0!=S[this.zb+13>>0>>>0]},this.Rb=function(t,e){this.Fb(0),this.Ub(t),this.Sb(e),this.Tb(),this.Ib(!1),this.Jb(!1)},this.Nb=function(){E[this.zb>>2>>>0]+=1},this.Xb=function(){var t=E[this.zb>>2>>>0];return E[this.zb>>2>>>0]=t-1,1===t},this.Fb=function(t){M[this.zb+16>>2>>>0]=t},this.Ob=function(){return M[this.zb+16>>2>>>0]},this.Qb=function(){if(Mt(this.Eb()))return M[this.Db>>2>>>0];var t=this.Ob();return 0!==t?t:this.Db}}function nt(t){return vt(new et(t).zb)}var rt=[];function at(t){var e=rt[t];return e||(t>=rt.length&&(rt.length=t+1),rt[t]=e=U.get(t)),e}function it(t){var e=D(t)+1,n=gt(e);return n&&j(t,S,n,e),n}var ot={};function ut(){if(!st){var t,e={USER:"web_user",LOGNAME:"web_user",PATH:"/",PWD:"/",HOME:"/home/web_user",LANG:("object"==typeof navigator&&navigator.languages&&navigator.languages[0]||"C").replace("-","_")+".UTF-8",_:p||"./this.program"};for(t in ot)void 0===ot[t]?delete e[t]:e[t]=ot[t];var n=[];for(t in e)n.push(t+"="+e[t]);st=n}return st}var st,ct=[null,[],[]];function lt(t,e){var n=ct[t];0===e||10===e?((1===t?v:_)(R(n,0)),n.length=0):n.push(e)}var ft=0;function pt(t){return 0==t%4&&(0!=t%100||0==t%400)}var ht=[31,29,31,30,31,30,31,31,30,31,30,31],dt=[31,28,31,30,31,30,31,31,30,31,30,31];function yt(t,e,n,r){function a(t,e,n){for(t="number"==typeof t?t.toString():t||"";t.length<e;)t=n[0]+t;return t}function i(t,e){return a(t,e,"0")}function o(t,e){function n(t){return 0>t?-1:0<t?1:0}var r;return 0===(r=n(t.getFullYear()-e.getFullYear()))&&0===(r=n(t.getMonth()-e.getMonth()))&&(r=n(t.getDate()-e.getDate())),r}function u(t){switch(t.getDay()){case 0:return new Date(t.getFullYear()-1,11,29);case 1:return t;case 2:return new Date(t.getFullYear(),0,3);case 3:return new Date(t.getFullYear(),0,2);case 4:return new Date(t.getFullYear(),0,1);case 5:return new Date(t.getFullYear()-1,11,31);case 6:return new Date(t.getFullYear()-1,11,30)}}function s(t){var e=t.Bb;for(t=new Date(new Date(t.Cb+1900,0,1).getTime());0<e;){var n=t.getMonth(),r=(pt(t.getFullYear())?ht:dt)[n];if(!(e>r-t.getDate())){t.setDate(t.getDate()+e);break}e-=r-t.getDate()+1,t.setDate(1),11>n?t.setMonth(n+1):(t.setMonth(0),t.setFullYear(t.getFullYear()+1))}return n=new Date(t.getFullYear()+1,0,4),e=u(new Date(t.getFullYear(),0,4)),n=u(n),0>=o(e,t)?0>=o(n,t)?t.getFullYear()+1:t.getFullYear():t.getFullYear()-1}var c=E[r+40>>2>>>0];for(var l in r={$b:E[r>>2>>>0],Zb:E[r+4>>2>>>0],Gb:E[r+8>>2>>>0],Kb:E[r+12>>2>>>0],Hb:E[r+16>>2>>>0],Cb:E[r+20>>2>>>0],Ab:E[r+24>>2>>>0],Bb:E[r+28>>2>>>0],bc:E[r+32>>2>>>0],Yb:E[r+36>>2>>>0],ac:c?k(c):""},n=k(n),c={"%c":"%a %b %d %H:%M:%S %Y","%D":"%m/%d/%y","%F":"%Y-%m-%d","%h":"%b","%r":"%I:%M:%S %p","%R":"%H:%M","%T":"%H:%M:%S","%x":"%m/%d/%y","%X":"%H:%M:%S","%Ec":"%c","%EC":"%C","%Ex":"%m/%d/%y","%EX":"%H:%M:%S","%Ey":"%y","%EY":"%Y","%Od":"%d","%Oe":"%e","%OH":"%H","%OI":"%I","%Om":"%m","%OM":"%M","%OS":"%S","%Ou":"%u","%OU":"%U","%OV":"%V","%Ow":"%w","%OW":"%W","%Oy":"%y"})n=n.replace(new RegExp(l,"g"),c[l]);var f="Sunday Monday Tuesday Wednesday Thursday Friday Saturday".split(" "),p="January February March April May June July August September October November December".split(" ");for(l in c={"%a":function(t){return f[t.Ab].substring(0,3)},"%A":function(t){return f[t.Ab]},"%b":function(t){return p[t.Hb].substring(0,3)},"%B":function(t){return p[t.Hb]},"%C":function(t){return i((t.Cb+1900)/100|0,2)},"%d":function(t){return i(t.Kb,2)},"%e":function(t){return a(t.Kb,2," ")},"%g":function(t){return s(t).toString().substring(2)},"%G":function(t){return s(t)},"%H":function(t){return i(t.Gb,2)},"%I":function(t){return 0==(t=t.Gb)?t=12:12<t&&(t-=12),i(t,2)},"%j":function(t){for(var e=0,n=0;n<=t.Hb-1;e+=(pt(t.Cb+1900)?ht:dt)[n++]);return i(t.Kb+e,3)},"%m":function(t){return i(t.Hb+1,2)},"%M":function(t){return i(t.Zb,2)},"%n":function(){return"\\n"},"%p":function(t){return 0<=t.Gb&&12>t.Gb?"AM":"PM"},"%S":function(t){return i(t.$b,2)},"%t":function(){return"\\t"},"%u":function(t){return t.Ab||7},"%U":function(t){return i(Math.floor((t.Bb+7-t.Ab)/7),2)},"%V":function(t){var e=Math.floor((t.Bb+7-(t.Ab+6)%7)/7);if(2>=(t.Ab+371-t.Bb-2)%7&&e++,e)53==e&&(4==(n=(t.Ab+371-t.Bb)%7)||3==n&&pt(t.Cb)||(e=1));else{e=52;var n=(t.Ab+7-t.Bb-1)%7;(4==n||5==n&&pt(t.Cb%400-1))&&e++}return i(e,2)},"%w":function(t){return t.Ab},"%W":function(t){return i(Math.floor((t.Bb+7-(t.Ab+6)%7)/7),2)},"%y":function(t){return(t.Cb+1900).toString().substring(2)},"%Y":function(t){return t.Cb+1900},"%z":function(t){var e=0<=(t=t.Yb);return t=Math.abs(t)/60,(e?"+":"-")+String("0000"+(t/60*100+t%60)).slice(-4)},"%Z":function(t){return t.ac},"%%":function(){return"%"}},n=n.replace(/%%/g,"\\0\\0"),c)n.includes(l)&&(n=n.replace(new RegExp(l,"g"),c[l](r)));return l=function(t){var e=Array(D(t)+1);return j(t,e,0,e.length),e}(n=n.replace(/\\0\\0/g,"%")),l.length>e?0:(S.set(l,t>>>0),l.length-1)}var bt={a:function(t){return gt(t+24)+24},m:function(t){return(t=new et(t)).Pb()||(t.Ib(!0),K--),t.Jb(!1),Q.push(t),t.Nb(),t.Qb()},ia:function(t){throw _("Unexpected exception thrown, this is not properly supported - aborting"),C=!0,t},w:function(){Ot(0);var t=Q.pop();if(t.Xb()&&!t.Lb()){var e=t.Wb();e&&at(e)(t.Db),nt(t.Db)}tt=0},d:function(){var t=tt;if(!t)return ft=0;var e=new et(t);e.Fb(t);var n=e.Eb();if(!n)return ft=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(Et(i,n,e.zb+16))return ft=i,t}return ft=n,t},k:function(){var t=tt;if(!t)return ft=0;var e=new et(t);e.Fb(t);var n=e.Eb();if(!n)return ft=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(Et(i,n,e.zb+16))return ft=i,t}return ft=n,t},g:function(){var t=tt;if(!t)return ft=0;var e=new et(t);e.Fb(t);var n=e.Eb();if(!n)return ft=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(Et(i,n,e.zb+16))return ft=i,t}return ft=n,t},s:nt,L:function(){var t=Q.pop();t||V("no exception to throw");var e=t.Db;throw t.Lb()||(Q.push(t),t.Jb(!0),t.Ib(!1),K++),tt=e,e},b:function(t,e,n){throw new et(t).Rb(e,n),tt=t,K++,t},la:function(){return K},i:function(t){throw tt||(tt=t),t},H:function(){return 0},Ba:function(){},pa:function(){},ra:function(){},ka:function(){return 0},za:function(){},ua:function(){},ya:function(){},R:function(){},qa:function(){},na:function(){},Aa:function(){},oa:function(){},Ha:function(){},Ja:function(){V("To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking")},Ia:function(){V("To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking")},S:function(){return Date.now()},Ca:function(){return!0},Da:function(t,e){t=new Date(1e3*(M[t>>>2]+4294967296*E[t+4>>>2])),E[e>>2>>>0]=t.getUTCSeconds(),E[e+4>>2>>>0]=t.getUTCMinutes(),E[e+8>>2>>>0]=t.getUTCHours(),E[e+12>>2>>>0]=t.getUTCDate(),E[e+16>>2>>>0]=t.getUTCMonth(),E[e+20>>2>>>0]=t.getUTCFullYear()-1900,E[e+24>>2>>>0]=t.getUTCDay(),E[e+28>>2>>>0]=(t.getTime()-Date.UTC(t.getUTCFullYear(),0,1,0,0,0,0))/864e5|0},Ea:function(t,e){t=new Date(1e3*(M[t>>>2]+4294967296*E[t+4>>>2])),E[e>>2>>>0]=t.getSeconds(),E[e+4>>2>>>0]=t.getMinutes(),E[e+8>>2>>>0]=t.getHours(),E[e+12>>2>>>0]=t.getDate(),E[e+16>>2>>>0]=t.getMonth(),E[e+20>>2>>>0]=t.getFullYear()-1900,E[e+24>>2>>>0]=t.getDay();var n=new Date(t.getFullYear(),0,1);E[e+28>>2>>>0]=(t.getTime()-n.getTime())/864e5|0,E[e+36>>2>>>0]=-60*t.getTimezoneOffset();var r=new Date(t.getFullYear(),6,1).getTimezoneOffset();n=n.getTimezoneOffset(),E[e+32>>2>>>0]=0|(r!=n&&t.getTimezoneOffset()==Math.min(n,r))},Fa:function(t){var e=new Date(E[t+20>>2>>>0]+1900,E[t+16>>2>>>0],E[t+12>>2>>>0],E[t+8>>2>>>0],E[t+4>>2>>>0],E[t>>2>>>0],0),n=E[t+32>>2>>>0],r=e.getTimezoneOffset(),a=new Date(e.getFullYear(),0,1),i=new Date(e.getFullYear(),6,1).getTimezoneOffset(),o=a.getTimezoneOffset(),u=Math.min(o,i);return 0>n?E[t+32>>2>>>0]=Number(i!=o&&u==r):0<n!=(u==r)&&(i=Math.max(o,i),e.setTime(e.getTime()+6e4*((0<n?u:i)-r))),E[t+24>>2>>>0]=e.getDay(),E[t+28>>2>>>0]=(e.getTime()-a.getTime())/864e5|0,E[t>>2>>>0]=e.getSeconds(),E[t+4>>2>>>0]=e.getMinutes(),E[t+8>>2>>>0]=e.getHours(),E[t+12>>2>>>0]=e.getDate(),E[t+16>>2>>>0]=e.getMonth(),e.getTime()/1e3|0},sa:function(){return-52},ta:function(){},Ga:function t(e,n,r){t.Vb||(t.Vb=!0,function(t,e,n){function r(t){return(t=t.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?t[1]:"GMT"}var a=(new Date).getFullYear(),i=new Date(a,0,1),o=new Date(a,6,1);a=i.getTimezoneOffset();var u=o.getTimezoneOffset();E[t>>2>>>0]=60*Math.max(a,u),E[e>>2>>>0]=Number(a!=u),t=r(i),e=r(o),t=it(t),e=it(e),u<a?(M[n>>2>>>0]=t,M[n+4>>2>>>0]=e):(M[n>>2>>>0]=e,M[n+4>>2>>>0]=t)}(e,n,r))},B:function(){V("")},ma:function(){return 4294901760},I:b?()=>{var t=process.hrtime();return 1e3*t[0]+t[1]/1e6}:()=>performance.now(),xa:function(t,e,n){T.copyWithin(t>>>0,e>>>0,e+n>>>0)},G:function(t){var e=T.length;if(4294901760<(t>>>=0))return!1;for(var n=1;4>=n;n*=2){var r=e*(1+.2/n);r=Math.min(r,t+100663296);var a=Math;r=Math.max(t,r),a=a.min.call(a,4294901760,r+(65536-r%65536)%65536);t:{try{O.grow(a-A.byteLength+65535>>>16),P();var i=1;break t}catch(t){}i=void 0}if(i)return!0}return!1},va:function(t,e){var n=0;return ut().forEach((function(r,a){var i=e+n;for(a=M[t+4*a>>2>>>0]=i,i=0;i<r.length;++i)S[a++>>0>>>0]=r.charCodeAt(i);S[a>>0>>>0]=0,n+=r.length+1})),0},wa:function(t,e){var n=ut();M[t>>2>>>0]=n.length;var r=0;return n.forEach((function(t){r+=t.length+1})),M[e>>2>>>0]=r,0},ba:function(t){w||0<z||(wt(),Z(W),_t(0),ct[1].length&&lt(1,10),ct[2].length&&lt(2,10)),w||0<z||(e.onExit&&e.onExit(t),C=!0),h(t,new J(t))},E:function(){return 52},Q:function(){return 52},ca:function(){return 70},P:function(t,e,n,r){for(var a=0,i=0;i<n;i++){var o=M[e>>2>>>0],u=M[e+4>>2>>>0];e+=8;for(var s=0;s<u;s++)lt(t,T[o+s>>>0]);a+=u}return M[r>>2>>>0]=a,0},c:function(){return ft},ja:function t(e,r){t.Mb||(t.Mb=function(){if("object"==typeof crypto&&"function"==typeof crypto.getRandomValues){var t=new Uint8Array(1);return()=>(crypto.getRandomValues(t),t[0])}if(b)try{var e=n(113);return()=>e.randomBytes(1)[0]}catch(t){}return()=>V("randomDevice")}());for(var a=0;a<r;a++)S[e+a>>0>>>0]=t.Mb();return 0},ea:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},fa:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},J:function(t){var e=At();try{return at(t)()}catch(t){if(St(e),t!==t+0)throw t;Ot(1,0)}},e:function(t,e){var n=At();try{return at(t)(e)}catch(t){if(St(n),t!==t+0)throw t;Ot(1,0)}},N:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},O:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},j:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},o:function(t,e,n,r){var a=At();try{return at(t)(e,n,r)}catch(t){if(St(a),t!==t+0)throw t;Ot(1,0)}},p:function(t,e,n,r,a){var i=At();try{return at(t)(e,n,r,a)}catch(t){if(St(i),t!==t+0)throw t;Ot(1,0)}},M:function(t,e,n,r,a,i){var o=At();try{return at(t)(e,n,r,a,i)}catch(t){if(St(o),t!==t+0)throw t;Ot(1,0)}},r:function(t,e,n,r,a,i){var o=At();try{return at(t)(e,n,r,a,i)}catch(t){if(St(o),t!==t+0)throw t;Ot(1,0)}},v:function(t,e,n,r,a,i,o){var u=At();try{return at(t)(e,n,r,a,i,o)}catch(t){if(St(u),t!==t+0)throw t;Ot(1,0)}},K:function(t,e,n,r,a,i,o,u){var s=At();try{return at(t)(e,n,r,a,i,o,u)}catch(t){if(St(s),t!==t+0)throw t;Ot(1,0)}},D:function(t,e,n,r,a,i,o,u,s,c,l,f){var p=At();try{return at(t)(e,n,r,a,i,o,u,s,c,l,f)}catch(t){if(St(p),t!==t+0)throw t;Ot(1,0)}},X:function(t,e,n,r,a,i,o,u){var s=At();try{return Ft(t,e,n,r,a,i,o,u)}catch(t){if(St(s),t!==t+0)throw t;Ot(1,0)}},V:function(t,e,n,r,a,i,o){var u=At();try{return xt(t,e,n,r,a,i,o)}catch(t){if(St(u),t!==t+0)throw t;Ot(1,0)}},U:function(t,e,n,r,a){var i=At();try{return It(t,e,n,r,a)}catch(t){if(St(i),t!==t+0)throw t;Ot(1,0)}},Z:function(t,e,n,r){var a=At();try{return Pt(t,e,n,r)}catch(t){if(St(a),t!==t+0)throw t;Ot(1,0)}},W:function(t){var e=At();try{return Ct(t)}catch(t){if(St(e),t!==t+0)throw t;Ot(1,0)}},Y:function(t,e){var n=At();try{return Ut(t,e)}catch(t){if(St(n),t!==t+0)throw t;Ot(1,0)}},T:function(t,e,n){var r=At();try{return Rt(t,e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},f:function(t){var e=At();try{at(t)()}catch(t){if(St(e),t!==t+0)throw t;Ot(1,0)}},q:function(t,e){var n=At();try{at(t)(e)}catch(t){if(St(n),t!==t+0)throw t;Ot(1,0)}},h:function(t,e,n){var r=At();try{at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},da:function(t,e,n,r){var a=At();try{at(t)(e,n,r)}catch(t){if(St(a),t!==t+0)throw t;Ot(1,0)}},l:function(t,e,n,r){var a=At();try{at(t)(e,n,r)}catch(t){if(St(a),t!==t+0)throw t;Ot(1,0)}},t:function(t,e,n,r,a){var i=At();try{at(t)(e,n,r,a)}catch(t){if(St(i),t!==t+0)throw t;Ot(1,0)}},u:function(t,e,n,r,a,i){var o=At();try{at(t)(e,n,r,a,i)}catch(t){if(St(o),t!==t+0)throw t;Ot(1,0)}},x:function(t,e,n,r,a,i,o){var u=At();try{at(t)(e,n,r,a,i,o)}catch(t){if(St(u),t!==t+0)throw t;Ot(1,0)}},z:function(t,e,n,r,a,i,o,u){var s=At();try{at(t)(e,n,r,a,i,o,u)}catch(t){if(St(s),t!==t+0)throw t;Ot(1,0)}},ga:function(t,e,n,r,a,i,o,u,s){var c=At();try{at(t)(e,n,r,a,i,o,u,s)}catch(t){if(St(c),t!==t+0)throw t;Ot(1,0)}},A:function(t,e,n,r,a,i,o,u,s,c,l){var f=At();try{at(t)(e,n,r,a,i,o,u,s,c,l)}catch(t){if(St(f),t!==t+0)throw t;Ot(1,0)}},C:function(t,e,n,r,a,i,o,u,s,c,l,f,p,h,d,y){var b=At();try{at(t)(e,n,r,a,i,o,u,s,c,l,f,p,h,d,y)}catch(t){if(St(b),t!==t+0)throw t;Ot(1,0)}},aa:function(t,e,n,r,a,i,o,u){var s=At();try{kt(t,e,n,r,a,i,o,u)}catch(t){if(St(s),t!==t+0)throw t;Ot(1,0)}},_:function(t,e,n,r,a,i,o,u,s,c,l,f){var p=At();try{Dt(t,e,n,r,a,i,o,u,s,c,l,f)}catch(t){if(St(p),t!==t+0)throw t;Ot(1,0)}},$:function(t,e,n,r,a,i){var o=At();try{jt(t,e,n,r,a,i)}catch(t){if(St(o),t!==t+0)throw t;Ot(1,0)}},n:function(t){return t},F:function(t){ft=t},ha:yt,y:function(t,e,n,r){return yt(t,e,n,r)}};!function(){function t(t){e.asm=t.exports,O=e.asm.Ka,P(),U=e.asm.ib,I.unshift(e.asm.La),B--,e.monitorRunDependencies&&e.monitorRunDependencies(B),0==B&&(null!==G&&(clearInterval(G),G=null),N&&(t=N,N=null,t()))}function n(e){t(e.instance)}function r(t){return function(){if(!g&&(d||y)){if("function"==typeof fetch&&!Y.startsWith("file://"))return fetch(Y,{credentials:"same-origin"}).then((function(t){if(!t.ok)throw"failed to load wasm binary file at \'"+Y+"\'";return t.arrayBuffer()})).catch((function(){return X()}));if(o)return new Promise((function(t,e){o(Y,(function(e){t(new Uint8Array(e))}),e)}))}return Promise.resolve().then((function(){return X()}))}().then((function(t){return WebAssembly.instantiate(t,i)})).then((function(t){return t})).then(t,(function(t){_("failed to asynchronously prepare wasm: "+t),V(t)}))}var i={a:bt};if(B++,e.monitorRunDependencies&&e.monitorRunDependencies(B),e.instantiateWasm)try{return e.instantiateWasm(i,t)}catch(t){return _("Module.instantiateWasm callback failed with error: "+t),!1}(g||"function"!=typeof WebAssembly.instantiateStreaming||q()||Y.startsWith("file://")||b||"function"!=typeof fetch?r(n):fetch(Y,{credentials:"same-origin"}).then((function(t){return WebAssembly.instantiateStreaming(t,i).then(n,(function(t){return _("wasm streaming compile failed: "+t),_("falling back to ArrayBuffer instantiation"),r(n)}))}))).catch(a)}(),e.___wasm_call_ctors=function(){return(e.___wasm_call_ctors=e.asm.La).apply(null,arguments)},e._OrtInit=function(){return(e._OrtInit=e.asm.Ma).apply(null,arguments)},e._OrtCreateSessionOptions=function(){return(e._OrtCreateSessionOptions=e.asm.Na).apply(null,arguments)},e._OrtAppendExecutionProvider=function(){return(e._OrtAppendExecutionProvider=e.asm.Oa).apply(null,arguments)},e._OrtAddSessionConfigEntry=function(){return(e._OrtAddSessionConfigEntry=e.asm.Pa).apply(null,arguments)},e._OrtReleaseSessionOptions=function(){return(e._OrtReleaseSessionOptions=e.asm.Qa).apply(null,arguments)},e._OrtCreateSession=function(){return(e._OrtCreateSession=e.asm.Ra).apply(null,arguments)},e._OrtReleaseSession=function(){return(e._OrtReleaseSession=e.asm.Sa).apply(null,arguments)},e._OrtGetInputCount=function(){return(e._OrtGetInputCount=e.asm.Ta).apply(null,arguments)},e._OrtGetOutputCount=function(){return(e._OrtGetOutputCount=e.asm.Ua).apply(null,arguments)},e._OrtGetInputName=function(){return(e._OrtGetInputName=e.asm.Va).apply(null,arguments)},e._OrtGetOutputName=function(){return(e._OrtGetOutputName=e.asm.Wa).apply(null,arguments)},e._OrtFree=function(){return(e._OrtFree=e.asm.Xa).apply(null,arguments)},e._OrtCreateTensor=function(){return(e._OrtCreateTensor=e.asm.Ya).apply(null,arguments)},e._OrtGetTensorData=function(){return(e._OrtGetTensorData=e.asm.Za).apply(null,arguments)},e._OrtReleaseTensor=function(){return(e._OrtReleaseTensor=e.asm._a).apply(null,arguments)},e._OrtCreateRunOptions=function(){return(e._OrtCreateRunOptions=e.asm.$a).apply(null,arguments)},e._OrtAddRunConfigEntry=function(){return(e._OrtAddRunConfigEntry=e.asm.ab).apply(null,arguments)},e._OrtReleaseRunOptions=function(){return(e._OrtReleaseRunOptions=e.asm.bb).apply(null,arguments)},e._OrtRun=function(){return(e._OrtRun=e.asm.cb).apply(null,arguments)},e._OrtEndProfiling=function(){return(e._OrtEndProfiling=e.asm.db).apply(null,arguments)};var mt,gt=e._malloc=function(){return(gt=e._malloc=e.asm.eb).apply(null,arguments)},vt=e._free=function(){return(vt=e._free=e.asm.fb).apply(null,arguments)},_t=e._fflush=function(){return(_t=e._fflush=e.asm.gb).apply(null,arguments)},wt=e.___funcs_on_exit=function(){return(wt=e.___funcs_on_exit=e.asm.hb).apply(null,arguments)},Ot=e._setThrew=function(){return(Ot=e._setThrew=e.asm.jb).apply(null,arguments)},At=e.stackSave=function(){return(At=e.stackSave=e.asm.kb).apply(null,arguments)},St=e.stackRestore=function(){return(St=e.stackRestore=e.asm.lb).apply(null,arguments)},Tt=e.stackAlloc=function(){return(Tt=e.stackAlloc=e.asm.mb).apply(null,arguments)},Et=e.___cxa_can_catch=function(){return(Et=e.___cxa_can_catch=e.asm.nb).apply(null,arguments)},Mt=e.___cxa_is_pointer_type=function(){return(Mt=e.___cxa_is_pointer_type=e.asm.ob).apply(null,arguments)},Ct=e.dynCall_j=function(){return(Ct=e.dynCall_j=e.asm.pb).apply(null,arguments)},xt=e.dynCall_iiiiij=function(){return(xt=e.dynCall_iiiiij=e.asm.qb).apply(null,arguments)},Rt=e.dynCall_jii=function(){return(Rt=e.dynCall_jii=e.asm.rb).apply(null,arguments)},kt=e.dynCall_viiiiij=function(){return(kt=e.dynCall_viiiiij=e.asm.sb).apply(null,arguments)},jt=e.dynCall_vjji=function(){return(jt=e.dynCall_vjji=e.asm.tb).apply(null,arguments)},Dt=e.dynCall_viiijjjii=function(){return(Dt=e.dynCall_viiijjjii=e.asm.ub).apply(null,arguments)},Pt=e.dynCall_iij=function(){return(Pt=e.dynCall_iij=e.asm.vb).apply(null,arguments)},Ut=e.dynCall_ji=function(){return(Ut=e.dynCall_ji=e.asm.wb).apply(null,arguments)},Ft=e.dynCall_iiiiiij=function(){return(Ft=e.dynCall_iiiiiij=e.asm.xb).apply(null,arguments)},It=e.dynCall_iiij=function(){return(It=e.dynCall_iiij=e.asm.yb).apply(null,arguments)};function Wt(){function t(){if(!mt&&(mt=!0,e.calledRun=!0,!C)){if(Z(I),r(e),e.onRuntimeInitialized&&e.onRuntimeInitialized(),e.postRun)for("function"==typeof e.postRun&&(e.postRun=[e.postRun]);e.postRun.length;){var t=e.postRun.shift();H.unshift(t)}Z(H)}}if(!(0<B)){if(e.preRun)for("function"==typeof e.preRun&&(e.preRun=[e.preRun]);e.preRun.length;)L();Z(F),0<B||(e.setStatus?(e.setStatus("Running..."),setTimeout((function(){setTimeout((function(){e.setStatus("")}),1),t()}),1)):t())}}if(e.UTF8ToString=k,e.stringToUTF8=function(t,e,n){return j(t,T,e,n)},e.lengthBytesUTF8=D,e.stackSave=At,e.stackRestore=St,e.stackAlloc=Tt,N=function t(){mt||Wt(),mt||(N=t)},e.preInit)for("function"==typeof e.preInit&&(e.preInit=[e.preInit]);0<e.preInit.length;)e.preInit.pop()();return Wt(),t.ready});t.exports=r},967:(t,e)=>{"use strict";Object.defineProperty(e,"__esModule",{value:!0}),e.iterateExtraOptions=void 0,e.iterateExtraOptions=(t,n,r,a)=>{if("object"==typeof t&&null!==t){if(r.has(t))throw new Error("Circular reference in options");r.add(t)}Object.entries(t).forEach((([t,i])=>{const o=n?n+t:t;if("object"==typeof i)(0,e.iterateExtraOptions)(i,o+".",r,a);else if("string"==typeof i||"number"==typeof i)a(o,i.toString());else{if("boolean"!=typeof i)throw new Error("Can\'t handle extra config type: "+typeof i);a(o,i?"1":"0")}}))}},586:(t,e,n)=>{"use strict";Object.defineProperty(e,"__esModule",{value:!0}),e.setRunOptions=void 0;const r=n(967),a=n(983),i=n(361);e.setRunOptions=t=>{const e=(0,i.getInstance)();let n=0;const o=[],u=t||{};try{if(void 0===(null==t?void 0:t.logSeverityLevel))u.logSeverityLevel=2;else if("number"!=typeof t.logSeverityLevel||!Number.isInteger(t.logSeverityLevel)||t.logSeverityLevel<0||t.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${t.logSeverityLevel}`);if(void 0===(null==t?void 0:t.logVerbosityLevel))u.logVerbosityLevel=0;else if("number"!=typeof t.logVerbosityLevel||!Number.isInteger(t.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${t.logVerbosityLevel}`);void 0===(null==t?void 0:t.terminate)&&(u.terminate=!1);let i=0;if(void 0!==(null==t?void 0:t.tag)&&(i=(0,a.allocWasmString)(t.tag,o)),n=e._OrtCreateRunOptions(u.logSeverityLevel,u.logVerbosityLevel,!!u.terminate,i),0===n)throw new Error("Can\'t create run options");return void 0!==(null==t?void 0:t.extra)&&(0,r.iterateExtraOptions)(t.extra,"",new WeakSet,((t,r)=>{const i=(0,a.allocWasmString)(t,o),u=(0,a.allocWasmString)(r,o);if(0!==e._OrtAddRunConfigEntry(n,i,u))throw new Error(`Can\'t set a run config entry: ${t} - ${r}`)})),[n,o]}catch(t){throw 0!==n&&e._OrtReleaseRunOptions(n),o.forEach(e._free),t}}},919:(t,e,n)=>{"use strict";Object.defineProperty(e,"__esModule",{value:!0}),e.setSessionOptions=void 0;const r=n(967),a=n(983),i=n(361);e.setSessionOptions=t=>{const e=(0,i.getInstance)();let n=0;const o=[],u=t||{};(t=>{t.extra||(t.extra={}),t.extra.session||(t.extra.session={});const e=t.extra.session;e.use_ort_model_bytes_directly||(e.use_ort_model_bytes_directly="1")})(u);try{void 0===(null==t?void 0:t.graphOptimizationLevel)&&(u.graphOptimizationLevel="all");const s=(t=>{switch(t){case"disabled":return 0;case"basic":return 1;case"extended":return 2;case"all":return 99;default:throw new Error(`unsupported graph optimization level: ${t}`)}})(u.graphOptimizationLevel);void 0===(null==t?void 0:t.enableCpuMemArena)&&(u.enableCpuMemArena=!0),void 0===(null==t?void 0:t.enableMemPattern)&&(u.enableMemPattern=!0),void 0===(null==t?void 0:t.executionMode)&&(u.executionMode="sequential");const c=(t=>{switch(t){case"sequential":return 0;case"parallel":return 1;default:throw new Error(`unsupported execution mode: ${t}`)}})(u.executionMode);let l=0;if(void 0!==(null==t?void 0:t.logId)&&(l=(0,a.allocWasmString)(t.logId,o)),void 0===(null==t?void 0:t.logSeverityLevel))u.logSeverityLevel=2;else if("number"!=typeof t.logSeverityLevel||!Number.isInteger(t.logSeverityLevel)||t.logSeverityLevel<0||t.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${t.logSeverityLevel}`);if(void 0===(null==t?void 0:t.logVerbosityLevel))u.logVerbosityLevel=0;else if("number"!=typeof t.logVerbosityLevel||!Number.isInteger(t.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${t.logVerbosityLevel}`);if(void 0===(null==t?void 0:t.enableProfiling)&&(u.enableProfiling=!1),n=e._OrtCreateSessionOptions(s,!!u.enableCpuMemArena,!!u.enableMemPattern,c,!!u.enableProfiling,0,l,u.logSeverityLevel,u.logVerbosityLevel),0===n)throw new Error("Can\'t create session options");return(null==t?void 0:t.executionProviders)&&((t,e,n)=>{for(const r of e){let e="string"==typeof r?r:r.name;switch(e){case"xnnpack":e="XNNPACK";break;case"wasm":case"cpu":continue;default:throw new Error(`not supported EP: ${e}`)}const o=(0,a.allocWasmString)(e,n);if(0!==(0,i.getInstance)()._OrtAppendExecutionProvider(t,o))throw new Error(`Can\'t append execution provider: ${e}`)}})(n,t.executionProviders,o),void 0!==(null==t?void 0:t.extra)&&(0,r.iterateExtraOptions)(t.extra,"",new WeakSet,((t,r)=>{const i=(0,a.allocWasmString)(t,o),u=(0,a.allocWasmString)(r,o);if(0!==e._OrtAddSessionConfigEntry(n,i,u))throw new Error(`Can\'t set a session config entry: ${t} - ${r}`)})),[n,o]}catch(t){throw 0!==n&&e._OrtReleaseSessionOptions(n),o.forEach(e._free),t}}},983:(t,e,n)=>{"use strict";Object.defineProperty(e,"__esModule",{value:!0}),e.allocWasmString=void 0;const r=n(361);e.allocWasmString=(t,e)=>{const n=(0,r.getInstance)(),a=n.lengthBytesUTF8(t)+1,i=n._malloc(a);return n.stringToUTF8(t,i,a),e.push(i),i}},349:(t,e,n)=>{"use strict";Object.defineProperty(e,"__esModule",{value:!0}),e.extractTransferableBuffers=e.endProfiling=e.run=e.releaseSession=e.createSession=e.createSessionFinalize=e.createSessionAllocate=e.initOrt=void 0;const r=n(586),a=n(919),i=n(983),o=n(361);e.initOrt=(t,e)=>{const n=(0,o.getInstance)()._OrtInit(t,e);if(0!==n)throw new Error(`Can\'t initialize onnxruntime. error code = ${n}`)};const u=new Map;e.createSessionAllocate=t=>{const e=(0,o.getInstance)(),n=e._malloc(t.byteLength);return e.HEAPU8.set(t,n),[n,t.byteLength]},e.createSessionFinalize=(t,e)=>{const n=(0,o.getInstance)();let r=0,i=0,s=[];try{if([i,s]=(0,a.setSessionOptions)(e),r=n._OrtCreateSession(t[0],t[1],i),0===r)throw new Error("Can\'t create a session")}finally{n._free(t[0]),n._OrtReleaseSessionOptions(i),s.forEach(n._free)}const c=n._OrtGetInputCount(r),l=n._OrtGetOutputCount(r),f=[],p=[],h=[],d=[];for(let t=0;t<c;t++){const e=n._OrtGetInputName(r,t);if(0===e)throw new Error("Can\'t get an input name");p.push(e),f.push(n.UTF8ToString(e))}for(let t=0;t<l;t++){const e=n._OrtGetOutputName(r,t);if(0===e)throw new Error("Can\'t get an output name");d.push(e),h.push(n.UTF8ToString(e))}return u.set(r,[r,p,d]),[r,f,h]},e.createSession=(t,n)=>{const r=(0,e.createSessionAllocate)(t);return(0,e.createSessionFinalize)(r,n)},e.releaseSession=t=>{const e=(0,o.getInstance)(),n=u.get(t);if(!n)throw new Error("invalid session id");const r=n[0],a=n[1],i=n[2];a.forEach(e._OrtFree),i.forEach(e._OrtFree),e._OrtReleaseSession(r),u.delete(t)};const s=t=>{switch(t){case"int8":return 3;case"uint8":return 2;case"bool":return 9;case"int16":return 5;case"uint16":return 4;case"int32":return 6;case"uint32":return 12;case"float32":return 1;case"float64":return 11;case"string":return 8;case"int64":return 7;case"uint64":return 13;default:throw new Error(`unsupported data type: ${t}`)}},c=t=>{switch(t){case 3:return"int8";case 2:return"uint8";case 9:return"bool";case 5:return"int16";case 4:return"uint16";case 6:return"int32";case 12:return"uint32";case 1:return"float32";case 11:return"float64";case 8:return"string";case 7:return"int64";case 13:return"uint64";default:throw new Error(`unsupported data type: ${t}`)}},l=t=>{switch(t){case"float32":return Float32Array;case"uint8":case"bool":return Uint8Array;case"int8":return Int8Array;case"uint16":return Uint16Array;case"int16":return Int16Array;case"int32":return Int32Array;case"float64":return Float64Array;case"uint32":return Uint32Array;case"int64":return BigInt64Array;case"uint64":return BigUint64Array;default:throw new Error(`unsupported type: ${t}`)}};e.run=(t,e,n,a,f)=>{const p=(0,o.getInstance)(),h=u.get(t);if(!h)throw new Error("invalid session id");const d=h[0],y=h[1],b=h[2],m=e.length,g=a.length;let v=0,_=[];const w=[],O=[];try{[v,_]=(0,r.setRunOptions)(f);for(let t=0;t<m;t++){const e=n[t][0],r=n[t][1],a=n[t][2];let o,u;if(Array.isArray(a)){u=4*a.length,o=p._malloc(u),O.push(o);let t=o/4;for(let e=0;e<a.length;e++){if("string"!=typeof a[e])throw new TypeError(`tensor data at index ${e} is not a string`);p.HEAPU32[t++]=(0,i.allocWasmString)(a[e],O)}}else u=a.byteLength,o=p._malloc(u),O.push(o),p.HEAPU8.set(new Uint8Array(a.buffer,a.byteOffset,u),o);const c=p.stackSave(),l=p.stackAlloc(4*r.length);try{let t=l/4;r.forEach((e=>p.HEAP32[t++]=e));const n=p._OrtCreateTensor(s(e),o,u,l,r.length);if(0===n)throw new Error("Can\'t create a tensor");w.push(n)}finally{p.stackRestore(c)}}const t=p.stackSave(),o=p.stackAlloc(4*m),u=p.stackAlloc(4*m),h=p.stackAlloc(4*g),A=p.stackAlloc(4*g);try{let n=o/4,r=u/4,i=h/4,s=A/4;for(let t=0;t<m;t++)p.HEAPU32[n++]=w[t],p.HEAPU32[r++]=y[e[t]];for(let t=0;t<g;t++)p.HEAPU32[i++]=0,p.HEAPU32[s++]=b[a[t]];let f=p._OrtRun(d,u,o,m,A,g,h,v);const _=[];if(0===f)for(let t=0;t<g;t++){const e=p.HEAPU32[h/4+t],n=p.stackSave(),r=p.stackAlloc(16);let a,i=0;try{if(f=p._OrtGetTensorData(e,r,r+4,r+8,r+12),0!==f)throw new Error(`Can\'t access output tensor data. error code = ${f}`);let t=r/4;const o=p.HEAPU32[t++];i=p.HEAPU32[t++];const u=p.HEAPU32[t++],s=p.HEAPU32[t++],h=[];for(let t=0;t<s;t++)h.push(p.HEAPU32[u/4+t]);p._OrtFree(u);const d=0===h.length?1:h.reduce(((t,e)=>t*e));if(a=c(o),"string"===a){const t=[];let e=i/4;for(let n=0;n<d;n++){const r=p.HEAPU32[e++],a=n===d-1?void 0:p.HEAPU32[e]-r;t.push(p.UTF8ToString(r,a))}_.push([a,h,t])}else{const t=new(l(a))(d);new Uint8Array(t.buffer,t.byteOffset,t.byteLength).set(p.HEAPU8.subarray(i,i+t.byteLength)),_.push([a,h,t])}}finally{p.stackRestore(n),"string"===a&&i&&p._free(i),p._OrtReleaseTensor(e)}}if(0===f)return _;throw new Error(`failed to call OrtRun(). error code = ${f}.`)}finally{p.stackRestore(t)}}finally{w.forEach(p._OrtReleaseTensor),O.forEach(p._free),p._OrtReleaseRunOptions(v),_.forEach(p._free)}},e.endProfiling=t=>{const e=(0,o.getInstance)(),n=u.get(t);if(!n)throw new Error("invalid session id");const r=n[0],a=e._OrtEndProfiling(r);if(0===a)throw new Error("Can\'t get an profile file name");e._OrtFree(a)},e.extractTransferableBuffers=t=>{const e=[];for(const n of t){const t=n[2];!Array.isArray(t)&&t.buffer&&e.push(t.buffer)}return e}},361:function(t,e,n){"use strict";var r=this&&this.__createBinding||(Object.create?function(t,e,n,r){void 0===r&&(r=n);var a=Object.getOwnPropertyDescriptor(e,n);a&&!("get"in a?!e.__esModule:a.writable||a.configurable)||(a={enumerable:!0,get:function(){return e[n]}}),Object.defineProperty(t,r,a)}:function(t,e,n,r){void 0===r&&(r=n),t[r]=e[n]}),a=this&&this.__setModuleDefault||(Object.create?function(t,e){Object.defineProperty(t,"default",{enumerable:!0,value:e})}:function(t,e){t.default=e}),i=this&&this.__importStar||function(t){if(t&&t.__esModule)return t;var e={};if(null!=t)for(var n in t)"default"!==n&&Object.prototype.hasOwnProperty.call(t,n)&&r(e,t,n);return a(e,t),e},o=this&&this.__importDefault||function(t){return t&&t.__esModule?t:{default:t}};Object.defineProperty(e,"__esModule",{value:!0}),e.dispose=e.getInstance=e.initializeWebAssembly=void 0;const u=i(n(17)),s=o(n(932)),c=n(474);let l,f=!1,p=!1,h=!1;const d=(t,e)=>e?t?"ort-wasm-simd-threaded.wasm":"ort-wasm-threaded.wasm":t?"ort-wasm-simd.wasm":"ort-wasm.wasm";e.initializeWebAssembly=async t=>{if(f)return Promise.resolve();if(p)throw new Error("multiple calls to \'initializeWebAssembly()\' detected.");if(h)throw new Error("previous call to \'initializeWebAssembly()\' failed.");p=!0;const e=t.initTimeout,r=t.numThreads,a=t.simd,i=r>1&&(()=>{try{return"undefined"!=typeof SharedArrayBuffer&&("undefined"!=typeof MessageChannel&&(new MessageChannel).port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11])))}catch(t){return!1}})(),o=a&&(()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch(t){return!1}})(),y="string"==typeof t.wasmPaths?t.wasmPaths:void 0,b=d(!1,i),m=d(o,i),g="object"==typeof t.wasmPaths?t.wasmPaths[m]:void 0;let v=!1;const _=[];if(e>0&&_.push(new Promise((t=>{setTimeout((()=>{v=!0,t()}),e)}))),_.push(new Promise(((t,e)=>{const r=i?c:s.default,a={locateFile:(t,e)=>i&&t.endsWith(".worker.js")&&"undefined"!=typeof Blob?URL.createObjectURL(new Blob([n(154)],{type:"text/javascript"})):t===b?null!=g?g:(null!=y?y:e)+m:e+t};if(i)if("undefined"==typeof Blob)a.mainScriptUrlOrBlob=u.join(__dirname,"ort-wasm-threaded.js");else{const t=`var ortWasmThreaded=(function(){var _scriptDir;return ${r.toString()}})();`;a.mainScriptUrlOrBlob=new Blob([t],{type:"text/javascript"})}r(a).then((e=>{p=!1,f=!0,l=e,t()}),(t=>{p=!1,h=!0,e(t)}))}))),await Promise.race(_),v)throw new Error(`WebAssembly backend initializing failed due to timeout: ${e}ms`)},e.getInstance=()=>{if(f&&l)return l;throw new Error("WebAssembly is not initialized yet.")},e.dispose=()=>{var t;!f||p||h||(p=!0,null===(t=l.PThread)||void 0===t||t.terminateAllThreads(),l=void 0,p=!1,f=!1,h=!0)}},154:t=>{"use strict";t.exports=\'"use strict";var e={},t="object"==typeof process&&"object"==typeof process.versions&&"string"==typeof process.versions.node;if(t){var r=require("worker_threads"),a=r.parentPort;a.on("message",(e=>onmessage({data:e})));var o=require("fs");Object.assign(global,{self:global,require:require,Module:e,location:{href:__filename},Worker:r.Worker,importScripts:function(e){(0,eval)(o.readFileSync(e,"utf8"))},postMessage:function(e){a.postMessage(e)},performance:global.performance||{now:function(){return Date.now()}}})}var s=!1,n=[],i=function(){var e=Array.prototype.slice.call(arguments).join(" ");t?o.writeSync(2,e+"\\\\n"):console.error(e)};self.alert=function(){var t=Array.prototype.slice.call(arguments).join(" ");postMessage({cmd:"alert",text:t,threadId:e._pthread_self()})},e.instantiateWasm=(t,r)=>{var a=new WebAssembly.Instance(e.wasmModule,t);return r(a),e.wasmModule=null,a.exports},self.onunhandledrejection=e=>{throw e.reason??e},self.onmessage=t=>{try{if("load"===t.data.cmd){if(e.wasmModule=t.data.wasmModule,e.wasmMemory=t.data.wasmMemory,e.buffer=e.wasmMemory.buffer,e.ENVIRONMENT_IS_PTHREAD=!0,"string"==typeof t.data.urlOrBlob)importScripts(t.data.urlOrBlob);else{var r=URL.createObjectURL(t.data.urlOrBlob);importScripts(r),URL.revokeObjectURL(r)}ortWasmThreaded(e).then((function(t){e=t}))}else if("run"===t.data.cmd){e.__performance_now_clock_drift=performance.now()-t.data.time,e.__emscripten_thread_init(t.data.pthread_ptr,0,0,1),e.establishStackSpace(),e.PThread.receiveObjectTransfer(t.data),e.PThread.threadInitTLS(),s||(n.forEach((t=>{e.executeNotifiedProxyingQueue(t)})),n=[],s=!0);try{e.invokeEntryPoint(t.data.start_routine,t.data.arg)}catch(t){if("unwind"!=t){if(!(t instanceof e.ExitStatus))throw t;e.keepRuntimeAlive()||e.__emscripten_thread_exit(t.status)}}}else"cancel"===t.data.cmd?e._pthread_self()&&e.__emscripten_thread_exit(-1):"setimmediate"===t.data.target||("processProxyingQueue"===t.data.cmd?s?e.executeNotifiedProxyingQueue(t.data.queue):n.push(t.data.queue):(i("worker.js received unknown command "+t.data.cmd),i(t.data)))}catch(t){throw i("worker.js onmessage() captured an uncaught exception: "+t),t&&t.stack&&i(t.stack),e.__emscripten_thread_crashed&&e.__emscripten_thread_crashed(),t}};\\n\'},113:t=>{"use strict";t.exports=require("crypto")},147:t=>{"use strict";t.exports=require("fs")},37:t=>{"use strict";t.exports=require("os")},17:t=>{"use strict";t.exports=require("path")},74:t=>{"use strict";t.exports=require("perf_hooks")},267:t=>{"use strict";t.exports=require("worker_threads")}},e={};function n(r){var a=e[r];if(void 0!==a)return a.exports;var i=e[r]={exports:{}};return t[r].call(i.exports,i,i.exports,n),i.exports}(()=>{"use strict";const t=n(349),e=n(361);self.onmessage=n=>{switch(n.data.type){case"init-wasm":(0,e.initializeWebAssembly)(n.data.in).then((()=>postMessage({type:"init-wasm"})),(t=>postMessage({type:"init-wasm",err:t})));break;case"init-ort":try{const{numThreads:e,loggingLevel:r}=n.data.in;(0,t.initOrt)(e,r),postMessage({type:"init-ort"})}catch(t){postMessage({type:"init-ort",err:t})}break;case"create_allocate":try{const{model:e}=n.data.in,r=(0,t.createSessionAllocate)(e);postMessage({type:"create_allocate",out:r})}catch(t){postMessage({type:"create_allocate",err:t})}break;case"create_finalize":try{const{modeldata:e,options:r}=n.data.in,a=(0,t.createSessionFinalize)(e,r);postMessage({type:"create_finalize",out:a})}catch(t){postMessage({type:"create_finalize",err:t})}break;case"create":try{const{model:e,options:r}=n.data.in,a=(0,t.createSession)(e,r);postMessage({type:"create",out:a})}catch(t){postMessage({type:"create",err:t})}break;case"release":try{const e=n.data.in;(0,t.releaseSession)(e),postMessage({type:"release"})}catch(t){postMessage({type:"release",err:t})}break;case"run":try{const{sessionId:e,inputIndices:r,inputs:a,outputIndices:i,options:o}=n.data.in,u=(0,t.run)(e,r,a,i,o);postMessage({type:"run",out:u},(0,t.extractTransferableBuffers)(u))}catch(t){postMessage({type:"run",err:t})}break;case"end-profiling":try{const e=n.data.in;(0,t.endProfiling)(e),postMessage({type:"end-profiling"})}catch(t){postMessage({type:"end-profiling",err:t})}}}})()})();\n', "Worker", void 0, void 0);
      }
    }, 477: (t2) => {
      t2.exports = function(t3, e, n, r) {
        var i2 = self || window;
        try {
          try {
            var o;
            try {
              o = new i2.Blob([t3]);
            } catch (e2) {
              (o = new (i2.BlobBuilder || i2.WebKitBlobBuilder || i2.MozBlobBuilder || i2.MSBlobBuilder)()).append(t3), o = o.getBlob();
            }
            var a = i2.URL || i2.webkitURL, s = a.createObjectURL(o), u = new i2[e](s, n);
            return a.revokeObjectURL(s), u;
          } catch (r2) {
            return new i2[e]("data:application/javascript,".concat(encodeURIComponent(t3)), n);
          }
        } catch (t4) {
          if (!r) throw Error("Inline worker is not supported");
          return new i2[e](r, n);
        }
      };
    }, 4154: (t2) => {
      t2.exports = '"use strict";var e={},t="object"==typeof process&&"object"==typeof process.versions&&"string"==typeof process.versions.node;if(t){var r=require("worker_threads"),a=r.parentPort;a.on("message",(e=>onmessage({data:e})));var o=require("fs");Object.assign(global,{self:global,require:require,Module:e,location:{href:__filename},Worker:r.Worker,importScripts:function(e){(0,eval)(o.readFileSync(e,"utf8"))},postMessage:function(e){a.postMessage(e)},performance:global.performance||{now:function(){return Date.now()}}})}var s=!1,n=[],i=function(){var e=Array.prototype.slice.call(arguments).join(" ");t?o.writeSync(2,e+"\\n"):console.error(e)};self.alert=function(){var t=Array.prototype.slice.call(arguments).join(" ");postMessage({cmd:"alert",text:t,threadId:e._pthread_self()})},e.instantiateWasm=(t,r)=>{var a=new WebAssembly.Instance(e.wasmModule,t);return r(a),e.wasmModule=null,a.exports},self.onunhandledrejection=e=>{throw e.reason??e},self.onmessage=t=>{try{if("load"===t.data.cmd){if(e.wasmModule=t.data.wasmModule,e.wasmMemory=t.data.wasmMemory,e.buffer=e.wasmMemory.buffer,e.ENVIRONMENT_IS_PTHREAD=!0,"string"==typeof t.data.urlOrBlob)importScripts(t.data.urlOrBlob);else{var r=URL.createObjectURL(t.data.urlOrBlob);importScripts(r),URL.revokeObjectURL(r)}ortWasmThreaded(e).then((function(t){e=t}))}else if("run"===t.data.cmd){e.__performance_now_clock_drift=performance.now()-t.data.time,e.__emscripten_thread_init(t.data.pthread_ptr,0,0,1),e.establishStackSpace(),e.PThread.receiveObjectTransfer(t.data),e.PThread.threadInitTLS(),s||(n.forEach((t=>{e.executeNotifiedProxyingQueue(t)})),n=[],s=!0);try{e.invokeEntryPoint(t.data.start_routine,t.data.arg)}catch(t){if("unwind"!=t){if(!(t instanceof e.ExitStatus))throw t;e.keepRuntimeAlive()||e.__emscripten_thread_exit(t.status)}}}else"cancel"===t.data.cmd?e._pthread_self()&&e.__emscripten_thread_exit(-1):"setimmediate"===t.data.target||("processProxyingQueue"===t.data.cmd?s?e.executeNotifiedProxyingQueue(t.data.queue):n.push(t.data.queue):(i("worker.js received unknown command "+t.data.cmd),i(t.data)))}catch(t){throw i("worker.js onmessage() captured an uncaught exception: "+t),t&&t.stack&&i(t.stack),e.__emscripten_thread_crashed&&e.__emscripten_thread_crashed(),t}};\n';
    }, 6231: (t2) => {
      t2.exports = fs$4;
    }, 9719: (t2) => {
      t2.exports = require$$1$1;
    }, 1423: (t2) => {
      t2.exports = path$4;
    }, 498: (t2) => {
      t2.exports = require$$3$2;
    }, 6464: (t2) => {
      t2.exports = require$$4$1;
    }, 4564: (t2) => {
      t2.exports = require$$5$1;
    }, 6207: (t2) => {
      t2.exports = require$$6;
    }, 6113: (t2) => {
      t2.exports = require$$7$2;
    }, 5686: (t2, e, n) => {
      n.r(e), n.d(e, { flatbuffers: () => r });
      var r = {};
      r.Offset, r.Table, r.SIZEOF_SHORT = 2, r.SIZEOF_INT = 4, r.FILE_IDENTIFIER_LENGTH = 4, r.SIZE_PREFIX_LENGTH = 4, r.Encoding = { UTF8_BYTES: 1, UTF16_STRING: 2 }, r.int32 = new Int32Array(2), r.float32 = new Float32Array(r.int32.buffer), r.float64 = new Float64Array(r.int32.buffer), r.isLittleEndian = 1 === new Uint16Array(new Uint8Array([1, 0]).buffer)[0], r.Long = function(t3, e2) {
        this.low = 0 | t3, this.high = 0 | e2;
      }, r.Long.create = function(t3, e2) {
        return 0 == t3 && 0 == e2 ? r.Long.ZERO : new r.Long(t3, e2);
      }, r.Long.prototype.toFloat64 = function() {
        return (this.low >>> 0) + 4294967296 * this.high;
      }, r.Long.prototype.equals = function(t3) {
        return this.low == t3.low && this.high == t3.high;
      }, r.Long.ZERO = new r.Long(0, 0), r.Builder = function(t3) {
        if (t3) e2 = t3;
        else var e2 = 1024;
        this.bb = r.ByteBuffer.allocate(e2), this.space = e2, this.minalign = 1, this.vtable = null, this.vtable_in_use = 0, this.isNested = false, this.object_start = 0, this.vtables = [], this.vector_num_elems = 0, this.force_defaults = false;
      }, r.Builder.prototype.clear = function() {
        this.bb.clear(), this.space = this.bb.capacity(), this.minalign = 1, this.vtable = null, this.vtable_in_use = 0, this.isNested = false, this.object_start = 0, this.vtables = [], this.vector_num_elems = 0, this.force_defaults = false;
      }, r.Builder.prototype.forceDefaults = function(t3) {
        this.force_defaults = t3;
      }, r.Builder.prototype.dataBuffer = function() {
        return this.bb;
      }, r.Builder.prototype.asUint8Array = function() {
        return this.bb.bytes().subarray(this.bb.position(), this.bb.position() + this.offset());
      }, r.Builder.prototype.prep = function(t3, e2) {
        t3 > this.minalign && (this.minalign = t3);
        for (var n2 = 1 + ~(this.bb.capacity() - this.space + e2) & t3 - 1; this.space < n2 + t3 + e2; ) {
          var i2 = this.bb.capacity();
          this.bb = r.Builder.growByteBuffer(this.bb), this.space += this.bb.capacity() - i2;
        }
        this.pad(n2);
      }, r.Builder.prototype.pad = function(t3) {
        for (var e2 = 0; e2 < t3; e2++) this.bb.writeInt8(--this.space, 0);
      }, r.Builder.prototype.writeInt8 = function(t3) {
        this.bb.writeInt8(this.space -= 1, t3);
      }, r.Builder.prototype.writeInt16 = function(t3) {
        this.bb.writeInt16(this.space -= 2, t3);
      }, r.Builder.prototype.writeInt32 = function(t3) {
        this.bb.writeInt32(this.space -= 4, t3);
      }, r.Builder.prototype.writeInt64 = function(t3) {
        this.bb.writeInt64(this.space -= 8, t3);
      }, r.Builder.prototype.writeFloat32 = function(t3) {
        this.bb.writeFloat32(this.space -= 4, t3);
      }, r.Builder.prototype.writeFloat64 = function(t3) {
        this.bb.writeFloat64(this.space -= 8, t3);
      }, r.Builder.prototype.addInt8 = function(t3) {
        this.prep(1, 0), this.writeInt8(t3);
      }, r.Builder.prototype.addInt16 = function(t3) {
        this.prep(2, 0), this.writeInt16(t3);
      }, r.Builder.prototype.addInt32 = function(t3) {
        this.prep(4, 0), this.writeInt32(t3);
      }, r.Builder.prototype.addInt64 = function(t3) {
        this.prep(8, 0), this.writeInt64(t3);
      }, r.Builder.prototype.addFloat32 = function(t3) {
        this.prep(4, 0), this.writeFloat32(t3);
      }, r.Builder.prototype.addFloat64 = function(t3) {
        this.prep(8, 0), this.writeFloat64(t3);
      }, r.Builder.prototype.addFieldInt8 = function(t3, e2, n2) {
        (this.force_defaults || e2 != n2) && (this.addInt8(e2), this.slot(t3));
      }, r.Builder.prototype.addFieldInt16 = function(t3, e2, n2) {
        (this.force_defaults || e2 != n2) && (this.addInt16(e2), this.slot(t3));
      }, r.Builder.prototype.addFieldInt32 = function(t3, e2, n2) {
        (this.force_defaults || e2 != n2) && (this.addInt32(e2), this.slot(t3));
      }, r.Builder.prototype.addFieldInt64 = function(t3, e2, n2) {
        !this.force_defaults && e2.equals(n2) || (this.addInt64(e2), this.slot(t3));
      }, r.Builder.prototype.addFieldFloat32 = function(t3, e2, n2) {
        (this.force_defaults || e2 != n2) && (this.addFloat32(e2), this.slot(t3));
      }, r.Builder.prototype.addFieldFloat64 = function(t3, e2, n2) {
        (this.force_defaults || e2 != n2) && (this.addFloat64(e2), this.slot(t3));
      }, r.Builder.prototype.addFieldOffset = function(t3, e2, n2) {
        (this.force_defaults || e2 != n2) && (this.addOffset(e2), this.slot(t3));
      }, r.Builder.prototype.addFieldStruct = function(t3, e2, n2) {
        e2 != n2 && (this.nested(e2), this.slot(t3));
      }, r.Builder.prototype.nested = function(t3) {
        if (t3 != this.offset()) throw new Error("FlatBuffers: struct must be serialized inline.");
      }, r.Builder.prototype.notNested = function() {
        if (this.isNested) throw new Error("FlatBuffers: object serialization must not be nested.");
      }, r.Builder.prototype.slot = function(t3) {
        this.vtable[t3] = this.offset();
      }, r.Builder.prototype.offset = function() {
        return this.bb.capacity() - this.space;
      }, r.Builder.growByteBuffer = function(t3) {
        var e2 = t3.capacity();
        if (3221225472 & e2) throw new Error("FlatBuffers: cannot grow buffer beyond 2 gigabytes.");
        var n2 = e2 << 1, i2 = r.ByteBuffer.allocate(n2);
        return i2.setPosition(n2 - e2), i2.bytes().set(t3.bytes(), n2 - e2), i2;
      }, r.Builder.prototype.addOffset = function(t3) {
        this.prep(r.SIZEOF_INT, 0), this.writeInt32(this.offset() - t3 + r.SIZEOF_INT);
      }, r.Builder.prototype.startObject = function(t3) {
        this.notNested(), null == this.vtable && (this.vtable = []), this.vtable_in_use = t3;
        for (var e2 = 0; e2 < t3; e2++) this.vtable[e2] = 0;
        this.isNested = true, this.object_start = this.offset();
      }, r.Builder.prototype.endObject = function() {
        if (null == this.vtable || !this.isNested) throw new Error("FlatBuffers: endObject called without startObject");
        this.addInt32(0);
        for (var t3 = this.offset(), e2 = this.vtable_in_use - 1; e2 >= 0 && 0 == this.vtable[e2]; e2--) ;
        for (var n2 = e2 + 1; e2 >= 0; e2--) this.addInt16(0 != this.vtable[e2] ? t3 - this.vtable[e2] : 0);
        this.addInt16(t3 - this.object_start);
        var i2 = (n2 + 2) * r.SIZEOF_SHORT;
        this.addInt16(i2);
        var o = 0, a = this.space;
        t: for (e2 = 0; e2 < this.vtables.length; e2++) {
          var s = this.bb.capacity() - this.vtables[e2];
          if (i2 == this.bb.readInt16(s)) {
            for (var u = r.SIZEOF_SHORT; u < i2; u += r.SIZEOF_SHORT) if (this.bb.readInt16(a + u) != this.bb.readInt16(s + u)) continue t;
            o = this.vtables[e2];
            break;
          }
        }
        return o ? (this.space = this.bb.capacity() - t3, this.bb.writeInt32(this.space, o - t3)) : (this.vtables.push(this.offset()), this.bb.writeInt32(this.bb.capacity() - t3, this.offset() - t3)), this.isNested = false, t3;
      }, r.Builder.prototype.finish = function(t3, e2, n2) {
        var i2 = n2 ? r.SIZE_PREFIX_LENGTH : 0;
        if (e2) {
          var o = e2;
          if (this.prep(this.minalign, r.SIZEOF_INT + r.FILE_IDENTIFIER_LENGTH + i2), o.length != r.FILE_IDENTIFIER_LENGTH) throw new Error("FlatBuffers: file identifier must be length " + r.FILE_IDENTIFIER_LENGTH);
          for (var a = r.FILE_IDENTIFIER_LENGTH - 1; a >= 0; a--) this.writeInt8(o.charCodeAt(a));
        }
        this.prep(this.minalign, r.SIZEOF_INT + i2), this.addOffset(t3), i2 && this.addInt32(this.bb.capacity() - this.space), this.bb.setPosition(this.space);
      }, r.Builder.prototype.finishSizePrefixed = function(t3, e2) {
        this.finish(t3, e2, true);
      }, r.Builder.prototype.requiredField = function(t3, e2) {
        var n2 = this.bb.capacity() - t3, r2 = n2 - this.bb.readInt32(n2);
        if (0 == this.bb.readInt16(r2 + e2)) throw new Error("FlatBuffers: field " + e2 + " must be set");
      }, r.Builder.prototype.startVector = function(t3, e2, n2) {
        this.notNested(), this.vector_num_elems = e2, this.prep(r.SIZEOF_INT, t3 * e2), this.prep(n2, t3 * e2);
      }, r.Builder.prototype.endVector = function() {
        return this.writeInt32(this.vector_num_elems), this.offset();
      }, r.Builder.prototype.createString = function(t3) {
        if (t3 instanceof Uint8Array) var e2 = t3;
        else {
          e2 = [];
          for (var n2 = 0; n2 < t3.length; ) {
            var r2, i2 = t3.charCodeAt(n2++);
            (r2 = i2 < 55296 || i2 >= 56320 ? i2 : (i2 << 10) + t3.charCodeAt(n2++) + -56613888) < 128 ? e2.push(r2) : (r2 < 2048 ? e2.push(r2 >> 6 & 31 | 192) : (r2 < 65536 ? e2.push(r2 >> 12 & 15 | 224) : e2.push(r2 >> 18 & 7 | 240, r2 >> 12 & 63 | 128), e2.push(r2 >> 6 & 63 | 128)), e2.push(63 & r2 | 128));
          }
        }
        this.addInt8(0), this.startVector(1, e2.length, 1), this.bb.setPosition(this.space -= e2.length), n2 = 0;
        for (var o = this.space, a = this.bb.bytes(); n2 < e2.length; n2++) a[o++] = e2[n2];
        return this.endVector();
      }, r.Builder.prototype.createLong = function(t3, e2) {
        return r.Long.create(t3, e2);
      }, r.ByteBuffer = function(t3) {
        this.bytes_ = t3, this.position_ = 0;
      }, r.ByteBuffer.allocate = function(t3) {
        return new r.ByteBuffer(new Uint8Array(t3));
      }, r.ByteBuffer.prototype.clear = function() {
        this.position_ = 0;
      }, r.ByteBuffer.prototype.bytes = function() {
        return this.bytes_;
      }, r.ByteBuffer.prototype.position = function() {
        return this.position_;
      }, r.ByteBuffer.prototype.setPosition = function(t3) {
        this.position_ = t3;
      }, r.ByteBuffer.prototype.capacity = function() {
        return this.bytes_.length;
      }, r.ByteBuffer.prototype.readInt8 = function(t3) {
        return this.readUint8(t3) << 24 >> 24;
      }, r.ByteBuffer.prototype.readUint8 = function(t3) {
        return this.bytes_[t3];
      }, r.ByteBuffer.prototype.readInt16 = function(t3) {
        return this.readUint16(t3) << 16 >> 16;
      }, r.ByteBuffer.prototype.readUint16 = function(t3) {
        return this.bytes_[t3] | this.bytes_[t3 + 1] << 8;
      }, r.ByteBuffer.prototype.readInt32 = function(t3) {
        return this.bytes_[t3] | this.bytes_[t3 + 1] << 8 | this.bytes_[t3 + 2] << 16 | this.bytes_[t3 + 3] << 24;
      }, r.ByteBuffer.prototype.readUint32 = function(t3) {
        return this.readInt32(t3) >>> 0;
      }, r.ByteBuffer.prototype.readInt64 = function(t3) {
        return new r.Long(this.readInt32(t3), this.readInt32(t3 + 4));
      }, r.ByteBuffer.prototype.readUint64 = function(t3) {
        return new r.Long(this.readUint32(t3), this.readUint32(t3 + 4));
      }, r.ByteBuffer.prototype.readFloat32 = function(t3) {
        return r.int32[0] = this.readInt32(t3), r.float32[0];
      }, r.ByteBuffer.prototype.readFloat64 = function(t3) {
        return r.int32[r.isLittleEndian ? 0 : 1] = this.readInt32(t3), r.int32[r.isLittleEndian ? 1 : 0] = this.readInt32(t3 + 4), r.float64[0];
      }, r.ByteBuffer.prototype.writeInt8 = function(t3, e2) {
        this.bytes_[t3] = e2;
      }, r.ByteBuffer.prototype.writeUint8 = function(t3, e2) {
        this.bytes_[t3] = e2;
      }, r.ByteBuffer.prototype.writeInt16 = function(t3, e2) {
        this.bytes_[t3] = e2, this.bytes_[t3 + 1] = e2 >> 8;
      }, r.ByteBuffer.prototype.writeUint16 = function(t3, e2) {
        this.bytes_[t3] = e2, this.bytes_[t3 + 1] = e2 >> 8;
      }, r.ByteBuffer.prototype.writeInt32 = function(t3, e2) {
        this.bytes_[t3] = e2, this.bytes_[t3 + 1] = e2 >> 8, this.bytes_[t3 + 2] = e2 >> 16, this.bytes_[t3 + 3] = e2 >> 24;
      }, r.ByteBuffer.prototype.writeUint32 = function(t3, e2) {
        this.bytes_[t3] = e2, this.bytes_[t3 + 1] = e2 >> 8, this.bytes_[t3 + 2] = e2 >> 16, this.bytes_[t3 + 3] = e2 >> 24;
      }, r.ByteBuffer.prototype.writeInt64 = function(t3, e2) {
        this.writeInt32(t3, e2.low), this.writeInt32(t3 + 4, e2.high);
      }, r.ByteBuffer.prototype.writeUint64 = function(t3, e2) {
        this.writeUint32(t3, e2.low), this.writeUint32(t3 + 4, e2.high);
      }, r.ByteBuffer.prototype.writeFloat32 = function(t3, e2) {
        r.float32[0] = e2, this.writeInt32(t3, r.int32[0]);
      }, r.ByteBuffer.prototype.writeFloat64 = function(t3, e2) {
        r.float64[0] = e2, this.writeInt32(t3, r.int32[r.isLittleEndian ? 0 : 1]), this.writeInt32(t3 + 4, r.int32[r.isLittleEndian ? 1 : 0]);
      }, r.ByteBuffer.prototype.getBufferIdentifier = function() {
        if (this.bytes_.length < this.position_ + r.SIZEOF_INT + r.FILE_IDENTIFIER_LENGTH) throw new Error("FlatBuffers: ByteBuffer is too short to contain an identifier.");
        for (var t3 = "", e2 = 0; e2 < r.FILE_IDENTIFIER_LENGTH; e2++) t3 += String.fromCharCode(this.readInt8(this.position_ + r.SIZEOF_INT + e2));
        return t3;
      }, r.ByteBuffer.prototype.__offset = function(t3, e2) {
        var n2 = t3 - this.readInt32(t3);
        return e2 < this.readInt16(n2) ? this.readInt16(n2 + e2) : 0;
      }, r.ByteBuffer.prototype.__union = function(t3, e2) {
        return t3.bb_pos = e2 + this.readInt32(e2), t3.bb = this, t3;
      }, r.ByteBuffer.prototype.__string = function(t3, e2) {
        t3 += this.readInt32(t3);
        var n2 = this.readInt32(t3), i2 = "", o = 0;
        if (t3 += r.SIZEOF_INT, e2 === r.Encoding.UTF8_BYTES) return this.bytes_.subarray(t3, t3 + n2);
        for (; o < n2; ) {
          var a, s = this.readUint8(t3 + o++);
          if (s < 192) a = s;
          else {
            var u = this.readUint8(t3 + o++);
            if (s < 224) a = (31 & s) << 6 | 63 & u;
            else {
              var c = this.readUint8(t3 + o++);
              a = s < 240 ? (15 & s) << 12 | (63 & u) << 6 | 63 & c : (7 & s) << 18 | (63 & u) << 12 | (63 & c) << 6 | 63 & this.readUint8(t3 + o++);
            }
          }
          a < 65536 ? i2 += String.fromCharCode(a) : (a -= 65536, i2 += String.fromCharCode(55296 + (a >> 10), 56320 + (1023 & a)));
        }
        return i2;
      }, r.ByteBuffer.prototype.__indirect = function(t3) {
        return t3 + this.readInt32(t3);
      }, r.ByteBuffer.prototype.__vector = function(t3) {
        return t3 + this.readInt32(t3) + r.SIZEOF_INT;
      }, r.ByteBuffer.prototype.__vector_len = function(t3) {
        return this.readInt32(t3 + this.readInt32(t3));
      }, r.ByteBuffer.prototype.__has_identifier = function(t3) {
        if (t3.length != r.FILE_IDENTIFIER_LENGTH) throw new Error("FlatBuffers: file identifier must be length " + r.FILE_IDENTIFIER_LENGTH);
        for (var e2 = 0; e2 < r.FILE_IDENTIFIER_LENGTH; e2++) if (t3.charCodeAt(e2) != this.readInt8(this.position_ + r.SIZEOF_INT + e2)) return false;
        return true;
      }, r.ByteBuffer.prototype.createLong = function(t3, e2) {
        return r.Long.create(t3, e2);
      };
    } }, __webpack_module_cache__ = {};
    function __webpack_require__(t2) {
      var e = __webpack_module_cache__[t2];
      if (void 0 !== e) return e.exports;
      var n = __webpack_module_cache__[t2] = { exports: {} };
      return __webpack_modules__[t2].call(n.exports, n, n.exports, __webpack_require__), n.exports;
    }
    __webpack_require__.n = (t2) => {
      var e = t2 && t2.__esModule ? () => t2.default : () => t2;
      return __webpack_require__.d(e, { a: e }), e;
    }, __webpack_require__.d = (t2, e) => {
      for (var n in e) __webpack_require__.o(e, n) && !__webpack_require__.o(t2, n) && Object.defineProperty(t2, n, { enumerable: true, get: e[n] });
    }, __webpack_require__.o = (t2, e) => Object.prototype.hasOwnProperty.call(t2, e), __webpack_require__.r = (t2) => {
      "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(t2, Symbol.toStringTag, { value: "Module" }), Object.defineProperty(t2, "__esModule", { value: true });
    };
    var __webpack_exports__ = __webpack_require__(6018), __webpack_export_target__ = exports$1;
    for (var i in __webpack_exports__) __webpack_export_target__[i] = __webpack_exports__[i];
    __webpack_exports__.__esModule && Object.defineProperty(__webpack_export_target__, "__esModule", { value: true });
  })();
})(ortWeb_node$1);
const ortWeb_node = /* @__PURE__ */ getDefaultExportFromCjs(ortWeb_node$1);
const ONNX_WEB = /* @__PURE__ */ _mergeNamespaces({
  __proto__: null,
  default: ortWeb_node
}, [ortWeb_node$1]);
let ONNX;
const executionProviders = [
  // 'webgpu',
  "wasm"
];
if (typeof process !== "undefined" && ((_a = process == null ? void 0 : process.release) == null ? void 0 : _a.name) === "node") {
  ONNX = index ?? ONNX_NODE;
  executionProviders.unshift("cpu");
} else {
  ONNX = ortWeb_node ?? ONNX_WEB;
  const isIOS = typeof navigator !== "undefined" && /iP(hone|od|ad).+16_4.+AppleWebKit/.test(navigator.userAgent);
  if (isIOS) {
    ONNX.env.wasm.simd = false;
  }
}
const { env: onnx_env } = ONNX;
const VERSION = "2.17.2";
const WEB_CACHE_AVAILABLE = typeof self !== "undefined" && "caches" in self;
const FS_AVAILABLE = !isEmpty(fs$4);
const PATH_AVAILABLE = !isEmpty(path$4);
const RUNNING_LOCALLY = FS_AVAILABLE && PATH_AVAILABLE;
const __dirname$2 = RUNNING_LOCALLY ? path$4.dirname(path$4.dirname(url.fileURLToPath(import.meta.url))) : "./";
const DEFAULT_CACHE_DIR = RUNNING_LOCALLY ? path$4.join(__dirname$2, "/.cache/") : null;
const DEFAULT_LOCAL_MODEL_PATH = "/models/";
const localModelPath = RUNNING_LOCALLY ? path$4.join(__dirname$2, DEFAULT_LOCAL_MODEL_PATH) : DEFAULT_LOCAL_MODEL_PATH;
if (onnx_env == null ? void 0 : onnx_env.wasm) {
  onnx_env.wasm.wasmPaths = RUNNING_LOCALLY ? path$4.join(__dirname$2, "/dist/") : `https://cdn.jsdelivr.net/npm/@xenova/transformers@${VERSION}/dist/`;
}
const env$3 = {
  version: VERSION,
  remoteHost: "https://huggingface.co/",
  remotePathTemplate: "{model}/resolve/{revision}/",
  localModelPath,
  useFS: FS_AVAILABLE,
  /////////////////// Cache settings ///////////////////
  useBrowserCache: WEB_CACHE_AVAILABLE,
  useFSCache: FS_AVAILABLE,
  cacheDir: DEFAULT_CACHE_DIR
};
function isEmpty(obj) {
  return Object.keys(obj).length === 0;
}
class FileResponse {
  /**
   * Creates a new `FileResponse` object.
   * @param {string|URL} filePath
   */
  constructor(filePath) {
    /**
     * Mapping from file extensions to MIME types.
     */
    __publicField(this, "_CONTENT_TYPE_MAP", {
      "txt": "text/plain",
      "html": "text/html",
      "css": "text/css",
      "js": "text/javascript",
      "json": "application/json",
      "png": "image/png",
      "jpg": "image/jpeg",
      "jpeg": "image/jpeg",
      "gif": "image/gif"
    });
    this.filePath = filePath;
    this.headers = new Headers();
    this.exists = fs$4.existsSync(filePath);
    if (this.exists) {
      this.status = 200;
      this.statusText = "OK";
      let stats2 = fs$4.statSync(filePath);
      this.headers.set("content-length", stats2.size.toString());
      this.updateContentType();
      let self2 = this;
      this.body = new ReadableStream({
        start(controller) {
          self2.arrayBuffer().then((buffer2) => {
            controller.enqueue(new Uint8Array(buffer2));
            controller.close();
          });
        }
      });
    } else {
      this.status = 404;
      this.statusText = "Not Found";
      this.body = null;
    }
  }
  /**
   * Updates the 'content-type' header property of the response based on the extension of
   * the file specified by the filePath property of the current object.
   * @returns {void}
   */
  updateContentType() {
    const extension = this.filePath.toString().split(".").pop().toLowerCase();
    this.headers.set("content-type", this._CONTENT_TYPE_MAP[extension] ?? "application/octet-stream");
  }
  /**
   * Clone the current FileResponse object.
   * @returns {FileResponse} A new FileResponse object with the same properties as the current object.
   */
  clone() {
    let response = new FileResponse(this.filePath);
    response.exists = this.exists;
    response.status = this.status;
    response.statusText = this.statusText;
    response.headers = new Headers(this.headers);
    return response;
  }
  /**
   * Reads the contents of the file specified by the filePath property and returns a Promise that
   * resolves with an ArrayBuffer containing the file's contents.
   * @returns {Promise<ArrayBuffer>} A Promise that resolves with an ArrayBuffer containing the file's contents.
   * @throws {Error} If the file cannot be read.
   */
  async arrayBuffer() {
    const data = await fs$4.promises.readFile(this.filePath);
    return data.buffer;
  }
  /**
   * Reads the contents of the file specified by the filePath property and returns a Promise that
   * resolves with a Blob containing the file's contents.
   * @returns {Promise<Blob>} A Promise that resolves with a Blob containing the file's contents.
   * @throws {Error} If the file cannot be read.
   */
  async blob() {
    const data = await fs$4.promises.readFile(this.filePath);
    return new Blob([data], { type: this.headers.get("content-type") });
  }
  /**
   * Reads the contents of the file specified by the filePath property and returns a Promise that
   * resolves with a string containing the file's contents.
   * @returns {Promise<string>} A Promise that resolves with a string containing the file's contents.
   * @throws {Error} If the file cannot be read.
   */
  async text() {
    const data = await fs$4.promises.readFile(this.filePath, "utf8");
    return data;
  }
  /**
   * Reads the contents of the file specified by the filePath property and returns a Promise that
   * resolves with a parsed JavaScript object containing the file's contents.
   * 
   * @returns {Promise<Object>} A Promise that resolves with a parsed JavaScript object containing the file's contents.
   * @throws {Error} If the file cannot be read.
   */
  async json() {
    return JSON.parse(await this.text());
  }
}
function isValidUrl(string2, protocols = null, validHosts = null) {
  let url2;
  try {
    url2 = new URL(string2);
  } catch (_) {
    return false;
  }
  if (protocols && !protocols.includes(url2.protocol)) {
    return false;
  }
  if (validHosts && !validHosts.includes(url2.hostname)) {
    return false;
  }
  return true;
}
async function getFile(urlOrPath) {
  var _a2, _b, _c, _d;
  if (env$3.useFS && !isValidUrl(urlOrPath, ["http:", "https:", "blob:"])) {
    return new FileResponse(urlOrPath);
  } else if (typeof process !== "undefined" && ((_a2 = process == null ? void 0 : process.release) == null ? void 0 : _a2.name) === "node") {
    const IS_CI = !!((_b = process.env) == null ? void 0 : _b.TESTING_REMOTELY);
    const version2 = env$3.version;
    const headers = new Headers();
    headers.set("User-Agent", `transformers.js/${version2}; is_ci/${IS_CI};`);
    const isHFURL = isValidUrl(urlOrPath, ["http:", "https:"], ["huggingface.co", "hf.co"]);
    if (isHFURL) {
      const token = ((_c = process.env) == null ? void 0 : _c.HF_TOKEN) ?? ((_d = process.env) == null ? void 0 : _d.HF_ACCESS_TOKEN);
      if (token) {
        headers.set("Authorization", `Bearer ${token}`);
      }
    }
    return fetch(urlOrPath, { headers });
  } else {
    return fetch(urlOrPath);
  }
}
const ERROR_MAPPING = {
  // 4xx errors (https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#client_error_responses)
  400: "Bad request error occurred while trying to load file",
  401: "Unauthorized access to file",
  403: "Forbidden access to file",
  404: "Could not locate file",
  408: "Request timeout error occurred while trying to load file",
  // 5xx errors (https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses)
  500: "Internal server error error occurred while trying to load file",
  502: "Bad gateway error occurred while trying to load file",
  503: "Service unavailable error occurred while trying to load file",
  504: "Gateway timeout error occurred while trying to load file"
};
function handleError(status, remoteURL, fatal) {
  if (!fatal) {
    return null;
  }
  const message = ERROR_MAPPING[status] ?? `Error (${status}) occurred while trying to load file`;
  throw Error(`${message}: "${remoteURL}".`);
}
class FileCache {
  /**
   * Instantiate a `FileCache` object.
   * @param {string} path 
   */
  constructor(path2) {
    this.path = path2;
  }
  /**
   * Checks whether the given request is in the cache.
   * @param {string} request 
   * @returns {Promise<FileResponse | undefined>}
   */
  async match(request) {
    let filePath = path$4.join(this.path, request);
    let file = new FileResponse(filePath);
    if (file.exists) {
      return file;
    } else {
      return void 0;
    }
  }
  /**
   * Adds the given response to the cache.
   * @param {string} request 
   * @param {Response|FileResponse} response 
   * @returns {Promise<void>}
   */
  async put(request, response) {
    const buffer2 = Buffer.from(await response.arrayBuffer());
    let outputPath = path$4.join(this.path, request);
    try {
      await fs$4.promises.mkdir(path$4.dirname(outputPath), { recursive: true });
      await fs$4.promises.writeFile(outputPath, buffer2);
    } catch (err) {
      console.warn("An error occurred while writing the file to cache:", err);
    }
  }
  // TODO add the rest?
  // addAll(requests: RequestInfo[]): Promise<void>;
  // delete(request: RequestInfo | URL, options?: CacheQueryOptions): Promise<boolean>;
  // keys(request?: RequestInfo | URL, options?: CacheQueryOptions): Promise<ReadonlyArray<Request>>;
  // match(request: RequestInfo | URL, options?: CacheQueryOptions): Promise<Response | undefined>;
  // matchAll(request?: RequestInfo | URL, options?: CacheQueryOptions): Promise<ReadonlyArray<Response>>;
}
async function tryCache(cache2, ...names2) {
  for (let name2 of names2) {
    try {
      let result = await cache2.match(name2);
      if (result) return result;
    } catch (e) {
      continue;
    }
  }
  return void 0;
}
async function getModelFile(path_or_repo_id, filename, fatal = true, options = {}) {
  dispatchCallback(options.progress_callback, {
    status: "initiate",
    name: path_or_repo_id,
    file: filename
  });
  let cache2;
  if (!cache2 && env$3.useBrowserCache) {
    if (typeof caches === "undefined") {
      throw Error("Browser cache is not available in this environment.");
    }
    try {
      cache2 = await caches.open("transformers-cache");
    } catch (e) {
      console.warn("An error occurred while opening the browser cache:", e);
    }
  }
  if (!cache2 && env$3.useFSCache) {
    cache2 = new FileCache(options.cache_dir ?? env$3.cacheDir);
  }
  const revision = options.revision ?? "main";
  let requestURL = pathJoin(path_or_repo_id, filename);
  let localPath = pathJoin(env$3.localModelPath, requestURL);
  let remoteURL = pathJoin(
    env$3.remoteHost,
    env$3.remotePathTemplate.replaceAll("{model}", path_or_repo_id).replaceAll("{revision}", encodeURIComponent(revision)),
    filename
  );
  let fsCacheKey = revision === "main" ? requestURL : pathJoin(path_or_repo_id, revision, filename);
  let cacheKey;
  let proposedCacheKey = cache2 instanceof FileCache ? fsCacheKey : remoteURL;
  let toCacheResponse = false;
  let response;
  if (cache2) {
    response = await tryCache(cache2, localPath, proposedCacheKey);
  }
  const cacheHit = response !== void 0;
  if (response === void 0) {
    {
      const isURL = isValidUrl(requestURL, ["http:", "https:"]);
      if (!isURL) {
        try {
          response = await getFile(localPath);
          cacheKey = localPath;
        } catch (e) {
          console.warn(`Unable to load from local path "${localPath}": "${e}"`);
        }
      } else if (options.local_files_only) {
        throw new Error(`\`local_files_only=true\`, but attempted to load a remote file from: ${requestURL}.`);
      } else ;
    }
    if (response === void 0 || response.status === 404) {
      if (options.local_files_only || false) {
        if (fatal) {
          throw Error(`\`local_files_only=true\` or \`env.allowRemoteModels=false\` and file was not found locally at "${localPath}".`);
        } else {
          return null;
        }
      }
      response = await getFile(remoteURL);
      if (response.status !== 200) {
        return handleError(response.status, remoteURL, fatal);
      }
      cacheKey = proposedCacheKey;
    }
    toCacheResponse = cache2 && typeof Response !== "undefined" && response instanceof Response && response.status === 200;
  }
  dispatchCallback(options.progress_callback, {
    status: "download",
    name: path_or_repo_id,
    file: filename
  });
  const progressInfo = {
    status: "progress",
    name: path_or_repo_id,
    file: filename
  };
  let buffer2;
  if (!options.progress_callback) {
    buffer2 = new Uint8Array(await response.arrayBuffer());
  } else if (cacheHit && typeof navigator !== "undefined" && /firefox/i.test(navigator.userAgent)) {
    buffer2 = new Uint8Array(await response.arrayBuffer());
    dispatchCallback(options.progress_callback, {
      ...progressInfo,
      progress: 100,
      loaded: buffer2.length,
      total: buffer2.length
    });
  } else {
    buffer2 = await readResponse(response, (data) => {
      dispatchCallback(options.progress_callback, {
        ...progressInfo,
        ...data
      });
    });
  }
  if (
    // Only cache web responses
    // i.e., do not cache FileResponses (prevents duplication)
    toCacheResponse && cacheKey && // Check again whether request is in cache. If not, we add the response to the cache
    await cache2.match(cacheKey) === void 0
  ) {
    await cache2.put(cacheKey, new Response(buffer2, {
      headers: response.headers
    })).catch((err) => {
      console.warn(`Unable to add response to browser cache: ${err}.`);
    });
  }
  dispatchCallback(options.progress_callback, {
    status: "done",
    name: path_or_repo_id,
    file: filename
  });
  return buffer2;
}
async function getModelJSON(modelPath, fileName, fatal = true, options = {}) {
  let buffer2 = await getModelFile(modelPath, fileName, fatal, options);
  if (buffer2 === null) {
    return {};
  }
  let decoder = new TextDecoder("utf-8");
  let jsonData = decoder.decode(buffer2);
  return JSON.parse(jsonData);
}
async function readResponse(response, progress_callback) {
  const contentLength = response.headers.get("Content-Length");
  if (contentLength === null) {
    console.warn("Unable to determine content-length from response headers. Will expand buffer when needed.");
  }
  let total = parseInt(contentLength ?? "0");
  let buffer2 = new Uint8Array(total);
  let loaded = 0;
  const reader = response.body.getReader();
  async function read() {
    const { done, value } = await reader.read();
    if (done) return;
    let newLoaded = loaded + value.length;
    if (newLoaded > total) {
      total = newLoaded;
      let newBuffer = new Uint8Array(total);
      newBuffer.set(buffer2);
      buffer2 = newBuffer;
    }
    buffer2.set(value, loaded);
    loaded = newLoaded;
    const progress = loaded / total * 100;
    progress_callback({
      progress,
      loaded,
      total
    });
    return read();
  }
  await read();
  return buffer2;
}
function pathJoin(...parts) {
  parts = parts.map((part, index2) => {
    if (index2) {
      part = part.replace(new RegExp("^/"), "");
    }
    if (index2 !== parts.length - 1) {
      part = part.replace(new RegExp("/$"), "");
    }
    return part;
  });
  return parts.join("/");
}
function interpolate_data(input2, [in_channels, in_height, in_width], [out_height, out_width], mode = "bilinear", align_corners = false) {
  const x_scale = out_width / in_width;
  const y_scale = out_height / in_height;
  const out_img = new input2.constructor(out_height * out_width * in_channels);
  const inStride = in_height * in_width;
  const outStride = out_height * out_width;
  for (let i2 = 0; i2 < out_height; ++i2) {
    for (let j = 0; j < out_width; ++j) {
      const outOffset = i2 * out_width + j;
      const x = (j + 0.5) / x_scale - 0.5;
      const y = (i2 + 0.5) / y_scale - 0.5;
      let x1 = Math.floor(x);
      let y1 = Math.floor(y);
      const x2 = Math.min(x1 + 1, in_width - 1);
      const y2 = Math.min(y1 + 1, in_height - 1);
      x1 = Math.max(x1, 0);
      y1 = Math.max(y1, 0);
      const s = x - x1;
      const t2 = y - y1;
      const w1 = (1 - s) * (1 - t2);
      const w2 = s * (1 - t2);
      const w3 = (1 - s) * t2;
      const w4 = s * t2;
      const yStride = y1 * in_width;
      const xStride = y2 * in_width;
      const idx1 = yStride + x1;
      const idx2 = yStride + x2;
      const idx3 = xStride + x1;
      const idx4 = xStride + x2;
      for (let k = 0; k < in_channels; ++k) {
        const cOffset = k * inStride;
        out_img[k * outStride + outOffset] = w1 * input2[cOffset + idx1] + w2 * input2[cOffset + idx2] + w3 * input2[cOffset + idx3] + w4 * input2[cOffset + idx4];
      }
    }
  }
  return out_img;
}
function permute_data(array, dims, axes) {
  const shape = new Array(axes.length);
  const stride = new Array(axes.length);
  for (let i2 = axes.length - 1, s = 1; i2 >= 0; --i2) {
    stride[i2] = s;
    shape[i2] = dims[axes[i2]];
    s *= shape[i2];
  }
  const invStride = axes.map((_, i2) => stride[axes.indexOf(i2)]);
  const permutedData = new array.constructor(array.length);
  for (let i2 = 0; i2 < array.length; ++i2) {
    let newIndex = 0;
    for (let j = dims.length - 1, k = i2; j >= 0; --j) {
      newIndex += k % dims[j] * invStride[j];
      k = Math.floor(k / dims[j]);
    }
    permutedData[newIndex] = array[i2];
  }
  return [permutedData, shape];
}
function softmax(arr) {
  const maxVal = max(arr)[0];
  const exps = arr.map((x) => Math.exp(x - maxVal));
  const sumExps = exps.reduce((acc, val) => acc + val, 0);
  const softmaxArr = exps.map((x) => x / sumExps);
  return (
    /** @type {T} */
    softmaxArr
  );
}
function log_softmax(arr) {
  const softmaxArr = softmax(arr);
  const logSoftmaxArr = softmaxArr.map((x) => Math.log(x));
  return (
    /** @type {T} */
    logSoftmaxArr
  );
}
function getTopItems(items2, top_k = 0) {
  items2 = Array.from(items2).map((x, i2) => [i2, x]).sort((a, b) => b[1] - a[1]);
  if (top_k !== null && top_k > 0) {
    items2 = items2.slice(0, top_k);
  }
  return items2;
}
function min(arr) {
  if (arr.length === 0) throw Error("Array must not be empty");
  let min2 = arr[0];
  let indexOfMin = 0;
  for (let i2 = 1; i2 < arr.length; ++i2) {
    if (arr[i2] < min2) {
      min2 = arr[i2];
      indexOfMin = i2;
    }
  }
  return [min2, indexOfMin];
}
function max(arr) {
  if (arr.length === 0) throw Error("Array must not be empty");
  let max2 = arr[0];
  let indexOfMax = 0;
  for (let i2 = 1; i2 < arr.length; ++i2) {
    if (arr[i2] > max2) {
      max2 = arr[i2];
      indexOfMax = i2;
    }
  }
  return [Number(max2), indexOfMax];
}
function isPowerOfTwo(number2) {
  return number2 > 0 && (number2 & number2 - 1) === 0;
}
class P2FFT {
  /**
   * @param {number} size The size of the input array. Must be a power of two larger than 1.
   * @throws {Error} FFT size must be a power of two larger than 1.
   */
  constructor(size) {
    this.size = size | 0;
    if (this.size <= 1 || !isPowerOfTwo(this.size))
      throw new Error("FFT size must be a power of two larger than 1");
    this._csize = size << 1;
    this.table = new Float64Array(this.size * 2);
    for (let i2 = 0; i2 < this.table.length; i2 += 2) {
      const angle = Math.PI * i2 / this.size;
      this.table[i2] = Math.cos(angle);
      this.table[i2 + 1] = -Math.sin(angle);
    }
    let power = 0;
    for (let t2 = 1; this.size > t2; t2 <<= 1)
      ++power;
    this._width = power % 2 === 0 ? power - 1 : power;
    this._bitrev = new Int32Array(1 << this._width);
    for (let j = 0; j < this._bitrev.length; ++j) {
      this._bitrev[j] = 0;
      for (let shift = 0; shift < this._width; shift += 2) {
        const revShift = this._width - shift - 2;
        this._bitrev[j] |= (j >>> shift & 3) << revShift;
      }
    }
  }
  /**
   * Create a complex number array with size `2 * size`
   *
   * @returns {Float64Array} A complex number array with size `2 * size`
   */
  createComplexArray() {
    return new Float64Array(this._csize);
  }
  /**
   * Converts a complex number representation stored in a Float64Array to an array of real numbers.
   * 
   * @param {Float64Array} complex The complex number representation to be converted.
   * @param {number[]} [storage] An optional array to store the result in.
   * @returns {number[]} An array of real numbers representing the input complex number representation.
   */
  fromComplexArray(complex, storage) {
    const res = storage || new Array(complex.length >>> 1);
    for (let i2 = 0; i2 < complex.length; i2 += 2)
      res[i2 >>> 1] = complex[i2];
    return res;
  }
  /**
   * Convert a real-valued input array to a complex-valued output array.
   * @param {Float64Array} input The real-valued input array.
   * @param {Float64Array} [storage] Optional buffer to store the output array.
   * @returns {Float64Array} The complex-valued output array.
   */
  toComplexArray(input2, storage) {
    const res = storage || this.createComplexArray();
    for (let i2 = 0; i2 < res.length; i2 += 2) {
      res[i2] = input2[i2 >>> 1];
      res[i2 + 1] = 0;
    }
    return res;
  }
  /**
   * Performs a Fast Fourier Transform (FFT) on the given input data and stores the result in the output buffer.
   * 
   * @param {Float64Array} out The output buffer to store the result.
   * @param {Float64Array} data The input data to transform.
   * 
   * @throws {Error} Input and output buffers must be different.
   * 
   * @returns {void}
   */
  transform(out, data) {
    if (out === data)
      throw new Error("Input and output buffers must be different");
    this._transform4(
      out,
      data,
      1
      /* DONE */
    );
  }
  /**
   * Performs a real-valued forward FFT on the given input buffer and stores the result in the given output buffer.
   * The input buffer must contain real values only, while the output buffer will contain complex values. The input and
   * output buffers must be different.
   *
   * @param {Float64Array} out The output buffer.
   * @param {Float64Array} data The input buffer containing real values.
   *
   * @throws {Error} If the input and output buffers are the same.
   */
  realTransform(out, data) {
    if (out === data)
      throw new Error("Input and output buffers must be different");
    this._realTransform4(
      out,
      data,
      1
      /* DONE */
    );
  }
  /**
   * Performs an inverse FFT transformation on the given `data` array, and stores the result in `out`.
   * The `out` array must be a different buffer than the `data` array. The `out` array will contain the
   * result of the transformation. The `data` array will not be modified.
   * 
   * @param {Float64Array} out The output buffer for the transformed data.
   * @param {Float64Array} data The input data to transform.
   * @throws {Error} If `out` and `data` refer to the same buffer.
   * @returns {void}
   */
  inverseTransform(out, data) {
    if (out === data)
      throw new Error("Input and output buffers must be different");
    this._transform4(
      out,
      data,
      -1
      /* DONE */
    );
    for (let i2 = 0; i2 < out.length; ++i2)
      out[i2] /= this.size;
  }
  /**
   * Performs a radix-4 implementation of a discrete Fourier transform on a given set of data.
   *
   * @param {Float64Array} out The output buffer for the transformed data.
   * @param {Float64Array} data The input buffer of data to be transformed.
   * @param {number} inv A scaling factor to apply to the transform.
   * @returns {void}
   */
  _transform4(out, data, inv) {
    const size = this._csize;
    const width = this._width;
    let step = 1 << width;
    let len = size / step << 1;
    let outOff;
    let t2;
    const bitrev = this._bitrev;
    if (len === 4) {
      for (outOff = 0, t2 = 0; outOff < size; outOff += len, ++t2) {
        const off = bitrev[t2];
        this._singleTransform2(data, out, outOff, off, step);
      }
    } else {
      for (outOff = 0, t2 = 0; outOff < size; outOff += len, ++t2) {
        const off = bitrev[t2];
        this._singleTransform4(data, out, outOff, off, step, inv);
      }
    }
    const table = this.table;
    for (step >>= 2; step >= 2; step >>= 2) {
      len = size / step << 1;
      const quarterLen = len >>> 2;
      for (outOff = 0; outOff < size; outOff += len) {
        const limit2 = outOff + quarterLen - 1;
        for (let i2 = outOff, k = 0; i2 < limit2; i2 += 2, k += step) {
          const A = i2;
          const B = A + quarterLen;
          const C = B + quarterLen;
          const D = C + quarterLen;
          const Ar = out[A];
          const Ai = out[A + 1];
          const Br = out[B];
          const Bi = out[B + 1];
          const Cr = out[C];
          const Ci = out[C + 1];
          const Dr = out[D];
          const Di = out[D + 1];
          const tableBr = table[k];
          const tableBi = inv * table[k + 1];
          const MBr = Br * tableBr - Bi * tableBi;
          const MBi = Br * tableBi + Bi * tableBr;
          const tableCr = table[2 * k];
          const tableCi = inv * table[2 * k + 1];
          const MCr = Cr * tableCr - Ci * tableCi;
          const MCi = Cr * tableCi + Ci * tableCr;
          const tableDr = table[3 * k];
          const tableDi = inv * table[3 * k + 1];
          const MDr = Dr * tableDr - Di * tableDi;
          const MDi = Dr * tableDi + Di * tableDr;
          const T0r = Ar + MCr;
          const T0i = Ai + MCi;
          const T1r = Ar - MCr;
          const T1i = Ai - MCi;
          const T2r = MBr + MDr;
          const T2i = MBi + MDi;
          const T3r = inv * (MBr - MDr);
          const T3i = inv * (MBi - MDi);
          out[A] = T0r + T2r;
          out[A + 1] = T0i + T2i;
          out[B] = T1r + T3i;
          out[B + 1] = T1i - T3r;
          out[C] = T0r - T2r;
          out[C + 1] = T0i - T2i;
          out[D] = T1r - T3i;
          out[D + 1] = T1i + T3r;
        }
      }
    }
  }
  /**
   * Performs a radix-2 implementation of a discrete Fourier transform on a given set of data.
   *
   * @param {Float64Array} data The input buffer of data to be transformed.
   * @param {Float64Array} out The output buffer for the transformed data.
   * @param {number} outOff The offset at which to write the output data.
   * @param {number} off The offset at which to begin reading the input data.
   * @param {number} step The step size for indexing the input data.
   * @returns {void}
   */
  _singleTransform2(data, out, outOff, off, step) {
    const evenR = data[off];
    const evenI = data[off + 1];
    const oddR = data[off + step];
    const oddI = data[off + step + 1];
    out[outOff] = evenR + oddR;
    out[outOff + 1] = evenI + oddI;
    out[outOff + 2] = evenR - oddR;
    out[outOff + 3] = evenI - oddI;
  }
  /**
   * Performs radix-4 transformation on input data of length 8
   *
   * @param {Float64Array} data Input data array of length 8
   * @param {Float64Array} out Output data array of length 8
   * @param {number} outOff Index of output array to start writing from
   * @param {number} off Index of input array to start reading from
   * @param {number} step Step size between elements in input array
   * @param {number} inv Scaling factor for inverse transform
   * 
   * @returns {void}
   */
  _singleTransform4(data, out, outOff, off, step, inv) {
    const step2 = step * 2;
    const step3 = step * 3;
    const Ar = data[off];
    const Ai = data[off + 1];
    const Br = data[off + step];
    const Bi = data[off + step + 1];
    const Cr = data[off + step2];
    const Ci = data[off + step2 + 1];
    const Dr = data[off + step3];
    const Di = data[off + step3 + 1];
    const T0r = Ar + Cr;
    const T0i = Ai + Ci;
    const T1r = Ar - Cr;
    const T1i = Ai - Ci;
    const T2r = Br + Dr;
    const T2i = Bi + Di;
    const T3r = inv * (Br - Dr);
    const T3i = inv * (Bi - Di);
    out[outOff] = T0r + T2r;
    out[outOff + 1] = T0i + T2i;
    out[outOff + 2] = T1r + T3i;
    out[outOff + 3] = T1i - T3r;
    out[outOff + 4] = T0r - T2r;
    out[outOff + 5] = T0i - T2i;
    out[outOff + 6] = T1r - T3i;
    out[outOff + 7] = T1i + T3r;
  }
  /**
   * Real input radix-4 implementation
   * @param {Float64Array} out Output array for the transformed data
   * @param {Float64Array} data Input array of real data to be transformed
   * @param {number} inv The scale factor used to normalize the inverse transform
   */
  _realTransform4(out, data, inv) {
    const size = this._csize;
    const width = this._width;
    let step = 1 << width;
    let len = size / step << 1;
    let outOff;
    let t2;
    const bitrev = this._bitrev;
    if (len === 4) {
      for (outOff = 0, t2 = 0; outOff < size; outOff += len, ++t2) {
        const off = bitrev[t2];
        this._singleRealTransform2(data, out, outOff, off >>> 1, step >>> 1);
      }
    } else {
      for (outOff = 0, t2 = 0; outOff < size; outOff += len, ++t2) {
        const off = bitrev[t2];
        this._singleRealTransform4(data, out, outOff, off >>> 1, step >>> 1, inv);
      }
    }
    const table = this.table;
    for (step >>= 2; step >= 2; step >>= 2) {
      len = size / step << 1;
      const halfLen = len >>> 1;
      const quarterLen = halfLen >>> 1;
      const hquarterLen = quarterLen >>> 1;
      for (outOff = 0; outOff < size; outOff += len) {
        for (let i2 = 0, k = 0; i2 <= hquarterLen; i2 += 2, k += step) {
          const A = outOff + i2;
          const B = A + quarterLen;
          const C = B + quarterLen;
          const D = C + quarterLen;
          const Ar = out[A];
          const Ai = out[A + 1];
          const Br = out[B];
          const Bi = out[B + 1];
          const Cr = out[C];
          const Ci = out[C + 1];
          const Dr = out[D];
          const Di = out[D + 1];
          const MAr = Ar;
          const MAi = Ai;
          const tableBr = table[k];
          const tableBi = inv * table[k + 1];
          const MBr = Br * tableBr - Bi * tableBi;
          const MBi = Br * tableBi + Bi * tableBr;
          const tableCr = table[2 * k];
          const tableCi = inv * table[2 * k + 1];
          const MCr = Cr * tableCr - Ci * tableCi;
          const MCi = Cr * tableCi + Ci * tableCr;
          const tableDr = table[3 * k];
          const tableDi = inv * table[3 * k + 1];
          const MDr = Dr * tableDr - Di * tableDi;
          const MDi = Dr * tableDi + Di * tableDr;
          const T0r = MAr + MCr;
          const T0i = MAi + MCi;
          const T1r = MAr - MCr;
          const T1i = MAi - MCi;
          const T2r = MBr + MDr;
          const T2i = MBi + MDi;
          const T3r = inv * (MBr - MDr);
          const T3i = inv * (MBi - MDi);
          out[A] = T0r + T2r;
          out[A + 1] = T0i + T2i;
          out[B] = T1r + T3i;
          out[B + 1] = T1i - T3r;
          if (i2 === 0) {
            out[C] = T0r - T2r;
            out[C + 1] = T0i - T2i;
            continue;
          }
          if (i2 === hquarterLen)
            continue;
          const SA = outOff + quarterLen - i2;
          const SB = outOff + halfLen - i2;
          out[SA] = T1r - inv * T3i;
          out[SA + 1] = -T1i - inv * T3r;
          out[SB] = T0r - inv * T2r;
          out[SB + 1] = -T0i + inv * T2i;
        }
      }
    }
    const half = size >>> 1;
    for (let i2 = 2; i2 < half; i2 += 2) {
      out[size - i2] = out[i2];
      out[size - i2 + 1] = -out[i2 + 1];
    }
  }
  /**
   * Performs a single real input radix-2 transformation on the provided data
   * 
   * @param {Float64Array} data The input data array
   * @param {Float64Array} out The output data array
   * @param {number} outOff The output offset
   * @param {number} off The input offset
   * @param {number} step The step
   * 
   * @returns {void}
   */
  _singleRealTransform2(data, out, outOff, off, step) {
    const evenR = data[off];
    const oddR = data[off + step];
    out[outOff] = evenR + oddR;
    out[outOff + 1] = 0;
    out[outOff + 2] = evenR - oddR;
    out[outOff + 3] = 0;
  }
  /**
   * Computes a single real-valued transform using radix-4 algorithm.
   * This method is only called for len=8.
   *
   * @param {Float64Array} data The input data array.
   * @param {Float64Array} out The output data array.
   * @param {number} outOff The offset into the output array.
   * @param {number} off The offset into the input array.
   * @param {number} step The step size for the input array.
   * @param {number} inv The value of inverse.
   */
  _singleRealTransform4(data, out, outOff, off, step, inv) {
    const step2 = step * 2;
    const step3 = step * 3;
    const Ar = data[off];
    const Br = data[off + step];
    const Cr = data[off + step2];
    const Dr = data[off + step3];
    const T0r = Ar + Cr;
    const T1r = Ar - Cr;
    const T2r = Br + Dr;
    const T3r = inv * (Br - Dr);
    out[outOff] = T0r + T2r;
    out[outOff + 1] = 0;
    out[outOff + 2] = T1r;
    out[outOff + 3] = -T3r;
    out[outOff + 4] = T0r - T2r;
    out[outOff + 5] = 0;
    out[outOff + 6] = T1r;
    out[outOff + 7] = T3r;
  }
}
class NP2FFT {
  /**
   * Constructs a new NP2FFT object.
   * @param {number} fft_length The length of the FFT
   */
  constructor(fft_length) {
    const a = 2 * (fft_length - 1);
    const b = 2 * (2 * fft_length - 1);
    const nextP2 = 2 ** Math.ceil(Math.log2(b));
    this.bufferSize = nextP2;
    this._a = a;
    const chirp = new Float64Array(b);
    const ichirp = new Float64Array(nextP2);
    this._chirpBuffer = new Float64Array(nextP2);
    this._buffer1 = new Float64Array(nextP2);
    this._buffer2 = new Float64Array(nextP2);
    this._outBuffer1 = new Float64Array(nextP2);
    this._outBuffer2 = new Float64Array(nextP2);
    const theta = -2 * Math.PI / fft_length;
    const baseR = Math.cos(theta);
    const baseI = Math.sin(theta);
    for (let i2 = 0; i2 < b >> 1; ++i2) {
      const e = (i2 + 1 - fft_length) ** 2 / 2;
      const result_mod = Math.sqrt(baseR ** 2 + baseI ** 2) ** e;
      const result_arg = e * Math.atan2(baseI, baseR);
      const i22 = 2 * i2;
      chirp[i22] = result_mod * Math.cos(result_arg);
      chirp[i22 + 1] = result_mod * Math.sin(result_arg);
      ichirp[i22] = chirp[i22];
      ichirp[i22 + 1] = -chirp[i22 + 1];
    }
    this._slicedChirpBuffer = chirp.subarray(a, b);
    this._f = new P2FFT(nextP2 >> 1);
    this._f.transform(this._chirpBuffer, ichirp);
  }
  _transform(output2, input2, real) {
    const ib1 = this._buffer1;
    const ib2 = this._buffer2;
    const ob2 = this._outBuffer1;
    const ob3 = this._outBuffer2;
    const cb = this._chirpBuffer;
    const sb = this._slicedChirpBuffer;
    const a = this._a;
    if (real) {
      for (let j = 0; j < sb.length; j += 2) {
        const j2 = j + 1;
        const j3 = j >> 1;
        const a_real = input2[j3];
        ib1[j] = a_real * sb[j];
        ib1[j2] = a_real * sb[j2];
      }
    } else {
      for (let j = 0; j < sb.length; j += 2) {
        const j2 = j + 1;
        ib1[j] = input2[j] * sb[j] - input2[j2] * sb[j2];
        ib1[j2] = input2[j] * sb[j2] + input2[j2] * sb[j];
      }
    }
    this._f.transform(ob2, ib1);
    for (let j = 0; j < cb.length; j += 2) {
      const j2 = j + 1;
      ib2[j] = ob2[j] * cb[j] - ob2[j2] * cb[j2];
      ib2[j2] = ob2[j] * cb[j2] + ob2[j2] * cb[j];
    }
    this._f.inverseTransform(ob3, ib2);
    for (let j = 0; j < ob3.length; j += 2) {
      const a_real = ob3[j + a];
      const a_imag = ob3[j + a + 1];
      const b_real = sb[j];
      const b_imag = sb[j + 1];
      output2[j] = a_real * b_real - a_imag * b_imag;
      output2[j + 1] = a_real * b_imag + a_imag * b_real;
    }
  }
  transform(output2, input2) {
    this._transform(output2, input2, false);
  }
  realTransform(output2, input2) {
    this._transform(output2, input2, true);
  }
}
class FFT {
  constructor(fft_length) {
    this.fft_length = fft_length;
    this.isPowerOfTwo = isPowerOfTwo(fft_length);
    if (this.isPowerOfTwo) {
      this.fft = new P2FFT(fft_length);
      this.outputBufferSize = 2 * fft_length;
    } else {
      this.fft = new NP2FFT(fft_length);
      this.outputBufferSize = this.fft.bufferSize;
    }
  }
  realTransform(out, input2) {
    this.fft.realTransform(out, input2);
  }
  transform(out, input2) {
    this.fft.transform(out, input2);
  }
}
function medianFilter(data, windowSize) {
  if (windowSize % 2 === 0 || windowSize <= 0) {
    throw new Error("Window size must be a positive odd number");
  }
  const outputArray = new data.constructor(data.length);
  const buffer2 = new data.constructor(windowSize);
  const halfWindowSize = Math.floor(windowSize / 2);
  for (let i2 = 0; i2 < data.length; ++i2) {
    let valuesIndex = 0;
    for (let j = -halfWindowSize; j <= halfWindowSize; ++j) {
      let index2 = i2 + j;
      if (index2 < 0) {
        index2 = Math.abs(index2);
      } else if (index2 >= data.length) {
        index2 = 2 * (data.length - 1) - index2;
      }
      buffer2[valuesIndex++] = data[index2];
    }
    buffer2.sort();
    outputArray[i2] = buffer2[halfWindowSize];
  }
  return outputArray;
}
function round(num, decimals) {
  const pow = Math.pow(10, decimals);
  return Math.round(num * pow) / pow;
}
function bankers_round(x) {
  const r = Math.round(x);
  const br = Math.abs(x) % 1 === 0.5 ? r % 2 === 0 ? r : r - 1 : r;
  return br;
}
const DataTypeMap = Object.freeze({
  float32: Float32Array,
  float64: Float64Array,
  string: Array,
  // string[]
  int8: Int8Array,
  uint8: Uint8Array,
  int16: Int16Array,
  uint16: Uint16Array,
  int32: Int32Array,
  uint32: Uint32Array,
  int64: BigInt64Array,
  uint64: BigUint64Array,
  bool: Uint8Array
});
const ONNXTensor$1 = ONNX.Tensor;
class Tensor {
  /**
   * Create a new Tensor or copy an existing Tensor.
   * @param {[DataType, DataArray, number[]]|[import('onnxruntime-common').Tensor]} args
   */
  constructor(...args) {
    /** @type {number[]} Dimensions of the tensor. */
    __publicField(this, "dims");
    /** @type {DataType} Type of the tensor. */
    __publicField(this, "type");
    /** @type {DataArray} The data stored in the tensor. */
    __publicField(this, "data");
    /** @type {number} The number of elements in the tensor. */
    __publicField(this, "size");
    if (args[0] instanceof ONNXTensor$1) {
      Object.assign(this, args[0]);
    } else {
      Object.assign(this, new ONNXTensor$1(
        /** @type {DataType} */
        args[0],
        /** @type {Exclude<import('./maths.js').AnyTypedArray, Uint8ClampedArray>} */
        args[1],
        args[2]
      ));
    }
    return new Proxy(this, {
      get: (obj, key) => {
        if (typeof key === "string") {
          let index2 = Number(key);
          if (Number.isInteger(index2)) {
            return obj._getitem(index2);
          }
        }
        return obj[key];
      },
      set: (obj, key, value) => {
        return obj[key] = value;
      }
    });
  }
  /**
   * Returns an iterator object for iterating over the tensor data in row-major order.
   * If the tensor has more than one dimension, the iterator will yield subarrays.
   * @returns {Iterator} An iterator object for iterating over the tensor data in row-major order.
   */
  *[Symbol.iterator]() {
    const [iterLength, ...iterDims] = this.dims;
    if (iterDims.length > 0) {
      const iterSize = iterDims.reduce((a, b) => a * b);
      for (let i2 = 0; i2 < iterLength; ++i2) {
        yield this._subarray(i2, iterSize, iterDims);
      }
    } else {
      yield* this.data;
    }
  }
  /**
   * Index into a Tensor object.
   * @param {number} index The index to access.
   * @returns {Tensor} The data at the specified index.
   */
  _getitem(index2) {
    const [iterLength, ...iterDims] = this.dims;
    index2 = safeIndex(index2, iterLength);
    if (iterDims.length > 0) {
      const iterSize = iterDims.reduce((a, b) => a * b);
      return this._subarray(index2, iterSize, iterDims);
    } else {
      return new Tensor(this.type, [this.data[index2]], iterDims);
    }
  }
  /**
   * @param {number|bigint} item The item to search for in the tensor
   * @returns {number} The index of the first occurrence of item in the tensor data.
   */
  indexOf(item) {
    for (let index2 = 0; index2 < this.data.length; ++index2) {
      if (this.data[index2] == item) {
        return index2;
      }
    }
    return -1;
  }
  /**
   * @param {number} index 
   * @param {number} iterSize 
   * @param {any} iterDims 
   * @returns {Tensor}
   */
  _subarray(index2, iterSize, iterDims) {
    const o1 = index2 * iterSize;
    const o2 = (index2 + 1) * iterSize;
    const data = "subarray" in this.data ? this.data.subarray(o1, o2) : this.data.slice(o1, o2);
    return new Tensor(this.type, data, iterDims);
  }
  /**
   * Returns the value of this tensor as a standard JavaScript Number. This only works
   * for tensors with one element. For other cases, see `Tensor.tolist()`.
   * @returns {number|bigint} The value of this tensor as a standard JavaScript Number.
   * @throws {Error} If the tensor has more than one element.
   */
  item() {
    if (this.data.length !== 1) {
      throw new Error(`a Tensor with ${this.data.length} elements cannot be converted to Scalar`);
    }
    return this.data[0];
  }
  /**
   * Convert tensor data to a n-dimensional JS list
   * @returns {Array}
   */
  tolist() {
    return reshape(this.data, this.dims);
  }
  /**
   * Return a new Tensor with the sigmoid function applied to each element.
   * @returns {Tensor} The tensor with the sigmoid function applied.
   */
  sigmoid() {
    return this.clone().sigmoid_();
  }
  /**
   * Applies the sigmoid function to the tensor in place.
   * @returns {Tensor} Returns `this`.
   */
  sigmoid_() {
    for (let i2 = 0; i2 < this.data.length; ++i2) {
      this.data[i2] = 1 / (1 + Math.exp(-this.data[i2]));
    }
    return this;
  }
  /**
   * Return a new Tensor with every element multiplied by a constant.
   * @param {number} val The value to multiply by.
   * @returns {Tensor} The new tensor.
   */
  mul(val) {
    return this.clone().mul_(val);
  }
  /**
   * Multiply the tensor by a constant in place.
   * @param {number} val The value to multiply by.
   * @returns {Tensor} Returns `this`.
   */
  mul_(val) {
    for (let i2 = 0; i2 < this.data.length; ++i2) {
      this.data[i2] *= val;
    }
    return this;
  }
  /**
   * Return a new Tensor with every element added by a constant.
   * @param {number} val The value to add by.
   * @returns {Tensor} The new tensor.
   */
  add(val) {
    return this.clone().add_(val);
  }
  /**
   * Add the tensor by a constant in place.
   * @param {number} val The value to add by.
   * @returns {Tensor} Returns `this`.
   */
  add_(val) {
    for (let i2 = 0; i2 < this.data.length; ++i2) {
      this.data[i2] += val;
    }
    return this;
  }
  clone() {
    return new Tensor(this.type, this.data.slice(), this.dims.slice());
  }
  slice(...slices) {
    let newTensorDims = [];
    let newOffsets = [];
    for (let sliceIndex = 0; sliceIndex < this.dims.length; ++sliceIndex) {
      let slice2 = slices[sliceIndex];
      if (slice2 === null || slice2 === void 0) {
        newOffsets.push([0, this.dims[sliceIndex]]);
        newTensorDims.push(this.dims[sliceIndex]);
      } else if (typeof slice2 === "number") {
        slice2 = safeIndex(slice2, this.dims[sliceIndex], sliceIndex);
        newOffsets.push([slice2, slice2 + 1]);
      } else if (Array.isArray(slice2) && slice2.length === 2) {
        if (slice2[0] > slice2[1]) {
          throw new Error(`Invalid slice: ${slice2}`);
        }
        let offsets = [
          Math.max(slice2[0], 0),
          Math.min(slice2[1], this.dims[sliceIndex])
        ];
        newOffsets.push(offsets);
        newTensorDims.push(offsets[1] - offsets[0]);
      } else {
        throw new Error(`Invalid slice: ${slice2}`);
      }
    }
    let newDims = newOffsets.map(([start, end]) => end - start);
    let newBufferSize = newDims.reduce((a, b) => a * b);
    let data = new this.data.constructor(newBufferSize);
    const stride = this.stride();
    for (let i2 = 0; i2 < newBufferSize; ++i2) {
      let originalIndex = 0;
      for (let j = newDims.length - 1, num = i2; j >= 0; --j) {
        const size = newDims[j];
        originalIndex += (num % size + newOffsets[j][0]) * stride[j];
        num = Math.floor(num / size);
      }
      data[i2] = this.data[originalIndex];
    }
    return new Tensor(this.type, data, newTensorDims);
  }
  /**
   * Return a permuted version of this Tensor, according to the provided dimensions.
   * @param  {...number} dims Dimensions to permute.
   * @returns {Tensor} The permuted tensor.
   */
  permute(...dims) {
    return permute(this, dims);
  }
  // TODO: implement transpose. For now (backwards compatibility), it's just an alias for permute()
  transpose(...dims) {
    return this.permute(...dims);
  }
  // TODO add .max() and .min() methods
  /**
   * Returns the sum of each row of the input tensor in the given dimension dim.
   * 
   * @param {number} [dim=null] The dimension or dimensions to reduce. If `null`, all dimensions are reduced.
   * @param {boolean} keepdim Whether the output tensor has `dim` retained or not.
   * @returns The summed tensor
   */
  sum(dim = null, keepdim = false) {
    return this.norm(1, dim, keepdim);
  }
  /**
   * Returns the matrix norm or vector norm of a given tensor.
   * @param {number|string} [p='fro'] The order of norm
   * @param {number} [dim=null] Specifies which dimension of the tensor to calculate the norm across.
   * If dim is None, the norm will be calculated across all dimensions of input.
   * @param {boolean} [keepdim=false] Whether the output tensors have dim retained or not.
   * @returns {Tensor} The norm of the tensor.
   */
  norm(p = "fro", dim = null, keepdim = false) {
    if (p === "fro") {
      p = 2;
    } else if (typeof p === "string") {
      throw Error(`Unsupported norm: ${p}`);
    }
    if (dim === null) {
      let val = this.data.reduce((a, b) => a + b ** p, 0) ** (1 / p);
      return new Tensor(this.type, [val], []);
    }
    dim = safeIndex(dim, this.dims.length);
    const resultDims = this.dims.slice();
    resultDims[dim] = 1;
    const result = new this.data.constructor(this.data.length / this.dims[dim]);
    for (let i2 = 0; i2 < this.data.length; ++i2) {
      let resultIndex = 0;
      for (let j = this.dims.length - 1, num = i2, resultMultiplier = 1; j >= 0; --j) {
        const size = this.dims[j];
        if (j !== dim) {
          const index2 = num % size;
          resultIndex += index2 * resultMultiplier;
          resultMultiplier *= resultDims[j];
        }
        num = Math.floor(num / size);
      }
      result[resultIndex] += this.data[i2] ** p;
    }
    if (p !== 1) {
      for (let i2 = 0; i2 < result.length; ++i2) {
        result[i2] = result[i2] ** (1 / p);
      }
    }
    if (!keepdim) {
      resultDims.splice(dim, 1);
    }
    return new Tensor(this.type, result, resultDims);
  }
  /**
   * Performs `L_p` normalization of inputs over specified dimension. Operates in place.
   * @param {number} [p=2] The exponent value in the norm formulation
   * @param {number} [dim=1] The dimension to reduce
   * @returns {Tensor} `this` for operation chaining.
   */
  normalize_(p = 2, dim = 1) {
    dim = safeIndex(dim, this.dims.length);
    const norm = this.norm(p, dim, true);
    for (let i2 = 0; i2 < this.data.length; ++i2) {
      let resultIndex = 0;
      for (let j = this.dims.length - 1, num = i2, resultMultiplier = 1; j >= 0; --j) {
        const size = this.dims[j];
        if (j !== dim) {
          const index2 = num % size;
          resultIndex += index2 * resultMultiplier;
          resultMultiplier *= this.dims[j];
        }
        num = Math.floor(num / size);
      }
      this.data[i2] /= norm.data[resultIndex];
    }
    return this;
  }
  /**
   * Performs `L_p` normalization of inputs over specified dimension.
   * @param {number} [p=2] The exponent value in the norm formulation
   * @param {number} [dim=1] The dimension to reduce
   * @returns {Tensor} The normalized tensor.
   */
  normalize(p = 2, dim = 1) {
    return this.clone().normalize_(p, dim);
  }
  /**
   * Compute and return the stride of this tensor.
   * Stride is the jump necessary to go from one element to the next one in the specified dimension dim.
   * @returns {number[]} The stride of this tensor.
   */
  stride() {
    return dimsToStride(this.dims);
  }
  /**
   * Returns a tensor with all specified dimensions of input of size 1 removed.
   * 
   * NOTE: The returned tensor shares the storage with the input tensor, so changing the contents of one will change the contents of the other.
   * If you would like a copy, use `tensor.clone()` before squeezing.
   * 
   * @param {number} [dim=null] If given, the input will be squeezed only in the specified dimensions.
   * @returns The squeezed tensor
   */
  squeeze(dim = null) {
    return new Tensor(
      this.type,
      this.data,
      calc_squeeze_dims(this.dims, dim)
    );
  }
  /**
   * In-place version of @see {@link Tensor.squeeze}
   */
  squeeze_(dim = null) {
    this.dims = calc_squeeze_dims(this.dims, dim);
    return this;
  }
  /**
   * Returns a new tensor with a dimension of size one inserted at the specified position.
   * 
   * NOTE: The returned tensor shares the same underlying data with this tensor.
   * 
   * @param {number} dim The index at which to insert the singleton dimension
   * @returns The unsqueezed tensor
   */
  unsqueeze(dim = null) {
    return new Tensor(
      this.type,
      this.data,
      calc_unsqueeze_dims(this.dims, dim)
    );
  }
  /**
   * In-place version of @see {@link Tensor.unsqueeze}
   */
  unsqueeze_(dim = null) {
    this.dims = calc_unsqueeze_dims(this.dims, dim);
    return this;
  }
  /**
   * In-place version of @see {@link Tensor.flatten}
   */
  flatten_(start_dim = 0, end_dim = -1) {
    end_dim = (end_dim + this.dims.length) % this.dims.length;
    let dimsToKeepBefore = this.dims.slice(0, start_dim);
    let dimsToFlatten = this.dims.slice(start_dim, end_dim + 1);
    let dimsToKeepAfter = this.dims.slice(end_dim + 1);
    this.dims = [...dimsToKeepBefore, dimsToFlatten.reduce((a, b) => a * b, 1), ...dimsToKeepAfter];
    return this;
  }
  /**
   * Flattens input by reshaping it into a one-dimensional tensor.
   * If `start_dim` or `end_dim` are passed, only dimensions starting with `start_dim`
   * and ending with `end_dim` are flattened. The order of elements in input is unchanged.
   * @param {number} start_dim the first dim to flatten
   * @param {number} end_dim the last dim to flatten
   * @returns The flattened tensor.
   */
  flatten(start_dim = 0, end_dim = -1) {
    return this.clone().flatten_(start_dim, end_dim);
  }
  /**
   * Returns a new tensor with the same data as the `self` tensor but of a different `shape`.
   * @param  {...number} dims the desired size
   * @returns {Tensor} The tensor with the same data but different shape
   */
  view(...dims) {
    let inferredIndex = -1;
    for (let i2 = 0; i2 < dims.length; ++i2) {
      if (dims[i2] === -1) {
        if (inferredIndex !== -1) {
          throw new Error("Only one dimension can be inferred");
        }
        inferredIndex = i2;
      }
    }
    if (inferredIndex !== -1) {
      const productOther = dims.reduce((product2, curr, index2) => {
        return index2 !== inferredIndex ? product2 * curr : product2;
      }, 1);
      dims[inferredIndex] = this.data.length / productOther;
    }
    return new Tensor(this.type, this.data, dims);
  }
  neg_() {
    for (let i2 = 0; i2 < this.data.length; ++i2) {
      this.data[i2] = -this.data[i2];
    }
    return this;
  }
  neg() {
    return this.clone().neg_();
  }
  /**
   * In-place version of @see {@link Tensor.clamp}
   */
  clamp_(min2, max2) {
    for (let i2 = 0; i2 < this.data.length; ++i2) {
      this.data[i2] = Math.min(Math.max(this.data[i2], min2), max2);
    }
    return this;
  }
  /**
   * Clamps all elements in input into the range [ min, max ]
   * @param {number} min lower-bound of the range to be clamped to
   * @param {number} max upper-bound of the range to be clamped to
   * @returns the output tensor.
   */
  clamp(min2, max2) {
    return this.clone().clamp_(min2, max2);
  }
  /**
   * In-place version of @see {@link Tensor.round}
   */
  round_() {
    for (let i2 = 0; i2 < this.data.length; ++i2) {
      this.data[i2] = Math.round(this.data[i2]);
    }
    return this;
  }
  /**
   * Rounds elements of input to the nearest integer.
   * @returns the output tensor.
   */
  round() {
    return this.clone().round_();
  }
  /**
   * Performs Tensor dtype conversion.
   * @param {DataType} type The desired data type.
   * @returns {Tensor} The converted tensor.
   */
  to(type2) {
    if (this.type === type2) return this;
    if (!DataTypeMap.hasOwnProperty(type2)) {
      throw new Error(`Unsupported type: ${type2}`);
    }
    return new Tensor(type2, DataTypeMap[type2].from(this.data), this.dims);
  }
}
function reshape(data, dimensions) {
  const totalElements = data.length;
  const dimensionSize = dimensions.reduce((a, b) => a * b);
  if (totalElements !== dimensionSize) {
    throw Error(`cannot reshape array of size ${totalElements} into shape (${dimensions})`);
  }
  let reshapedArray = data;
  for (let i2 = dimensions.length - 1; i2 >= 0; i2--) {
    reshapedArray = reshapedArray.reduce((acc, val) => {
      let lastArray = acc[acc.length - 1];
      if (lastArray.length < dimensions[i2]) {
        lastArray.push(val);
      } else {
        acc.push([val]);
      }
      return acc;
    }, [[]]);
  }
  return reshapedArray[0];
}
function permute(tensor, axes) {
  const [permutedData, shape] = permute_data(tensor.data, tensor.dims, axes);
  return new Tensor(tensor.type, permutedData, shape);
}
function interpolate(input2, [out_height, out_width], mode = "bilinear", align_corners = false) {
  const in_channels = input2.dims.at(-3) ?? 1;
  const in_height = input2.dims.at(-2);
  const in_width = input2.dims.at(-1);
  let output2 = interpolate_data(
    /** @type {import('./maths.js').TypedArray}*/
    input2.data,
    [in_channels, in_height, in_width],
    [out_height, out_width],
    mode,
    align_corners
  );
  return new Tensor(input2.type, output2, [in_channels, out_height, out_width]);
}
function mean_pooling(last_hidden_state, attention_mask) {
  let shape = [last_hidden_state.dims[0], last_hidden_state.dims[2]];
  let returnedData = new last_hidden_state.data.constructor(shape[0] * shape[1]);
  let [batchSize, seqLength, embedDim] = last_hidden_state.dims;
  let outIndex = 0;
  for (let i2 = 0; i2 < batchSize; ++i2) {
    let offset = i2 * embedDim * seqLength;
    for (let k = 0; k < embedDim; ++k) {
      let sum = 0;
      let count = 0;
      let attnMaskOffset = i2 * seqLength;
      let offset2 = offset + k;
      for (let j = 0; j < seqLength; ++j) {
        let attn = Number(attention_mask.data[attnMaskOffset + j]);
        count += attn;
        sum += last_hidden_state.data[offset2 + j * embedDim] * attn;
      }
      let avg = sum / count;
      returnedData[outIndex++] = avg;
    }
  }
  return new Tensor(
    last_hidden_state.type,
    returnedData,
    shape
  );
}
function calc_squeeze_dims(dims, dim) {
  dims = dims.slice();
  if (dim === null) {
    dims = dims.filter((d) => d !== 1);
  } else if (typeof dim === "number") {
    if (dims[dim] === 1) {
      dims.splice(dim, 1);
    }
  } else if (Array.isArray(dim)) {
    dims = dims.filter((x, i2) => {
      return x !== 1 || !dim.includes(i2);
    });
  }
  return dims;
}
function calc_unsqueeze_dims(dims, dim) {
  dim = safeIndex(dim, dims.length + 1);
  dims = dims.slice();
  dims.splice(dim, 0, 1);
  return dims;
}
function safeIndex(index2, size, dimension = null) {
  if (index2 < -size || index2 >= size) {
    throw new Error(`IndexError: index ${index2} is out of bounds for dimension${dimension === null ? "" : " " + dimension} with size ${size}`);
  }
  if (index2 < 0) {
    index2 = (index2 % size + size) % size;
  }
  return index2;
}
function cat(tensors, dim = 0) {
  dim = safeIndex(dim, tensors[0].dims.length);
  const resultDims = tensors[0].dims.slice();
  resultDims[dim] = tensors.reduce((a, b) => a + b.dims[dim], 0);
  const resultSize = resultDims.reduce((a, b) => a * b, 1);
  const result = new tensors[0].data.constructor(resultSize);
  const resultType = tensors[0].type;
  if (dim === 0) {
    let offset = 0;
    for (let t2 of tensors) {
      result.set(t2.data, offset);
      offset += t2.data.length;
    }
  } else {
    let currentDim = 0;
    for (let t2 = 0; t2 < tensors.length; ++t2) {
      let tensor = tensors[t2];
      for (let i2 = 0; i2 < tensor.data.length; ++i2) {
        let resultIndex = 0;
        for (let j = tensor.dims.length - 1, num = i2, resultMultiplier = 1; j >= 0; --j) {
          const size = tensor.dims[j];
          let index2 = num % size;
          if (j === dim) {
            index2 += currentDim;
          }
          resultIndex += index2 * resultMultiplier;
          resultMultiplier *= resultDims[j];
          num = Math.floor(num / size);
        }
        result[resultIndex] = tensor.data[i2];
      }
      currentDim += tensor.dims[dim];
    }
  }
  return new Tensor(resultType, result, resultDims);
}
function stack(tensors, dim = 0) {
  return cat(tensors.map((t2) => t2.unsqueeze(dim)), dim);
}
function std_mean(input2, dim = null, correction = 1, keepdim = false) {
  if (dim === null) {
    const sum = input2.data.reduce((a, b) => a + b, 0);
    const mean2 = sum / input2.data.length;
    const std = Math.sqrt(input2.data.reduce((a, b) => a + (b - mean2) ** 2, 0) / (input2.data.length - correction));
    const meanTensor2 = new Tensor(input2.type, [mean2], [
      /* scalar */
    ]);
    const stdTensor2 = new Tensor(input2.type, [std], [
      /* scalar */
    ]);
    return [stdTensor2, meanTensor2];
  }
  dim = safeIndex(dim, input2.dims.length);
  const meanTensor = mean(input2, dim, keepdim);
  const resultDims = input2.dims.slice();
  resultDims[dim] = 1;
  const result = new input2.data.constructor(input2.data.length / input2.dims[dim]);
  for (let i2 = 0; i2 < input2.data.length; ++i2) {
    let resultIndex = 0;
    for (let j = input2.dims.length - 1, num = i2, resultMultiplier = 1; j >= 0; --j) {
      const size = input2.dims[j];
      if (j !== dim) {
        const index2 = num % size;
        resultIndex += index2 * resultMultiplier;
        resultMultiplier *= resultDims[j];
      }
      num = Math.floor(num / size);
    }
    result[resultIndex] += (input2.data[i2] - meanTensor.data[resultIndex]) ** 2;
  }
  for (let i2 = 0; i2 < result.length; ++i2) {
    result[i2] = Math.sqrt(result[i2] / (input2.dims[dim] - correction));
  }
  if (!keepdim) {
    resultDims.splice(dim, 1);
  }
  const stdTensor = new Tensor(input2.type, result, resultDims);
  return [stdTensor, meanTensor];
}
function mean(input2, dim = null, keepdim = false) {
  if (dim === null) {
    let val = input2.data.reduce((a, b) => a + b, 0);
    return new Tensor(input2.type, [val / input2.data.length], [
      /* scalar */
    ]);
  }
  dim = safeIndex(dim, input2.dims.length);
  const resultDims = input2.dims.slice();
  resultDims[dim] = 1;
  const result = new input2.data.constructor(input2.data.length / input2.dims[dim]);
  for (let i2 = 0; i2 < input2.data.length; ++i2) {
    let resultIndex = 0;
    for (let j = input2.dims.length - 1, num = i2, resultMultiplier = 1; j >= 0; --j) {
      const size = input2.dims[j];
      if (j !== dim) {
        const index2 = num % size;
        resultIndex += index2 * resultMultiplier;
        resultMultiplier *= resultDims[j];
      }
      num = Math.floor(num / size);
    }
    result[resultIndex] += input2.data[i2];
  }
  if (input2.dims[dim] !== 1) {
    for (let i2 = 0; i2 < result.length; ++i2) {
      result[i2] = result[i2] / input2.dims[dim];
    }
  }
  if (!keepdim) {
    resultDims.splice(dim, 1);
  }
  return new Tensor(input2.type, result, resultDims);
}
function dynamicTimeWarping(matrix) {
  const [output_length, input_length] = matrix.dims;
  const outputShape = [output_length + 1, input_length + 1];
  const cost = new Tensor(
    "float32",
    new Float32Array(outputShape[0] * outputShape[1]).fill(Infinity),
    outputShape
  );
  const trace = new Tensor(
    "float32",
    new Float32Array(outputShape[0] * outputShape[1]).fill(-1),
    outputShape
  );
  cost[0].data[0] = 0;
  for (let j2 = 1; j2 < input_length + 1; ++j2) {
    for (let i3 = 1; i3 < output_length + 1; ++i3) {
      const c0 = cost[i3 - 1][j2 - 1].item();
      const c1 = cost[i3 - 1][j2].item();
      const c2 = cost[i3][j2 - 1].item();
      let c, t2;
      if (c0 < c1 && c0 < c2) {
        c = c0;
        t2 = 0;
      } else if (c1 < c0 && c1 < c2) {
        c = c1;
        t2 = 1;
      } else {
        c = c2;
        t2 = 2;
      }
      cost[i3].data[j2] = matrix[i3 - 1][j2 - 1].item() + c;
      trace[i3].data[j2] = t2;
    }
  }
  let i2 = output_length;
  let j = input_length;
  trace.data.fill(2, 0, outputShape[1]);
  for (let i3 = 0; i3 < outputShape[0]; ++i3) {
    trace[i3].data[0] = 1;
  }
  let text_indices = [];
  let time_indices = [];
  while (i2 > 0 || j > 0) {
    text_indices.push(i2 - 1);
    time_indices.push(j - 1);
    const t2 = trace[i2][j].item();
    switch (t2) {
      case 0:
        --i2;
        --j;
        break;
      case 1:
        --i2;
        break;
      case 2:
        --j;
        break;
      default:
        throw new Error(
          `Internal error in dynamic time warping. Unexpected trace[${i2}, ${j}]. Please file a bug report.`
        );
    }
  }
  text_indices.reverse();
  time_indices.reverse();
  return [text_indices, time_indices];
}
function dimsToStride(dims) {
  const stride = new Array(dims.length);
  for (let i2 = dims.length - 1, s2 = 1; i2 >= 0; --i2) {
    stride[i2] = s2;
    s2 *= dims[i2];
  }
  return stride;
}
function ones(size) {
  const numElements = size.reduce((a, b) => a * b, 1);
  return new Tensor(
    "int64",
    new BigInt64Array(numElements).fill(1n),
    size
  );
}
function ones_like(tensor) {
  return ones(tensor.dims);
}
function quantize_embeddings(tensor, precision) {
  if (tensor.dims.length !== 2) {
    throw new Error("The tensor must have 2 dimensions");
  }
  if (tensor.dims.at(-1) % 8 !== 0) {
    throw new Error("The last dimension of the tensor must be a multiple of 8");
  }
  if (!["binary", "ubinary"].includes(precision)) {
    throw new Error("The precision must be either 'binary' or 'ubinary'");
  }
  const signed = precision === "binary";
  const dtype = signed ? "int8" : "uint8";
  const cls = signed ? Int8Array : Uint8Array;
  const inputData = tensor.data;
  const outputData = new cls(inputData.length / 8);
  for (let i2 = 0; i2 < inputData.length; ++i2) {
    const bit = inputData[i2] > 0 ? 1 : 0;
    const arrayIndex = Math.floor(i2 / 8);
    const bitPosition = i2 % 8;
    outputData[arrayIndex] |= bit << 7 - bitPosition;
    if (signed && bitPosition === 0) {
      outputData[arrayIndex] -= 128;
    }
  }
  return new Tensor(dtype, outputData, [tensor.dims[0], tensor.dims[1] / 8]);
}
class PriorityQueue {
  /**
   * Create a new PriorityQueue.
   * @param {Function} comparator Comparator function to determine priority. Defaults to a MaxHeap.
   */
  constructor(comparator2 = (a, b) => a > b) {
    this._heap = [];
    this._comparator = comparator2;
  }
  /**
   * The size of the queue
   */
  get size() {
    return this._heap.length;
  }
  /**
   * Check if the queue is empty.
   * @returns {boolean} `true` if the queue is empty, `false` otherwise.
   */
  isEmpty() {
    return this.size === 0;
  }
  /**
   * Return the element with the highest priority in the queue.
   * @returns {any} The highest priority element in the queue.
   */
  peek() {
    return this._heap[0];
  }
  /**
   * Add one or more elements to the queue.
   * @param  {...any} values The values to push into the queue.
   * @returns {number} The new size of the queue.
   */
  push(...values) {
    return this.extend(values);
  }
  /**
   * Add multiple elements to the queue.
   * @param {any[]} values The values to push into the queue.
   * @returns {number} The new size of the queue.
   */
  extend(values) {
    for (const value of values) {
      this._heap.push(value);
      this._siftUp();
    }
    return this.size;
  }
  /**
   * Remove and return the element with the highest priority in the queue.
   * @returns {any} The element with the highest priority in the queue.
   */
  pop() {
    const poppedValue = this.peek();
    const bottom = this.size - 1;
    if (bottom > 0) {
      this._swap(0, bottom);
    }
    this._heap.pop();
    this._siftDown();
    return poppedValue;
  }
  /**
   * Replace the element with the highest priority in the queue with a new value.
   * @param {*} value The new value.
   * @returns {*} The replaced value.
   */
  replace(value) {
    const replacedValue = this.peek();
    this._heap[0] = value;
    this._siftDown();
    return replacedValue;
  }
  /**
   * Compute the index for the parent of the node at index `i`.
   * @param {number} i The index of the node to get the parent of.
   * @returns {number} The index of the parent node.
   * @private
   */
  _parent(i2) {
    return (i2 + 1 >>> 1) - 1;
  }
  /**
   * Compute the index for the left child of the node at index `i`.
   * @param {number} i The index of the node to get the left child of.
   * @returns {number} The index of the left child.
   * @private
   */
  _left(i2) {
    return (i2 << 1) + 1;
  }
  /**
   * Compute the index for the right child of the node at index `i`.
   * @param {number} i The index of the node to get the right child of.
   * @returns {number} The index of the right child.
   * @private
   */
  _right(i2) {
    return i2 + 1 << 1;
  }
  /**
   * Check if the element at index `i` is greater than the element at index `j`.
   * @param {number} i The index of the first element to compare.
   * @param {number} j The index of the second element to compare.
   * @returns {boolean} `true` if the element at index `i` is greater than the element at index `j`, `false` otherwise.
   * @private
   */
  _greater(i2, j) {
    return this._comparator(this._heap[i2], this._heap[j]);
  }
  /**
   * Swap the elements at indices `i` and `j`.
   * @param {number} i The index of the first element to swap.
   * @param {number} j The index of the second element to swap.
   * @private
   */
  _swap(i2, j) {
    const temp = this._heap[i2];
    this._heap[i2] = this._heap[j];
    this._heap[j] = temp;
  }
  /**
   * Maintain the heap property by updating positions in the heap,
   * starting at the last element and moving up the heap.
   * @private
   */
  _siftUp() {
    let node = this.size - 1;
    while (node > 0 && this._greater(node, this._parent(node))) {
      this._swap(node, this._parent(node));
      node = this._parent(node);
    }
  }
  /**
   * Maintain the heap property by updating positions in the heap,
   * starting at the first element and moving down the heap.
   * @private
   */
  _siftDown() {
    let node = 0;
    while (this._left(node) < this.size && this._greater(this._left(node), node) || this._right(node) < this.size && this._greater(this._right(node), node)) {
      const maxChild = this._right(node) < this.size && this._greater(this._right(node), this._left(node)) ? this._right(node) : this._left(node);
      this._swap(node, maxChild);
      node = maxChild;
    }
  }
}
class CharTrie {
  constructor() {
    this.root = CharTrieNode.default();
  }
  /**
   * Adds one or more `texts` to the trie.
   * @param {string[]} texts The strings to add to the trie.
   */
  extend(texts) {
    for (let text of texts) {
      this.push(text);
    }
  }
  /**
   * Adds text to the trie.
   * @param {string} text The string to add to the trie.
   */
  push(text) {
    let node = this.root;
    for (let ch of text) {
      let child = node.children.get(ch);
      if (child === void 0) {
        child = CharTrieNode.default();
        node.children.set(ch, child);
      }
      node = child;
    }
    node.isLeaf = true;
  }
  /**
   * Searches the trie for all strings with a common prefix of `text`.
   * @param {string} text The common prefix to search for.
   * @yields {string} Each string in the trie that has `text` as a prefix.
   */
  *commonPrefixSearch(text) {
    let node = this.root;
    let prefix = "";
    for (let i2 = 0; i2 < text.length && node !== void 0; ++i2) {
      const ch = text[i2];
      prefix += ch;
      node = node.children.get(ch);
      if (node !== void 0 && node.isLeaf) {
        yield prefix;
      }
    }
  }
}
class CharTrieNode {
  /**
   * Create a new CharTrieNode.
   * @param {boolean} isLeaf Whether the node is a leaf node or not.
   * @param {Map<string, CharTrieNode>} children A map containing the node's children, where the key is a character and the value is a `CharTrieNode`.
   */
  constructor(isLeaf, children) {
    this.isLeaf = isLeaf;
    this.children = children;
  }
  /**
   * Returns a new `CharTrieNode` instance with default values.
   * @returns {CharTrieNode} A new `CharTrieNode` instance with `isLeaf` set to `false` and an empty `children` map.
   */
  static default() {
    return new CharTrieNode(false, /* @__PURE__ */ new Map());
  }
}
class TokenLattice {
  /**
   * Creates a new TokenLattice instance.
   *
   * @param {string} sentence The input sentence to be tokenized.
   * @param {number} bosTokenId The beginning-of-sequence token ID.
   * @param {number} eosTokenId The end-of-sequence token ID.
   */
  constructor(sentence, bosTokenId, eosTokenId) {
    this.sentence = sentence;
    this.len = sentence.length;
    this.bosTokenId = bosTokenId;
    this.eosTokenId = eosTokenId;
    this.nodes = [];
    this.beginNodes = Array.from({ length: this.len + 1 }, () => []);
    this.endNodes = Array.from({ length: this.len + 1 }, () => []);
    const bos = new TokenLatticeNode(this.bosTokenId, 0, 0, 0, 0);
    const eos = new TokenLatticeNode(this.eosTokenId, 1, this.len, 0, 0);
    this.nodes.push(bos.clone());
    this.nodes.push(eos.clone());
    this.beginNodes[this.len].push(eos);
    this.endNodes[0].push(bos);
  }
  /**
   * Inserts a new token node into the token lattice.
   *
   * @param {number} pos The starting position of the token.
   * @param {number} length The length of the token.
   * @param {number} score The score of the token.
   * @param {number} tokenId The token ID of the token.
   */
  insert(pos, length, score, tokenId) {
    const nodeId = this.nodes.length;
    const node = new TokenLatticeNode(tokenId, nodeId, pos, length, score);
    this.beginNodes[pos].push(node);
    this.endNodes[pos + length].push(node);
    this.nodes.push(node);
  }
  /**
   * Implements the Viterbi algorithm to compute the most likely sequence of tokens.
   *
   * @returns {TokenLatticeNode[]} The array of nodes representing the most likely sequence of tokens.
   */
  viterbi() {
    const len = this.len;
    let pos = 0;
    while (pos <= len) {
      if (this.beginNodes[pos].length == 0) {
        return [];
      }
      for (let rnode of this.beginNodes[pos]) {
        rnode.prev = null;
        let bestScore = 0;
        let bestNode = null;
        for (let lnode of this.endNodes[pos]) {
          const score = lnode.backtraceScore + rnode.score;
          if (bestNode === null || score > bestScore) {
            bestNode = lnode.clone();
            bestScore = score;
          }
        }
        if (bestNode !== null) {
          rnode.prev = bestNode;
          rnode.backtraceScore = bestScore;
        } else {
          return [];
        }
      }
      ++pos;
    }
    const results = [];
    const root = this.beginNodes[len][0];
    const prev = root.prev;
    if (prev === null) {
      return [];
    }
    let node = prev.clone();
    while (node.prev !== null) {
      results.push(node.clone());
      const n = node.clone();
      node = n.prev.clone();
    }
    results.reverse();
    return results;
  }
  /**
   * @param {TokenLatticeNode} node
   * @returns {string} The array of nodes representing the most likely sequence of tokens.
   */
  piece(node) {
    return this.sentence.slice(node.pos, node.pos + node.length);
  }
  /**
   * @returns {Array} The array of nodes representing the most likely sequence of tokens.
   */
  tokens() {
    const nodes = this.viterbi();
    return nodes.map((x) => this.piece(x));
  }
  /**
   * @returns {Array} The array of nodes representing the most likely sequence of tokens.
   */
  tokenIds() {
    const nodes = this.viterbi();
    return nodes.map((x) => x.tokenId);
  }
}
class TokenLatticeNode {
  /**
   * Represents a node in a token lattice for a given sentence.
   * @param {number} tokenId The ID of the token associated with this node.
   * @param {number} nodeId The ID of this node.
   * @param {number} pos The starting position of the token in the sentence.
   * @param {number} length The length of the token.
   * @param {number} score The score associated with the token.
   */
  constructor(tokenId, nodeId, pos, length, score) {
    this.tokenId = tokenId;
    this.nodeId = nodeId;
    this.pos = pos;
    this.length = length;
    this.score = score;
    this.prev = null;
    this.backtraceScore = 0;
  }
  /**
   * Returns a clone of this node.
   * @returns {TokenLatticeNode} A clone of this node.
   */
  clone() {
    const n = new TokenLatticeNode(this.tokenId, this.nodeId, this.pos, this.length, this.score);
    n.prev = this.prev;
    n.backtraceScore = this.backtraceScore;
    return n;
  }
}
var TOKEN_TYPES = Object.freeze({
  Text: "Text",
  // The text between Jinja statements or expressions
  NumericLiteral: "NumericLiteral",
  // e.g., 123
  BooleanLiteral: "BooleanLiteral",
  // true or false
  StringLiteral: "StringLiteral",
  // 'string'
  Identifier: "Identifier",
  // Variables, functions, etc.
  Equals: "Equals",
  // =
  OpenParen: "OpenParen",
  // (
  CloseParen: "CloseParen",
  // )
  OpenStatement: "OpenStatement",
  // {%
  CloseStatement: "CloseStatement",
  // %}
  OpenExpression: "OpenExpression",
  // {{
  CloseExpression: "CloseExpression",
  // }}
  OpenSquareBracket: "OpenSquareBracket",
  // [
  CloseSquareBracket: "CloseSquareBracket",
  // ]
  OpenCurlyBracket: "OpenCurlyBracket",
  // {
  CloseCurlyBracket: "CloseCurlyBracket",
  // }
  Comma: "Comma",
  // ,
  Dot: "Dot",
  // .
  Colon: "Colon",
  // :
  Pipe: "Pipe",
  // |
  CallOperator: "CallOperator",
  // ()
  AdditiveBinaryOperator: "AdditiveBinaryOperator",
  // + -
  MultiplicativeBinaryOperator: "MultiplicativeBinaryOperator",
  // * / %
  ComparisonBinaryOperator: "ComparisonBinaryOperator",
  // < > <= >= == !=
  UnaryOperator: "UnaryOperator",
  // ! - +
  // Keywords
  Set: "Set",
  If: "If",
  For: "For",
  In: "In",
  Is: "Is",
  NotIn: "NotIn",
  Else: "Else",
  EndIf: "EndIf",
  ElseIf: "ElseIf",
  EndFor: "EndFor",
  And: "And",
  Or: "Or",
  Not: "UnaryOperator"
});
var KEYWORDS = Object.freeze({
  set: TOKEN_TYPES.Set,
  for: TOKEN_TYPES.For,
  in: TOKEN_TYPES.In,
  is: TOKEN_TYPES.Is,
  if: TOKEN_TYPES.If,
  else: TOKEN_TYPES.Else,
  endif: TOKEN_TYPES.EndIf,
  elif: TOKEN_TYPES.ElseIf,
  endfor: TOKEN_TYPES.EndFor,
  and: TOKEN_TYPES.And,
  or: TOKEN_TYPES.Or,
  not: TOKEN_TYPES.Not,
  "not in": TOKEN_TYPES.NotIn,
  // Literals
  true: TOKEN_TYPES.BooleanLiteral,
  false: TOKEN_TYPES.BooleanLiteral
});
var Token = class {
  /**
   * Constructs a new Token.
   * @param {string} value The raw value as seen inside the source code.
   * @param {TokenType} type The type of token.
   */
  constructor(value, type2) {
    this.value = value;
    this.type = type2;
  }
};
function isWord(char) {
  return /\w/.test(char);
}
function isInteger(char) {
  return /[0-9]/.test(char);
}
var ORDERED_MAPPING_TABLE = [
  // Control sequences
  ["{%", TOKEN_TYPES.OpenStatement],
  ["%}", TOKEN_TYPES.CloseStatement],
  ["{{", TOKEN_TYPES.OpenExpression],
  ["}}", TOKEN_TYPES.CloseExpression],
  // Single character tokens
  ["(", TOKEN_TYPES.OpenParen],
  [")", TOKEN_TYPES.CloseParen],
  ["{", TOKEN_TYPES.OpenCurlyBracket],
  ["}", TOKEN_TYPES.CloseCurlyBracket],
  ["[", TOKEN_TYPES.OpenSquareBracket],
  ["]", TOKEN_TYPES.CloseSquareBracket],
  [",", TOKEN_TYPES.Comma],
  [".", TOKEN_TYPES.Dot],
  [":", TOKEN_TYPES.Colon],
  ["|", TOKEN_TYPES.Pipe],
  // Comparison operators
  ["<=", TOKEN_TYPES.ComparisonBinaryOperator],
  [">=", TOKEN_TYPES.ComparisonBinaryOperator],
  ["==", TOKEN_TYPES.ComparisonBinaryOperator],
  ["!=", TOKEN_TYPES.ComparisonBinaryOperator],
  ["<", TOKEN_TYPES.ComparisonBinaryOperator],
  [">", TOKEN_TYPES.ComparisonBinaryOperator],
  // Arithmetic operators
  ["+", TOKEN_TYPES.AdditiveBinaryOperator],
  ["-", TOKEN_TYPES.AdditiveBinaryOperator],
  ["*", TOKEN_TYPES.MultiplicativeBinaryOperator],
  ["/", TOKEN_TYPES.MultiplicativeBinaryOperator],
  ["%", TOKEN_TYPES.MultiplicativeBinaryOperator],
  // Assignment operator
  ["=", TOKEN_TYPES.Equals]
];
var ESCAPE_CHARACTERS = /* @__PURE__ */ new Map([
  ["n", "\n"],
  // New line
  ["t", "	"],
  // Horizontal tab
  ["r", "\r"],
  // Carriage return
  ["b", "\b"],
  // Backspace
  ["f", "\f"],
  // Form feed
  ["v", "\v"],
  // Vertical tab
  ["'", "'"],
  // Single quote
  ['"', '"'],
  // Double quote
  ["\\", "\\"]
  // Backslash
]);
function preprocess(template, options = {}) {
  if (template.endsWith("\n")) {
    template = template.slice(0, -1);
  }
  template = template.replace(/{#.*?#}/gs, "{##}");
  if (options.lstrip_blocks) {
    template = template.replace(/^[ \t]*({[#%])/gm, "$1");
  }
  if (options.trim_blocks) {
    template = template.replace(/([#%]})\n/g, "$1");
  }
  return template.replace(/{##}/g, "").replace(/-%}\s*/g, "%}").replace(/\s*{%-/g, "{%").replace(/-}}\s*/g, "}}").replace(/\s*{{-/g, "{{");
}
function tokenize(source, options = {}) {
  var _a2, _b, _c;
  const tokens = [];
  const src = preprocess(source, options);
  let cursorPosition = 0;
  const consumeWhile = (predicate) => {
    let str = "";
    while (predicate(src[cursorPosition])) {
      if (src[cursorPosition] === "\\") {
        ++cursorPosition;
        if (cursorPosition >= src.length)
          throw new SyntaxError("Unexpected end of input");
        const escaped = src[cursorPosition++];
        const unescaped = ESCAPE_CHARACTERS.get(escaped);
        if (unescaped === void 0) {
          throw new SyntaxError(`Unexpected escaped character: ${escaped}`);
        }
        str += unescaped;
        continue;
      }
      str += src[cursorPosition++];
      if (cursorPosition >= src.length)
        throw new SyntaxError("Unexpected end of input");
    }
    return str;
  };
  main:
    while (cursorPosition < src.length) {
      const lastTokenType = (_a2 = tokens.at(-1)) == null ? void 0 : _a2.type;
      if (lastTokenType === void 0 || lastTokenType === TOKEN_TYPES.CloseStatement || lastTokenType === TOKEN_TYPES.CloseExpression) {
        let text = "";
        while (cursorPosition < src.length && // Keep going until we hit the next Jinja statement or expression
        !(src[cursorPosition] === "{" && (src[cursorPosition + 1] === "%" || src[cursorPosition + 1] === "{"))) {
          text += src[cursorPosition++];
        }
        if (text.length > 0) {
          tokens.push(new Token(text, TOKEN_TYPES.Text));
          continue;
        }
      }
      consumeWhile((char2) => /\s/.test(char2));
      const char = src[cursorPosition];
      if (char === "-" || char === "+") {
        const lastTokenType2 = (_b = tokens.at(-1)) == null ? void 0 : _b.type;
        if (lastTokenType2 === TOKEN_TYPES.Text || lastTokenType2 === void 0) {
          throw new SyntaxError(`Unexpected character: ${char}`);
        }
        switch (lastTokenType2) {
          case TOKEN_TYPES.Identifier:
          case TOKEN_TYPES.NumericLiteral:
          case TOKEN_TYPES.BooleanLiteral:
          case TOKEN_TYPES.StringLiteral:
          case TOKEN_TYPES.CloseParen:
          case TOKEN_TYPES.CloseSquareBracket:
            break;
          default: {
            ++cursorPosition;
            const num = consumeWhile(isInteger);
            tokens.push(
              new Token(`${char}${num}`, num.length > 0 ? TOKEN_TYPES.NumericLiteral : TOKEN_TYPES.UnaryOperator)
            );
            continue;
          }
        }
      }
      for (const [char2, token] of ORDERED_MAPPING_TABLE) {
        const slice2 = src.slice(cursorPosition, cursorPosition + char2.length);
        if (slice2 === char2) {
          tokens.push(new Token(char2, token));
          cursorPosition += char2.length;
          continue main;
        }
      }
      if (char === "'" || char === '"') {
        ++cursorPosition;
        const str = consumeWhile((c) => c !== char);
        tokens.push(new Token(str, TOKEN_TYPES.StringLiteral));
        ++cursorPosition;
        continue;
      }
      if (isInteger(char)) {
        const num = consumeWhile(isInteger);
        tokens.push(new Token(num, TOKEN_TYPES.NumericLiteral));
        continue;
      }
      if (isWord(char)) {
        const word = consumeWhile(isWord);
        const type2 = Object.hasOwn(KEYWORDS, word) ? KEYWORDS[word] : TOKEN_TYPES.Identifier;
        if (type2 === TOKEN_TYPES.In && ((_c = tokens.at(-1)) == null ? void 0 : _c.type) === TOKEN_TYPES.Not) {
          tokens.pop();
          tokens.push(new Token("not in", TOKEN_TYPES.NotIn));
        } else {
          tokens.push(new Token(word, type2));
        }
        continue;
      }
      throw new SyntaxError(`Unexpected character: ${char}`);
    }
  return tokens;
}
var Statement = class {
  constructor() {
    __publicField(this, "type", "Statement");
  }
};
var Program = class extends Statement {
  constructor(body) {
    super();
    __publicField(this, "type", "Program");
    this.body = body;
  }
};
var If = class extends Statement {
  constructor(test, body, alternate) {
    super();
    __publicField(this, "type", "If");
    this.test = test;
    this.body = body;
    this.alternate = alternate;
  }
};
var For = class extends Statement {
  constructor(loopvar, iterable, body) {
    super();
    __publicField(this, "type", "For");
    this.loopvar = loopvar;
    this.iterable = iterable;
    this.body = body;
  }
};
var SetStatement = class extends Statement {
  constructor(assignee, value) {
    super();
    __publicField(this, "type", "Set");
    this.assignee = assignee;
    this.value = value;
  }
};
var Expression = class extends Statement {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "Expression");
  }
};
var MemberExpression = class extends Expression {
  constructor(object2, property, computed) {
    super();
    __publicField(this, "type", "MemberExpression");
    this.object = object2;
    this.property = property;
    this.computed = computed;
  }
};
var CallExpression = class extends Expression {
  constructor(callee, args) {
    super();
    __publicField(this, "type", "CallExpression");
    this.callee = callee;
    this.args = args;
  }
};
var Identifier = class extends Expression {
  /**
   * @param {string} value The name of the identifier
   */
  constructor(value) {
    super();
    __publicField(this, "type", "Identifier");
    this.value = value;
  }
};
var Literal = class extends Expression {
  constructor(value) {
    super();
    __publicField(this, "type", "Literal");
    this.value = value;
  }
};
var NumericLiteral = class extends Literal {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "NumericLiteral");
  }
};
var StringLiteral = class extends Literal {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "StringLiteral");
  }
};
var BooleanLiteral = class extends Literal {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "BooleanLiteral");
  }
};
var ArrayLiteral = class extends Literal {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "ArrayLiteral");
  }
};
var TupleLiteral = class extends Literal {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "TupleLiteral");
  }
};
var ObjectLiteral = class extends Literal {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "ObjectLiteral");
  }
};
var BinaryExpression = class extends Expression {
  constructor(operator, left, right) {
    super();
    __publicField(this, "type", "BinaryExpression");
    this.operator = operator;
    this.left = left;
    this.right = right;
  }
};
var FilterExpression = class extends Expression {
  constructor(operand, filter) {
    super();
    __publicField(this, "type", "FilterExpression");
    this.operand = operand;
    this.filter = filter;
  }
};
var TestExpression = class extends Expression {
  constructor(operand, negate2, test) {
    super();
    __publicField(this, "type", "TestExpression");
    this.operand = operand;
    this.negate = negate2;
    this.test = test;
  }
};
var UnaryExpression = class extends Expression {
  constructor(operator, argument) {
    super();
    __publicField(this, "type", "UnaryExpression");
    this.operator = operator;
    this.argument = argument;
  }
};
var SliceExpression = class extends Expression {
  constructor(start = void 0, stop = void 0, step = void 0) {
    super();
    __publicField(this, "type", "SliceExpression");
    this.start = start;
    this.stop = stop;
    this.step = step;
  }
};
var KeywordArgumentExpression = class extends Expression {
  constructor(key, value) {
    super();
    __publicField(this, "type", "KeywordArgumentExpression");
    this.key = key;
    this.value = value;
  }
};
function parse$2(tokens) {
  const program = new Program([]);
  let current = 0;
  function expect(type2, error2) {
    const prev = tokens[current++];
    if (!prev || prev.type !== type2) {
      throw new Error(`Parser Error: ${error2}. ${prev.type} !== ${type2}.`);
    }
    return prev;
  }
  function parseAny() {
    switch (tokens[current].type) {
      case TOKEN_TYPES.Text:
        return parseText();
      case TOKEN_TYPES.OpenStatement:
        return parseJinjaStatement();
      case TOKEN_TYPES.OpenExpression:
        return parseJinjaExpression();
      default:
        throw new SyntaxError(`Unexpected token type: ${tokens[current].type}`);
    }
  }
  function not2(...types2) {
    return current + types2.length <= tokens.length && types2.some((type2, i2) => type2 !== tokens[current + i2].type);
  }
  function is2(...types2) {
    return current + types2.length <= tokens.length && types2.every((type2, i2) => type2 === tokens[current + i2].type);
  }
  function parseText() {
    return new StringLiteral(expect(TOKEN_TYPES.Text, "Expected text token").value);
  }
  function parseJinjaStatement() {
    expect(TOKEN_TYPES.OpenStatement, "Expected opening statement token");
    let result;
    switch (tokens[current].type) {
      case TOKEN_TYPES.Set:
        ++current;
        result = parseSetStatement();
        expect(TOKEN_TYPES.CloseStatement, "Expected closing statement token");
        break;
      case TOKEN_TYPES.If:
        ++current;
        result = parseIfStatement();
        expect(TOKEN_TYPES.OpenStatement, "Expected {% token");
        expect(TOKEN_TYPES.EndIf, "Expected endif token");
        expect(TOKEN_TYPES.CloseStatement, "Expected %} token");
        break;
      case TOKEN_TYPES.For:
        ++current;
        result = parseForStatement();
        expect(TOKEN_TYPES.OpenStatement, "Expected {% token");
        expect(TOKEN_TYPES.EndFor, "Expected endfor token");
        expect(TOKEN_TYPES.CloseStatement, "Expected %} token");
        break;
      default:
        throw new SyntaxError(`Unknown statement type: ${tokens[current].type}`);
    }
    return result;
  }
  function parseJinjaExpression() {
    expect(TOKEN_TYPES.OpenExpression, "Expected opening expression token");
    const result = parseExpression();
    expect(TOKEN_TYPES.CloseExpression, "Expected closing expression token");
    return result;
  }
  function parseSetStatement() {
    const left = parseExpression();
    if (is2(TOKEN_TYPES.Equals)) {
      ++current;
      const value = parseSetStatement();
      return new SetStatement(left, value);
    }
    return left;
  }
  function parseIfStatement() {
    var _a2, _b, _c, _d, _e, _f, _g, _h;
    const test = parseExpression();
    expect(TOKEN_TYPES.CloseStatement, "Expected closing statement token");
    const body = [];
    const alternate = [];
    while (!(((_a2 = tokens[current]) == null ? void 0 : _a2.type) === TOKEN_TYPES.OpenStatement && (((_b = tokens[current + 1]) == null ? void 0 : _b.type) === TOKEN_TYPES.ElseIf || ((_c = tokens[current + 1]) == null ? void 0 : _c.type) === TOKEN_TYPES.Else || ((_d = tokens[current + 1]) == null ? void 0 : _d.type) === TOKEN_TYPES.EndIf))) {
      body.push(parseAny());
    }
    if (((_e = tokens[current]) == null ? void 0 : _e.type) === TOKEN_TYPES.OpenStatement && ((_f = tokens[current + 1]) == null ? void 0 : _f.type) !== TOKEN_TYPES.EndIf) {
      ++current;
      if (is2(TOKEN_TYPES.ElseIf)) {
        expect(TOKEN_TYPES.ElseIf, "Expected elseif token");
        alternate.push(parseIfStatement());
      } else {
        expect(TOKEN_TYPES.Else, "Expected else token");
        expect(TOKEN_TYPES.CloseStatement, "Expected closing statement token");
        while (!(((_g = tokens[current]) == null ? void 0 : _g.type) === TOKEN_TYPES.OpenStatement && ((_h = tokens[current + 1]) == null ? void 0 : _h.type) === TOKEN_TYPES.EndIf)) {
          alternate.push(parseAny());
        }
      }
    }
    return new If(test, body, alternate);
  }
  function parseExpressionSequence(primary = false) {
    const fn2 = primary ? parsePrimaryExpression : parseExpression;
    const expressions = [fn2()];
    const isTuple = is2(TOKEN_TYPES.Comma);
    while (isTuple) {
      ++current;
      expressions.push(fn2());
      if (!is2(TOKEN_TYPES.Comma)) {
        break;
      }
    }
    return isTuple ? new TupleLiteral(expressions) : expressions[0];
  }
  function parseForStatement() {
    const loopVariable = parseExpressionSequence(true);
    if (!(loopVariable instanceof Identifier || loopVariable instanceof TupleLiteral)) {
      throw new SyntaxError(`Expected identifier/tuple for the loop variable, got ${loopVariable.type} instead`);
    }
    expect(TOKEN_TYPES.In, "Expected `in` keyword following loop variable");
    const iterable = parseExpression();
    expect(TOKEN_TYPES.CloseStatement, "Expected closing statement token");
    const body = [];
    while (not2(TOKEN_TYPES.OpenStatement, TOKEN_TYPES.EndFor)) {
      body.push(parseAny());
    }
    return new For(loopVariable, iterable, body);
  }
  function parseExpression() {
    return parseTernaryExpression();
  }
  function parseTernaryExpression() {
    const a = parseLogicalOrExpression();
    if (is2(TOKEN_TYPES.If)) {
      ++current;
      const predicate = parseLogicalOrExpression();
      expect(TOKEN_TYPES.Else, "Expected else token");
      const b = parseLogicalOrExpression();
      return new If(predicate, [a], [b]);
    }
    return a;
  }
  function parseLogicalOrExpression() {
    let left = parseLogicalAndExpression();
    while (is2(TOKEN_TYPES.Or)) {
      const operator = tokens[current];
      ++current;
      const right = parseLogicalAndExpression();
      left = new BinaryExpression(operator, left, right);
    }
    return left;
  }
  function parseLogicalAndExpression() {
    let left = parseLogicalNegationExpression();
    while (is2(TOKEN_TYPES.And)) {
      const operator = tokens[current];
      ++current;
      const right = parseLogicalNegationExpression();
      left = new BinaryExpression(operator, left, right);
    }
    return left;
  }
  function parseLogicalNegationExpression() {
    let right;
    while (is2(TOKEN_TYPES.Not)) {
      const operator = tokens[current];
      ++current;
      const arg = parseLogicalNegationExpression();
      right = new UnaryExpression(operator, arg);
    }
    return right ?? parseComparisonExpression();
  }
  function parseComparisonExpression() {
    let left = parseAdditiveExpression();
    while (is2(TOKEN_TYPES.ComparisonBinaryOperator) || is2(TOKEN_TYPES.In) || is2(TOKEN_TYPES.NotIn)) {
      const operator = tokens[current];
      ++current;
      const right = parseAdditiveExpression();
      left = new BinaryExpression(operator, left, right);
    }
    return left;
  }
  function parseAdditiveExpression() {
    let left = parseMultiplicativeExpression();
    while (is2(TOKEN_TYPES.AdditiveBinaryOperator)) {
      const operator = tokens[current];
      ++current;
      const right = parseMultiplicativeExpression();
      left = new BinaryExpression(operator, left, right);
    }
    return left;
  }
  function parseCallMemberExpression() {
    const member = parseMemberExpression();
    if (is2(TOKEN_TYPES.OpenParen)) {
      return parseCallExpression(member);
    }
    return member;
  }
  function parseCallExpression(callee) {
    let callExpression = new CallExpression(callee, parseArgs());
    if (is2(TOKEN_TYPES.OpenParen)) {
      callExpression = parseCallExpression(callExpression);
    }
    return callExpression;
  }
  function parseArgs() {
    expect(TOKEN_TYPES.OpenParen, "Expected opening parenthesis for arguments list");
    const args = parseArgumentsList();
    expect(TOKEN_TYPES.CloseParen, "Expected closing parenthesis for arguments list");
    return args;
  }
  function parseArgumentsList() {
    const args = [];
    while (!is2(TOKEN_TYPES.CloseParen)) {
      let argument = parseExpression();
      if (is2(TOKEN_TYPES.Equals)) {
        ++current;
        if (!(argument instanceof Identifier)) {
          throw new SyntaxError(`Expected identifier for keyword argument`);
        }
        const value = parseExpression();
        argument = new KeywordArgumentExpression(argument, value);
      }
      args.push(argument);
      if (is2(TOKEN_TYPES.Comma)) {
        ++current;
      }
    }
    return args;
  }
  function parseMemberExpressionArgumentsList() {
    const slices = [];
    let isSlice = false;
    while (!is2(TOKEN_TYPES.CloseSquareBracket)) {
      if (is2(TOKEN_TYPES.Colon)) {
        slices.push(void 0);
        ++current;
        isSlice = true;
      } else {
        slices.push(parseExpression());
        if (is2(TOKEN_TYPES.Colon)) {
          ++current;
          isSlice = true;
        }
      }
    }
    if (slices.length === 0) {
      throw new SyntaxError(`Expected at least one argument for member/slice expression`);
    }
    if (isSlice) {
      if (slices.length > 3) {
        throw new SyntaxError(`Expected 0-3 arguments for slice expression`);
      }
      return new SliceExpression(...slices);
    }
    return slices[0];
  }
  function parseMemberExpression() {
    let object2 = parsePrimaryExpression();
    while (is2(TOKEN_TYPES.Dot) || is2(TOKEN_TYPES.OpenSquareBracket)) {
      const operator = tokens[current];
      ++current;
      let property;
      const computed = operator.type !== TOKEN_TYPES.Dot;
      if (computed) {
        property = parseMemberExpressionArgumentsList();
        expect(TOKEN_TYPES.CloseSquareBracket, "Expected closing square bracket");
      } else {
        property = parsePrimaryExpression();
        if (property.type !== "Identifier") {
          throw new SyntaxError(`Expected identifier following dot operator`);
        }
      }
      object2 = new MemberExpression(object2, property, computed);
    }
    return object2;
  }
  function parseMultiplicativeExpression() {
    let left = parseTestExpression();
    while (is2(TOKEN_TYPES.MultiplicativeBinaryOperator)) {
      const operator = tokens[current];
      ++current;
      const right = parseTestExpression();
      left = new BinaryExpression(operator, left, right);
    }
    return left;
  }
  function parseTestExpression() {
    let operand = parseFilterExpression();
    while (is2(TOKEN_TYPES.Is)) {
      ++current;
      const negate2 = is2(TOKEN_TYPES.Not);
      if (negate2) {
        ++current;
      }
      let filter = parsePrimaryExpression();
      if (filter instanceof BooleanLiteral) {
        filter = new Identifier(filter.value.toString());
      }
      if (!(filter instanceof Identifier)) {
        throw new SyntaxError(`Expected identifier for the test`);
      }
      operand = new TestExpression(operand, negate2, filter);
    }
    return operand;
  }
  function parseFilterExpression() {
    let operand = parseCallMemberExpression();
    while (is2(TOKEN_TYPES.Pipe)) {
      ++current;
      let filter = parsePrimaryExpression();
      if (!(filter instanceof Identifier)) {
        throw new SyntaxError(`Expected identifier for the filter`);
      }
      if (is2(TOKEN_TYPES.OpenParen)) {
        filter = parseCallExpression(filter);
      }
      operand = new FilterExpression(operand, filter);
    }
    return operand;
  }
  function parsePrimaryExpression() {
    const token = tokens[current];
    switch (token.type) {
      case TOKEN_TYPES.NumericLiteral:
        ++current;
        return new NumericLiteral(Number(token.value));
      case TOKEN_TYPES.StringLiteral:
        ++current;
        return new StringLiteral(token.value);
      case TOKEN_TYPES.BooleanLiteral:
        ++current;
        return new BooleanLiteral(token.value === "true");
      case TOKEN_TYPES.Identifier:
        ++current;
        return new Identifier(token.value);
      case TOKEN_TYPES.OpenParen: {
        ++current;
        const expression = parseExpressionSequence();
        if (tokens[current].type !== TOKEN_TYPES.CloseParen) {
          throw new SyntaxError(`Expected closing parenthesis, got ${tokens[current].type} instead`);
        }
        ++current;
        return expression;
      }
      case TOKEN_TYPES.OpenSquareBracket: {
        ++current;
        const values = [];
        while (!is2(TOKEN_TYPES.CloseSquareBracket)) {
          values.push(parseExpression());
          if (is2(TOKEN_TYPES.Comma)) {
            ++current;
          }
        }
        ++current;
        return new ArrayLiteral(values);
      }
      case TOKEN_TYPES.OpenCurlyBracket: {
        ++current;
        const values = /* @__PURE__ */ new Map();
        while (!is2(TOKEN_TYPES.CloseCurlyBracket)) {
          const key = parseExpression();
          expect(TOKEN_TYPES.Colon, "Expected colon between key and value in object literal");
          const value = parseExpression();
          values.set(key, value);
          if (is2(TOKEN_TYPES.Comma)) {
            ++current;
          }
        }
        ++current;
        return new ObjectLiteral(values);
      }
      default:
        throw new SyntaxError(`Unexpected token: ${token.type}`);
    }
  }
  while (current < tokens.length) {
    program.body.push(parseAny());
  }
  return program;
}
function range(start, stop, step = 1) {
  if (stop === void 0) {
    stop = start;
    start = 0;
  }
  const result = [];
  for (let i2 = start; i2 < stop; i2 += step) {
    result.push(i2);
  }
  return result;
}
function slice$1(array, start, stop, step = 1) {
  const direction = Math.sign(step);
  if (direction >= 0) {
    start = (start ?? (start = 0)) < 0 ? Math.max(array.length + start, 0) : Math.min(start, array.length);
    stop = (stop ?? (stop = array.length)) < 0 ? Math.max(array.length + stop, 0) : Math.min(stop, array.length);
  } else {
    start = (start ?? (start = array.length - 1)) < 0 ? Math.max(array.length + start, -1) : Math.min(start, array.length - 1);
    stop = (stop ?? (stop = -1)) < -1 ? Math.max(array.length + stop, -1) : Math.min(stop, array.length - 1);
  }
  const result = [];
  for (let i2 = start; direction * i2 < direction * stop; i2 += step) {
    result.push(array[i2]);
  }
  return result;
}
function titleCase(value) {
  return value.replace(/\b\w/g, (c) => c.toUpperCase());
}
var RuntimeValue = class {
  /**
   * Creates a new RuntimeValue.
   */
  constructor(value = void 0) {
    __publicField(this, "type", "RuntimeValue");
    __publicField(this, "value");
    /**
     * A collection of built-in functions for this type.
     */
    __publicField(this, "builtins", /* @__PURE__ */ new Map());
    this.value = value;
  }
  /**
   * Determines truthiness or falsiness of the runtime value.
   * This function should be overridden by subclasses if it has custom truthiness criteria.
   * @returns {BooleanValue} BooleanValue(true) if the value is truthy, BooleanValue(false) otherwise.
   */
  __bool__() {
    return new BooleanValue(!!this.value);
  }
};
var NumericValue = class extends RuntimeValue {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "NumericValue");
  }
};
var StringValue = class extends RuntimeValue {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "StringValue");
    __publicField(this, "builtins", /* @__PURE__ */ new Map([
      [
        "upper",
        new FunctionValue(() => {
          return new StringValue(this.value.toUpperCase());
        })
      ],
      [
        "lower",
        new FunctionValue(() => {
          return new StringValue(this.value.toLowerCase());
        })
      ],
      [
        "strip",
        new FunctionValue(() => {
          return new StringValue(this.value.trim());
        })
      ],
      [
        "title",
        new FunctionValue(() => {
          return new StringValue(titleCase(this.value));
        })
      ],
      ["length", new NumericValue(this.value.length)]
    ]));
  }
};
var BooleanValue = class extends RuntimeValue {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "BooleanValue");
  }
};
var ObjectValue = class extends RuntimeValue {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "ObjectValue");
    __publicField(this, "builtins", /* @__PURE__ */ new Map([
      [
        "get",
        new FunctionValue(([key, defaultValue]) => {
          if (!(key instanceof StringValue)) {
            throw new Error(`Object key must be a string: got ${key.type}`);
          }
          return this.value.get(key.value) ?? defaultValue ?? new NullValue();
        })
      ],
      [
        "items",
        new FunctionValue(() => {
          return new ArrayValue(
            Array.from(this.value.entries()).map(([key, value]) => new ArrayValue([new StringValue(key), value]))
          );
        })
      ]
    ]));
  }
  /**
   * NOTE: necessary to override since all JavaScript arrays are considered truthy,
   * while only non-empty Python arrays are consider truthy.
   *
   * e.g.,
   *  - JavaScript:  {} && 5 -> 5
   *  - Python:      {} and 5 -> {}
   */
  __bool__() {
    return new BooleanValue(this.value.size > 0);
  }
};
var ArrayValue = class extends RuntimeValue {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "ArrayValue");
    __publicField(this, "builtins", /* @__PURE__ */ new Map([["length", new NumericValue(this.value.length)]]));
  }
  /**
   * NOTE: necessary to override since all JavaScript arrays are considered truthy,
   * while only non-empty Python arrays are consider truthy.
   *
   * e.g.,
   *  - JavaScript:  [] && 5 -> 5
   *  - Python:      [] and 5 -> []
   */
  __bool__() {
    return new BooleanValue(this.value.length > 0);
  }
};
var TupleValue = class extends ArrayValue {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "TupleValue");
  }
};
var FunctionValue = class extends RuntimeValue {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "FunctionValue");
  }
};
var NullValue = class extends RuntimeValue {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "NullValue");
  }
};
var UndefinedValue = class extends RuntimeValue {
  constructor() {
    super(...arguments);
    __publicField(this, "type", "UndefinedValue");
  }
};
var Environment = class {
  constructor(parent) {
    /**
     * The variables declared in this environment.
     */
    __publicField(this, "variables", /* @__PURE__ */ new Map([
      [
        "namespace",
        new FunctionValue((args) => {
          if (args.length === 0) {
            return new ObjectValue(/* @__PURE__ */ new Map());
          }
          if (args.length !== 1 || !(args[0] instanceof ObjectValue)) {
            throw new Error("`namespace` expects either zero arguments or a single object argument");
          }
          return args[0];
        })
      ]
    ]));
    /**
     * The tests available in this environment.
     */
    __publicField(this, "tests", /* @__PURE__ */ new Map([
      ["boolean", (operand) => operand.type === "BooleanValue"],
      ["callable", (operand) => operand instanceof FunctionValue],
      [
        "odd",
        (operand) => {
          if (operand.type !== "NumericValue") {
            throw new Error(`Cannot apply test "odd" to type: ${operand.type}`);
          }
          return operand.value % 2 !== 0;
        }
      ],
      [
        "even",
        (operand) => {
          if (operand.type !== "NumericValue") {
            throw new Error(`Cannot apply test "even" to type: ${operand.type}`);
          }
          return operand.value % 2 === 0;
        }
      ],
      ["false", (operand) => operand.type === "BooleanValue" && !operand.value],
      ["true", (operand) => operand.type === "BooleanValue" && operand.value],
      ["number", (operand) => operand.type === "NumericValue"],
      ["integer", (operand) => operand.type === "NumericValue" && Number.isInteger(operand.value)],
      ["iterable", (operand) => operand instanceof ArrayValue || operand instanceof StringValue],
      [
        "lower",
        (operand) => {
          const str = operand.value;
          return operand.type === "StringValue" && str === str.toLowerCase();
        }
      ],
      [
        "upper",
        (operand) => {
          const str = operand.value;
          return operand.type === "StringValue" && str === str.toUpperCase();
        }
      ],
      ["none", (operand) => operand.type === "NullValue"],
      ["defined", (operand) => operand.type !== "UndefinedValue"],
      ["undefined", (operand) => operand.type === "UndefinedValue"],
      ["equalto", (a, b) => a.value === b.value]
    ]));
    this.parent = parent;
  }
  /**
   * Set the value of a variable in the current environment.
   */
  set(name2, value) {
    return this.declareVariable(name2, convertToRuntimeValues(value));
  }
  declareVariable(name2, value) {
    if (this.variables.has(name2)) {
      throw new SyntaxError(`Variable already declared: ${name2}`);
    }
    this.variables.set(name2, value);
    return value;
  }
  // private assignVariable(name: string, value: AnyRuntimeValue): AnyRuntimeValue {
  // 	const env = this.resolve(name);
  // 	env.variables.set(name, value);
  // 	return value;
  // }
  /**
   * Set variable in the current scope.
   * See https://jinja.palletsprojects.com/en/3.0.x/templates/#assignments for more information.
   */
  setVariable(name2, value) {
    this.variables.set(name2, value);
    return value;
  }
  /**
   * Resolve the environment in which the variable is declared.
   * @param {string} name The name of the variable.
   * @returns {Environment} The environment in which the variable is declared.
   */
  resolve(name2) {
    if (this.variables.has(name2)) {
      return this;
    }
    if (this.parent) {
      return this.parent.resolve(name2);
    }
    throw new Error(`Unknown variable: ${name2}`);
  }
  lookupVariable(name2) {
    try {
      return this.resolve(name2).variables.get(name2) ?? new UndefinedValue();
    } catch {
      return new UndefinedValue();
    }
  }
};
var Interpreter = class {
  constructor(env2) {
    __publicField(this, "global");
    this.global = env2 ?? new Environment();
  }
  /**
   * Run the program.
   */
  run(program) {
    return this.evaluate(program, this.global);
  }
  /**
   * Evaluates expressions following the binary operation type.
   */
  evaluateBinaryExpression(node, environment) {
    const left = this.evaluate(node.left, environment);
    switch (node.operator.value) {
      case "and":
        return left.__bool__().value ? this.evaluate(node.right, environment) : left;
      case "or":
        return left.__bool__().value ? left : this.evaluate(node.right, environment);
    }
    const right = this.evaluate(node.right, environment);
    switch (node.operator.value) {
      case "==":
        return new BooleanValue(left.value == right.value);
      case "!=":
        return new BooleanValue(left.value != right.value);
    }
    if (left instanceof UndefinedValue || right instanceof UndefinedValue) {
      throw new Error("Cannot perform operation on undefined values");
    } else if (left instanceof NullValue || right instanceof NullValue) {
      throw new Error("Cannot perform operation on null values");
    } else if (left instanceof NumericValue && right instanceof NumericValue) {
      switch (node.operator.value) {
        case "+":
          return new NumericValue(left.value + right.value);
        case "-":
          return new NumericValue(left.value - right.value);
        case "*":
          return new NumericValue(left.value * right.value);
        case "/":
          return new NumericValue(left.value / right.value);
        case "%":
          return new NumericValue(left.value % right.value);
        case "<":
          return new BooleanValue(left.value < right.value);
        case ">":
          return new BooleanValue(left.value > right.value);
        case ">=":
          return new BooleanValue(left.value >= right.value);
        case "<=":
          return new BooleanValue(left.value <= right.value);
      }
    } else if (left instanceof ArrayValue && right instanceof ArrayValue) {
      switch (node.operator.value) {
        case "+":
          return new ArrayValue(left.value.concat(right.value));
      }
    } else if (right instanceof ArrayValue) {
      const member = right.value.find((x) => x.value === left.value) !== void 0;
      switch (node.operator.value) {
        case "in":
          return new BooleanValue(member);
        case "not in":
          return new BooleanValue(!member);
      }
    }
    if (left instanceof StringValue || right instanceof StringValue) {
      switch (node.operator.value) {
        case "+":
          return new StringValue(left.value.toString() + right.value.toString());
      }
    }
    if (left instanceof StringValue && right instanceof StringValue) {
      switch (node.operator.value) {
        case "in":
          return new BooleanValue(right.value.includes(left.value));
        case "not in":
          return new BooleanValue(!right.value.includes(left.value));
      }
    }
    if (left instanceof StringValue && right instanceof ObjectValue) {
      switch (node.operator.value) {
        case "in":
          return new BooleanValue(right.value.has(left.value));
        case "not in":
          return new BooleanValue(!right.value.has(left.value));
      }
    }
    throw new SyntaxError(`Unknown operator "${node.operator.value}" between ${left.type} and ${right.type}`);
  }
  /**
   * Evaluates expressions following the filter operation type.
   */
  evaluateFilterExpression(node, environment) {
    const operand = this.evaluate(node.operand, environment);
    if (node.filter.type === "Identifier") {
      const filter = node.filter;
      if (operand instanceof ArrayValue) {
        switch (filter.value) {
          case "list":
            return operand;
          case "first":
            return operand.value[0];
          case "last":
            return operand.value[operand.value.length - 1];
          case "length":
            return new NumericValue(operand.value.length);
          case "reverse":
            return new ArrayValue(operand.value.reverse());
          case "sort":
            return new ArrayValue(
              operand.value.sort((a, b) => {
                if (a.type !== b.type) {
                  throw new Error(`Cannot compare different types: ${a.type} and ${b.type}`);
                }
                switch (a.type) {
                  case "NumericValue":
                    return a.value - b.value;
                  case "StringValue":
                    return a.value.localeCompare(b.value);
                  default:
                    throw new Error(`Cannot compare type: ${a.type}`);
                }
              })
            );
          default:
            throw new Error(`Unknown ArrayValue filter: ${filter.value}`);
        }
      } else if (operand instanceof StringValue) {
        switch (filter.value) {
          case "length":
            return new NumericValue(operand.value.length);
          case "upper":
            return new StringValue(operand.value.toUpperCase());
          case "lower":
            return new StringValue(operand.value.toLowerCase());
          case "title":
            return new StringValue(titleCase(operand.value));
          case "capitalize":
            return new StringValue(operand.value.charAt(0).toUpperCase() + operand.value.slice(1));
          case "trim":
            return new StringValue(operand.value.trim());
          default:
            throw new Error(`Unknown StringValue filter: ${filter.value}`);
        }
      } else if (operand instanceof NumericValue) {
        switch (filter.value) {
          case "abs":
            return new NumericValue(Math.abs(operand.value));
          default:
            throw new Error(`Unknown NumericValue filter: ${filter.value}`);
        }
      } else if (operand instanceof ObjectValue) {
        switch (filter.value) {
          case "items":
            return new ArrayValue(
              Array.from(operand.value.entries()).map(([key, value]) => new ArrayValue([new StringValue(key), value]))
            );
          case "length":
            return new NumericValue(operand.value.size);
          default:
            throw new Error(`Unknown ObjectValue filter: ${filter.value}`);
        }
      }
      throw new Error(`Cannot apply filter "${filter.value}" to type: ${operand.type}`);
    } else if (node.filter.type === "CallExpression") {
      const filter = node.filter;
      if (filter.callee.type !== "Identifier") {
        throw new Error(`Unknown filter: ${filter.callee.type}`);
      }
      const filterName = filter.callee.value;
      if (operand instanceof ArrayValue) {
        switch (filterName) {
          case "selectattr": {
            if (operand.value.some((x) => !(x instanceof ObjectValue))) {
              throw new Error("`selectattr` can only be applied to array of objects");
            }
            if (filter.args.some((x) => x.type !== "StringLiteral")) {
              throw new Error("arguments of `selectattr` must be strings");
            }
            const [attr, testName, value] = filter.args.map((x) => this.evaluate(x, environment));
            let testFunction;
            if (testName) {
              const test = environment.tests.get(testName.value);
              if (!test) {
                throw new Error(`Unknown test: ${testName.value}`);
              }
              testFunction = test;
            } else {
              testFunction = (...x) => x[0].__bool__().value;
            }
            const filtered = operand.value.filter((item) => {
              const a = item.value.get(attr.value);
              if (a) {
                return testFunction(a, value);
              }
              return false;
            });
            return new ArrayValue(filtered);
          }
        }
        throw new Error(`Unknown ArrayValue filter: ${filterName}`);
      } else {
        throw new Error(`Cannot apply filter "${filterName}" to type: ${operand.type}`);
      }
    }
    throw new Error(`Unknown filter: ${node.filter.type}`);
  }
  /**
   * Evaluates expressions following the test operation type.
   */
  evaluateTestExpression(node, environment) {
    const operand = this.evaluate(node.operand, environment);
    const test = environment.tests.get(node.test.value);
    if (!test) {
      throw new Error(`Unknown test: ${node.test.value}`);
    }
    const result = test(operand);
    return new BooleanValue(node.negate ? !result : result);
  }
  /**
   * Evaluates expressions following the unary operation type.
   */
  evaluateUnaryExpression(node, environment) {
    const argument = this.evaluate(node.argument, environment);
    switch (node.operator.value) {
      case "not":
        return new BooleanValue(!argument.value);
      default:
        throw new SyntaxError(`Unknown operator: ${node.operator.value}`);
    }
  }
  evalProgram(program, environment) {
    return this.evaluateBlock(program.body, environment);
  }
  evaluateBlock(statements, environment) {
    let result = "";
    for (const statement of statements) {
      const lastEvaluated = this.evaluate(statement, environment);
      if (lastEvaluated.type !== "NullValue" && lastEvaluated.type !== "UndefinedValue") {
        result += lastEvaluated.value;
      }
    }
    return new StringValue(result);
  }
  evaluateIdentifier(node, environment) {
    return environment.lookupVariable(node.value);
  }
  evaluateCallExpression(expr, environment) {
    const args = [];
    const kwargs = /* @__PURE__ */ new Map();
    for (const argument of expr.args) {
      if (argument.type === "KeywordArgumentExpression") {
        const kwarg = argument;
        kwargs.set(kwarg.key.value, this.evaluate(kwarg.value, environment));
      } else {
        args.push(this.evaluate(argument, environment));
      }
    }
    if (kwargs.size > 0) {
      args.push(new ObjectValue(kwargs));
    }
    const fn2 = this.evaluate(expr.callee, environment);
    if (fn2.type !== "FunctionValue") {
      throw new Error(`Cannot call something that is not a function: got ${fn2.type}`);
    }
    return fn2.value(args, environment);
  }
  evaluateSliceExpression(object2, expr, environment) {
    if (!(object2 instanceof ArrayValue || object2 instanceof StringValue)) {
      throw new Error("Slice object must be an array or string");
    }
    const start = this.evaluate(expr.start, environment);
    const stop = this.evaluate(expr.stop, environment);
    const step = this.evaluate(expr.step, environment);
    if (!(start instanceof NumericValue || start instanceof UndefinedValue)) {
      throw new Error("Slice start must be numeric or undefined");
    }
    if (!(stop instanceof NumericValue || stop instanceof UndefinedValue)) {
      throw new Error("Slice stop must be numeric or undefined");
    }
    if (!(step instanceof NumericValue || step instanceof UndefinedValue)) {
      throw new Error("Slice step must be numeric or undefined");
    }
    if (object2 instanceof ArrayValue) {
      return new ArrayValue(slice$1(object2.value, start.value, stop.value, step.value));
    } else {
      return new StringValue(slice$1(Array.from(object2.value), start.value, stop.value, step.value).join(""));
    }
  }
  evaluateMemberExpression(expr, environment) {
    const object2 = this.evaluate(expr.object, environment);
    let property;
    if (expr.computed) {
      if (expr.property.type === "SliceExpression") {
        return this.evaluateSliceExpression(object2, expr.property, environment);
      } else {
        property = this.evaluate(expr.property, environment);
      }
    } else {
      property = new StringValue(expr.property.value);
    }
    let value;
    if (object2 instanceof ObjectValue) {
      if (!(property instanceof StringValue)) {
        throw new Error(`Cannot access property with non-string: got ${property.type}`);
      }
      value = object2.value.get(property.value) ?? object2.builtins.get(property.value);
    } else if (object2 instanceof ArrayValue || object2 instanceof StringValue) {
      if (property instanceof NumericValue) {
        value = object2.value.at(property.value);
        if (object2 instanceof StringValue) {
          value = new StringValue(object2.value.at(property.value));
        }
      } else if (property instanceof StringValue) {
        value = object2.builtins.get(property.value);
      } else {
        throw new Error(`Cannot access property with non-string/non-number: got ${property.type}`);
      }
    } else {
      if (!(property instanceof StringValue)) {
        throw new Error(`Cannot access property with non-string: got ${property.type}`);
      }
      value = object2.builtins.get(property.value);
    }
    return value instanceof RuntimeValue ? value : new UndefinedValue();
  }
  evaluateSet(node, environment) {
    const rhs = this.evaluate(node.value, environment);
    if (node.assignee.type === "Identifier") {
      const variableName = node.assignee.value;
      environment.setVariable(variableName, rhs);
    } else if (node.assignee.type === "MemberExpression") {
      const member = node.assignee;
      const object2 = this.evaluate(member.object, environment);
      if (!(object2 instanceof ObjectValue)) {
        throw new Error("Cannot assign to member of non-object");
      }
      if (member.property.type !== "Identifier") {
        throw new Error("Cannot assign to member with non-identifier property");
      }
      object2.value.set(member.property.value, rhs);
    } else {
      throw new Error(`Invalid LHS inside assignment expression: ${JSON.stringify(node.assignee)}`);
    }
    return new NullValue();
  }
  evaluateIf(node, environment) {
    const test = this.evaluate(node.test, environment);
    return this.evaluateBlock(test.__bool__().value ? node.body : node.alternate, environment);
  }
  evaluateFor(node, environment) {
    const scope2 = new Environment(environment);
    const iterable = this.evaluate(node.iterable, scope2);
    if (!(iterable instanceof ArrayValue)) {
      throw new Error(`Expected iterable type in for loop: got ${iterable.type}`);
    }
    let result = "";
    for (let i2 = 0; i2 < iterable.value.length; ++i2) {
      const loop = /* @__PURE__ */ new Map([
        ["index", new NumericValue(i2 + 1)],
        ["index0", new NumericValue(i2)],
        ["revindex", new NumericValue(iterable.value.length - i2)],
        ["revindex0", new NumericValue(iterable.value.length - i2 - 1)],
        ["first", new BooleanValue(i2 === 0)],
        ["last", new BooleanValue(i2 === iterable.value.length - 1)],
        ["length", new NumericValue(iterable.value.length)],
        ["previtem", i2 > 0 ? iterable.value[i2 - 1] : new UndefinedValue()],
        ["nextitem", i2 < iterable.value.length - 1 ? iterable.value[i2 + 1] : new UndefinedValue()]
      ]);
      scope2.setVariable("loop", new ObjectValue(loop));
      const current = iterable.value[i2];
      if (node.loopvar.type === "Identifier") {
        scope2.setVariable(node.loopvar.value, current);
      } else if (node.loopvar.type === "TupleLiteral") {
        const loopvar = node.loopvar;
        if (current.type !== "ArrayValue") {
          throw new Error(`Cannot unpack non-iterable type: ${current.type}`);
        }
        const c = current;
        if (loopvar.value.length !== c.value.length) {
          throw new Error(`Too ${loopvar.value.length > c.value.length ? "few" : "many"} items to unpack`);
        }
        for (let j = 0; j < loopvar.value.length; ++j) {
          if (loopvar.value[j].type !== "Identifier") {
            throw new Error(`Cannot unpack non-identifier type: ${loopvar.value[j].type}`);
          }
          scope2.setVariable(loopvar.value[j].value, c.value[j]);
        }
      }
      const evaluated = this.evaluateBlock(node.body, scope2);
      result += evaluated.value;
    }
    return new StringValue(result);
  }
  evaluate(statement, environment) {
    if (statement === void 0)
      return new UndefinedValue();
    switch (statement.type) {
      case "Program":
        return this.evalProgram(statement, environment);
      case "Set":
        return this.evaluateSet(statement, environment);
      case "If":
        return this.evaluateIf(statement, environment);
      case "For":
        return this.evaluateFor(statement, environment);
      case "NumericLiteral":
        return new NumericValue(Number(statement.value));
      case "StringLiteral":
        return new StringValue(statement.value);
      case "BooleanLiteral":
        return new BooleanValue(statement.value);
      case "ArrayLiteral":
        return new ArrayValue(statement.value.map((x) => this.evaluate(x, environment)));
      case "TupleLiteral":
        return new TupleValue(statement.value.map((x) => this.evaluate(x, environment)));
      case "ObjectLiteral": {
        const mapping = /* @__PURE__ */ new Map();
        for (const [key, value] of statement.value) {
          const evaluatedKey = this.evaluate(key, environment);
          if (!(evaluatedKey instanceof StringValue)) {
            throw new Error(`Object keys must be strings: got ${evaluatedKey.type}`);
          }
          mapping.set(evaluatedKey.value, this.evaluate(value, environment));
        }
        return new ObjectValue(mapping);
      }
      case "Identifier":
        return this.evaluateIdentifier(statement, environment);
      case "CallExpression":
        return this.evaluateCallExpression(statement, environment);
      case "MemberExpression":
        return this.evaluateMemberExpression(statement, environment);
      case "UnaryExpression":
        return this.evaluateUnaryExpression(statement, environment);
      case "BinaryExpression":
        return this.evaluateBinaryExpression(statement, environment);
      case "FilterExpression":
        return this.evaluateFilterExpression(statement, environment);
      case "TestExpression":
        return this.evaluateTestExpression(statement, environment);
      default:
        throw new SyntaxError(`Unknown node type: ${statement.type}`);
    }
  }
};
function convertToRuntimeValues(input2) {
  switch (typeof input2) {
    case "number":
      return new NumericValue(input2);
    case "string":
      return new StringValue(input2);
    case "boolean":
      return new BooleanValue(input2);
    case "object":
      if (input2 === null) {
        return new NullValue();
      } else if (Array.isArray(input2)) {
        return new ArrayValue(input2.map(convertToRuntimeValues));
      } else {
        return new ObjectValue(
          new Map(Object.entries(input2).map(([key, value]) => [key, convertToRuntimeValues(value)]))
        );
      }
    case "function":
      return new FunctionValue((args, _scope) => {
        const result = input2(...args.map((x) => x.value)) ?? null;
        return convertToRuntimeValues(result);
      });
    default:
      throw new Error(`Cannot convert to runtime value: ${input2}`);
  }
}
var Template = class {
  /**
   * @param {string} template The template string
   */
  constructor(template) {
    __publicField(this, "parsed");
    const tokens = tokenize(template, {
      lstrip_blocks: true,
      trim_blocks: true
    });
    this.parsed = parse$2(tokens);
  }
  render(items2) {
    const env2 = new Environment();
    env2.set("false", false);
    env2.set("true", true);
    env2.set("raise_exception", (args) => {
      throw new Error(args);
    });
    env2.set("range", range);
    for (const [key, value] of Object.entries(items2)) {
      env2.set(key, value);
    }
    const interpreter = new Interpreter(env2);
    const result = interpreter.run(this.parsed);
    return result.value;
  }
};
async function loadTokenizer(pretrained_model_name_or_path, options) {
  const info = await Promise.all([
    getModelJSON(pretrained_model_name_or_path, "tokenizer.json", true, options),
    getModelJSON(pretrained_model_name_or_path, "tokenizer_config.json", true, options)
  ]);
  if (options.legacy !== null) {
    info[1].legacy = options.legacy;
  }
  return info;
}
function regexSplit(text, regex) {
  const result = [];
  let prev = 0;
  for (const match of text.matchAll(regex)) {
    const fullMatch = match[0];
    if (prev < match.index) {
      result.push(text.slice(prev, match.index));
    }
    if (fullMatch.length > 0) {
      result.push(fullMatch);
    }
    prev = match.index + fullMatch.length;
  }
  if (prev < text.length) {
    result.push(text.slice(prev));
  }
  return result;
}
function createPattern(pattern2, invert = true) {
  if (pattern2.Regex !== void 0) {
    let regex = pattern2.Regex.replace(/\\([#&~])/g, "$1");
    for (const [key, value] of PROBLEMATIC_REGEX_MAP) {
      regex = regex.replaceAll(key, value);
    }
    return new RegExp(regex, "gu");
  } else if (pattern2.String !== void 0) {
    const escaped = escapeRegExp(pattern2.String);
    return new RegExp(invert ? escaped : `(${escaped})`, "gu");
  } else {
    console.warn("Unknown pattern type:", pattern2);
    return null;
  }
}
function objectToMap(obj) {
  return new Map(Object.entries(obj));
}
function prepareTensorForDecode(tensor) {
  const dims = tensor.dims;
  switch (dims.length) {
    case 1:
      return tensor.tolist();
    case 2:
      if (dims[0] !== 1) {
        throw new Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.");
      }
      return tensor.tolist()[0];
    default:
      throw new Error(`Expected tensor to have 1-2 dimensions, got ${dims.length}.`);
  }
}
function clean_up_tokenization(text) {
  return text.replace(/ \./g, ".").replace(/ \?/g, "?").replace(/ \!/g, "!").replace(/ ,/g, ",").replace(/ \' /g, "'").replace(/ n\'t/g, "n't").replace(/ \'m/g, "'m").replace(/ \'s/g, "'s").replace(/ \'ve/g, "'ve").replace(/ \'re/g, "'re");
}
function remove_accents(text) {
  return text.replace(/[\u0300-\u036f]/g, "");
}
function lowercase_and_remove_accent(text) {
  return remove_accents(text.toLowerCase());
}
function fuse(arr, value, mapping) {
  const fused = [];
  let i2 = 0;
  while (i2 < arr.length) {
    fused.push(arr[i2]);
    if ((mapping.get(arr[i2]) ?? value) !== value) {
      ++i2;
      continue;
    }
    while (i2 < arr.length && (mapping.get(arr[i2]) ?? value) === value) {
      ++i2;
    }
  }
  return fused;
}
function whitespace_split(text) {
  return text.match(/\S+/g) || [];
}
const PUNCTUATION_REGEX = "\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E";
const PROBLEMATIC_REGEX_MAP = /* @__PURE__ */ new Map([
  // This uses the case insensitive group modifier, which is not supported in JavaScript.
  // When parsing the regex, an "Invalid group" error is thrown.
  ["(?i:'s|'t|'re|'ve|'m|'ll|'d)", "(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))"]
]);
class AddedToken {
  /**
   * Creates a new instance of AddedToken.
   * @param {Object} config Added token configuration object.
   * @param {string} config.content The content of the added token.
   * @param {number} config.id The id of the added token.
   * @param {boolean} [config.single_word=false] Whether this token must be a single word or can break words.
   * @param {boolean} [config.lstrip=false] Whether this token should strip whitespaces on its left.
   * @param {boolean} [config.rstrip=false] Whether this token should strip whitespaces on its right.
   * @param {boolean} [config.normalized=false] Whether this token should be normalized.
   * @param {boolean} [config.special=false] Whether this token is special.
   */
  constructor(config2) {
    this.content = config2.content;
    this.id = config2.id;
    this.single_word = config2.single_word ?? false;
    this.lstrip = config2.lstrip ?? false;
    this.rstrip = config2.rstrip ?? false;
    this.special = config2.special ?? false;
    this.normalized = config2.normalized ?? null;
  }
}
class TokenizerModel extends Callable {
  /**
   * Creates a new instance of TokenizerModel.
   * @param {Object} config The configuration object for the TokenizerModel.
   */
  constructor(config2) {
    super();
    this.config = config2;
    this.vocab = [];
    this.tokens_to_ids = /* @__PURE__ */ new Map();
    this.unk_token_id = void 0;
    this.unk_token = void 0;
    this.end_of_word_suffix = void 0;
    this.fuse_unk = this.config.fuse_unk ?? false;
  }
  /**
   * Instantiates a new TokenizerModel instance based on the configuration object provided.
   * @param {Object} config The configuration object for the TokenizerModel.
   * @param {...*} args Optional arguments to pass to the specific TokenizerModel constructor.
   * @returns {TokenizerModel} A new instance of a TokenizerModel.
   * @throws Will throw an error if the TokenizerModel type in the config is not recognized.
   */
  static fromConfig(config2, ...args) {
    switch (config2.type) {
      case "WordPiece":
        return new WordPieceTokenizer(config2);
      case "Unigram":
        return new Unigram(config2, ...args);
      case "BPE":
        return new BPE(config2);
      default:
        if (config2.vocab) {
          return new LegacyTokenizerModel(config2, ...args);
        }
        throw new Error(`Unknown TokenizerModel type: ${config2.type}`);
    }
  }
  /**
   * Internal function to call the TokenizerModel instance.
   * @param {string[]} tokens The tokens to encode.
   * @returns {string[]} The encoded token IDs.
   */
  _call(tokens) {
    let ids = this.encode(tokens);
    if (this.fuse_unk) {
      ids = fuse(ids, this.unk_token_id, this.tokens_to_ids);
    }
    return ids;
  }
  /**
   * Encodes a list of tokens into a list of token IDs.
   * @param {string[]} tokens The tokens to encode.
   * @returns {string[]} The encoded tokens.
   * @throws Will throw an error if not implemented in a subclass.
   */
  encode(tokens) {
    throw Error("encode should be implemented in subclass.");
  }
  /**
   * Converts a list of tokens into a list of token IDs.
   * @param {string[]} tokens The tokens to convert.
   * @returns {number[]} The converted token IDs.
   */
  convert_tokens_to_ids(tokens) {
    return tokens.map((t2) => this.tokens_to_ids.get(t2) ?? this.unk_token_id);
  }
  /**
   * Converts a list of token IDs into a list of tokens.
   * @param {number[]} ids The token IDs to convert.
   * @returns {string[]} The converted tokens.
   */
  convert_ids_to_tokens(ids) {
    return ids.map((i2) => this.vocab[i2] ?? this.unk_token);
  }
}
class WordPieceTokenizer extends TokenizerModel {
  /**
   * @param {Object} config The configuration object.
   * @param {Object} config.vocab A mapping of tokens to ids.
   * @param {string} config.unk_token The unknown token string.
   * @param {string} config.continuing_subword_prefix The prefix to use for continuing subwords.
   * @param {number} [config.max_input_chars_per_word=100] The maximum number of characters per word.
   */
  constructor(config2) {
    super(config2);
    this.tokens_to_ids = objectToMap(config2.vocab);
    this.unk_token_id = this.tokens_to_ids.get(config2.unk_token);
    this.unk_token = config2.unk_token;
    this.max_input_chars_per_word = config2.max_input_chars_per_word ?? 100;
    this.vocab = new Array(this.tokens_to_ids.size);
    for (const [key, value] of this.tokens_to_ids) {
      this.vocab[value] = key;
    }
  }
  /**
   * Encodes an array of tokens using WordPiece encoding.
   * @param {string[]} tokens The tokens to encode.
   * @returns {string[]} An array of encoded tokens.
   */
  encode(tokens) {
    const outputTokens = [];
    for (const token of tokens) {
      const chars = [...token];
      if (chars.length > this.max_input_chars_per_word) {
        outputTokens.push(this.unk_token);
        continue;
      }
      let isUnknown = false;
      let start = 0;
      const subTokens = [];
      while (start < chars.length) {
        let end = chars.length;
        let currentSubstring = null;
        while (start < end) {
          let substr = chars.slice(start, end).join("");
          if (start > 0) {
            substr = this.config.continuing_subword_prefix + substr;
          }
          if (this.tokens_to_ids.has(substr)) {
            currentSubstring = substr;
            break;
          }
          --end;
        }
        if (currentSubstring === null) {
          isUnknown = true;
          break;
        }
        subTokens.push(currentSubstring);
        start = end;
      }
      if (isUnknown) {
        outputTokens.push(this.unk_token);
      } else {
        outputTokens.push(...subTokens);
      }
    }
    return outputTokens;
  }
}
class Unigram extends TokenizerModel {
  /**
   * Create a new Unigram tokenizer model.
   * @param {Object} config The configuration object for the Unigram model.
   * @param {number} config.unk_id The ID of the unknown token
   * @param {any[][]} config.vocab A 2D array representing a mapping of tokens to scores.
   * @param {Object} moreConfig Additional configuration object for the Unigram model.
   */
  constructor(config2, moreConfig) {
    super(config2);
    const vocabSize = config2.vocab.length;
    this.vocab = new Array(vocabSize);
    this.scores = new Array(vocabSize);
    for (let i2 = 0; i2 < vocabSize; ++i2) {
      const piece = config2.vocab[i2];
      this.vocab[i2] = piece[0];
      this.scores[i2] = piece[1];
    }
    this.unk_token_id = config2.unk_id;
    this.unk_token = this.vocab[config2.unk_id];
    this.tokens_to_ids = new Map(this.vocab.map((x, i2) => [x, i2]));
    this.bosToken = " ";
    this.bosTokenId = this.tokens_to_ids.get(this.bosToken);
    this.eosToken = moreConfig.eos_token;
    this.eosTokenId = this.tokens_to_ids.get(this.eosToken);
    this.unkToken = this.vocab[this.unk_token_id];
    this.minScore = min(this.scores)[0];
    this.unkScore = this.minScore - 10;
    this.scores[this.unk_token_id] = this.unkScore;
    this.trie = new CharTrie();
    this.trie.extend(this.vocab);
    this.fuse_unk = true;
  }
  /**
   * Populates lattice nodes.
   * @param {TokenLattice} lattice The token lattice to populate with nodes.
   */
  populateNodes(lattice) {
    const sentence = lattice.sentence;
    const len = sentence.length;
    let beginPos = 0;
    while (beginPos < len) {
      const mblen = 1;
      let hasSingleNode = false;
      for (let token of this.trie.commonPrefixSearch(sentence.slice(beginPos))) {
        const tokenId = this.tokens_to_ids.get(token);
        const tokenScore = this.scores[tokenId];
        const n = token.length;
        lattice.insert(beginPos, n, tokenScore, tokenId);
        if (!hasSingleNode && n === mblen) {
          hasSingleNode = true;
        }
      }
      if (!hasSingleNode) {
        lattice.insert(beginPos, mblen, this.unkScore, this.unk_token_id);
      }
      beginPos += mblen;
    }
  }
  /**
   * Encodes an array of tokens into an array of subtokens using the unigram model.
   *
   * @param {string} normalized The normalized string.
   * @returns {string[]} An array of subtokens obtained by encoding the input tokens using the unigram model.
   */
  tokenize(normalized) {
    const lattice = new TokenLattice(normalized, this.bosTokenId, this.eosTokenId);
    this.populateNodes(lattice);
    return lattice.tokens();
  }
  /**
   * Encodes an array of tokens using Unigram encoding.
   * @param {string[]} tokens The tokens to encode.
   * @returns {string[]} An array of encoded tokens.
   */
  encode(tokens) {
    const toReturn = [];
    for (const token of tokens) {
      const tokenized = this.tokenize(token);
      toReturn.push(...tokenized);
    }
    return toReturn;
  }
}
const BYTES_TO_UNICODE = (() => {
  const bs = [
    ...Array.from({ length: "~".charCodeAt(0) - "!".charCodeAt(0) + 1 }, (_, i2) => i2 + "!".charCodeAt(0)),
    ...Array.from({ length: "".charCodeAt(0) - "".charCodeAt(0) + 1 }, (_, i2) => i2 + "".charCodeAt(0)),
    ...Array.from({ length: "".charCodeAt(0) - "".charCodeAt(0) + 1 }, (_, i2) => i2 + "".charCodeAt(0))
  ];
  const cs2 = bs.slice();
  let n = 0;
  for (let b = 0; b < 256; ++b) {
    if (!bs.includes(b)) {
      bs.push(b);
      cs2.push(256 + n);
      n += 1;
    }
  }
  const ccs = cs2.map((n2) => String.fromCharCode(n2));
  return Object.fromEntries(bs.map((b, i2) => [b, ccs[i2]]));
})();
const UNICODE_TO_BYTES = reverseDictionary(BYTES_TO_UNICODE);
class BPE extends TokenizerModel {
  /**
   * Create a BPE instance.
   * @param {Object} config The configuration object for BPE.
   * @param {Object} config.vocab A mapping of tokens to ids.
   * @param {string[]} config.merges An array of BPE merges as strings.
   * @param {string} config.unk_token The unknown token used for out of vocabulary words.
   * @param {string} config.end_of_word_suffix The suffix to place at the end of each word.
   * @param {string} [config.continuing_subword_suffix] The suffix to insert between words.
   * @param {boolean} [config.byte_fallback=false] Whether to use spm byte-fallback trick (defaults to False)
   * @param {boolean} [config.ignore_merges=false] Whether or not to match tokens with the vocab before using merges.
   */
  constructor(config2) {
    super(config2);
    this.BPE_SPLIT_TOKEN = " ";
    this.tokens_to_ids = objectToMap(config2.vocab);
    this.unk_token_id = this.tokens_to_ids.get(config2.unk_token);
    this.unk_token = config2.unk_token;
    this.vocab = new Array(this.tokens_to_ids.size);
    for (const [key, value] of this.tokens_to_ids) {
      this.vocab[value] = key;
    }
    this.bpe_ranks = new Map(config2.merges.map((x, i2) => [x, i2]));
    this.merges = config2.merges.map((x) => x.split(this.BPE_SPLIT_TOKEN));
    this.end_of_word_suffix = config2.end_of_word_suffix;
    this.continuing_subword_suffix = config2.continuing_subword_suffix ?? null;
    this.byte_fallback = this.config.byte_fallback ?? false;
    if (this.byte_fallback) {
      this.text_encoder = new TextEncoder();
    }
    this.ignore_merges = this.config.ignore_merges ?? false;
    this.cache = /* @__PURE__ */ new Map();
  }
  /**
   * Apply Byte-Pair-Encoding (BPE) to a given token. Efficient heap-based priority
   * queue implementation adapted from https://github.com/belladoreai/llama-tokenizer-js.
   * @param {string} token The token to encode.
   * @returns {string[]} The BPE encoded tokens.
   */
  bpe(token) {
    if (token.length === 0) {
      return [];
    }
    const cached = this.cache.get(token);
    if (cached !== void 0) {
      return cached;
    }
    const word = Array.from(token);
    if (this.end_of_word_suffix) {
      word[word.length - 1] += this.end_of_word_suffix;
    }
    let result = [];
    if (word.length > 1) {
      const queue2 = new PriorityQueue((a, b) => a.score < b.score);
      let startingNode = {
        token: word[0],
        bias: 0,
        prev: null,
        next: null
      };
      let previousNode = startingNode;
      for (let i2 = 1; i2 < word.length; ++i2) {
        const currentNode = {
          bias: i2 / word.length,
          // Add fractional component to break ties
          token: word[i2],
          prev: previousNode,
          next: null
        };
        previousNode.next = currentNode;
        this._add_node(queue2, previousNode);
        previousNode = currentNode;
      }
      while (!queue2.isEmpty()) {
        const node = queue2.pop();
        if (node.deleted || !node.next || node.next.deleted) continue;
        node.deleted = true;
        node.next.deleted = true;
        if (node.prev) {
          const newPreviousNode = { ...node.prev };
          node.prev.deleted = true;
          node.prev = newPreviousNode;
          if (newPreviousNode.prev) {
            newPreviousNode.prev.next = newPreviousNode;
          } else {
            startingNode = newPreviousNode;
          }
        }
        const merged = {
          token: node.token + node.next.token,
          bias: node.bias,
          prev: node.prev,
          next: node.next.next
        };
        if (merged.prev) {
          merged.prev.next = merged;
          this._add_node(queue2, merged.prev);
        } else {
          startingNode = merged;
        }
        if (merged.next) {
          merged.next.prev = merged;
          this._add_node(queue2, merged);
        }
      }
      for (let currentNode = startingNode; currentNode !== null; currentNode = currentNode.next) {
        result.push(currentNode.token);
      }
    } else {
      result = word;
    }
    if (this.continuing_subword_suffix) {
      for (let i2 = 0; i2 < result.length - 1; ++i2) {
        result[i2] += this.continuing_subword_suffix;
      }
    }
    this.cache.set(token, result);
    return result;
  }
  /**
   * Helper function to add a node to the priority queue.
   * @param {PriorityQueue} queue 
   * @param {BPENode} node
   * @private
   */
  _add_node(queue2, node) {
    const rank = this.bpe_ranks.get(node.token + this.BPE_SPLIT_TOKEN + node.next.token);
    if (rank !== void 0) {
      node.score = rank + node.bias;
      queue2.push(node);
    }
  }
  /**
   * Encodes the input sequence of tokens using the BPE algorithm and returns the resulting subword tokens.
   * @param {string[]} tokens The input sequence of tokens to encode.
   * @returns {string[]} The resulting subword tokens after applying the BPE algorithm to the input sequence of tokens.
   */
  encode(tokens) {
    const outputTokens = [];
    for (const token of tokens) {
      if (this.ignore_merges && this.tokens_to_ids.has(token)) {
        outputTokens.push(token);
        continue;
      }
      const bpe_token_list = this.bpe(token);
      for (const t2 of bpe_token_list) {
        if (this.tokens_to_ids.has(t2)) {
          outputTokens.push(t2);
        } else {
          if (this.byte_fallback) {
            outputTokens.push(
              ...Array.from(this.text_encoder.encode(t2)).map((x) => `<0x${x.toString(16).toUpperCase().padStart(2, "0")}>`)
            );
          } else {
            outputTokens.push(this.unk_token);
          }
        }
      }
    }
    return outputTokens;
  }
}
class LegacyTokenizerModel extends TokenizerModel {
  /**
   * Create a LegacyTokenizerModel instance.
   * @param {Object} config The configuration object for LegacyTokenizerModel.
   * @param {Object} config.vocab A (possibly nested) mapping of tokens to ids.
   * @param {Object} moreConfig Additional configuration object for the LegacyTokenizerModel model.
   */
  constructor(config2, moreConfig) {
    super(config2);
    this.tokens_to_ids = objectToMap(
      moreConfig.target_lang ? config2.vocab[moreConfig.target_lang] : config2.vocab
    );
    this.bos_token = moreConfig.bos_token;
    this.bos_token_id = this.tokens_to_ids.get(this.bos_token);
    this.eos_token = moreConfig.eos_token;
    this.eos_token_id = this.tokens_to_ids.get(this.eos_token);
    this.pad_token = moreConfig.pad_token;
    this.pad_token_id = this.tokens_to_ids.get(this.pad_token);
    this.unk_token = moreConfig.unk_token;
    this.unk_token_id = this.tokens_to_ids.get(this.unk_token);
    this.vocab = new Array(this.tokens_to_ids.size);
    for (const [key, value] of this.tokens_to_ids) {
      this.vocab[value] = key;
    }
  }
  encode(tokens) {
    return tokens;
  }
}
class Normalizer extends Callable {
  /**
   * @param {Object} config The configuration object for the normalizer.
   */
  constructor(config2) {
    super();
    this.config = config2;
  }
  /**
   * Factory method for creating normalizers from config objects.
   * @static
   * @param {Object} config The configuration object for the normalizer.
   * @returns {Normalizer} A Normalizer object.
   * @throws {Error} If an unknown Normalizer type is specified in the config.
   */
  static fromConfig(config2) {
    if (config2 === null) return null;
    switch (config2.type) {
      case "BertNormalizer":
        return new BertNormalizer(config2);
      case "Precompiled":
        return new Precompiled(config2);
      case "Sequence":
        return new NormalizerSequence(config2);
      case "Replace":
        return new Replace(config2);
      case "NFC":
        return new NFC(config2);
      case "NFKC":
        return new NFKC(config2);
      case "NFKD":
        return new NFKD(config2);
      case "Strip":
        return new StripNormalizer(config2);
      case "StripAccents":
        return new StripAccents(config2);
      case "Lowercase":
        return new Lowercase(config2);
      case "Prepend":
        return new Prepend(config2);
      default:
        throw new Error(`Unknown Normalizer type: ${config2.type}`);
    }
  }
  /**
   * Normalize the input text.
   * @abstract
   * @param {string} text The text to normalize.
   * @returns {string} The normalized text.
   * @throws {Error} If this method is not implemented in a subclass.
   */
  normalize(text) {
    throw Error("normalize should be implemented in subclass.");
  }
  /**
   * Alias for {@link Normalizer#normalize}.
   * @param {string} text The text to normalize.
   * @returns {string} The normalized text.
   */
  _call(text) {
    return this.normalize(text);
  }
}
class Replace extends Normalizer {
  /**
   * Normalize the input text by replacing the pattern with the content.
   * @param {string} text The input text to be normalized.
   * @returns {string} The normalized text after replacing the pattern with the content.
   */
  normalize(text) {
    const pattern2 = createPattern(this.config.pattern);
    return pattern2 === null ? text : text.replaceAll(pattern2, this.config.content);
  }
}
class NFC extends Normalizer {
  /**
   * Normalize the input text by applying Unicode normalization form C (NFC).
   * @param {string} text The input text to be normalized.
   * @returns {string} The normalized text.
   */
  normalize(text) {
    text = text.normalize("NFC");
    return text;
  }
}
class NFKC extends Normalizer {
  /**
   * Normalize text using NFKC normalization.
   * @param {string} text The text to be normalized.
   * @returns {string} The normalized text.
   */
  normalize(text) {
    text = text.normalize("NFKC");
    return text;
  }
}
class NFKD extends Normalizer {
  /**
   * Normalize text using NFKD normalization.
   * @param {string} text The text to be normalized.
   * @returns {string} The normalized text.
   */
  normalize(text) {
    text = text.normalize("NFKD");
    return text;
  }
}
class StripNormalizer extends Normalizer {
  /**
   * Strip leading and/or trailing whitespace from the input text.
   * @param {string} text The input text.
   * @returns {string} The normalized text.
   */
  normalize(text) {
    if (this.config.strip_left && this.config.strip_right) {
      text = text.trim();
    } else {
      if (this.config.strip_left) {
        text = text.trimStart();
      }
      if (this.config.strip_right) {
        text = text.trimEnd();
      }
    }
    return text;
  }
}
class StripAccents extends Normalizer {
  /**
   * Remove all accents from the text.
   * @param {string} text The input text.
   * @returns {string} The normalized text without accents.
   */
  normalize(text) {
    text = remove_accents(text);
    return text;
  }
}
class Lowercase extends Normalizer {
  /**
   * Lowercases the input string.
   * @param {string} text The text to normalize.
   * @returns {string} The normalized text.
   */
  normalize(text) {
    text = text.toLowerCase();
    return text;
  }
}
class Prepend extends Normalizer {
  /**
   * Prepends the input string.
   * @param {string} text The text to normalize.
   * @returns {string} The normalized text.
   */
  normalize(text) {
    text = this.config.prepend + text;
    return text;
  }
}
class NormalizerSequence extends Normalizer {
  /**
  * Create a new instance of NormalizerSequence.
  * @param {Object} config The configuration object.
  * @param {Object[]} config.normalizers An array of Normalizer configuration objects.
  */
  constructor(config2) {
    super(config2);
    this.normalizers = config2.normalizers.map((x) => Normalizer.fromConfig(x));
  }
  /**
  * Apply a sequence of Normalizers to the input text.
  * @param {string} text The text to normalize.
  * @returns {string} The normalized text.
  */
  normalize(text) {
    return this.normalizers.reduce((t2, normalizer) => {
      return normalizer.normalize(t2);
    }, text);
  }
}
class BertNormalizer extends Normalizer {
  /**
   * Adds whitespace around any CJK (Chinese, Japanese, or Korean) character in the input text.
   *
   * @param {string} text The input text to tokenize.
   * @returns {string} The tokenized text with whitespace added around CJK characters.
   */
  _tokenize_chinese_chars(text) {
    const output2 = [];
    for (let i2 = 0; i2 < text.length; ++i2) {
      const char = text[i2];
      const cp = char.charCodeAt(0);
      if (this._is_chinese_char(cp)) {
        output2.push(" ");
        output2.push(char);
        output2.push(" ");
      } else {
        output2.push(char);
      }
    }
    return output2.join("");
  }
  /**
   * Checks whether the given Unicode codepoint represents a CJK (Chinese, Japanese, or Korean) character.
   *
   * A "chinese character" is defined as anything in the CJK Unicode block:
   * https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)
   *
   * Note that the CJK Unicode block is NOT all Japanese and Korean characters, despite its name.
   * The modern Korean Hangul alphabet is a different block, as is Japanese Hiragana and Katakana.
   * Those alphabets are used to write space-separated words, so they are not treated specially
   * and are handled like all other languages.
   *
   * @param {number} cp The Unicode codepoint to check.
   * @returns {boolean} True if the codepoint represents a CJK character, false otherwise.
   */
  _is_chinese_char(cp) {
    return cp >= 19968 && cp <= 40959 || cp >= 13312 && cp <= 19903 || cp >= 131072 && cp <= 173791 || cp >= 173824 && cp <= 177983 || cp >= 177984 && cp <= 178207 || cp >= 178208 && cp <= 183983 || cp >= 63744 && cp <= 64255 || cp >= 194560 && cp <= 195103;
  }
  /**
   * Strips accents from the given text.
   * @param {string} text The text to strip accents from.
   * @returns {string} The text with accents removed.
   */
  stripAccents(text) {
    return text.normalize("NFD").replace(/[\u0300-\u036f]/g, "");
  }
  /**
   * Checks whether `char` is a control character.
   * @param {string} char The character to check.
   * @returns {boolean} Whether `char` is a control character.
   * @private
   */
  _is_control(char) {
    switch (char) {
      case "	":
      case "\n":
      case "\r":
        return false;
      default:
        return new RegExp("^\\p{Cc}|\\p{Cf}|\\p{Co}|\\p{Cs}$", "u").test(char);
    }
  }
  /**
   * Performs invalid character removal and whitespace cleanup on text.
   * @param {string} text The text to clean.
   * @returns {string} The cleaned text.
   * @private
   */
  _clean_text(text) {
    const output2 = [];
    for (const char of text) {
      const cp = char.charCodeAt(0);
      if (cp === 0 || cp === 65533 || this._is_control(char)) {
        continue;
      }
      if (/^\s$/.test(char)) {
        output2.push(" ");
      } else {
        output2.push(char);
      }
    }
    return output2.join("");
  }
  /**
   * Normalizes the given text based on the configuration.
   * @param {string} text The text to normalize.
   * @returns {string} The normalized text.
   */
  normalize(text) {
    if (this.config.clean_text) {
      text = this._clean_text(text);
    }
    if (this.config.handle_chinese_chars) {
      text = this._tokenize_chinese_chars(text);
    }
    if (this.config.lowercase) {
      text = text.toLowerCase();
      if (this.config.strip_accents !== false) {
        text = this.stripAccents(text);
      }
    } else if (this.config.strip_accents) {
      text = this.stripAccents(text);
    }
    return text;
  }
}
class PreTokenizer extends Callable {
  /**
  * Factory method that returns an instance of a subclass of `PreTokenizer` based on the provided configuration.
  *
  * @static
  * @param {Object} config A configuration object for the pre-tokenizer.
  * @returns {PreTokenizer} An instance of a subclass of `PreTokenizer`.
  * @throws {Error} If the provided configuration object does not correspond to any known pre-tokenizer.
  */
  static fromConfig(config2) {
    if (config2 === null) return null;
    switch (config2.type) {
      case "BertPreTokenizer":
        return new BertPreTokenizer(config2);
      case "Sequence":
        return new PreTokenizerSequence(config2);
      case "Whitespace":
        return new WhitespacePreTokenizer(config2);
      case "WhitespaceSplit":
        return new WhitespaceSplit(config2);
      case "Metaspace":
        return new MetaspacePreTokenizer(config2);
      case "ByteLevel":
        return new ByteLevelPreTokenizer(config2);
      case "Split":
        return new SplitPreTokenizer(config2);
      case "Punctuation":
        return new PunctuationPreTokenizer(config2);
      case "Digits":
        return new DigitsPreTokenizer(config2);
      case "Replace":
        return new ReplacePreTokenizer(config2);
      default:
        throw new Error(`Unknown PreTokenizer type: ${config2.type}`);
    }
  }
  /**
   * Method that should be implemented by subclasses to define the specific pre-tokenization logic.
   *
   * @abstract
   * @param {string} text The text to pre-tokenize.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} The pre-tokenized text.
   * @throws {Error} If the method is not implemented in the subclass.
   */
  pre_tokenize_text(text, options) {
    throw Error("pre_tokenize_text should be implemented in subclass.");
  }
  /**
   * Tokenizes the given text into pre-tokens.
   * @param {string|string[]} text The text or array of texts to pre-tokenize.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of pre-tokens.
   */
  pre_tokenize(text, options) {
    return (Array.isArray(text) ? text.map((x) => this.pre_tokenize_text(x, options)) : this.pre_tokenize_text(text, options)).flat();
  }
  /**
   * Alias for {@link PreTokenizer#pre_tokenize}.
   * @param {string|string[]} text The text or array of texts to pre-tokenize.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of pre-tokens.
   */
  _call(text, options) {
    return this.pre_tokenize(text, options);
  }
}
class BertPreTokenizer extends PreTokenizer {
  /**
   * A PreTokenizer that splits text into wordpieces using a basic tokenization scheme
   * similar to that used in the original implementation of BERT.
   * 
   * @param {Object} config The configuration object.
   */
  constructor(config2) {
    super();
    this.pattern = new RegExp(`[^\\s${PUNCTUATION_REGEX}]+|[${PUNCTUATION_REGEX}]`, "gu");
  }
  /**
   * Tokenizes a single text using the BERT pre-tokenization scheme.
   * 
   * @param {string} text The text to tokenize.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of tokens.
   */
  pre_tokenize_text(text, options) {
    return text.trim().match(this.pattern) || [];
  }
}
class ByteLevelPreTokenizer extends PreTokenizer {
  /**
   * Creates a new instance of the `ByteLevelPreTokenizer` class.
   * @param {Object} config The configuration object.
   */
  constructor(config2) {
    super();
    this.config = config2;
    this.add_prefix_space = this.config.add_prefix_space;
    this.trim_offsets = this.config.trim_offsets;
    this.use_regex = this.config.use_regex ?? true;
    this.pattern = new RegExp("'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+", "gu");
    this.byte_encoder = BYTES_TO_UNICODE;
    this.text_encoder = new TextEncoder();
  }
  /**
   * Tokenizes a single piece of text using byte-level tokenization.
   * @param {string} text The text to tokenize.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of tokens.
   */
  pre_tokenize_text(text, options) {
    if (this.add_prefix_space && !text.startsWith(" ")) {
      text = " " + text;
    }
    const tokens = this.use_regex ? text.match(this.pattern) || [] : [text];
    return tokens.map(
      (token) => Array.from(this.text_encoder.encode(token), (byte) => this.byte_encoder[byte]).join("")
    );
  }
}
class SplitPreTokenizer extends PreTokenizer {
  /**
   * @param {Object} config The configuration options for the pre-tokenizer.
   * @param {Object} config.pattern The pattern used to split the text. Can be a string or a regex object.
   * @param {string|undefined} config.pattern.String The string to use for splitting. Only defined if the pattern is a string.
   * @param {string|undefined} config.pattern.Regex The regex to use for splitting. Only defined if the pattern is a regex.
   * @param {SplitDelimiterBehavior} config.behavior The behavior to use when splitting.
   * @param {boolean} config.invert Whether to split (invert=false) or match (invert=true) the pattern.
   */
  constructor(config2) {
    super();
    this.config = config2;
    this.pattern = createPattern(this.config.pattern, this.config.invert);
  }
  /**
   * Tokenizes text by splitting it using the given pattern.
   * @param {string} text The text to tokenize.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of tokens.
   */
  pre_tokenize_text(text, options) {
    if (this.pattern === null) {
      return [];
    }
    if (this.config.invert) {
      return text.match(this.pattern) || [];
    } else {
      return regexSplit(text, this.pattern);
    }
  }
}
class PunctuationPreTokenizer extends PreTokenizer {
  /**
   * @param {Object} config The configuration options for the pre-tokenizer.
   * @param {SplitDelimiterBehavior} config.behavior The behavior to use when splitting.
   */
  constructor(config2) {
    super();
    this.config = config2;
    this.pattern = new RegExp(`[^${PUNCTUATION_REGEX}]+|[${PUNCTUATION_REGEX}]+`, "gu");
  }
  /**
   * Tokenizes text by splitting it using the given pattern.
   * @param {string} text The text to tokenize.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of tokens.
   */
  pre_tokenize_text(text, options) {
    return text.match(this.pattern) || [];
  }
}
class DigitsPreTokenizer extends PreTokenizer {
  /**
   * @param {Object} config The configuration options for the pre-tokenizer.
   * @param {boolean} config.individual_digits Whether to split on individual digits.
   */
  constructor(config2) {
    super();
    this.config = config2;
    const digit_pattern = `[^\\d]+|\\d${this.config.individual_digits ? "" : "+"}`;
    this.pattern = new RegExp(digit_pattern, "gu");
  }
  /**
   * Tokenizes text by splitting it using the given pattern.
   * @param {string} text The text to tokenize.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of tokens.
   */
  pre_tokenize_text(text, options) {
    return text.match(this.pattern) || [];
  }
}
class PostProcessor extends Callable {
  /**
   * @param {Object} config The configuration for the post-processor.
   */
  constructor(config2) {
    super();
    this.config = config2;
  }
  /**
   * Factory method to create a PostProcessor object from a configuration object.
   *
   * @param {Object} config Configuration object representing a PostProcessor.
   * @returns {PostProcessor} A PostProcessor object created from the given configuration.
   * @throws {Error} If an unknown PostProcessor type is encountered.
   */
  static fromConfig(config2) {
    if (config2 === null) return null;
    switch (config2.type) {
      case "TemplateProcessing":
        return new TemplateProcessing(config2);
      case "ByteLevel":
        return new ByteLevelPostProcessor(config2);
      case "RobertaProcessing":
        return new RobertaProcessing(config2);
      case "BertProcessing":
        return new BertProcessing(config2);
      case "Sequence":
        return new PostProcessorSequence(config2);
      default:
        throw new Error(`Unknown PostProcessor type: ${config2.type}`);
    }
  }
  /**
   * Method to be implemented in subclass to apply post-processing on the given tokens.
   *
   * @param {Array} tokens The input tokens to be post-processed.
   * @param {...*} args Additional arguments required by the post-processing logic.
   * @returns {PostProcessedOutput} The post-processed tokens.
   * @throws {Error} If the method is not implemented in subclass.
   */
  post_process(tokens, ...args) {
    throw Error("post_process should be implemented in subclass.");
  }
  /**
   * Alias for {@link PostProcessor#post_process}.
   * @param {Array} tokens The text or array of texts to post-process.
   * @param {...*} args Additional arguments required by the post-processing logic.
   * @returns {PostProcessedOutput} The post-processed tokens.
   */
  _call(tokens, ...args) {
    return this.post_process(tokens, ...args);
  }
}
class BertProcessing extends PostProcessor {
  /**
   * @param {Object} config The configuration for the post-processor.
   * @param {string[]} config.cls The special tokens to add to the beginning of the input.
   * @param {string[]} config.sep The special tokens to add to the end of the input.
   */
  constructor(config2) {
    super(config2);
    this.cls = config2.cls[0];
    this.sep = config2.sep[0];
  }
  /**
   * Adds the special tokens to the beginning and end of the input.
   * @param {string[]} tokens The input tokens.
   * @param {string[]} [tokens_pair=null] An optional second set of input tokens.
   * @returns {PostProcessedOutput} The post-processed tokens with the special tokens added to the beginning and end.
   */
  post_process(tokens, tokens_pair = null, {
    add_special_tokens = true
  } = {}) {
    if (add_special_tokens) {
      tokens = mergeArrays([this.cls], tokens, [this.sep]);
    }
    let token_type_ids = new Array(tokens.length).fill(0);
    if (tokens_pair !== null) {
      const middle = add_special_tokens && this instanceof RobertaProcessing ? [this.sep] : [];
      const after = add_special_tokens ? [this.sep] : [];
      tokens = mergeArrays(tokens, middle, tokens_pair, after);
      token_type_ids = mergeArrays(token_type_ids, new Array(tokens_pair.length + middle.length + after.length).fill(1));
    }
    return { tokens, token_type_ids };
  }
}
class RobertaProcessing extends BertProcessing {
}
class TemplateProcessing extends PostProcessor {
  /**
   * Creates a new instance of `TemplateProcessing`.
   * @param {Object} config The configuration options for the post processor.
   * @param {Array} config.single The template for a single sequence of tokens.
   * @param {Array} config.pair The template for a pair of sequences of tokens.
   */
  constructor(config2) {
    super(config2);
    this.single = config2.single;
    this.pair = config2.pair;
  }
  /**
   * Replaces special tokens in the template with actual tokens.
   * @param {string[]} tokens The list of tokens for the first sequence.
   * @param {string[]} [tokens_pair=null] The list of tokens for the second sequence (optional).
   * @returns {PostProcessedOutput} An object containing the list of tokens with the special tokens replaced with actual tokens.
   */
  post_process(tokens, tokens_pair = null, {
    add_special_tokens = true
  } = {}) {
    const type2 = tokens_pair === null ? this.single : this.pair;
    let processedTokens = [];
    let types2 = [];
    for (const item of type2) {
      if ("SpecialToken" in item) {
        if (add_special_tokens) {
          processedTokens.push(item.SpecialToken.id);
          types2.push(item.SpecialToken.type_id);
        }
      } else if ("Sequence" in item) {
        if (item.Sequence.id === "A") {
          processedTokens = mergeArrays(processedTokens, tokens);
          types2 = mergeArrays(types2, new Array(tokens.length).fill(item.Sequence.type_id));
        } else if (item.Sequence.id === "B") {
          processedTokens = mergeArrays(processedTokens, tokens_pair);
          types2 = mergeArrays(types2, new Array(tokens_pair.length).fill(item.Sequence.type_id));
        }
      }
    }
    return { tokens: processedTokens, token_type_ids: types2 };
  }
}
class ByteLevelPostProcessor extends PostProcessor {
  /**
   * Post process the given tokens.
   * @param {string[]} tokens The list of tokens for the first sequence.
   * @param {string[]} [tokens_pair=null] The list of tokens for the second sequence (optional).
   * @returns {PostProcessedOutput} An object containing the post-processed tokens.
   */
  post_process(tokens, tokens_pair = null) {
    if (tokens_pair) {
      tokens = mergeArrays(tokens, tokens_pair);
    }
    return { tokens };
  }
}
class PostProcessorSequence extends PostProcessor {
  /**
   * Creates a new instance of PostProcessorSequence.
   * @param {Object} config The configuration object.
   * @param {Object[]} config.processors The list of post-processors to apply.
   */
  constructor(config2) {
    super(config2);
    this.processors = config2.processors.map((x) => PostProcessor.fromConfig(x));
  }
  /**
   * Post process the given tokens.
   * @param {string[]} tokens The list of tokens for the first sequence.
   * @param {string[]} [tokens_pair=null] The list of tokens for the second sequence (optional).
   * @returns {PostProcessedOutput} An object containing the post-processed tokens.
   */
  post_process(tokens, tokens_pair = null, options = {}) {
    let token_type_ids;
    for (const processor of this.processors) {
      if (processor instanceof ByteLevelPostProcessor) {
        const output2 = processor.post_process(tokens);
        tokens = output2.tokens;
        if (tokens_pair) {
          const pair_output = processor.post_process(tokens_pair);
          tokens_pair = pair_output.tokens;
        }
      } else {
        const output2 = processor.post_process(tokens, tokens_pair, options);
        tokens = output2.tokens;
        token_type_ids = output2.token_type_ids;
      }
    }
    return { tokens, token_type_ids };
  }
}
class Decoder extends Callable {
  /**
  * Creates an instance of `Decoder`.
  *
  * @param {Object} config The configuration object.
  */
  constructor(config2) {
    super();
    this.config = config2;
    this.added_tokens = [];
    this.end_of_word_suffix = null;
    this.trim_offsets = config2.trim_offsets;
  }
  /**
  * Creates a decoder instance based on the provided configuration.
  *
  * @param {Object} config The configuration object.
  * @returns {Decoder} A decoder instance.
  * @throws {Error} If an unknown decoder type is provided.
  */
  static fromConfig(config2) {
    if (config2 === null) return null;
    switch (config2.type) {
      case "WordPiece":
        return new WordPieceDecoder(config2);
      case "Metaspace":
        return new MetaspaceDecoder(config2);
      case "ByteLevel":
        return new ByteLevelDecoder(config2);
      case "Replace":
        return new ReplaceDecoder(config2);
      case "ByteFallback":
        return new ByteFallback(config2);
      case "Fuse":
        return new FuseDecoder(config2);
      case "Strip":
        return new StripDecoder(config2);
      case "Sequence":
        return new DecoderSequence(config2);
      case "CTC":
        return new CTCDecoder(config2);
      case "BPEDecoder":
        return new BPEDecoder(config2);
      default:
        throw new Error(`Unknown Decoder type: ${config2.type}`);
    }
  }
  /**
  * Calls the `decode` method.
  *
  * @param {string[]} tokens The list of tokens.
  * @returns {string} The decoded string.
  */
  _call(tokens) {
    return this.decode(tokens);
  }
  /**
  * Decodes a list of tokens.
  * @param {string[]} tokens The list of tokens.
  * @returns {string} The decoded string.
  */
  decode(tokens) {
    return this.decode_chain(tokens).join("");
  }
  /**
   * Apply the decoder to a list of tokens.
   * 
   * @param {string[]} tokens The list of tokens.
   * @returns {string[]} The decoded list of tokens.
   * @throws {Error} If the `decode_chain` method is not implemented in the subclass.
   */
  decode_chain(tokens) {
    throw Error("`decode_chain` should be implemented in subclass.");
  }
}
class ReplaceDecoder extends Decoder {
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    const pattern2 = createPattern(this.config.pattern);
    return pattern2 === null ? tokens : tokens.map((token) => token.replaceAll(pattern2, this.config.content));
  }
}
class ByteFallback extends Decoder {
  constructor(config2) {
    super(config2);
    this.text_decoder = new TextDecoder();
  }
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    const new_tokens = [];
    let previous_byte_tokens = [];
    for (const token of tokens) {
      let bytes = null;
      if (token.length === 6 && token.startsWith("<0x") && token.endsWith(">")) {
        const byte = parseInt(token.slice(3, 5), 16);
        if (!isNaN(byte)) {
          bytes = byte;
        }
      }
      if (bytes !== null) {
        previous_byte_tokens.push(bytes);
      } else {
        if (previous_byte_tokens.length > 0) {
          const string2 = this.text_decoder.decode(Uint8Array.from(previous_byte_tokens));
          new_tokens.push(string2);
          previous_byte_tokens = [];
        }
        new_tokens.push(token);
      }
    }
    if (previous_byte_tokens.length > 0) {
      const string2 = this.text_decoder.decode(Uint8Array.from(previous_byte_tokens));
      new_tokens.push(string2);
      previous_byte_tokens = [];
    }
    return new_tokens;
  }
}
class FuseDecoder extends Decoder {
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    return [tokens.join("")];
  }
}
class StripDecoder extends Decoder {
  constructor(config2) {
    super(config2);
    this.content = this.config.content;
    this.start = this.config.start;
    this.stop = this.config.stop;
  }
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    return tokens.map((token) => {
      let start_cut = 0;
      for (let i2 = 0; i2 < this.start; ++i2) {
        if (token[i2] === this.content) {
          start_cut = i2 + 1;
          continue;
        } else {
          break;
        }
      }
      let stop_cut = token.length;
      for (let i2 = 0; i2 < this.stop; ++i2) {
        const index2 = token.length - i2 - 1;
        if (token[index2] === this.content) {
          stop_cut = index2;
          continue;
        } else {
          break;
        }
      }
      return token.slice(start_cut, stop_cut);
    });
  }
}
class WordPieceDecoder extends Decoder {
  /**
   * Creates a new instance of WordPieceDecoder.
   * @param {Object} config The configuration object.
   * @param {string} config.prefix The prefix used for WordPiece encoding.
   * @param {boolean} config.cleanup Whether to cleanup the decoded string.
   */
  constructor(config2) {
    super(config2);
    this.cleanup = config2.cleanup;
  }
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    return tokens.map((token, i2) => {
      if (i2 !== 0) {
        if (token.startsWith(this.config.prefix)) {
          token = token.replace(this.config.prefix, "");
        } else {
          token = " " + token;
        }
      }
      if (this.cleanup) {
        token = clean_up_tokenization(token);
      }
      return token;
    });
  }
}
class ByteLevelDecoder extends Decoder {
  /**
   * Create a `ByteLevelDecoder` object.
   * @param {Object} config Configuration object.
   */
  constructor(config2) {
    super(config2);
    this.byte_decoder = UNICODE_TO_BYTES;
    this.text_decoder = new TextDecoder("utf-8", {
      fatal: false,
      ignoreBOM: true
    });
    this.end_of_word_suffix = null;
  }
  /**
   * Convert an array of tokens to string by decoding each byte.
   * @param {string[]} tokens Array of tokens to be decoded.
   * @returns {string} The decoded string.
   */
  convert_tokens_to_string(tokens) {
    const text = tokens.join("");
    const byteArray = new Uint8Array([...text].map((c) => this.byte_decoder[c]));
    const decoded_text = this.text_decoder.decode(byteArray);
    return decoded_text;
  }
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    const sub_texts = [];
    let current_sub_text = [];
    for (const token of tokens) {
      if (this.added_tokens.find((x) => x.content === token) !== void 0) {
        if (current_sub_text.length > 0) {
          sub_texts.push(this.convert_tokens_to_string(current_sub_text));
          current_sub_text = [];
        }
        sub_texts.push(token);
      } else {
        current_sub_text.push(token);
      }
    }
    if (current_sub_text.length > 0) {
      sub_texts.push(this.convert_tokens_to_string(current_sub_text));
    }
    return sub_texts;
  }
}
class CTCDecoder extends Decoder {
  constructor(config2) {
    super(config2);
    this.pad_token = this.config.pad_token;
    this.word_delimiter_token = this.config.word_delimiter_token;
    this.cleanup = this.config.cleanup;
  }
  /**
   * Converts a connectionist-temporal-classification (CTC) output tokens into a single string.
   * @param {string[]} tokens Array of tokens to be decoded.
   * @returns {string} The decoded string.
   */
  convert_tokens_to_string(tokens) {
    if (tokens.length === 0) return "";
    const grouped_tokens = [tokens[0]];
    for (let i2 = 1; i2 < tokens.length; ++i2) {
      if (tokens[i2] !== grouped_tokens.at(-1)) {
        grouped_tokens.push(tokens[i2]);
      }
    }
    const filtered_tokens = grouped_tokens.filter((token) => token !== this.pad_token);
    let text = filtered_tokens.join("");
    if (this.cleanup) {
      text = clean_up_tokenization(text).replaceAll(this.word_delimiter_token, " ").trim();
    }
    return text;
  }
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    return [this.convert_tokens_to_string(tokens)];
  }
}
class DecoderSequence extends Decoder {
  /**
   * Creates a new instance of DecoderSequence.
   * @param {Object} config The configuration object.
   * @param {Object[]} config.decoders The list of decoders to apply.
   */
  constructor(config2) {
    super(config2);
    this.decoders = config2.decoders.map((x) => Decoder.fromConfig(x));
  }
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    return this.decoders.reduce((toks, decoder) => {
      return decoder.decode_chain(toks);
    }, tokens);
  }
}
class BPEDecoder extends Decoder {
  constructor(config2) {
    super(config2);
    this.suffix = this.config.suffix;
  }
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    return tokens.map((token, i2) => {
      return token.replaceAll(this.suffix, i2 === tokens.length - 1 ? "" : " ");
    });
  }
}
class VitsDecoder extends Decoder {
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    let decoded = "";
    for (let i2 = 1; i2 < tokens.length; i2 += 2) {
      decoded += tokens[i2];
    }
    return [decoded];
  }
}
class MetaspacePreTokenizer extends PreTokenizer {
  /**
   * @param {Object} config The configuration object for the MetaspacePreTokenizer.
   * @param {boolean} config.add_prefix_space Whether to add a prefix space to the first token.
   * @param {string} config.replacement The character to replace spaces with.
   * @param {string} [config.str_rep=config.replacement] An optional string representation of the replacement character.
   * @param {'first'|'never'|'always'} [config.prepend_scheme='always'] The metaspace prepending scheme.
   */
  constructor(config2) {
    super();
    this.addPrefixSpace = config2.add_prefix_space;
    this.replacement = config2.replacement;
    this.strRep = config2.str_rep || this.replacement;
    this.prepend_scheme = config2.prepend_scheme ?? "always";
  }
  /**
   * This method takes a string, replaces spaces with the replacement character,
   * adds a prefix space if requested, and returns a new list of tokens.
   * @param {string} text The text to pre-tokenize.
   * @param {Object} [options] The options for the pre-tokenization.
   * @param {number} [options.section_index] The index of the section to pre-tokenize.
   * @returns {string[]} A new list of pre-tokenized tokens.
   */
  pre_tokenize_text(text, {
    section_index = void 0
  } = {}) {
    let normalized = text.replaceAll(" ", this.strRep);
    if (
      // We add a prefix space if:
      //  (1) The addPrefixSpace option is enabled and the normalized
      //      token does not already start with the replacement character.
      this.addPrefixSpace && !normalized.startsWith(this.replacement) && (this.prepend_scheme === "always" || this.prepend_scheme === "first" && section_index === 0)
    ) {
      normalized = this.strRep + normalized;
    }
    return [normalized];
  }
}
class MetaspaceDecoder extends Decoder {
  /**
   * Constructs a new MetaspaceDecoder object.
   * @param {Object} config The configuration object for the MetaspaceDecoder.
   * @param {boolean} config.add_prefix_space Whether to add a prefix space to the decoded string.
   * @param {string} config.replacement The string to replace spaces with.
   */
  constructor(config2) {
    super(config2);
    this.addPrefixSpace = config2.add_prefix_space;
    this.replacement = config2.replacement;
  }
  /** @type {Decoder['decode_chain']} */
  decode_chain(tokens) {
    const result = [];
    for (let i2 = 0; i2 < tokens.length; ++i2) {
      let normalized = tokens[i2].replaceAll(this.replacement, " ");
      if (this.addPrefixSpace && i2 == 0 && normalized.startsWith(" ")) {
        normalized = normalized.substring(1);
      }
      result.push(normalized);
    }
    return result;
  }
}
class Precompiled extends Normalizer {
  /**
   * Create a new instance of Precompiled normalizer.
   * @param {Object} config The configuration object.
   * @param {any} config.precompiled_charsmap Precompiled chars mapping.
   */
  constructor(config2) {
    super(config2);
    this.charsmap = config2.precompiled_charsmap;
  }
  /**
   * Normalizes the given text by applying the precompiled charsmap.
   * @param {string} text The text to normalize.
   * @returns {string} The normalized text.
   */
  normalize(text) {
    text = text.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm, "");
    text = text.replace(/[\u0009\u000A\u000C\u000D\u1680\u200B\u200C\u200E\u200F\u2028\u2029\u2581\uFEFF\uFFFD]/gm, " ");
    if (text.includes("")) {
      const parts = text.split("");
      text = parts.map((part) => part.normalize("NFKC")).join("");
    } else {
      text = text.normalize("NFKC");
    }
    return text;
  }
}
class PreTokenizerSequence extends PreTokenizer {
  /**
   * Creates an instance of PreTokenizerSequence.
   * @param {Object} config The configuration object for the pre-tokenizer sequence.
   * @param {Object[]} config.pretokenizers An array of pre-tokenizer configurations.
   */
  constructor(config2) {
    super();
    this.tokenizers = config2.pretokenizers.map((x) => PreTokenizer.fromConfig(x));
  }
  /**
   * Applies each pre-tokenizer in the sequence to the input text in turn.
   * @param {string} text The text to pre-tokenize.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} The pre-tokenized text.
   */
  pre_tokenize_text(text, options) {
    return this.tokenizers.reduce((preTokenizedText, tokenizer) => {
      return tokenizer.pre_tokenize(preTokenizedText, options);
    }, [text]);
  }
}
class WhitespacePreTokenizer extends PreTokenizer {
  /**
   * Creates an instance of WhitespacePreTokenizer.
   * @param {Object} config The configuration object for the pre-tokenizer.
   */
  constructor(config2) {
    super();
  }
  /**
   * Pre-tokenizes the input text by splitting it on word boundaries.
   * @param {string} text The text to be pre-tokenized.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of tokens produced by splitting the input text on whitespace.
   */
  pre_tokenize_text(text, options) {
    return text.match(/\w+|[^\w\s]+/g) || [];
  }
}
class WhitespaceSplit extends PreTokenizer {
  /**
   * Creates an instance of WhitespaceSplit.
   * @param {Object} config The configuration object for the pre-tokenizer.
   */
  constructor(config2) {
    super();
  }
  /**
   * Pre-tokenizes the input text by splitting it on whitespace characters.
   * @param {string} text The text to be pre-tokenized.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of tokens produced by splitting the input text on whitespace.
   */
  pre_tokenize_text(text, options) {
    return whitespace_split(text);
  }
}
class ReplacePreTokenizer extends PreTokenizer {
  /**
   * @param {Object} config The configuration options for the pre-tokenizer.
   * @param {Object} config.pattern The pattern used to split the text. Can be a string or a regex object.
   * @param {string} config.content What to replace the pattern with.
   */
  constructor(config2) {
    super();
    this.config = config2;
    this.pattern = createPattern(this.config.pattern);
    this.content = this.config.content;
  }
  /**
   * Pre-tokenizes the input text by replacing certain characters.
   * @param {string} text The text to be pre-tokenized.
   * @param {Object} [options] Additional options for the pre-tokenization logic.
   * @returns {string[]} An array of tokens produced by replacing certain characters.
   */
  pre_tokenize_text(text, options) {
    if (this.pattern === null) {
      return [text];
    }
    return [text.replaceAll(this.pattern, this.config.content)];
  }
}
const SPECIAL_TOKEN_ATTRIBUTES = [
  "bos_token",
  "eos_token",
  "unk_token",
  "sep_token",
  "pad_token",
  "cls_token",
  "mask_token"
  // additional_special_tokens (TODO)
];
function padHelper(item, length, value_fn, side) {
  for (const key of Object.keys(item)) {
    const diff2 = length - item[key].length;
    const value = value_fn(key);
    const padData = new Array(diff2).fill(value);
    item[key] = side === "right" ? mergeArrays(item[key], padData) : mergeArrays(padData, item[key]);
  }
}
function truncateHelper(item, length) {
  for (const key of Object.keys(item)) {
    item[key].length = length;
  }
}
class PreTrainedTokenizer extends Callable {
  /**
   * Create a new PreTrainedTokenizer instance.
   * @param {Object} tokenizerJSON The JSON of the tokenizer.
   * @param {Object} tokenizerConfig The config of the tokenizer.
   */
  constructor(tokenizerJSON, tokenizerConfig) {
    super();
    __publicField(this, "return_token_type_ids", false);
    __publicField(this, "_default_chat_template", `{% for message in messages %}{{'<|im_start|>' + message['role'] + '
' + message['content'] + '<|im_end|>' + '
'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant
' }}{% endif %}`);
    this._tokenizer_config = tokenizerConfig;
    this.normalizer = Normalizer.fromConfig(tokenizerJSON.normalizer);
    this.pre_tokenizer = PreTokenizer.fromConfig(tokenizerJSON.pre_tokenizer);
    this.model = TokenizerModel.fromConfig(tokenizerJSON.model, tokenizerConfig);
    this.post_processor = PostProcessor.fromConfig(tokenizerJSON.post_processor);
    this.decoder = Decoder.fromConfig(tokenizerJSON.decoder);
    this.special_tokens = [];
    this.all_special_ids = [];
    this.added_tokens = [];
    for (const addedToken of tokenizerJSON.added_tokens) {
      const token = new AddedToken(addedToken);
      this.added_tokens.push(token);
      this.model.tokens_to_ids.set(token.content, token.id);
      this.model.vocab[token.id] = token.content;
      if (token.special) {
        this.special_tokens.push(token.content);
        this.all_special_ids.push(token.id);
      }
    }
    this.additional_special_tokens = tokenizerConfig.additional_special_tokens ?? [];
    this.special_tokens.push(...this.additional_special_tokens);
    this.special_tokens = [...new Set(this.special_tokens)];
    if (this.decoder) {
      this.decoder.added_tokens = this.added_tokens;
      this.decoder.end_of_word_suffix = this.model.end_of_word_suffix;
    }
    this.added_tokens_regex = this.added_tokens.length > 0 ? new RegExp(
      this.added_tokens.map((x) => `${x.lstrip ? "\\s*" : ""}(${escapeRegExp(x.content)})${x.rstrip ? "\\s*" : ""}`).join("|")
    ) : null;
    this.mask_token = this.getToken("mask_token");
    this.mask_token_id = this.model.tokens_to_ids.get(this.mask_token);
    this.pad_token = this.getToken("pad_token", "eos_token");
    this.pad_token_id = this.model.tokens_to_ids.get(this.pad_token);
    this.sep_token = this.getToken("sep_token");
    this.sep_token_id = this.model.tokens_to_ids.get(this.sep_token);
    this.unk_token = this.getToken("unk_token");
    this.unk_token_id = this.model.tokens_to_ids.get(this.unk_token);
    this.model_max_length = tokenizerConfig.model_max_length;
    this.remove_space = tokenizerConfig.remove_space;
    this.clean_up_tokenization_spaces = tokenizerConfig.clean_up_tokenization_spaces ?? true;
    this.do_lowercase_and_remove_accent = tokenizerConfig.do_lowercase_and_remove_accent ?? false;
    this.padding_side = "right";
    this.legacy = false;
    this.chat_template = tokenizerConfig.chat_template ?? null;
    if (Array.isArray(this.chat_template)) {
      const chat_template = /* @__PURE__ */ Object.create(null);
      for (const { name: name2, template } of this.chat_template) {
        if (typeof name2 !== "string" || typeof template !== "string") {
          throw new Error('Chat template must be a list of objects with "name" and "template" properties');
        }
        chat_template[name2] = template;
      }
      this.chat_template = chat_template;
    }
    this._compiled_template_cache = /* @__PURE__ */ new Map();
  }
  /**
   * Returns the value of the first matching key in the tokenizer config object.
   * @param {...string} keys One or more keys to search for in the tokenizer config object.
   * @returns {string|null} The value associated with the first matching key, or null if no match is found.
   * @throws {Error} If an object is found for a matching key and its __type property is not "AddedToken".
   */
  getToken(...keys) {
    for (const key of keys) {
      const item = this._tokenizer_config[key];
      if (!item) continue;
      if (typeof item === "object") {
        if (item.__type === "AddedToken") {
          return item.content;
        } else {
          throw Error(`Unknown token: ${item}`);
        }
      } else {
        return item;
      }
    }
    return null;
  }
  /**
   * Loads a pre-trained tokenizer from the given `pretrained_model_name_or_path`. 
   * 
   * @param {string} pretrained_model_name_or_path The path to the pre-trained tokenizer.
   * @param {PretrainedTokenizerOptions} options Additional options for loading the tokenizer.
   * 
   * @throws {Error} Throws an error if the tokenizer.json or tokenizer_config.json files are not found in the `pretrained_model_name_or_path`.
   * @returns {Promise<PreTrainedTokenizer>} A new instance of the `PreTrainedTokenizer` class.
   */
  static async from_pretrained(pretrained_model_name_or_path, {
    progress_callback = null,
    config: config2 = null,
    cache_dir = null,
    local_files_only = false,
    revision = "main",
    legacy = null
  } = {}) {
    const info = await loadTokenizer(pretrained_model_name_or_path, {
      progress_callback,
      cache_dir,
      local_files_only,
      revision,
      legacy
    });
    return new this(...info);
  }
  /**
   * @typedef {number[]|number[][]|Tensor} BatchEncodingItem
   * 
   * @typedef {Object} BatchEncoding Holds the output of the tokenizer's call function.
   * @property {BatchEncodingItem} input_ids List of token ids to be fed to a model.
   * @property {BatchEncodingItem} attention_mask List of indices specifying which tokens should be attended to by the model.
   * @property {BatchEncodingItem} [token_type_ids] List of token type ids to be fed to a model.
   */
  /**
   * Encode/tokenize the given text(s).
   * @param {string|string[]} text The text to tokenize.
   * @param {Object} options An optional object containing the following properties:
   * @param {string|string[]} [options.text_pair=null] Optional second sequence to be encoded. If set, must be the same type as text.
   * @param {boolean|'max_length'} [options.padding=false] Whether to pad the input sequences.
   * @param {boolean} [options.add_special_tokens=true] Whether or not to add the special tokens associated with the corresponding model.
   * @param {boolean} [options.truncation=null] Whether to truncate the input sequences.
   * @param {number} [options.max_length=null] Maximum length of the returned list and optionally padding length.
   * @param {boolean} [options.return_tensor=true] Whether to return the results as Tensors or arrays.
   * @param {boolean} [options.return_token_type_ids=null] Whether to return the token type ids.
   * @returns {BatchEncoding} Object to be passed to the model.
   */
  _call(text, {
    text_pair = null,
    add_special_tokens = true,
    padding = false,
    truncation = null,
    max_length = null,
    return_tensor = true,
    // Different to HF
    return_token_type_ids = null
  } = {}) {
    const isBatched = Array.isArray(text);
    let encodedTokens;
    if (isBatched) {
      if (text.length === 0) {
        throw Error("text array must be non-empty");
      }
      if (text_pair !== null) {
        if (!Array.isArray(text_pair)) {
          throw Error("text_pair must also be an array");
        } else if (text.length !== text_pair.length) {
          throw Error("text and text_pair must have the same length");
        }
        encodedTokens = text.map(
          (t2, i2) => this._encode_plus(t2, text_pair[i2], { add_special_tokens, return_token_type_ids })
        );
      } else {
        encodedTokens = text.map((x) => this._encode_plus(x, null, { add_special_tokens, return_token_type_ids }));
      }
    } else {
      if (text === null || text === void 0) {
        throw Error("text may not be null or undefined");
      }
      if (Array.isArray(text_pair)) {
        throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).");
      }
      encodedTokens = [this._encode_plus(text, text_pair, { add_special_tokens, return_token_type_ids })];
    }
    if (max_length === null) {
      if (padding === "max_length") {
        max_length = this.model_max_length;
      } else {
        max_length = max(encodedTokens.map((x) => x.input_ids.length))[0];
      }
    } else {
      if (!truncation) {
        console.warn(`Truncation was not explicitly activated but \`max_length\` is provided a specific value, please use \`truncation=true\` to explicitly truncate examples to max length.`);
      }
    }
    max_length = Math.min(max_length, this.model_max_length);
    if (padding || truncation) {
      for (let i2 = 0; i2 < encodedTokens.length; ++i2) {
        if (encodedTokens[i2].input_ids.length === max_length) {
          continue;
        } else if (encodedTokens[i2].input_ids.length > max_length) {
          if (truncation) {
            truncateHelper(encodedTokens[i2], max_length);
          }
        } else {
          if (padding) {
            padHelper(
              encodedTokens[i2],
              max_length,
              (key) => key === "input_ids" ? this.pad_token_id : 0,
              this.padding_side
            );
          }
        }
      }
    }
    const result = {};
    if (return_tensor) {
      if (!(padding && truncation)) {
        if (encodedTokens.some((x) => {
          var _a2;
          for (const key of Object.keys(x)) {
            if (x[key].length !== ((_a2 = encodedTokens[0][key]) == null ? void 0 : _a2.length)) {
              return true;
            }
          }
          return false;
        })) {
          throw Error(
            "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length."
          );
        }
      }
      const dims = [encodedTokens.length, encodedTokens[0].input_ids.length];
      for (const key of Object.keys(encodedTokens[0])) {
        result[key] = new Tensor(
          "int64",
          BigInt64Array.from(encodedTokens.flatMap((x) => x[key]).map(BigInt)),
          dims
        );
      }
    } else {
      for (const key of Object.keys(encodedTokens[0])) {
        result[key] = encodedTokens.map((x) => x[key]);
      }
      if (!isBatched) {
        for (const key of Object.keys(result)) {
          result[key] = result[key][0];
        }
      }
    }
    return (
      /** @type {BatchEncoding} */
      result
    );
  }
  /**
   * Encodes a single text using the preprocessor pipeline of the tokenizer.
   *
   * @param {string|null} text The text to encode.
   * @returns {string[]|null} The encoded tokens.
   */
  _encode_text(text) {
    if (text === null) return null;
    const sections = this.added_tokens_regex ? text.split(this.added_tokens_regex).filter((x) => x) : [text];
    const tokens = sections.map((x, section_index) => {
      const addedToken = this.added_tokens.find((t2) => t2.content === x);
      if (addedToken !== void 0) {
        return x;
      } else {
        if (this.remove_space === true) {
          x = x.trim().split(/\s+/).join(" ");
        }
        if (this.do_lowercase_and_remove_accent) {
          x = lowercase_and_remove_accent(x);
        }
        if (this.normalizer !== null) {
          x = this.normalizer(x);
        }
        if (x.length === 0) {
          return [];
        }
        const sectionTokens = this.pre_tokenizer !== null ? this.pre_tokenizer(x, {
          section_index
        }) : [x];
        const tokens2 = this.model(sectionTokens);
        return tokens2;
      }
    }).flat();
    return tokens;
  }
  /**
   * Encodes a single text or a pair of texts using the model's tokenizer.
   *
   * @param {string} text The text to encode.
   * @param {string|null} text_pair The optional second text to encode.
   * @param {Object} options An optional object containing the following properties:
   * @param {boolean} [options.add_special_tokens=true] Whether or not to add the special tokens associated with the corresponding model.
   * @param {boolean} [options.return_token_type_ids=null] Whether to return token_type_ids.
   * @returns {EncodingSingle} An object containing the encoded text.
   * @private
   */
  _encode_plus(text, text_pair = null, {
    add_special_tokens = true,
    return_token_type_ids = null
  } = {}) {
    const tokens = this._encode_text(text);
    const tokens2 = this._encode_text(text_pair);
    const combinedTokens = this.post_processor ? this.post_processor(tokens, tokens2, { add_special_tokens }) : { tokens: mergeArrays(tokens ?? [], tokens2 ?? []) };
    const input_ids = this.model.convert_tokens_to_ids(combinedTokens.tokens);
    const result = {
      input_ids,
      attention_mask: new Array(input_ids.length).fill(1)
    };
    if ((return_token_type_ids ?? this.return_token_type_ids) && combinedTokens.token_type_ids) {
      result.token_type_ids = combinedTokens.token_type_ids;
    }
    return result;
  }
  /**
   * Encodes a single text or a pair of texts using the model's tokenizer.
   *
   * @param {string} text The text to encode.
   * @param {string|null} text_pair The optional second text to encode.
   * @param {Object} options An optional object containing the following properties:
   * @param {boolean} [options.add_special_tokens=true] Whether or not to add the special tokens associated with the corresponding model.
   * @param {boolean} [options.return_token_type_ids=null] Whether to return token_type_ids.
   * @returns {number[]} An array of token IDs representing the encoded text(s).
   */
  encode(text, text_pair = null, {
    add_special_tokens = true,
    return_token_type_ids = null
  } = {}) {
    const { input_ids } = this._encode_plus(text, text_pair, {
      add_special_tokens,
      return_token_type_ids
    });
    return input_ids;
  }
  /**
   * Decode a batch of tokenized sequences.
   * @param {number[][]|Tensor} batch List/Tensor of tokenized input sequences.
   * @param {Object} decode_args (Optional) Object with decoding arguments.
   * @returns {string[]} List of decoded sequences.
   */
  batch_decode(batch, decode_args = {}) {
    if (batch instanceof Tensor) {
      batch = batch.tolist();
    }
    return batch.map((x) => this.decode(x, decode_args));
  }
  /**
   * Decodes a sequence of token IDs back to a string.
   *
   * @param {number[]|Tensor} token_ids List/Tensor of token IDs to decode.
   * @param {Object} [decode_args={}]
   * @param {boolean} [decode_args.skip_special_tokens=false] If true, special tokens are removed from the output string.
   * @param {boolean} [decode_args.clean_up_tokenization_spaces=true] If true, spaces before punctuations and abbreviated forms are removed.
   *
   * @returns {string} The decoded string.
   * @throws {Error} If `token_ids` is not a non-empty array of integers.
   */
  decode(token_ids, decode_args = {}) {
    if (token_ids instanceof Tensor) {
      token_ids = prepareTensorForDecode(token_ids);
    }
    if (!Array.isArray(token_ids) || token_ids.length === 0 || !isIntegralNumber(token_ids[0])) {
      throw Error("token_ids must be a non-empty array of integers.");
    }
    return this.decode_single(token_ids, decode_args);
  }
  /**
   * Decode a single list of token ids to a string.
   * @param {number[]} token_ids List of token ids to decode
   * @param {Object} decode_args Optional arguments for decoding
   * @param {boolean} [decode_args.skip_special_tokens=false] Whether to skip special tokens during decoding
   * @param {boolean} [decode_args.clean_up_tokenization_spaces=null] Whether to clean up tokenization spaces during decoding.
   * If null, the value is set to `this.decoder.cleanup` if it exists, falling back to `this.clean_up_tokenization_spaces` if it exists, falling back to `true`.
   * @returns {string} The decoded string
   */
  decode_single(token_ids, {
    skip_special_tokens = false,
    clean_up_tokenization_spaces = null
  }) {
    let tokens = this.model.convert_ids_to_tokens(token_ids);
    if (skip_special_tokens) {
      tokens = tokens.filter((x) => !this.special_tokens.includes(x));
    }
    let decoded = this.decoder ? this.decoder(tokens) : tokens.join(" ");
    if (this.decoder && this.decoder.end_of_word_suffix) {
      decoded = decoded.replaceAll(this.decoder.end_of_word_suffix, " ");
      if (skip_special_tokens) {
        decoded = decoded.trim();
      }
    }
    if (clean_up_tokenization_spaces ?? this.clean_up_tokenization_spaces) {
      decoded = clean_up_tokenization(decoded);
    }
    return decoded;
  }
  get default_chat_template() {
    if (!this._warned_about_chat_template) {
      console.warn(
        "No chat template is defined for this tokenizer - using a default chat template that implements the ChatML format. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information."
      );
      this._warned_about_chat_template = true;
    }
    return this._default_chat_template;
  }
  /**
   * Converts a list of message objects with `"role"` and `"content"` keys to a list of token
   * ids. This method is intended for use with chat models, and will read the tokenizer's chat_template attribute to
   * determine the format and control tokens to use when converting. When chat_template is None, it will fall back
   * to the default_chat_template specified at the class level.
   * 
   * See [here](https://huggingface.co/docs/transformers/chat_templating) for more information.
   * 
   * **Example:** Applying a chat template to a conversation.
   * 
   * ```javascript
   * import { AutoTokenizer } from "@xenova/transformers";
   * 
   * const tokenizer = await AutoTokenizer.from_pretrained("Xenova/mistral-tokenizer-v1");
   * 
   * const chat = [
   *   { "role": "user", "content": "Hello, how are you?" },
   *   { "role": "assistant", "content": "I'm doing great. How can I help you today?" },
   *   { "role": "user", "content": "I'd like to show off how chat templating works!" },
   * ]
   * 
   * const text = tokenizer.apply_chat_template(chat, { tokenize: false });
   * // "<s>[INST] Hello, how are you? [/INST]I'm doing great. How can I help you today?</s> [INST] I'd like to show off how chat templating works! [/INST]"
   * 
   * const input_ids = tokenizer.apply_chat_template(chat, { tokenize: true, return_tensor: false });
   * // [1, 733, 16289, 28793, 22557, 28725, 910, 460, 368, 28804, 733, 28748, 16289, 28793, 28737, 28742, 28719, 2548, 1598, 28723, 1602, 541, 315, 1316, 368, 3154, 28804, 2, 28705, 733, 16289, 28793, 315, 28742, 28715, 737, 298, 1347, 805, 910, 10706, 5752, 1077, 3791, 28808, 733, 28748, 16289, 28793]
   * ```
   * 
   * @param {Message[]} conversation A list of message objects with `"role"` and `"content"` keys.
   * @param {Object} options An optional object containing the following properties:
   * @param {string} [options.chat_template=null] A Jinja template to use for this conversion. If
   * this is not passed, the model's default chat template will be used instead.
   * @param {boolean} [options.add_generation_prompt=false] Whether to end the prompt with the token(s) that indicate
   * the start of an assistant message. This is useful when you want to generate a response from the model.
   * Note that this argument will be passed to the chat template, and so it must be supported in the
   * template for this argument to have any effect.
   * @param {boolean} [options.tokenize=true] Whether to tokenize the output. If false, the output will be a string.
   * @param {boolean} [options.padding=false] Whether to pad sequences to the maximum length. Has no effect if tokenize is false.
   * @param {boolean} [options.truncation=false] Whether to truncate sequences to the maximum length. Has no effect if tokenize is false.
   * @param {number} [options.max_length=null] Maximum length (in tokens) to use for padding or truncation. Has no effect if tokenize is false.
   * If not specified, the tokenizer's `max_length` attribute will be used as a default.
   * @param {boolean} [options.return_tensor=true] Whether to return the output as a Tensor or an Array. Has no effect if tokenize is false.
   * @param {Object} [options.tokenizer_kwargs={}] Additional options to pass to the tokenizer.
   * @returns {string | Tensor | number[]| number[][]} The tokenized output.
   */
  apply_chat_template(conversation, {
    chat_template = null,
    add_generation_prompt = false,
    tokenize: tokenize2 = true,
    padding = false,
    truncation = false,
    max_length = null,
    return_tensor = true,
    tokenizer_kwargs = {},
    ...kwargs
  } = {}) {
    if (this.chat_template && typeof this.chat_template === "object" || this.chat_template === null && this.default_chat_template && typeof this.default_chat_template === "object") {
      const template_dict = this.chat_template ?? this.default_chat_template;
      if (chat_template !== null && Object.hasOwn(template_dict, chat_template)) {
        chat_template = template_dict[chat_template];
      } else if (chat_template === null && "default" in template_dict) {
        chat_template = template_dict["default"];
      } else if (chat_template === null) {
        throw Error(
          `This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the 'chat_template' argument. Available template names are ${Object.keys(template_dict).sort()}.`
        );
      }
    } else {
      chat_template ?? (chat_template = this.chat_template ?? this.default_chat_template);
    }
    if (typeof chat_template !== "string") {
      throw Error(`chat_template must be a string, but got ${typeof chat_template}`);
    }
    let compiledTemplate = this._compiled_template_cache.get(chat_template);
    if (compiledTemplate === void 0) {
      compiledTemplate = new Template(chat_template);
      this._compiled_template_cache.set(chat_template, compiledTemplate);
    }
    const special_tokens_map = /* @__PURE__ */ Object.create(null);
    for (const key of SPECIAL_TOKEN_ATTRIBUTES) {
      const value = this.getToken(key);
      if (value) {
        special_tokens_map[key] = value;
      }
    }
    const rendered = compiledTemplate.render({
      messages: conversation,
      add_generation_prompt,
      ...special_tokens_map,
      ...kwargs
    });
    if (tokenize2) {
      return this._call(rendered, {
        add_special_tokens: false,
        padding,
        truncation,
        max_length,
        return_tensor,
        ...tokenizer_kwargs
      }).input_ids;
    }
    return rendered;
  }
}
class BertTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class AlbertTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class MobileBertTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class SqueezeBertTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class DebertaTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class DebertaV2Tokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class HerbertTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class ConvBertTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class RoFormerTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class DistilBertTokenizer extends PreTrainedTokenizer {
}
class CamembertTokenizer extends PreTrainedTokenizer {
}
class XLMTokenizer extends PreTrainedTokenizer {
  constructor(tokenizerJSON, tokenizerConfig) {
    super(tokenizerJSON, tokenizerConfig);
    __publicField(this, "return_token_type_ids", true);
    console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.');
  }
}
class ElectraTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "return_token_type_ids", true);
  }
}
class T5Tokenizer extends PreTrainedTokenizer {
}
class GPT2Tokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "_default_chat_template", `{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}`);
  }
}
class BartTokenizer extends PreTrainedTokenizer {
}
class MBartTokenizer extends PreTrainedTokenizer {
  constructor(tokenizerJSON, tokenizerConfig) {
    super(tokenizerJSON, tokenizerConfig);
    this.languageRegex = /^[a-z]{2}_[A-Z]{2}$/;
    this.language_codes = this.special_tokens.filter((x) => this.languageRegex.test(x));
    this.lang_to_token = (x) => x;
  }
  /**
   * Helper function to build translation inputs for an `MBartTokenizer`.
   * @param {string|string[]} raw_inputs The text to tokenize.
   * @param {Object} tokenizer_options Options to be sent to the tokenizer
   * @param {Object} generate_kwargs Generation options.
   * @returns {Object} Object to be passed to the model.
   */
  _build_translation_inputs(raw_inputs, tokenizer_options, generate_kwargs) {
    return _build_translation_inputs(this, raw_inputs, tokenizer_options, generate_kwargs);
  }
}
class MBart50Tokenizer extends MBartTokenizer {
}
class RobertaTokenizer extends PreTrainedTokenizer {
}
class BloomTokenizer extends GPT2Tokenizer {
  // NOTE: `GPT2Tokenizer` to get the correct chat template
  constructor(tokenizerJSON, tokenizerConfig) {
    var _a2, _b;
    const splitChars = ".,!?";
    const patternObject = (_b = (_a2 = tokenizerJSON.pre_tokenizer) == null ? void 0 : _a2.pretokenizers[0]) == null ? void 0 : _b.pattern;
    if (patternObject && patternObject.Regex === ` ?[^(\\s|[${splitChars}])]+`) {
      patternObject.Regex = ` ?[^\\s${splitChars}]+`;
    }
    super(tokenizerJSON, tokenizerConfig);
  }
}
const SPIECE_UNDERLINE = "";
class LlamaTokenizer extends PreTrainedTokenizer {
  constructor(tokenizerJSON, tokenizerConfig) {
    super(tokenizerJSON, tokenizerConfig);
    __publicField(this, "_default_chat_template", `{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif USE_DEFAULT_PROMPT == true and not '<<SYS>>' in messages[0]['content'] %}{% set loop_messages = messages %}{% set system_message = 'DEFAULT_SYSTEM_MESSAGE' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>
' + system_message + '
<</SYS>>

' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>
' + content.strip() + '
<</SYS>>

' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}`);
    __publicField(this, "DEFAULT_SYSTEM_PROMPT", "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.");
    this.use_default_system_prompt = tokenizerConfig.use_default_system_prompt ?? false;
    this.legacy = tokenizerConfig.legacy ?? true;
    if (!this.legacy) {
      this.normalizer = null;
      this.pre_tokenizer = new MetaspacePreTokenizer({
        replacement: SPIECE_UNDERLINE,
        add_prefix_space: true,
        prepend_scheme: "first"
      });
    }
  }
  /**
   * Helper function to handle legacy encoding of SPM tokenizers.
   * Adapted from https://github.com/huggingface/transformers/blob/e6dcf8abd6f65bb4b6dfc1831b20d9ba49ce00e2/src/transformers/models/t5/tokenization_t5.py#L374-L387
   * @param {string} text The text to encode.
   * @returns {string[]} The encoded tokens.
   */
  _encode_text(text) {
    if (text === null) return null;
    if (this.legacy || text.length === 0) {
      return super._encode_text(text);
    }
    let tokens = super._encode_text(SPIECE_UNDERLINE + text.replaceAll(SPIECE_UNDERLINE, " "));
    if (tokens.length > 1 && tokens[0] === SPIECE_UNDERLINE && this.special_tokens.includes(tokens[1])) {
      tokens = tokens.slice(1);
    }
    return tokens;
  }
  get default_chat_template() {
    return super.default_chat_template.replaceAll("USE_DEFAULT_PROMPT", this.use_default_system_prompt ? "true" : "false").replaceAll("DEFAULT_SYSTEM_MESSAGE", this.DEFAULT_SYSTEM_PROMPT.replaceAll("\n", "\\n").replaceAll("'", "\\'"));
  }
}
class CodeLlamaTokenizer extends LlamaTokenizer {
}
class XLMRobertaTokenizer extends PreTrainedTokenizer {
}
class MPNetTokenizer extends PreTrainedTokenizer {
}
class FalconTokenizer extends PreTrainedTokenizer {
}
class GPTNeoXTokenizer extends PreTrainedTokenizer {
}
class EsmTokenizer extends PreTrainedTokenizer {
}
class Qwen2Tokenizer extends PreTrainedTokenizer {
}
class GemmaTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "_default_chat_template", "{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}");
  }
}
class Grok1Tokenizer extends PreTrainedTokenizer {
}
function _build_translation_inputs(self2, raw_inputs, tokenizer_options, generate_kwargs) {
  if (!("language_codes" in self2) || !Array.isArray(self2.language_codes)) {
    throw new Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids.");
  }
  if (!("languageRegex" in self2) || !(self2.languageRegex instanceof RegExp)) {
    throw new Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression.");
  }
  if (!("lang_to_token" in self2) || typeof self2.lang_to_token !== "function") {
    throw new Error("Tokenizer must have `lang_to_token` attribute set and it should be a function.");
  }
  const src_lang_token = generate_kwargs.src_lang;
  const tgt_lang_token = generate_kwargs.tgt_lang;
  if (!self2.language_codes.includes(tgt_lang_token)) {
    throw new Error(`Target language code "${tgt_lang_token}" is not valid. Must be one of: {${self2.language_codes.join(", ")}}`);
  }
  if (src_lang_token !== void 0) {
    if (!self2.language_codes.includes(src_lang_token)) {
      throw new Error(`Source language code "${src_lang_token}" is not valid. Must be one of: {${self2.language_codes.join(", ")}}`);
    }
    for (const item of self2.post_processor.config.single) {
      if ("SpecialToken" in item && self2.languageRegex.test(item.SpecialToken.id)) {
        item.SpecialToken.id = self2.lang_to_token(src_lang_token);
        break;
      }
    }
  }
  generate_kwargs.forced_bos_token_id = self2.model.convert_tokens_to_ids([self2.lang_to_token(tgt_lang_token)])[0];
  return self2._call(raw_inputs, tokenizer_options);
}
class NllbTokenizer extends PreTrainedTokenizer {
  constructor(tokenizerJSON, tokenizerConfig) {
    super(tokenizerJSON, tokenizerConfig);
    this.languageRegex = /^[a-z]{3}_[A-Z][a-z]{3}$/;
    this.language_codes = this.special_tokens.filter((x) => this.languageRegex.test(x));
    this.lang_to_token = (x) => x;
  }
  /**
   * Helper function to build translation inputs for an `NllbTokenizer`.
   * @param {string|string[]} raw_inputs The text to tokenize.
   * @param {Object} tokenizer_options Options to be sent to the tokenizer
   * @param {Object} generate_kwargs Generation options.
   * @returns {Object} Object to be passed to the model.
   */
  _build_translation_inputs(raw_inputs, tokenizer_options, generate_kwargs) {
    return _build_translation_inputs(this, raw_inputs, tokenizer_options, generate_kwargs);
  }
}
class M2M100Tokenizer extends PreTrainedTokenizer {
  constructor(tokenizerJSON, tokenizerConfig) {
    super(tokenizerJSON, tokenizerConfig);
    this.languageRegex = /^__[a-z]{2,3}__$/;
    this.language_codes = this.special_tokens.filter((x) => this.languageRegex.test(x)).map((x) => x.slice(2, -2));
    this.lang_to_token = (x) => `__${x}__`;
  }
  /**
   * Helper function to build translation inputs for an `M2M100Tokenizer`.
   * @param {string|string[]} raw_inputs The text to tokenize.
   * @param {Object} tokenizer_options Options to be sent to the tokenizer
   * @param {Object} generate_kwargs Generation options.
   * @returns {Object} Object to be passed to the model.
   */
  _build_translation_inputs(raw_inputs, tokenizer_options, generate_kwargs) {
    return _build_translation_inputs(this, raw_inputs, tokenizer_options, generate_kwargs);
  }
}
const WHISPER_LANGUAGES = [
  ["en", "english"],
  ["zh", "chinese"],
  ["de", "german"],
  ["es", "spanish"],
  ["ru", "russian"],
  ["ko", "korean"],
  ["fr", "french"],
  ["ja", "japanese"],
  ["pt", "portuguese"],
  ["tr", "turkish"],
  ["pl", "polish"],
  ["ca", "catalan"],
  ["nl", "dutch"],
  ["ar", "arabic"],
  ["sv", "swedish"],
  ["it", "italian"],
  ["id", "indonesian"],
  ["hi", "hindi"],
  ["fi", "finnish"],
  ["vi", "vietnamese"],
  ["he", "hebrew"],
  ["uk", "ukrainian"],
  ["el", "greek"],
  ["ms", "malay"],
  ["cs", "czech"],
  ["ro", "romanian"],
  ["da", "danish"],
  ["hu", "hungarian"],
  ["ta", "tamil"],
  ["no", "norwegian"],
  ["th", "thai"],
  ["ur", "urdu"],
  ["hr", "croatian"],
  ["bg", "bulgarian"],
  ["lt", "lithuanian"],
  ["la", "latin"],
  ["mi", "maori"],
  ["ml", "malayalam"],
  ["cy", "welsh"],
  ["sk", "slovak"],
  ["te", "telugu"],
  ["fa", "persian"],
  ["lv", "latvian"],
  ["bn", "bengali"],
  ["sr", "serbian"],
  ["az", "azerbaijani"],
  ["sl", "slovenian"],
  ["kn", "kannada"],
  ["et", "estonian"],
  ["mk", "macedonian"],
  ["br", "breton"],
  ["eu", "basque"],
  ["is", "icelandic"],
  ["hy", "armenian"],
  ["ne", "nepali"],
  ["mn", "mongolian"],
  ["bs", "bosnian"],
  ["kk", "kazakh"],
  ["sq", "albanian"],
  ["sw", "swahili"],
  ["gl", "galician"],
  ["mr", "marathi"],
  ["pa", "punjabi"],
  ["si", "sinhala"],
  ["km", "khmer"],
  ["sn", "shona"],
  ["yo", "yoruba"],
  ["so", "somali"],
  ["af", "afrikaans"],
  ["oc", "occitan"],
  ["ka", "georgian"],
  ["be", "belarusian"],
  ["tg", "tajik"],
  ["sd", "sindhi"],
  ["gu", "gujarati"],
  ["am", "amharic"],
  ["yi", "yiddish"],
  ["lo", "lao"],
  ["uz", "uzbek"],
  ["fo", "faroese"],
  ["ht", "haitian creole"],
  ["ps", "pashto"],
  ["tk", "turkmen"],
  ["nn", "nynorsk"],
  ["mt", "maltese"],
  ["sa", "sanskrit"],
  ["lb", "luxembourgish"],
  ["my", "myanmar"],
  ["bo", "tibetan"],
  ["tl", "tagalog"],
  ["mg", "malagasy"],
  ["as", "assamese"],
  ["tt", "tatar"],
  ["haw", "hawaiian"],
  ["ln", "lingala"],
  ["ha", "hausa"],
  ["ba", "bashkir"],
  ["jw", "javanese"],
  ["su", "sundanese"]
];
const WHISPER_LANGUAGE_MAPPING = new Map(WHISPER_LANGUAGES);
const WHISPER_TO_LANGUAGE_CODE_MAPPING = new Map([
  ...WHISPER_LANGUAGES.map(([k, v]) => [v, k]),
  ...[
    ["burmese", "my"],
    ["valencian", "ca"],
    ["flemish", "nl"],
    ["haitian", "ht"],
    ["letzeburgesch", "lb"],
    ["pushto", "ps"],
    ["panjabi", "pa"],
    ["moldavian", "ro"],
    ["moldovan", "ro"],
    ["sinhalese", "si"],
    ["castilian", "es"]
  ]
]);
class WhisperTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "_default_chat_template", `{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}`);
  }
  /**
   * Decodes automatic speech recognition (ASR) sequences.
   * @param {Array<{tokens: number[], token_timestamps?: number[], stride: number[]}>} sequences The sequences to decode.
   * @param {Object} options The options to use for decoding.
   * @returns {Array<string|{chunks?: undefined|Array<{language: string|null, timestamp: Array<number|null>, text: string}>}>} The decoded sequences.
   */
  _decode_asr(sequences, {
    return_timestamps = false,
    return_language = false,
    time_precision = null,
    force_full_sequences = true
  } = {}) {
    if (time_precision === null) {
      throw Error("Must specify time_precision");
    }
    let last_language = null;
    const returnWordTimestamps = return_timestamps === "word";
    function new_chunk() {
      return { "language": last_language, "timestamp": [null, null], "text": "" };
    }
    const chunks = [];
    let chunk = new_chunk();
    let time_offset = 0;
    const timestamp_begin = this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0] + 1;
    let previous_tokens = [];
    let previous_token_timestamps = [];
    let skip = false;
    let right_stride_start = null;
    const all_special_ids = new Set(this.all_special_ids);
    for (const output2 of sequences) {
      const token_ids = output2.tokens;
      const token_timestamps = returnWordTimestamps ? output2.token_timestamps : null;
      let last_timestamp = null;
      let first_timestamp = timestamp_begin;
      if ("stride" in output2) {
        const [chunk_len, stride_left, stride_right] = output2.stride;
        time_offset -= stride_left;
        right_stride_start = chunk_len - stride_right;
        if (stride_left) {
          first_timestamp = stride_left / time_precision + timestamp_begin;
        }
        if (stride_right) {
          for (let i2 = token_ids.length - 1; i2 >= 0; --i2) {
            const token = token_ids[i2];
            if (token >= timestamp_begin) {
              if (last_timestamp !== null && (token - timestamp_begin) * time_precision < right_stride_start) {
                break;
              }
              last_timestamp = token;
            }
          }
        }
      }
      let current_tokens = [];
      let current_token_timestamps = [];
      for (let i2 = 0; i2 < token_ids.length; ++i2) {
        const token = token_ids[i2];
        if (all_special_ids.has(token)) {
          const text = this.decode([token]);
          const language = WHISPER_LANGUAGE_MAPPING.get(text.slice(2, -2));
          if (language !== void 0) {
            if (last_language !== null && language !== last_language && !return_timestamps) {
              previous_tokens.push(current_tokens);
              const resolved_tokens = this.findLongestCommonSequence(previous_tokens)[0];
              const resolved_text = this.decode(resolved_tokens);
              chunk.text = resolved_text;
              chunks.push(chunk);
              previous_tokens = [];
              current_tokens = [];
              chunk = new_chunk();
            }
            last_language = chunk.language = language;
          }
        } else if (token >= timestamp_begin) {
          const time = (token - timestamp_begin) * time_precision + time_offset;
          const rounded_time = round(time, 2);
          if (last_timestamp !== null && token >= last_timestamp) {
            skip = true;
          } else if (skip || previous_tokens.length > 0 && token < first_timestamp) {
            skip = false;
          } else if (chunk.timestamp[0] === null) {
            chunk.timestamp[0] = rounded_time;
          } else {
            if (rounded_time === chunk.timestamp[0]) ;
            else {
              chunk.timestamp[1] = rounded_time;
              previous_tokens.push(current_tokens);
              if (returnWordTimestamps) {
                previous_token_timestamps.push(current_token_timestamps);
              }
              const [resolved_tokens, resolved_token_timestamps] = this.findLongestCommonSequence(
                previous_tokens,
                previous_token_timestamps
              );
              const resolved_text = this.decode(resolved_tokens);
              chunk.text = resolved_text;
              if (returnWordTimestamps) {
                chunk.words = this.collateWordTimestamps(
                  resolved_tokens,
                  resolved_token_timestamps,
                  last_language
                );
              }
              chunks.push(chunk);
              previous_tokens = [];
              current_tokens = [];
              previous_token_timestamps = [];
              current_token_timestamps = [];
              chunk = new_chunk();
            }
          }
        } else {
          current_tokens.push(token);
          if (returnWordTimestamps) {
            let start_time = round(token_timestamps[i2] + time_offset, 2);
            let end_time;
            if (i2 + 1 < token_timestamps.length) {
              end_time = round(token_timestamps[i2 + 1] + time_offset, 2);
            } else {
              end_time = null;
            }
            current_token_timestamps.push([start_time, end_time]);
          }
        }
      }
      if ("stride" in output2) {
        const [chunk_len, stride_left, stride_right] = output2.stride;
        time_offset += chunk_len - stride_right;
      }
      if (current_tokens.length > 0) {
        previous_tokens.push(current_tokens);
        if (returnWordTimestamps) {
          previous_token_timestamps.push(current_token_timestamps);
        }
      } else if (previous_tokens.every((p) => p.length === 0)) {
        chunk = new_chunk();
        previous_tokens = [];
        current_tokens = [];
        previous_token_timestamps = [];
        current_token_timestamps = [];
      }
    }
    if (previous_tokens.length > 0) {
      if (force_full_sequences && return_timestamps) {
        throw new Error(
          "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation."
        );
      }
      const [resolved_tokens, resolved_token_timestamps] = this.findLongestCommonSequence(previous_tokens, previous_token_timestamps);
      const resolved_text = this.decode(resolved_tokens);
      chunk.text = resolved_text;
      if (returnWordTimestamps) {
        chunk.words = this.collateWordTimestamps(
          resolved_tokens,
          resolved_token_timestamps,
          last_language
        );
      }
      chunks.push(chunk);
    }
    let optional = /* @__PURE__ */ Object.create(null);
    const full_text = chunks.map((chunk2) => chunk2.text).join("");
    if (return_timestamps || return_language) {
      for (let i2 = 0; i2 < chunks.length; ++i2) {
        const chunk2 = chunks[i2];
        if (!return_timestamps) {
          delete chunk2["timestamp"];
        }
        if (!return_language) {
          delete chunk2["language"];
        }
      }
      if (returnWordTimestamps) {
        const new_chunks = [];
        for (const chunk2 of chunks) {
          for (const word of chunk2.words) {
            new_chunks.push(word);
          }
        }
        optional = { "chunks": new_chunks };
      } else {
        optional = { "chunks": chunks };
      }
    }
    return [full_text, optional];
  }
  /**
   * Finds the longest common sequence among the provided sequences.
   * @param {number[][]} sequences An array of sequences of token ids to compare.
   * @returns {number[][]} The longest common sequence found.
   * @throws {Error} If there is a bug within the function.
   * @private
   */
  findLongestCommonSequence(sequences, token_timestamp_sequences = null) {
    let leftSequence = sequences[0];
    let leftLength = leftSequence.length;
    let totalSequence = [];
    const use_token_timestamp_sequences = Array.isArray(token_timestamp_sequences) && token_timestamp_sequences.length > 0;
    let total_token_timestamp_sequence = use_token_timestamp_sequences ? [] : null;
    let left_token_timestamp_sequence = use_token_timestamp_sequences ? token_timestamp_sequences[0] : null;
    for (let i2 = 1; i2 < sequences.length; ++i2) {
      const rightSequence = sequences[i2];
      let max2 = 0;
      let maxIndices = [leftLength, leftLength, 0, 0];
      const rightLength = rightSequence.length;
      for (let j = 1; j < leftLength + rightLength; ++j) {
        const eps = j / 1e4;
        const leftStart2 = Math.max(0, leftLength - j);
        const leftStop2 = Math.min(leftLength, leftLength + rightLength - j);
        const left = leftSequence.slice(leftStart2, leftStop2);
        const rightStart2 = Math.max(0, j - leftLength);
        const rightStop2 = Math.min(rightLength, j);
        const right = rightSequence.slice(rightStart2, rightStop2);
        if (left.length !== right.length) {
          throw new Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.");
        }
        const matches = left.filter((elem, idx) => elem === right[idx]).length;
        const matching = matches / j + eps;
        if (matches > 1 && matching > max2) {
          max2 = matching;
          maxIndices = [leftStart2, leftStop2, rightStart2, rightStop2];
        }
      }
      const [leftStart, leftStop, rightStart, rightStop] = maxIndices;
      const leftMid = Math.floor((leftStop + leftStart) / 2);
      const rightMid = Math.floor((rightStop + rightStart) / 2);
      totalSequence.push(...leftSequence.slice(0, leftMid));
      leftSequence = rightSequence.slice(rightMid);
      leftLength = leftSequence.length;
      if (use_token_timestamp_sequences) {
        total_token_timestamp_sequence.push(...left_token_timestamp_sequence.slice(0, leftMid));
        left_token_timestamp_sequence = token_timestamp_sequences[i2].slice(rightMid);
      }
    }
    totalSequence.push(...leftSequence);
    if (use_token_timestamp_sequences) {
      total_token_timestamp_sequence.push(...left_token_timestamp_sequence);
      return [totalSequence, total_token_timestamp_sequence];
    } else {
      return [totalSequence, []];
    }
  }
  /** @private */
  collateWordTimestamps(tokens, token_timestamps, language) {
    const [words, _, token_indices] = this.combineTokensIntoWords(tokens, language);
    const timings = [];
    for (let i2 = 0; i2 < words.length; ++i2) {
      const indices = token_indices[i2];
      timings.push({
        text: words[i2],
        timestamp: [
          token_timestamps[indices.at(0)][0],
          token_timestamps[indices.at(-1)][1]
        ]
      });
    }
    return timings;
  }
  /**
   * Groups tokens by word. Returns a tuple containing a list of strings with the words,
   * and a list of `token_id` sequences with the tokens making up each word.
   * @param {number[]} tokens 
   * @param {string} [language] 
   * @param {string} prepend_punctionations 
   * @param {string} append_punctuations 
   * 
   * @private
   */
  combineTokensIntoWords(tokens, language, prepend_punctionations = `"'([{-`, append_punctuations = `"'.,!?:)]}`) {
    language = language ?? "english";
    let words, word_tokens, token_indices;
    if (["chinese", "japanese", "thai", "lao", "myanmar"].includes(language)) {
      [words, word_tokens, token_indices] = this.splitTokensOnUnicode(tokens);
    } else {
      [words, word_tokens, token_indices] = this.splitTokensOnSpaces(tokens);
    }
    return this.mergePunctuations(words, word_tokens, token_indices, prepend_punctionations, append_punctuations);
  }
  /** @type {PreTrainedTokenizer['decode']} */
  decode(token_ids, decode_args) {
    let text;
    if (decode_args && decode_args.decode_with_timestamps) {
      if (token_ids instanceof Tensor) {
        token_ids = prepareTensorForDecode(token_ids);
      }
      text = this.decodeWithTimestamps(token_ids, decode_args);
    } else {
      text = super.decode(token_ids, decode_args);
    }
    return text;
  }
  /**
   * @param {number[]} token_ids List of token IDs to decode.
   * @param {Object} decode_args Optional arguments for decoding
   * @private
   */
  decodeWithTimestamps(token_ids, decode_args) {
    const time_precision = (decode_args == null ? void 0 : decode_args.time_precision) ?? 0.02;
    const timestamp_begin = Array.from(this.all_special_ids).at(-1) + 1;
    let outputs = [[]];
    for (const token of token_ids) {
      if (token >= timestamp_begin) {
        const timestamp = round((token - timestamp_begin) * time_precision, 2);
        outputs.push(`<|${timestamp}|>`);
        outputs.push([]);
      } else {
        outputs[outputs.length - 1].push(token);
      }
    }
    outputs = outputs.map(
      (s) => {
        if (typeof s === "string") {
          return s;
        } else {
          return super.decode(s, decode_args);
        }
      }
    );
    return outputs.join("");
  }
  /**
   * Combine tokens into words by splitting at any position where the tokens are decoded as valid unicode points.
   * @param {number[]} tokens 
   * @returns {*}
   * @private
   */
  splitTokensOnUnicode(tokens) {
    const decoded_full = this.decode(tokens, {
      // @ts-ignore
      decode_with_timestamps: true
    });
    const replacement_char = "";
    const words = [];
    const word_tokens = [];
    const token_indices = [];
    let current_tokens = [];
    let current_indices = [];
    let unicode_offset = 0;
    for (let token_idx = 0; token_idx < tokens.length; ++token_idx) {
      const token = tokens[token_idx];
      current_tokens.push(token);
      current_indices.push(token_idx);
      const decoded = this.decode(current_tokens, {
        // @ts-ignore
        decode_with_timestamps: true
      });
      if (!decoded.includes(replacement_char) || decoded_full[unicode_offset + decoded.indexOf(replacement_char)] === replacement_char) {
        words.push(decoded);
        word_tokens.push(current_tokens);
        token_indices.push(current_indices);
        current_tokens = [];
        current_indices = [];
        unicode_offset += decoded.length;
      }
    }
    return [words, word_tokens, token_indices];
  }
  /**
   * Combine tokens into words by splitting at whitespace and punctuation tokens.
   * @param {number[]} tokens 
   * @private
   */
  splitTokensOnSpaces(tokens) {
    const [subwords, subword_tokens_list, subword_indices_list] = this.splitTokensOnUnicode(tokens);
    const words = [];
    const word_tokens = [];
    const token_indices = [];
    const punctuationRegex = new RegExp(`^[${PUNCTUATION_REGEX}]$`, "gu");
    for (let i2 = 0; i2 < subwords.length; ++i2) {
      const subword = subwords[i2];
      const subword_tokens = subword_tokens_list[i2];
      const subword_indices = subword_indices_list[i2];
      const special = subword_tokens[0] >= this.model.tokens_to_ids.get("<|endoftext|>");
      const with_space = subword.startsWith(" ");
      const trimmed = subword.trim();
      const punctuation = punctuationRegex.test(trimmed);
      if (special || with_space || punctuation || words.length === 0) {
        words.push(subword);
        word_tokens.push(subword_tokens);
        token_indices.push(subword_indices);
      } else {
        const ix = words.length - 1;
        words[ix] += subword;
        word_tokens[ix].push(...subword_tokens);
        token_indices[ix].push(...subword_indices);
      }
    }
    return [words, word_tokens, token_indices];
  }
  /**
   * Merges punctuation tokens with neighboring words.
   * @param {string[]} words 
   * @param {number[][]} tokens 
   * @param {number[][]} indices 
   * @param {string} prepended 
   * @param {string} appended 
   * @private
   */
  mergePunctuations(words, tokens, indices, prepended, appended) {
    const newWords = structuredClone(words);
    const newTokens = structuredClone(tokens);
    const newIndices = structuredClone(indices);
    let i2 = newWords.length - 2;
    let j = newWords.length - 1;
    while (i2 >= 0) {
      if (newWords[i2].startsWith(" ") && prepended.includes(newWords[i2].trim())) {
        newWords[j] = newWords[i2] + newWords[j];
        newTokens[j] = mergeArrays(newTokens[i2], newTokens[j]);
        newIndices[j] = mergeArrays(newIndices[i2], newIndices[j]);
        newWords[i2] = "";
        newTokens[i2] = [];
        newIndices[i2] = [];
      } else {
        j = i2;
      }
      --i2;
    }
    i2 = 0;
    j = 1;
    while (j < newWords.length) {
      if (!newWords[i2].endsWith(" ") && appended.includes(newWords[j])) {
        newWords[i2] += newWords[j];
        newTokens[i2] = mergeArrays(newTokens[i2], newTokens[j]);
        newIndices[i2] = mergeArrays(newIndices[i2], newIndices[j]);
        newWords[j] = "";
        newTokens[j] = [];
        newIndices[j] = [];
      } else {
        i2 = j;
      }
      ++j;
    }
    return [
      newWords.filter((x) => x),
      newTokens.filter((x) => x.length > 0),
      newIndices.filter((x) => x.length > 0)
    ];
  }
  /**
   * Helper function to build translation inputs for a `WhisperTokenizer`,
   * depending on the language, task, and whether to predict timestamp tokens.
   * 
   * Used to override the prefix tokens appended to the start of the label sequence.
   * 
   * **Example: Get ids for a language**
   * ```javascript
   * // instantiate the tokenizer and set the prefix token to Spanish
   * const tokenizer = await WhisperTokenizer.from_pretrained('Xenova/whisper-tiny');
   * const forced_decoder_ids = tokenizer.get_decoder_prompt_ids({ language: 'spanish' });
   * // [(1, 50262), (2, 50363)]
   * ```
   * 
   * @param {Object} options Options to generate the decoder prompt.
   * @param {string} [options.language] The language of the transcription text.
   * The corresponding language id token is appended to the start of the sequence for multilingual
   * speech recognition and speech translation tasks, e.g. for "Spanish" the token "<|es|>" is appended
   * to the start of sequence.
   * @param {string} [options.task] Task identifier to append at the start of sequence (if any).
   * This should be used for mulitlingual fine-tuning, with "transcribe" for speech recognition and
   * "translate" for speech translation.
   * @param {boolean} [options.no_timestamps] Whether to add the <|notimestamps|> token at the start of the sequence.
   * @returns {number[][]} The decoder prompt ids.
   */
  get_decoder_prompt_ids({
    language = null,
    task = null,
    no_timestamps = true
  } = {}) {
    const forced_decoder_ids = [];
    if (language) {
      language = language.toLowerCase();
      let language_code = WHISPER_TO_LANGUAGE_CODE_MAPPING.get(language);
      if (language_code === void 0) {
        if (WHISPER_LANGUAGE_MAPPING.has(language)) {
          language_code = language;
        } else {
          const is_language_code = language.length === 2;
          const langs = is_language_code ? WHISPER_LANGUAGE_MAPPING.keys() : WHISPER_LANGUAGE_MAPPING.values();
          throw new Error(`Language "${language}" is not supported. Must be one of: ${JSON.stringify(langs)}`);
        }
      }
      const language_token_id = this.model.tokens_to_ids.get(`<|${language_code}|>`);
      if (language_token_id === void 0) {
        throw new Error(`Unable to find language "${language_code}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`);
      }
      forced_decoder_ids.push(language_token_id);
    } else {
      forced_decoder_ids.push(null);
    }
    if (task) {
      task = task.toLowerCase();
      if (task !== "transcribe" && task !== "translate") {
        throw new Error(`Task "${task}" is not supported. Must be one of: ["transcribe", "translate"]`);
      }
      const task_token_id = this.model.tokens_to_ids.get(`<|${task}|>`);
      if (task_token_id === void 0) {
        throw new Error(`Unable to find task "${task}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`);
      }
      forced_decoder_ids.push(task_token_id);
    } else {
      forced_decoder_ids.push(null);
    }
    if (no_timestamps) {
      const no_timestamps_id = this.model.tokens_to_ids.get(`<|notimestamps|>`);
      if (no_timestamps_id === void 0) {
        throw new Error('Unable to find "<|notimestamps|>" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.');
      }
      forced_decoder_ids.push(no_timestamps_id);
    }
    return forced_decoder_ids.map((x, i2) => [i2 + 1, x]).filter((x) => x[1] !== null);
  }
}
class CodeGenTokenizer extends PreTrainedTokenizer {
}
class CLIPTokenizer extends PreTrainedTokenizer {
}
class SiglipTokenizer extends PreTrainedTokenizer {
}
class MarianTokenizer extends PreTrainedTokenizer {
  /**
   * Create a new MarianTokenizer instance.
   * @param {Object} tokenizerJSON The JSON of the tokenizer.
   * @param {Object} tokenizerConfig The config of the tokenizer.
   */
  constructor(tokenizerJSON, tokenizerConfig) {
    super(tokenizerJSON, tokenizerConfig);
    this.languageRegex = /^(>>\w+<<)\s*/g;
    this.supported_language_codes = this.model.vocab.filter(
      (x) => this.languageRegex.test(x)
    );
    console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.');
  }
  /**
   * Encodes a single text. Overriding this method is necessary since the language codes
   * must be removed before encoding with sentencepiece model.
   * @see https://github.com/huggingface/transformers/blob/12d51db243a00726a548a43cc333390ebae731e3/src/transformers/models/marian/tokenization_marian.py#L204-L213
   *
   * @param {string|null} text The text to encode.
   * @returns {Array} The encoded tokens.
   */
  _encode_text(text) {
    if (text === null) return null;
    const [matchInfo, ...remainder] = text.trim().split(this.languageRegex);
    if (remainder.length === 0) {
      return super._encode_text(matchInfo);
    } else if (remainder.length === 2) {
      const [language, text2] = remainder;
      if (!this.supported_language_codes.includes(language)) {
        console.warn(`Unsupported language code "${language}" detected, which may lead to unexpected behavior. Should be one of: ${JSON.stringify(this.supported_language_codes)}`);
      }
      return mergeArrays([language], super._encode_text(text2));
    }
  }
}
class Wav2Vec2CTCTokenizer extends PreTrainedTokenizer {
}
class BlenderbotTokenizer extends PreTrainedTokenizer {
  constructor() {
    super(...arguments);
    __publicField(this, "_default_chat_template", `{% for message in messages %}{% if message['role'] == 'user' %}{{ ' ' }}{% endif %}{{ message['content'] }}{% if not loop.last %}{{ '  ' }}{% endif %}{% endfor %}{{ eos_token }}`);
  }
}
class BlenderbotSmallTokenizer extends BlenderbotTokenizer {
}
class SpeechT5Tokenizer extends PreTrainedTokenizer {
}
class NougatTokenizer extends PreTrainedTokenizer {
}
class VitsTokenizer extends PreTrainedTokenizer {
  constructor(tokenizerJSON, tokenizerConfig) {
    super(tokenizerJSON, tokenizerConfig);
    this.decoder = new VitsDecoder({});
  }
}
class CohereTokenizer extends PreTrainedTokenizer {
}
class AutoTokenizer {
  /**
   * Instantiate one of the tokenizer classes of the library from a pretrained model.
   * 
   * The tokenizer class to instantiate is selected based on the `tokenizer_class` property of the config object
   * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)
   * 
   * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:
   * - A string, the *model id* of a pretrained tokenizer hosted inside a model repo on huggingface.co.
   *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a
   *   user or organization name, like `dbmdz/bert-base-german-cased`.
   * - A path to a *directory* containing tokenizer files, e.g., `./my_model_directory/`.
   * @param {PretrainedTokenizerOptions} options Additional options for loading the tokenizer.
   * 
   * @returns {Promise<PreTrainedTokenizer>} A new instance of the PreTrainedTokenizer class.
   */
  static async from_pretrained(pretrained_model_name_or_path, {
    quantized = true,
    progress_callback = null,
    config: config2 = null,
    cache_dir = null,
    local_files_only = false,
    revision = "main",
    legacy = null
  } = {}) {
    var _a2;
    const [tokenizerJSON, tokenizerConfig] = await loadTokenizer(pretrained_model_name_or_path, {
      progress_callback,
      cache_dir,
      local_files_only,
      revision,
      legacy
    });
    const tokenizerName = ((_a2 = tokenizerConfig.tokenizer_class) == null ? void 0 : _a2.replace(/Fast$/, "")) ?? "PreTrainedTokenizer";
    let cls = this.TOKENIZER_CLASS_MAPPING[tokenizerName];
    if (!cls) {
      console.warn(`Unknown tokenizer class "${tokenizerName}", attempting to construct from base class.`);
      cls = PreTrainedTokenizer;
    }
    return new cls(tokenizerJSON, tokenizerConfig);
  }
}
__publicField(AutoTokenizer, "TOKENIZER_CLASS_MAPPING", {
  T5Tokenizer,
  DistilBertTokenizer,
  CamembertTokenizer,
  DebertaTokenizer,
  DebertaV2Tokenizer,
  BertTokenizer,
  HerbertTokenizer,
  ConvBertTokenizer,
  RoFormerTokenizer,
  XLMTokenizer,
  ElectraTokenizer,
  MobileBertTokenizer,
  SqueezeBertTokenizer,
  AlbertTokenizer,
  GPT2Tokenizer,
  BartTokenizer,
  MBartTokenizer,
  MBart50Tokenizer,
  RobertaTokenizer,
  WhisperTokenizer,
  CodeGenTokenizer,
  CLIPTokenizer,
  SiglipTokenizer,
  MarianTokenizer,
  BloomTokenizer,
  NllbTokenizer,
  M2M100Tokenizer,
  LlamaTokenizer,
  CodeLlamaTokenizer,
  XLMRobertaTokenizer,
  MPNetTokenizer,
  FalconTokenizer,
  GPTNeoXTokenizer,
  EsmTokenizer,
  Wav2Vec2CTCTokenizer,
  BlenderbotTokenizer,
  BlenderbotSmallTokenizer,
  SpeechT5Tokenizer,
  NougatTokenizer,
  VitsTokenizer,
  Qwen2Tokenizer,
  GemmaTokenizer,
  Grok1Tokenizer,
  CohereTokenizer,
  // Base case:
  PreTrainedTokenizer
});
async function loadConfig(pretrained_model_name_or_path, options) {
  let info = await getModelJSON(pretrained_model_name_or_path, "config.json", true, options);
  return info;
}
class PretrainedConfig {
  // NOTE: Typo in original
  /**
   * Create a new PreTrainedTokenizer instance.
   * @param {Object} configJSON The JSON of the config.
   */
  constructor(configJSON) {
    this.model_type = null;
    this.is_encoder_decoder = false;
    Object.assign(this, configJSON);
  }
  /**
   * Loads a pre-trained config from the given `pretrained_model_name_or_path`. 
   * 
   * @param {string} pretrained_model_name_or_path The path to the pre-trained config.
   * @param {PretrainedOptions} options Additional options for loading the config.
   * @throws {Error} Throws an error if the config.json is not found in the `pretrained_model_name_or_path`.
   * 
   * @returns {Promise<PretrainedConfig>} A new instance of the `PretrainedConfig` class.
   */
  static async from_pretrained(pretrained_model_name_or_path, {
    progress_callback = null,
    config: config2 = null,
    cache_dir = null,
    local_files_only = false,
    revision = "main"
  } = {}) {
    let data = config2 ?? await loadConfig(pretrained_model_name_or_path, {
      progress_callback,
      cache_dir,
      local_files_only,
      revision
    });
    return new this(data);
  }
}
class AutoConfig {
  /** @type {PretrainedConfig.from_pretrained} */
  static async from_pretrained(...args) {
    return PretrainedConfig.from_pretrained(...args);
  }
}
class LogitsProcessorList extends Callable {
  /**
   * Constructs a new instance of `LogitsProcessorList`.
   */
  constructor() {
    super();
    this.processors = [];
  }
  /**
   * Adds a new logits processor to the list.
   *
   * @param {LogitsProcessor} item The logits processor function to add.
   */
  push(item) {
    this.processors.push(item);
  }
  /**
   * Adds multiple logits processors to the list.
   *
   * @param {LogitsProcessor[]} items The logits processor functions to add.
   */
  extend(items2) {
    this.processors.push(...items2);
  }
  /**
   * Applies all logits processors in the list to a batch of logits, modifying them in-place.
   *
   * @param {number[]} input_ids The input IDs for the language model.
   * @param {number[][]} batchedLogits A 2D array of logits, where each row corresponds to a single
   *                                                input sequence in the batch.
   */
  _call(input_ids, batchedLogits) {
    for (let logits of batchedLogits) {
      this.processors.forEach(
        (func) => func(input_ids, logits)
      );
    }
  }
  [Symbol.iterator]() {
    return this.processors.values();
  }
}
class LogitsProcessor extends Callable {
  /**
   * Apply the processor to the input logits.
   *
   * @abstract
   * @param {Array} input_ids The input ids.
   * @param {Tensor} logits The logits to process.
   * @throws {Error} Throws an error if `_call` is not implemented in the subclass.
   */
  _call(input_ids, logits) {
    throw Error("`_call` should be implemented in a subclass");
  }
}
class ForceTokensLogitsProcessor extends LogitsProcessor {
  /**
   * Constructs a new instance of `ForceTokensLogitsProcessor`.
   * 
   * @param {Array} forced_decoder_ids The ids of tokens that should be forced.
   */
  constructor(forced_decoder_ids) {
    super();
    this.force_token_map = Object.fromEntries(forced_decoder_ids ?? []);
  }
  /**
   * Apply the processor to the input logits.
   *
   * @param {Array} input_ids The input ids.
   * @param {Tensor} logits The logits to process.
   * @returns {Tensor} The processed logits.
   */
  _call(input_ids, logits) {
    let map = this.force_token_map[input_ids.length];
    if (exists(map)) {
      logits.data.fill(-Infinity);
      logits.data[map] = 0;
    }
    return logits;
  }
}
class ForcedBOSTokenLogitsProcessor extends LogitsProcessor {
  /**
   * Create a ForcedBOSTokenLogitsProcessor.
   * @param {number} bos_token_id The ID of the beginning-of-sequence token to be forced.
   */
  constructor(bos_token_id) {
    super();
    this.bos_token_id = bos_token_id;
  }
  /**
   * Apply the BOS token forcing to the logits.
   * @param {Array} input_ids The input IDs.
   * @param {Object} logits The logits.
   * @returns {Object} The logits with BOS token forcing.
   */
  _call(input_ids, logits) {
    if (input_ids.length === 1) {
      logits.data.fill(-Infinity);
      logits.data[this.bos_token_id] = 0;
    }
    return logits;
  }
}
class ForcedEOSTokenLogitsProcessor extends LogitsProcessor {
  /**
   * Create a ForcedEOSTokenLogitsProcessor.
   * @param {number} max_length Max length of the sequence.
   * @param {number|number[]} forced_eos_token_id The ID of the end-of-sequence token to be forced.
   */
  constructor(max_length, forced_eos_token_id) {
    super();
    this.max_length = max_length;
    this.forced_eos_token_id = forced_eos_token_id;
  }
  /**
   * Apply the processor to input_ids and logits.
   * 
   * @param {number[]} input_ids The input ids.
   * @param {Tensor} logits The logits tensor.
   */
  _call(input_ids, logits) {
  }
}
class SuppressTokensAtBeginLogitsProcessor extends LogitsProcessor {
  /**
   * Create a SuppressTokensAtBeginLogitsProcessor.
   * @param {number[]} begin_suppress_tokens The IDs of the tokens to suppress.
   * @param {number} begin_index The number of tokens to generate before suppressing tokens.
   */
  constructor(begin_suppress_tokens, begin_index) {
    super();
    this.begin_suppress_tokens = begin_suppress_tokens;
    this.begin_index = begin_index;
  }
  /**
   * Apply the BOS token forcing to the logits.
   * @param {Array} input_ids The input IDs.
   * @param {Object} logits The logits.
   * @returns {Object} The logits with BOS token forcing.
   */
  _call(input_ids, logits) {
    if (input_ids.length === this.begin_index) {
      for (let token_id of this.begin_suppress_tokens) {
        logits.data[token_id] = -Infinity;
      }
    }
    return logits;
  }
}
class WhisperTimeStampLogitsProcessor extends LogitsProcessor {
  /**
   * Constructs a new WhisperTimeStampLogitsProcessor.
   * @param {Object} generate_config The config object passed to the `generate()` method of a transformer model.
   * @param {number} generate_config.eos_token_id The ID of the end-of-sequence token.
   * @param {number} generate_config.no_timestamps_token_id The ID of the token used to indicate that a token should not have a timestamp.
   * @param {number[][]} [generate_config.forced_decoder_ids] An array of two-element arrays representing decoder IDs that are forced to appear in the output. The second element of each array indicates whether the token is a timestamp.
   * @param {number} [generate_config.max_initial_timestamp_index] The maximum index at which an initial timestamp can appear.
   */
  constructor(generate_config) {
    super();
    this.eos_token_id = generate_config.eos_token_id;
    this.no_timestamps_token_id = generate_config.no_timestamps_token_id;
    this.timestamp_begin = this.no_timestamps_token_id + 1;
    this.begin_index = (generate_config.forced_decoder_ids || []).length + 2;
    if (generate_config.forced_decoder_ids.slice(-1)[0][1] === this.no_timestamps_token_id) {
      this.begin_index -= 1;
    }
    this.max_initial_timestamp_index = generate_config.max_initial_timestamp_index;
  }
  /**
   * Modify the logits to handle timestamp tokens.
   * @param {Array} input_ids The input sequence of tokens.
   * @param {Tensor} logits The logits output by the model.
   * @returns {Tensor} The modified logits.
   */
  _call(input_ids, logits) {
    const logitsData = (
      /** @type {Float32Array} */
      logits.data
    );
    logitsData[this.no_timestamps_token_id] = -Infinity;
    if (input_ids.length === this.begin_index - 1) {
      logitsData.fill(-Infinity);
      logitsData[this.timestamp_begin] = 0;
      return logits;
    }
    const seq = input_ids.slice(this.begin_index);
    const last_was_timestamp = seq.length >= 1 && seq[seq.length - 1] >= this.timestamp_begin;
    const penultimate_was_timestamp = seq.length < 2 || seq[seq.length - 2] >= this.timestamp_begin;
    if (last_was_timestamp) {
      if (penultimate_was_timestamp) {
        logitsData.subarray(this.timestamp_begin).fill(-Infinity);
      } else {
        logitsData.subarray(0, this.eos_token_id).fill(-Infinity);
      }
    }
    if (input_ids.length === this.begin_index && this.max_initial_timestamp_index !== null) {
      const last_allowed = this.timestamp_begin + this.max_initial_timestamp_index;
      logitsData.subarray(last_allowed + 1).fill(-Infinity);
    }
    const logprobs = log_softmax(logitsData);
    const timestamp_logprob = Math.log(logprobs.subarray(this.timestamp_begin).map(Math.exp).reduce((a, b) => a + b));
    const max_text_token_logprob = max(logprobs.subarray(0, this.timestamp_begin))[0];
    if (timestamp_logprob > max_text_token_logprob) {
      logitsData.subarray(0, this.timestamp_begin).fill(-Infinity);
    }
    return logits;
  }
}
class NoRepeatNGramLogitsProcessor extends LogitsProcessor {
  /**
   * Create a NoRepeatNGramLogitsProcessor.
   * @param {number} no_repeat_ngram_size The no-repeat-ngram size. All ngrams of this size can only occur once.
   */
  constructor(no_repeat_ngram_size) {
    super();
    this.no_repeat_ngram_size = no_repeat_ngram_size;
  }
  /**
   * Generate n-grams from a sequence of token ids.
   * @param {number[]} prevInputIds List of previous input ids
   * @returns {Map<string, number[]>} Map of generated n-grams
   */
  getNgrams(prevInputIds) {
    const curLen = prevInputIds.length;
    const ngrams = [];
    for (let j = 0; j < curLen + 1 - this.no_repeat_ngram_size; ++j) {
      const ngram = [];
      for (let k = 0; k < this.no_repeat_ngram_size; ++k) {
        ngram.push(prevInputIds[j + k]);
      }
      ngrams.push(ngram);
    }
    const generatedNgram = /* @__PURE__ */ new Map();
    for (const ngram of ngrams) {
      const prevNgram = ngram.slice(0, ngram.length - 1);
      const prevNgramKey = JSON.stringify(prevNgram);
      const prevNgramValue = generatedNgram.get(prevNgramKey) ?? [];
      prevNgramValue.push(ngram[ngram.length - 1]);
      generatedNgram.set(prevNgramKey, prevNgramValue);
    }
    return generatedNgram;
  }
  /**
   * Generate n-grams from a sequence of token ids.
   * @param {Map<string, number[]>} bannedNgrams Map of banned n-grams
   * @param {number[]} prevInputIds List of previous input ids
   * @returns {number[]} Map of generated n-grams
   */
  getGeneratedNgrams(bannedNgrams, prevInputIds) {
    const ngramIdx = prevInputIds.slice(prevInputIds.length + 1 - this.no_repeat_ngram_size, prevInputIds.length);
    const banned = bannedNgrams.get(JSON.stringify(ngramIdx)) ?? [];
    return banned;
  }
  /**
   * Calculate banned n-gram tokens
   * @param {number[]} prevInputIds List of previous input ids
   * @returns {number[]} Map of generated n-grams
   */
  calcBannedNgramTokens(prevInputIds) {
    const bannedTokens = [];
    if (prevInputIds.length + 1 < this.no_repeat_ngram_size) {
      return bannedTokens;
    } else {
      const generatedNgrams = this.getNgrams(prevInputIds);
      const bannedTokens2 = this.getGeneratedNgrams(generatedNgrams, prevInputIds);
      return bannedTokens2;
    }
  }
  /**
   * Apply the no-repeat-ngram processor to the logits.
   * @param {Array} input_ids The input IDs.
   * @param {Object} logits The logits.
   * @returns {Object} The logits with no-repeat-ngram processing.
   */
  _call(input_ids, logits) {
    const bannedTokens = this.calcBannedNgramTokens(input_ids);
    for (const token of bannedTokens) {
      logits.data[token] = -Infinity;
    }
    return logits;
  }
}
class RepetitionPenaltyLogitsProcessor extends LogitsProcessor {
  /**
   * Create a RepetitionPenaltyLogitsProcessor.
   * @param {number} penalty The penalty to apply for repeated tokens.
   */
  constructor(penalty) {
    super();
    this.penalty = penalty;
  }
  /**
   * Apply the repetition penalty to the logits.
   * @param {Array} input_ids The input IDs.
   * @param {Object} logits The logits.
   * @returns {Object} The logits with repetition penalty processing.
   */
  _call(input_ids, logits) {
    for (const input_id of input_ids) {
      if (logits.data[input_id] < 0) {
        logits.data[input_id] *= this.penalty;
      } else {
        logits.data[input_id] /= this.penalty;
      }
    }
    return logits;
  }
}
class MinLengthLogitsProcessor extends LogitsProcessor {
  /**
   * Create a MinLengthLogitsProcessor.
   * @param {number} min_length The minimum length below which the score of `eos_token_id` is set to negative infinity.
   * @param {number|number[]} eos_token_id The ID/IDs of the end-of-sequence token.
   */
  constructor(min_length, eos_token_id) {
    super();
    this.min_length = min_length;
    this.eos_token_id = Array.isArray(eos_token_id) ? eos_token_id : [eos_token_id];
  }
  /**
   * Apply logit processor.
   * @param {Array} input_ids The input IDs.
   * @param {Object} logits The logits.
   * @returns {Object} The processed logits.
   */
  _call(input_ids, logits) {
    if (input_ids.length < this.min_length) {
      for (const eos_token of this.eos_token_id) {
        logits.data[eos_token] = -Infinity;
      }
    }
    return logits;
  }
}
class MinNewTokensLengthLogitsProcessor extends LogitsProcessor {
  /**
   * Create a MinNewTokensLengthLogitsProcessor.
   * @param {number} prompt_length_to_skip The input tokens length.
   * @param {number} min_new_tokens The minimum *new* tokens length below which the score of `eos_token_id` is set to negative infinity.
   * @param {number|number[]} eos_token_id The ID/IDs of the end-of-sequence token.
   */
  constructor(prompt_length_to_skip, min_new_tokens, eos_token_id) {
    super();
    this.prompt_length_to_skip = prompt_length_to_skip;
    this.min_new_tokens = min_new_tokens;
    this.eos_token_id = Array.isArray(eos_token_id) ? eos_token_id : [eos_token_id];
  }
  /**
   * Apply logit processor.
   * @param {Array} input_ids The input IDs.
   * @param {Object} logits The logits.
   * @returns {Object} The processed logits.
   */
  _call(input_ids, logits) {
    const new_tokens_length = input_ids.length - this.prompt_length_to_skip;
    if (new_tokens_length < this.min_new_tokens) {
      for (const eos_token of this.eos_token_id) {
        logits.data[eos_token] = -Infinity;
      }
    }
    return logits;
  }
}
class NoBadWordsLogitsProcessor extends LogitsProcessor {
  /**
   * Create a `NoBadWordsLogitsProcessor`.
   * @param {number[][]} bad_words_ids List of list of token ids that are not allowed to be generated.
   * @param {number|number[]} eos_token_id The id of the *end-of-sequence* token. Optionally, use a list to set multiple *end-of-sequence* tokens.
   */
  constructor(bad_words_ids, eos_token_id) {
    super();
    this.bad_words_ids = bad_words_ids;
    this.eos_token_id = Array.isArray(eos_token_id) ? eos_token_id : [eos_token_id];
  }
  /**
   * Apply logit processor.
   * @param {Array} input_ids The input IDs.
   * @param {Object} logits The logits.
   * @returns {Object} The processed logits.
   */
  _call(input_ids, logits) {
    for (const bad_word_ids of this.bad_words_ids) {
      let mark = true;
      for (let i2 = 1; i2 <= bad_word_ids.length - 1 && bad_word_ids.length < input_ids.length; ++i2) {
        if (bad_word_ids.at(-i2 - 1) !== input_ids.at(-i2)) {
          mark = false;
          break;
        }
      }
      if (mark) {
        logits.data[bad_word_ids.at(-1)] = -Infinity;
      }
    }
    return logits;
  }
}
const GenerationConfig = (
  /** @type {any} */
  class {
    /**
     * Create a new GenerationConfig object.
     * @param {GenerationConfigType} kwargs 
     */
    constructor(kwargs = {}) {
      this.max_length = kwargs.max_length ?? 20;
      this.max_new_tokens = kwargs.max_new_tokens ?? null;
      this.min_length = kwargs.min_length ?? 0;
      this.min_new_tokens = kwargs.min_new_tokens ?? null;
      this.early_stopping = kwargs.early_stopping ?? false;
      this.max_time = kwargs.max_time ?? null;
      this.do_sample = kwargs.do_sample ?? false;
      this.num_beams = kwargs.num_beams ?? 1;
      this.num_beam_groups = kwargs.num_beam_groups ?? 1;
      this.penalty_alpha = kwargs.penalty_alpha ?? null;
      this.use_cache = kwargs.use_cache ?? true;
      this.temperature = kwargs.temperature ?? 1;
      this.top_k = kwargs.top_k ?? 50;
      this.top_p = kwargs.top_p ?? 1;
      this.typical_p = kwargs.typical_p ?? 1;
      this.epsilon_cutoff = kwargs.epsilon_cutoff ?? 0;
      this.eta_cutoff = kwargs.eta_cutoff ?? 0;
      this.diversity_penalty = kwargs.diversity_penalty ?? 0;
      this.repetition_penalty = kwargs.repetition_penalty ?? 1;
      this.encoder_repetition_penalty = kwargs.encoder_repetition_penalty ?? 1;
      this.length_penalty = kwargs.length_penalty ?? 1;
      this.no_repeat_ngram_size = kwargs.no_repeat_ngram_size ?? 0;
      this.bad_words_ids = kwargs.bad_words_ids ?? null;
      this.force_words_ids = kwargs.force_words_ids ?? null;
      this.renormalize_logits = kwargs.renormalize_logits ?? false;
      this.constraints = kwargs.constraints ?? null;
      this.forced_bos_token_id = kwargs.forced_bos_token_id ?? null;
      this.forced_eos_token_id = kwargs.forced_eos_token_id ?? null;
      this.remove_invalid_values = kwargs.remove_invalid_values ?? false;
      this.exponential_decay_length_penalty = kwargs.exponential_decay_length_penalty ?? null;
      this.suppress_tokens = kwargs.suppress_tokens ?? null;
      this.begin_suppress_tokens = kwargs.begin_suppress_tokens ?? null;
      this.forced_decoder_ids = kwargs.forced_decoder_ids ?? null;
      this.num_return_sequences = kwargs.num_return_sequences ?? 1;
      this.output_attentions = kwargs.output_attentions ?? false;
      this.output_hidden_states = kwargs.output_hidden_states ?? false;
      this.output_scores = kwargs.output_scores ?? false;
      this.return_dict_in_generate = kwargs.return_dict_in_generate ?? false;
      this.pad_token_id = kwargs.pad_token_id ?? null;
      this.bos_token_id = kwargs.bos_token_id ?? null;
      this.eos_token_id = kwargs.eos_token_id ?? null;
      this.encoder_no_repeat_ngram_size = kwargs.encoder_no_repeat_ngram_size ?? 0;
      this.decoder_start_token_id = kwargs.decoder_start_token_id ?? null;
      this.generation_kwargs = kwargs.generation_kwargs ?? {};
    }
  }
);
class Sampler extends Callable {
  /**
   * Creates a new Sampler object with the specified generation config.
   * @param {GenerationConfigType} generation_config The generation config.
   */
  constructor(generation_config) {
    super();
    this.generation_config = generation_config;
  }
  /**
   * Executes the sampler, using the specified logits.
   * @param {Tensor} logits
   * @param {number} index
   * @returns {void}
   */
  _call(logits, index2 = -1) {
    return this.sample(logits, index2);
  }
  /**
   * Abstract method for sampling the logits.
   * @param {Tensor} logits
   * @param {number} index
   * @throws {Error}
   */
  sample(logits, index2) {
    throw Error("sample should be implemented in subclasses.");
  }
  /**
   * Returns the specified logits as an array, with temperature applied.
   * @param {Tensor} logits
   * @param {number} index
   * @returns {Float32Array}
   */
  getLogits(logits, index2) {
    let vocabSize = logits.dims.at(-1);
    let logs = (
      /** @type {Float32Array} */
      logits.data
    );
    if (index2 === -1) {
      logs = logs.slice(-vocabSize);
    } else {
      let startIndex = index2 * vocabSize;
      logs = logs.slice(startIndex, startIndex + vocabSize);
    }
    if (this.generation_config.temperature > 0) {
      logs = logs.map((x) => x / this.generation_config.temperature);
    }
    return logs;
  }
  /**
   * Selects an item randomly based on the specified probabilities.
   * @param {Array} probabilities An array of probabilities to use for selection.
   * @returns {number} The index of the selected item.
   */
  randomSelect(probabilities) {
    let sumProbabilities = probabilities.reduce((acc, curr) => acc + curr, 0);
    let r = Math.random() * sumProbabilities;
    for (let i2 = 0; i2 < probabilities.length; ++i2) {
      r -= probabilities[i2];
      if (r <= 0) {
        return i2;
      }
    }
    return 0;
  }
  /**
   * Returns a Sampler object based on the specified options.
   * @param {GenerationConfigType} generation_config An object containing options for the sampler.
   * @returns {Sampler} A Sampler object.
   */
  static getSampler(generation_config) {
    if (generation_config.do_sample) {
      return new MultinomialSampler(generation_config);
    } else if (generation_config.num_beams > 1) {
      return new BeamSearchSampler(generation_config);
    } else {
      if (generation_config.num_return_sequences > 1) {
        throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${generation_config.num_return_sequences}.`);
      }
      return new GreedySampler(generation_config);
    }
  }
}
class GreedySampler extends Sampler {
  /**
   * Sample the maximum probability of a given logits tensor.
   * @param {Tensor} logits
   * @param {number} [index=-1]
   * @returns {Array} An array with a single tuple, containing the index of the maximum value and a meaningless score (since this is a greedy search).
   */
  sample(logits, index2 = -1) {
    let logs = this.getLogits(logits, index2);
    let argmax = max(logs)[1];
    return [
      [argmax, 0]
    ];
  }
}
class MultinomialSampler extends Sampler {
  /**
   * Sample from the logits.
   * @param {Tensor} logits
   * @param {number} index
   * @returns {Array}
   */
  sample(logits, index2 = -1) {
    let k = logits.dims.at(-1);
    if (this.generation_config.top_k > 0) {
      k = Math.min(this.generation_config.top_k, k);
    }
    const logs = this.getLogits(logits, index2);
    const topLogits = getTopItems(logs, k);
    const probabilities = softmax(topLogits.map((x) => x[1]));
    return Array.from({ length: this.generation_config.num_beams }, () => {
      const sampledIndex = this.randomSelect(probabilities);
      return [
        topLogits[sampledIndex][0],
        // token id
        Math.log(probabilities[sampledIndex])
        // score
      ];
    });
  }
}
class BeamSearchSampler extends Sampler {
  /**
   * Sample from the logits.
   * @param {Tensor} logits
   * @param {number} index
   * @returns {Array}
   */
  sample(logits, index2 = -1) {
    let k = logits.dims.at(-1);
    if (this.generation_config.top_k > 0) {
      k = Math.min(this.generation_config.top_k, k);
    }
    const logs = this.getLogits(logits, index2);
    const topLogits = getTopItems(logs, k);
    const probabilities = softmax(topLogits.map((x) => x[1]));
    return Array.from({ length: this.generation_config.num_beams }, (_, i2) => {
      return [
        topLogits[i2][0],
        // token id
        Math.log(probabilities[i2])
        // score
      ];
    });
  }
}
const { InferenceSession, Tensor: ONNXTensor, env: env$2 } = ONNX;
const MODEL_TYPES = {
  EncoderOnly: 0,
  EncoderDecoder: 1,
  Seq2Seq: 2,
  Vision2Seq: 3,
  DecoderOnly: 4,
  MaskGeneration: 5
};
const MODEL_TYPE_MAPPING = /* @__PURE__ */ new Map();
const MODEL_NAME_TO_CLASS_MAPPING = /* @__PURE__ */ new Map();
const MODEL_CLASS_TO_NAME_MAPPING = /* @__PURE__ */ new Map();
async function constructSession(pretrained_model_name_or_path, fileName, options) {
  let modelFileName = `onnx/${fileName}${options.quantized ? "_quantized" : ""}.onnx`;
  let buffer2 = await getModelFile(pretrained_model_name_or_path, modelFileName, true, options);
  try {
    return await InferenceSession.create(buffer2, {
      executionProviders
    });
  } catch (err) {
    if (executionProviders.length === 1 && executionProviders[0] === "wasm") {
      throw err;
    }
    console.warn(err);
    console.warn(
      "Something went wrong during model construction (most likely a missing operation). Using `wasm` as a fallback. "
    );
    return await InferenceSession.create(buffer2, {
      executionProviders: ["wasm"]
    });
  }
}
function validateInputs(session, inputs) {
  const checkedInputs = /* @__PURE__ */ Object.create(null);
  const missingInputs = [];
  for (const inputName of session.inputNames) {
    const tensor = inputs[inputName];
    if (!(tensor instanceof Tensor)) {
      missingInputs.push(inputName);
      continue;
    }
    checkedInputs[inputName] = env$2.wasm.proxy ? tensor.clone() : tensor;
  }
  if (missingInputs.length > 0) {
    throw new Error(
      `An error occurred during model execution: "Missing the following inputs: ${missingInputs.join(", ")}.`
    );
  }
  const numInputsProvided = Object.keys(inputs).length;
  const numInputsNeeded = session.inputNames.length;
  if (numInputsProvided > numInputsNeeded) {
    let ignored = Object.keys(inputs).filter((inputName) => !session.inputNames.includes(inputName));
    console.warn(`WARNING: Too many inputs were provided (${numInputsProvided} > ${numInputsNeeded}). The following inputs will be ignored: "${ignored.join(", ")}".`);
  }
  return checkedInputs;
}
async function sessionRun(session, inputs) {
  const checkedInputs = validateInputs(session, inputs);
  try {
    let output2 = await session.run(checkedInputs);
    output2 = replaceTensors(output2);
    return output2;
  } catch (e) {
    console.error(`An error occurred during model execution: "${e}".`);
    console.error("Inputs given to model:", checkedInputs);
    throw e;
  }
}
function replaceTensors(obj) {
  for (let prop in obj) {
    if (obj[prop] instanceof ONNXTensor) {
      obj[prop] = new Tensor(obj[prop]);
    } else if (typeof obj[prop] === "object") {
      replaceTensors(obj[prop]);
    }
  }
  return obj;
}
function toI64Tensor(items2) {
  if (items2 instanceof Tensor) {
    return items2;
  }
  if (items2.length === 0) {
    throw Error("items must be non-empty");
  }
  if (Array.isArray(items2[0])) {
    if (items2.some((x) => x.length !== items2[0].length)) {
      throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");
    }
    return new Tensor(
      "int64",
      BigInt64Array.from(items2.flat().map((x) => BigInt(x))),
      [items2.length, items2[0].length]
    );
  } else {
    return new Tensor(
      "int64",
      BigInt64Array.from(items2.map((x) => BigInt(x))),
      [1, items2.length]
    );
  }
}
function prepareAttentionMask(self2, tokens) {
  let pad_token_id = self2.config.pad_token_id ?? null;
  let eos_token_id = self2.config.eos_token_id ?? null;
  if (isIntegralNumber(eos_token_id)) {
    eos_token_id = [eos_token_id];
  }
  let is_pad_token_in_inputs = tokens.indexOf(pad_token_id) !== -1;
  let is_pad_token_not_equal_to_eos_token_id = eos_token_id === null || !eos_token_id.includes(pad_token_id);
  if (is_pad_token_in_inputs && is_pad_token_not_equal_to_eos_token_id) {
    let data = BigInt64Array.from(
      // Note: != so that int matches bigint
      // @ts-ignore
      tokens.data.map((x) => x != pad_token_id)
    );
    return new Tensor("int64", data, tokens.dims);
  } else {
    return ones_like(tokens);
  }
}
function preparePositionIds(session, feeds, use_cache_branch) {
  if (!session.inputNames.includes("position_ids")) return;
  const data = new BigInt64Array(feeds.attention_mask.data.length);
  for (let i2 = 0; i2 < feeds.attention_mask.dims[0]; ++i2) {
    let start = i2 * feeds.attention_mask.dims[1];
    let sum = BigInt(0);
    for (let j = 0; j < feeds.attention_mask.dims[1]; ++j) {
      const index2 = start + j;
      if (feeds.attention_mask.data[index2] === 0n) {
        data[index2] = BigInt(1);
      } else {
        data[index2] = sum;
        sum += feeds.attention_mask.data[index2];
      }
    }
  }
  feeds.position_ids = new Tensor("int64", data, feeds.attention_mask.dims);
  if (use_cache_branch) {
    feeds.position_ids = feeds.position_ids.slice(null, -1).unsqueeze_(-1);
  }
}
function boolTensor(value) {
  return new Tensor("bool", [value], [1]);
}
async function seq2seqForward(self2, model_inputs) {
  let { encoder_outputs, past_key_values } = model_inputs;
  if (!encoder_outputs) {
    encoder_outputs = (await encoderForward(self2, model_inputs)).last_hidden_state;
  }
  let decoderFeeds = {
    input_ids: model_inputs.decoder_input_ids,
    encoder_hidden_states: encoder_outputs
  };
  const use_cache_branch = !!past_key_values;
  if (self2.decoder_merged_session.inputNames.includes("use_cache_branch")) {
    decoderFeeds.use_cache_branch = boolTensor(use_cache_branch);
  }
  if (self2.decoder_merged_session.inputNames.includes("encoder_attention_mask")) {
    decoderFeeds.encoder_attention_mask = model_inputs.attention_mask;
  }
  preparePositionIds(self2.decoder_merged_session, decoderFeeds, use_cache_branch);
  self2.addPastKeyValues(decoderFeeds, past_key_values);
  const decoderResults = await sessionRun(self2.decoder_merged_session, decoderFeeds);
  let logits = decoderResults.logits;
  past_key_values = self2.getPastKeyValues(decoderResults, past_key_values);
  const attns = self2.getAttentions(decoderResults);
  return new Seq2SeqLMOutput({ logits, past_key_values, encoder_outputs, ...attns });
}
function seq2seqStartBeams(self2, inputTokenIds, generation_config, numOutputTokens) {
  let beams = [];
  let beamId = 0;
  const requires_attention_mask = self2.requires_attention_mask ?? true;
  let decoder_input_ids = generation_config.decoder_input_ids ?? generation_config.decoder_start_token_id ?? generation_config.bos_token_id ?? generation_config.eos_token_id;
  if (decoder_input_ids instanceof Tensor) {
    decoder_input_ids = decoder_input_ids.tolist().flat();
  } else if (!Array.isArray(decoder_input_ids)) {
    decoder_input_ids = [decoder_input_ids];
  }
  for (let tokens of inputTokenIds) {
    tokens.dims = [1, ...tokens.dims];
    let start = {
      inputs: tokens,
      encoder_outputs: null,
      prev_model_outputs: null,
      output_token_ids: decoder_input_ids,
      done: false,
      score: 0,
      id: beamId++
      // assign unique id to beams
    };
    if (requires_attention_mask) {
      start.attention_mask = prepareAttentionMask(self2, tokens);
    }
    beams.push(start);
  }
  return beams;
}
async function seq2seqRunBeam(self2, beam) {
  var _a2;
  const input_name = self2.main_input_name;
  let decoder_input_ids = beam.output_token_ids;
  if (beam.prev_model_outputs) {
    decoder_input_ids = decoder_input_ids.slice(-1);
  }
  let model_inputs = {
    [input_name]: beam.inputs,
    decoder_input_ids: toI64Tensor(decoder_input_ids),
    encoder_outputs: beam.encoder_outputs,
    past_key_values: (_a2 = beam.prev_model_outputs) == null ? void 0 : _a2.past_key_values
  };
  if (beam.attention_mask) {
    model_inputs.attention_mask = beam.attention_mask;
  }
  let output2 = await self2.forward(model_inputs);
  beam.prev_model_outputs = output2;
  beam.encoder_outputs = output2.encoder_outputs;
  return output2;
}
function seq2seqUpdatebeam(beam, newTokenId) {
  beam.output_token_ids = [...beam.output_token_ids, newTokenId];
}
async function encoderForward(self2, model_inputs) {
  const encoderFeeds = /* @__PURE__ */ Object.create(null);
  for (const key of self2.session.inputNames) {
    encoderFeeds[key] = model_inputs[key];
  }
  if (self2.session.inputNames.includes("token_type_ids") && !encoderFeeds.token_type_ids) {
    encoderFeeds.token_type_ids = new Tensor(
      "int64",
      new BigInt64Array(encoderFeeds.input_ids.data.length),
      encoderFeeds.input_ids.dims
    );
  }
  return await sessionRun(self2.session, encoderFeeds);
}
async function decoderForward(self2, model_inputs) {
  let { input_ids, past_key_values, attention_mask } = model_inputs;
  let decoderFeeds = {
    input_ids,
    attention_mask: attention_mask ?? prepareAttentionMask(self2, input_ids)
  };
  const use_cache_branch = !!past_key_values;
  if (self2.session.inputNames.includes("use_cache_branch")) {
    decoderFeeds.use_cache_branch = boolTensor(use_cache_branch);
  }
  preparePositionIds(self2.session, decoderFeeds, use_cache_branch);
  self2.addPastKeyValues(decoderFeeds, past_key_values);
  let decoderResults = await sessionRun(self2.session, decoderFeeds);
  let logits = decoderResults.logits;
  past_key_values = self2.getPastKeyValues(decoderResults, past_key_values);
  return { logits, past_key_values };
}
function decoderStartBeams(self2, inputTokenIds, generation_config, numOutputTokens, inputs_attention_mask) {
  let beams = [];
  let beamId = 0;
  for (let tokens of inputTokenIds) {
    let output_token_ids = tokens.tolist().map(Number);
    tokens.dims = [1, ...tokens.dims];
    let attn_mask;
    if (inputs_attention_mask) {
      attn_mask = inputs_attention_mask[beamId];
      attn_mask.dims = [1, ...attn_mask.dims];
    } else {
      attn_mask = prepareAttentionMask(self2, tokens);
    }
    let start = {
      input: tokens,
      model_input_ids: tokens,
      attention_mask: attn_mask,
      prev_model_outputs: null,
      output_token_ids,
      num_output_tokens: numOutputTokens,
      done: false,
      score: 0,
      id: beamId++
      // assign unique id to beams
    };
    beams.push(start);
  }
  return beams;
}
async function decoderRunBeam(self2, beam) {
  var _a2;
  let attnMaskData = new BigInt64Array(beam.output_token_ids.length).fill(1n);
  let model_inputs = {
    input_ids: beam.model_input_ids,
    attention_mask: new Tensor(
      "int64",
      attnMaskData,
      [1, attnMaskData.length]
    ),
    past_key_values: (_a2 = beam.prev_model_outputs) == null ? void 0 : _a2.past_key_values
  };
  let output2 = await self2.forward(model_inputs);
  beam.prev_model_outputs = output2;
  return output2;
}
function decoderUpdatebeam(beam, newTokenId) {
  beam.output_token_ids = [...beam.output_token_ids, newTokenId];
  beam.model_input_ids = new Tensor("int64", [BigInt(newTokenId)], [1, 1]);
}
class PreTrainedModel extends Callable {
  /**
   * Creates a new instance of the `PreTrainedModel` class.
   * @param {Object} config The model configuration.
   * @param {any} session session for the model.
   */
  constructor(config2, session) {
    super();
    __publicField(this, "main_input_name", "input_ids");
    this.config = config2;
    this.session = session;
    const modelName = MODEL_CLASS_TO_NAME_MAPPING.get(this.constructor);
    const modelType = MODEL_TYPE_MAPPING.get(modelName);
    this.can_generate = false;
    this._runBeam = null;
    this._getStartBeams = null;
    this._updateBeam = null;
    this._forward = null;
    if (modelType === MODEL_TYPES.DecoderOnly) {
      this.can_generate = true;
      this._runBeam = decoderRunBeam;
      this._getStartBeams = decoderStartBeams;
      this._updateBeam = decoderUpdatebeam;
      this._forward = decoderForward;
    } else if (modelType === MODEL_TYPES.Seq2Seq || modelType === MODEL_TYPES.Vision2Seq) {
      this.can_generate = true;
      this._runBeam = seq2seqRunBeam;
      this._getStartBeams = seq2seqStartBeams;
      this._updateBeam = seq2seqUpdatebeam;
      this._forward = seq2seqForward;
    } else if (modelType === MODEL_TYPES.EncoderDecoder) {
      this._forward = encoderForward;
    } else {
      this._forward = encoderForward;
    }
  }
  /**
  * Disposes of all the ONNX sessions that were created during inference.
  * @returns {Promise<unknown[]>} An array of promises, one for each ONNX session that is being disposed.
  * @todo Use https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry
  */
  async dispose() {
    const promises = [];
    for (let key of Object.keys(this)) {
      const item = this[key];
      if (item instanceof InferenceSession) {
        promises.push(item.handler.dispose());
      }
    }
    return await Promise.all(promises);
  }
  /**
   * Instantiate one of the model classes of the library from a pretrained model.
   * 
   * The model class to instantiate is selected based on the `model_type` property of the config object
   * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)
   * 
   * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:
   * - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.
   *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a
   *   user or organization name, like `dbmdz/bert-base-german-cased`.
   * - A path to a *directory* containing model weights, e.g., `./my_model_directory/`.
   * @param {import('./utils/hub.js').PretrainedOptions} options Additional options for loading the model.
   * 
   * @returns {Promise<PreTrainedModel>} A new instance of the `PreTrainedModel` class.
   */
  static async from_pretrained(pretrained_model_name_or_path, {
    quantized = true,
    progress_callback = null,
    config: config2 = null,
    cache_dir = null,
    local_files_only = false,
    revision = "main",
    model_file_name = null
  } = {}) {
    let options = {
      quantized,
      progress_callback,
      config: config2,
      cache_dir,
      local_files_only,
      revision,
      model_file_name
    };
    const modelName = MODEL_CLASS_TO_NAME_MAPPING.get(this);
    const modelType = MODEL_TYPE_MAPPING.get(modelName);
    let info;
    if (modelType === MODEL_TYPES.DecoderOnly) {
      info = await Promise.all([
        AutoConfig.from_pretrained(pretrained_model_name_or_path, options),
        constructSession(pretrained_model_name_or_path, options.model_file_name ?? "decoder_model_merged", options),
        getModelJSON(pretrained_model_name_or_path, "generation_config.json", false, options)
      ]);
    } else if (modelType === MODEL_TYPES.Seq2Seq || modelType === MODEL_TYPES.Vision2Seq) {
      info = await Promise.all([
        AutoConfig.from_pretrained(pretrained_model_name_or_path, options),
        constructSession(pretrained_model_name_or_path, "encoder_model", options),
        constructSession(pretrained_model_name_or_path, "decoder_model_merged", options),
        getModelJSON(pretrained_model_name_or_path, "generation_config.json", false, options)
      ]);
    } else if (modelType === MODEL_TYPES.MaskGeneration) {
      info = await Promise.all([
        AutoConfig.from_pretrained(pretrained_model_name_or_path, options),
        constructSession(pretrained_model_name_or_path, "vision_encoder", options),
        constructSession(pretrained_model_name_or_path, "prompt_encoder_mask_decoder", options)
      ]);
    } else if (modelType === MODEL_TYPES.EncoderDecoder) {
      info = await Promise.all([
        AutoConfig.from_pretrained(pretrained_model_name_or_path, options),
        constructSession(pretrained_model_name_or_path, "encoder_model", options),
        constructSession(pretrained_model_name_or_path, "decoder_model_merged", options)
      ]);
    } else {
      if (modelType !== MODEL_TYPES.EncoderOnly) {
        console.warn(`Model type for '${modelName ?? (config2 == null ? void 0 : config2.model_type)}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`);
      }
      info = await Promise.all([
        AutoConfig.from_pretrained(pretrained_model_name_or_path, options),
        constructSession(pretrained_model_name_or_path, options.model_file_name ?? "model", options)
      ]);
    }
    return new this(...info);
  }
  /**
   * Runs the model with the provided inputs
   * @param {Object} model_inputs Object containing input tensors
   * @returns {Promise<Object>} Object containing output tensors
   */
  async _call(model_inputs) {
    return await this.forward(model_inputs);
  }
  /**
   * Forward method for a pretrained model. If not overridden by a subclass, the correct forward method
   * will be chosen based on the model type.
   * @param {Object} model_inputs The input data to the model in the format specified in the ONNX model.
   * @returns {Promise<Object>} The output data from the model in the format specified in the ONNX model.
   * @throws {Error} This method must be implemented in subclasses.
   */
  async forward(model_inputs) {
    return await this._forward(this, model_inputs);
  }
  /**
   * @param {import('./utils/generation.js').GenerationConfigType} generation_config 
   * @param {number} input_ids_seq_length The starting sequence length for the input ids.
   * @returns {LogitsProcessorList}
   * @private
   */
  _get_logits_processor(generation_config, input_ids_seq_length, logits_processor = null) {
    const processors = new LogitsProcessorList();
    if (generation_config.repetition_penalty !== null && generation_config.repetition_penalty !== 1) {
      processors.push(new RepetitionPenaltyLogitsProcessor(generation_config.repetition_penalty));
    }
    if (generation_config.no_repeat_ngram_size !== null && generation_config.no_repeat_ngram_size > 0) {
      processors.push(new NoRepeatNGramLogitsProcessor(generation_config.no_repeat_ngram_size));
    }
    if (generation_config.bad_words_ids !== null) {
      processors.push(new NoBadWordsLogitsProcessor(generation_config.bad_words_ids, generation_config.eos_token_id));
    }
    if (generation_config.min_length !== null && generation_config.eos_token_id !== null && generation_config.min_length > 0) {
      processors.push(new MinLengthLogitsProcessor(generation_config.min_length, generation_config.eos_token_id));
    }
    if (generation_config.min_new_tokens !== null && generation_config.eos_token_id !== null && generation_config.min_new_tokens > 0) {
      processors.push(new MinNewTokensLengthLogitsProcessor(
        input_ids_seq_length,
        generation_config.min_new_tokens,
        generation_config.eos_token_id
      ));
    }
    if (generation_config.forced_bos_token_id !== null) {
      processors.push(new ForcedBOSTokenLogitsProcessor(generation_config.forced_bos_token_id));
    }
    if (generation_config.forced_eos_token_id !== null) {
      processors.push(new ForcedEOSTokenLogitsProcessor(
        generation_config.max_length,
        generation_config.forced_eos_token_id
      ));
    }
    if (generation_config.begin_suppress_tokens !== null) {
      let begin_index = input_ids_seq_length > 1 || generation_config.forced_bos_token_id === null ? input_ids_seq_length : input_ids_seq_length + 1;
      if (generation_config.forced_decoder_ids !== null) {
        begin_index += generation_config.forced_decoder_ids[generation_config.forced_decoder_ids.length - 1][0];
      }
      processors.push(new SuppressTokensAtBeginLogitsProcessor(generation_config.begin_suppress_tokens, begin_index));
    }
    if (generation_config.forced_decoder_ids !== null) {
      processors.push(new ForceTokensLogitsProcessor(generation_config.forced_decoder_ids));
    }
    if (logits_processor !== null) {
      processors.extend(logits_processor);
    }
    return processors;
  }
  /**
   * This function merges multiple generation configs together to form a final generation config to be used by the model for text generation.
   * It first creates an empty `GenerationConfig` object, then it applies the model's own `generation_config` property to it. Finally, if a `generation_config` object was passed in the arguments, it overwrites the corresponding properties in the final config with those of the passed config object.
   * @param {import('./utils/generation.js').GenerationConfigType} generation_config A `GenerationConfig` object containing generation parameters.
   * @returns {import('./utils/generation.js').GenerationConfigType} The final generation config object to be used by the model for text generation.
   */
  _get_generation_config(generation_config) {
    let gen_config = new GenerationConfig(this.config);
    if ("generation_config" in this) {
      Object.assign(gen_config, this.generation_config);
    }
    if (generation_config !== null) {
      Object.assign(gen_config, generation_config);
    }
    return gen_config;
  }
  /**
   * @typedef {import('./utils/maths.js').TypedArray} TypedArray
   */
  /**
   * @typedef {{ sequences: Tensor, decoder_attentions: Tensor, cross_attentions: Tensor }} EncoderDecoderOutput
   * @typedef {Object} DecoderOutput
   * 
   * Generates text based on the given inputs and generation configuration using the model.
   * @param {Tensor|Array|TypedArray} inputs An array of input token IDs.
   * @param {Object|GenerationConfig|null} generation_config The generation configuration to use. If null, default configuration will be used.
   * @param {Object|null} logits_processor An optional logits processor to use. If null, a new LogitsProcessorList instance will be created.
   * @param {Object} options options
   * @param {Object} [options.inputs_attention_mask=null] An optional attention mask for the inputs.
   * @returns {Promise<number[][]|EncoderDecoderOutput|DecoderOutput>} An array of generated output sequences, where each sequence is an array of token IDs.
   * @throws {Error} Throws an error if the inputs array is empty.
   */
  async generate(inputs, generation_config = null, logits_processor = null, {
    inputs_attention_mask = null
  } = {}) {
    if (!this.can_generate) {
      const modelName = MODEL_CLASS_TO_NAME_MAPPING.get(this.constructor);
      let errorMessage = `The current model class (${modelName}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`;
      const modelType = this.config.model_type;
      const possibleInfo = MODEL_WITH_LM_HEAD_MAPPING_NAMES.get(modelType) ?? MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES.get(modelType) ?? MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES.get(modelType) ?? MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES.get(modelType);
      if (possibleInfo) {
        errorMessage += ` Please use the following class instead: '${possibleInfo[0]}'`;
      }
      throw Error(errorMessage);
    }
    if (!(inputs instanceof Tensor) && !isTypedArray(inputs) && !Array.isArray(inputs)) {
      throw Error(`\`inputs\` must be a Tensor, TypedArray, or Array, but is "${inputs.constructor.name}".`);
    }
    let input_ids_seq_length;
    if (this.config.is_encoder_decoder) {
      input_ids_seq_length = 0;
    } else {
      input_ids_seq_length = inputs instanceof Tensor ? inputs.dims.at(-1) : inputs.length;
      if (input_ids_seq_length === 0) {
        throw Error("Must supply a non-empty array of input token ids.");
      }
    }
    generation_config = this._get_generation_config(generation_config);
    logits_processor = logits_processor ?? new LogitsProcessorList();
    logits_processor = this._get_logits_processor(
      generation_config,
      input_ids_seq_length,
      logits_processor
    );
    let eos_token_ids = generation_config.eos_token_id;
    if (eos_token_ids !== null && !Array.isArray(eos_token_ids)) {
      eos_token_ids = [eos_token_ids];
    }
    let numOutputTokens = 1;
    const maxOutputTokens = numOutputTokens + (generation_config.max_new_tokens ?? Infinity);
    const useMaxLength = Number.isInteger(generation_config.max_length) && (generation_config.max_new_tokens ?? null) === null;
    let sampler = Sampler.getSampler(generation_config);
    let beams = this.getStartBeams(inputs, generation_config, numOutputTokens, inputs_attention_mask);
    while (beams.some((x) => !x.done) && numOutputTokens < maxOutputTokens) {
      let newest_beams = [];
      for (let beam of beams) {
        if (beam.done) {
          newest_beams.push(beam);
          continue;
        }
        if (useMaxLength && beam.output_token_ids.length >= generation_config.max_length) {
          beam.done = true;
          newest_beams.push(beam);
          continue;
        }
        let output2 = await this.runBeam(beam);
        if (generation_config.output_attentions) {
          this.addAttentionsToBeam(beam, output2);
        }
        if (generation_config.output_scores) ;
        let logits = output2.logits.slice(null, -1, null);
        logits_processor(beam.output_token_ids, logits);
        let sampledTokens = sampler(logits);
        for (let [newTokenId, logProb] of sampledTokens) {
          let newBeam = { ...beam };
          this.updateBeam(newBeam, newTokenId);
          newBeam.score += logProb;
          if (eos_token_ids && eos_token_ids.includes(newTokenId)) {
            newBeam.done = true;
          }
          newest_beams.push(newBeam);
        }
      }
      ++numOutputTokens;
      newest_beams = this.groupBeams(newest_beams).map(
        (group) => group.sort((a, b) => b.score - a.score).slice(0, generation_config.num_beams)
        // remove outside beam width
      );
      beams = newest_beams.flat();
      if (generation_config.callback_function) {
        generation_config.callback_function(beams);
      }
    }
    const groupedBeams = this.groupBeams(beams);
    const getFlattened = (key) => groupedBeams.map(
      (batch) => {
        if (generation_config.num_return_sequences > 1) {
          return batch.slice(0, generation_config.num_return_sequences).map((x) => x[key]);
        } else {
          return [batch[0][key]];
        }
      }
    ).flat();
    const sequences = getFlattened("output_token_ids");
    if (generation_config.return_dict_in_generate) {
      const decoder_attentions = getFlattened("decoder_attentions");
      const cross_attentions = getFlattened("cross_attentions");
      return {
        sequences,
        decoder_attentions,
        cross_attentions
      };
    } else {
      return sequences;
    }
  }
  /**
   * Helper function to add attentions to beam
   * @param {Object} beam 
   * @param {Object} output
   * @private 
   */
  addAttentionsToBeam(beam, output2) {
    if (this.config.is_encoder_decoder) {
      if (!output2.cross_attentions || output2.cross_attentions.length === 0) {
        throw Error(
          "`output_attentions` is true, but the model did not produce cross-attentions. This is most likely because the model was not exported with `output_attentions=True`."
        );
      }
      if (!beam.cross_attentions) {
        beam.cross_attentions = [];
      }
      beam.cross_attentions.push(output2.cross_attentions);
    }
    if (!output2.decoder_attentions || output2.decoder_attentions.length === 0) {
      throw Error(
        "`output_attentions` is true, but the model did not produce decoder-attentions. This is most likely because the model was not exported with `output_attentions=True`."
      );
    }
    if (!beam.decoder_attentions) {
      beam.decoder_attentions = [];
    }
    beam.decoder_attentions.push(output2.decoder_attentions);
  }
  /**
   * Groups an array of beam objects by their ids.
   *
   * @param {Array} beams The array of beam objects to group.
   * @returns {Array} An array of arrays, where each inner array contains beam objects with the same id.
   */
  groupBeams(beams) {
    const groups = /* @__PURE__ */ Object.create(null);
    for (const obj of beams) {
      if (groups[obj.id] === void 0) {
        groups[obj.id] = [obj];
      } else {
        groups[obj.id].push(obj);
      }
    }
    return Object.values(groups);
  }
  /**
   * Returns an object containing past key values from the given decoder results object.
   *
   * @param {Object} decoderResults The decoder results object.
   * @param {Object} pastKeyValues The previous past key values.
   * @returns {Object} An object containing past key values.
   */
  getPastKeyValues(decoderResults, pastKeyValues) {
    const pkvs = /* @__PURE__ */ Object.create(null);
    for (const name2 in decoderResults) {
      if (name2.startsWith("present")) {
        let newName = name2.replace("present", "past_key_values");
        if (pastKeyValues && name2.includes("encoder")) {
          pkvs[newName] = pastKeyValues[newName];
        } else {
          pkvs[newName] = decoderResults[name2];
        }
      }
    }
    return pkvs;
  }
  /**
   * Returns an object containing attentions from the given decoder results object.
   *
   * @param {Object} decoderResults The decoder results object.
   * @returns {Object} An object containing attentions.
   */
  getAttentions(decoderResults) {
    const attns = /* @__PURE__ */ Object.create(null);
    for (const attnName of ["cross_attentions", "decoder_attentions"]) {
      const result = [];
      for (const name2 in decoderResults) {
        if (name2.startsWith(attnName)) {
          const index2 = name2.split(".").pop();
          result[index2] = decoderResults[name2];
        }
      }
      attns[attnName] = result;
    }
    return attns;
  }
  /**
   * Adds past key values to the decoder feeds object. If pastKeyValues is null, creates new tensors for past key values.
   *
   * @param {Object} decoderFeeds The decoder feeds object to add past key values to.
   * @param {Object} pastKeyValues An object containing past key values.
   */
  addPastKeyValues(decoderFeeds, pastKeyValues) {
    if (pastKeyValues) {
      Object.assign(decoderFeeds, pastKeyValues);
    } else {
      const batch_size = 1;
      if (this.config.is_encoder_decoder && (this.add_encoder_pkv ?? true)) {
        let encoder_dims = [batch_size, this.num_encoder_heads, 0, this.encoder_dim_kv];
        let decoder_dims = [batch_size, this.num_decoder_heads, 0, this.decoder_dim_kv];
        for (let i2 = 0; i2 < this.num_decoder_layers; ++i2) {
          decoderFeeds[`past_key_values.${i2}.encoder.key`] = new Tensor("float32", [], encoder_dims);
          decoderFeeds[`past_key_values.${i2}.encoder.value`] = new Tensor("float32", [], encoder_dims);
          decoderFeeds[`past_key_values.${i2}.decoder.key`] = new Tensor("float32", [], decoder_dims);
          decoderFeeds[`past_key_values.${i2}.decoder.value`] = new Tensor("float32", [], decoder_dims);
        }
      } else if (this.config.model_type === "falcon") {
        let dims = [batch_size * this.num_heads, 0, this.dim_kv];
        for (let i2 = 0; i2 < this.num_layers; ++i2) {
          decoderFeeds[`past_key_values.${i2}.key`] = new Tensor("float32", [], dims);
          decoderFeeds[`past_key_values.${i2}.value`] = new Tensor("float32", [], dims);
        }
      } else if (this.config.multi_query) {
        let dims = [batch_size * this.num_heads, 0, 2 * this.dim_kv];
        for (let i2 = 0; i2 < this.num_layers; ++i2) {
          decoderFeeds[`past_key_values.${i2}.key_value`] = new Tensor("float32", [], dims);
        }
      } else if (this.config.model_type === "bloom") {
        let keyDims = [batch_size * this.num_heads, this.dim_kv, 0];
        let valueDims = [batch_size * this.num_heads, 0, this.dim_kv];
        for (let i2 = 0; i2 < this.num_layers; ++i2) {
          decoderFeeds[`past_key_values.${i2}.key`] = new Tensor("float32", [], keyDims);
          decoderFeeds[`past_key_values.${i2}.value`] = new Tensor("float32", [], valueDims);
        }
      } else {
        let dims = [batch_size, this.num_heads, 0, this.dim_kv];
        for (let i2 = 0; i2 < this.num_layers; ++i2) {
          decoderFeeds[`past_key_values.${i2}.key`] = new Tensor("float32", [], dims);
          decoderFeeds[`past_key_values.${i2}.value`] = new Tensor("float32", [], dims);
        }
      }
    }
  }
  /**
   * Initializes and returns the beam for text generation task
   * @param {Tensor} inputTokenIds The input token ids.
   * @param {Object} generation_config The generation config.
   * @param {number} numOutputTokens The number of tokens to be generated.
   * @param {Tensor} inputs_attention_mask Optional input attention mask.
   * @returns {any} A Beam object representing the initialized beam.
   * @private
   */
  getStartBeams(inputTokenIds, generation_config, numOutputTokens, inputs_attention_mask) {
    return this._getStartBeams(this, inputTokenIds, generation_config, numOutputTokens, inputs_attention_mask);
  }
  /**
   * Runs a single step of the beam search generation algorithm.
   * @param {any} beam The current beam being generated.
   * @returns {Promise<any>} The updated beam after a single generation step.
   * @private
   */
  async runBeam(beam) {
    return await this._runBeam(this, beam);
  }
  /**
   * Update a beam with a new token ID.
   * @param {Object} beam The beam to update.
   * @param {number} newTokenId The new token ID to add to the beam's output.
   * @private
   */
  updateBeam(beam, newTokenId) {
    return this._updateBeam(beam, newTokenId);
  }
}
class ModelOutput {
}
class BertPreTrainedModel extends PreTrainedModel {
}
class BertModel extends BertPreTrainedModel {
}
class BertForMaskedLM extends BertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class BertForSequenceClassification extends BertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class BertForTokenClassification extends BertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class BertForQuestionAnswering extends BertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class NomicBertPreTrainedModel extends PreTrainedModel {
}
class NomicBertModel extends NomicBertPreTrainedModel {
}
class RoFormerPreTrainedModel extends PreTrainedModel {
}
class RoFormerModel extends RoFormerPreTrainedModel {
}
class RoFormerForMaskedLM extends RoFormerPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class RoFormerForSequenceClassification extends RoFormerPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class RoFormerForTokenClassification extends RoFormerPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class RoFormerForQuestionAnswering extends RoFormerPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class ConvBertPreTrainedModel extends PreTrainedModel {
}
class ConvBertModel extends ConvBertPreTrainedModel {
}
class ConvBertForMaskedLM extends ConvBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class ConvBertForSequenceClassification extends ConvBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class ConvBertForTokenClassification extends ConvBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class ConvBertForQuestionAnswering extends ConvBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class ElectraPreTrainedModel extends PreTrainedModel {
}
class ElectraModel extends ElectraPreTrainedModel {
}
class ElectraForMaskedLM extends ElectraPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class ElectraForSequenceClassification extends ElectraPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class ElectraForTokenClassification extends ElectraPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class ElectraForQuestionAnswering extends ElectraPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class CamembertPreTrainedModel extends PreTrainedModel {
}
class CamembertModel extends CamembertPreTrainedModel {
}
class CamembertForMaskedLM extends CamembertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class CamembertForSequenceClassification extends CamembertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class CamembertForTokenClassification extends CamembertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class CamembertForQuestionAnswering extends CamembertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class DebertaPreTrainedModel extends PreTrainedModel {
}
class DebertaModel extends DebertaPreTrainedModel {
}
class DebertaForMaskedLM extends DebertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class DebertaForSequenceClassification extends DebertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class DebertaForTokenClassification extends DebertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class DebertaForQuestionAnswering extends DebertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class DebertaV2PreTrainedModel extends PreTrainedModel {
}
class DebertaV2Model extends DebertaV2PreTrainedModel {
}
class DebertaV2ForMaskedLM extends DebertaV2PreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class DebertaV2ForSequenceClassification extends DebertaV2PreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class DebertaV2ForTokenClassification extends DebertaV2PreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class DebertaV2ForQuestionAnswering extends DebertaV2PreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class DistilBertPreTrainedModel extends PreTrainedModel {
}
class DistilBertModel extends DistilBertPreTrainedModel {
}
class DistilBertForSequenceClassification extends DistilBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class DistilBertForTokenClassification extends DistilBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class DistilBertForQuestionAnswering extends DistilBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class DistilBertForMaskedLM extends DistilBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} returned object
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class EsmPreTrainedModel extends PreTrainedModel {
}
class EsmModel extends EsmPreTrainedModel {
}
class EsmForMaskedLM extends EsmPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class EsmForSequenceClassification extends EsmPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class EsmForTokenClassification extends EsmPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class MobileBertPreTrainedModel extends PreTrainedModel {
}
class MobileBertModel extends MobileBertPreTrainedModel {
}
class MobileBertForMaskedLM extends MobileBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} returned object
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class MobileBertForSequenceClassification extends MobileBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} returned object
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class MobileBertForQuestionAnswering extends MobileBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} returned object
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class MPNetPreTrainedModel extends PreTrainedModel {
}
class MPNetModel extends MPNetPreTrainedModel {
}
class MPNetForMaskedLM extends MPNetPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class MPNetForSequenceClassification extends MPNetPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class MPNetForTokenClassification extends MPNetPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class MPNetForQuestionAnswering extends MPNetPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class SqueezeBertPreTrainedModel extends PreTrainedModel {
}
class SqueezeBertModel extends SqueezeBertPreTrainedModel {
}
class SqueezeBertForMaskedLM extends SqueezeBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} returned object
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class SqueezeBertForSequenceClassification extends SqueezeBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} returned object
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class SqueezeBertForQuestionAnswering extends SqueezeBertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} returned object
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class AlbertPreTrainedModel extends PreTrainedModel {
}
class AlbertModel extends AlbertPreTrainedModel {
}
class AlbertForSequenceClassification extends AlbertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} returned object
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class AlbertForQuestionAnswering extends AlbertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} returned object
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class AlbertForMaskedLM extends AlbertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} returned object
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class T5PreTrainedModel extends PreTrainedModel {
}
class T5Model extends T5PreTrainedModel {
}
class T5ForConditionalGeneration extends T5PreTrainedModel {
  /**
   * Creates a new instance of the `T5ForConditionalGeneration` class.
   * @param {Object} config The model configuration.
   * @param {any} session session for the model.
   * @param {any} decoder_merged_session session for the decoder.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.num_decoder_layers;
    this.num_decoder_heads = this.config.num_heads;
    this.decoder_dim_kv = this.config.d_kv;
    this.num_encoder_layers = this.config.num_layers;
    this.num_encoder_heads = this.config.num_heads;
    this.encoder_dim_kv = this.config.d_kv;
  }
}
class LongT5PreTrainedModel extends PreTrainedModel {
}
class LongT5Model extends LongT5PreTrainedModel {
}
class LongT5ForConditionalGeneration extends LongT5PreTrainedModel {
  /**
   * Creates a new instance of the `LongT5ForConditionalGeneration` class.
   * @param {Object} config The model configuration.
   * @param {any} session session for the model.
   * @param {any} decoder_merged_session session for the decoder.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.num_decoder_layers;
    this.num_decoder_heads = this.config.num_heads;
    this.decoder_dim_kv = this.config.d_kv;
    this.num_encoder_layers = this.config.num_layers;
    this.num_encoder_heads = this.config.num_heads;
    this.encoder_dim_kv = this.config.d_kv;
  }
}
class MT5PreTrainedModel extends PreTrainedModel {
}
class MT5Model extends MT5PreTrainedModel {
}
class MT5ForConditionalGeneration extends MT5PreTrainedModel {
  /**
   * Creates a new instance of the `MT5ForConditionalGeneration` class.
   * @param {any} config The model configuration.
   * @param {any} session The ONNX session containing the encoder weights.
   * @param {any} decoder_merged_session The ONNX session containing the merged decoder weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.num_decoder_layers;
    this.num_decoder_heads = this.config.num_heads;
    this.decoder_dim_kv = this.config.d_kv;
    this.num_encoder_layers = this.config.num_layers;
    this.num_encoder_heads = this.config.num_heads;
    this.encoder_dim_kv = this.config.d_kv;
  }
}
class BartPretrainedModel extends PreTrainedModel {
}
class BartModel extends BartPretrainedModel {
}
class BartForConditionalGeneration extends BartPretrainedModel {
  /**
   * Creates a new instance of the `BartForConditionalGeneration` class.
   * @param {Object} config The configuration object for the Bart model.
   * @param {Object} session The ONNX session used to execute the model.
   * @param {Object} decoder_merged_session The ONNX session used to execute the decoder.
   * @param {Object} generation_config The generation configuration object.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.decoder_layers;
    this.num_decoder_heads = this.config.decoder_attention_heads;
    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;
    this.num_encoder_layers = this.config.encoder_layers;
    this.num_encoder_heads = this.config.encoder_attention_heads;
    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;
  }
}
class BartForSequenceClassification extends BartPretrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class MBartPreTrainedModel extends PreTrainedModel {
}
class MBartModel extends MBartPreTrainedModel {
}
class MBartForConditionalGeneration extends MBartPreTrainedModel {
  /**
   * Creates a new instance of the `MBartForConditionalGeneration` class.
   * @param {Object} config The configuration object for the Bart model.
   * @param {Object} session The ONNX session used to execute the model.
   * @param {Object} decoder_merged_session The ONNX session used to execute the decoder.
   * @param {Object} generation_config The generation configuration object.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.decoder_layers;
    this.num_decoder_heads = this.config.decoder_attention_heads;
    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;
    this.num_encoder_layers = this.config.encoder_layers;
    this.num_encoder_heads = this.config.encoder_attention_heads;
    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;
  }
}
class MBartForSequenceClassification extends MBartPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class MBartForCausalLM extends MBartPreTrainedModel {
  /**
   * Creates a new instance of the `MBartForCausalLM` class.
   * @param {Object} config Configuration object for the model.
   * @param {Object} decoder_merged_session ONNX Session object for the decoder.
   * @param {Object} generation_config Configuration object for the generation process.
   */
  constructor(config2, decoder_merged_session, generation_config) {
    super(config2, decoder_merged_session);
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.decoder_layers;
    this.num_decoder_heads = this.config.decoder_attention_heads;
    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;
    this.num_encoder_layers = this.config.encoder_layers;
    this.num_encoder_heads = this.config.encoder_attention_heads;
    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;
  }
}
class BlenderbotPreTrainedModel extends PreTrainedModel {
}
class BlenderbotModel extends BlenderbotPreTrainedModel {
}
class BlenderbotForConditionalGeneration extends BlenderbotPreTrainedModel {
  /**
   * Creates a new instance of the `BlenderbotForConditionalGeneration` class.
   * @param {any} config The model configuration.
   * @param {any} session The ONNX session containing the encoder weights.
   * @param {any} decoder_merged_session The ONNX session containing the merged decoder weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.decoder_layers;
    this.num_decoder_heads = this.config.decoder_attention_heads;
    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;
    this.num_encoder_layers = this.config.encoder_layers;
    this.num_encoder_heads = this.config.encoder_attention_heads;
    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;
  }
}
class BlenderbotSmallPreTrainedModel extends PreTrainedModel {
}
class BlenderbotSmallModel extends BlenderbotSmallPreTrainedModel {
}
class BlenderbotSmallForConditionalGeneration extends BlenderbotSmallPreTrainedModel {
  /**
   * Creates a new instance of the `BlenderbotForConditionalGeneration` class.
   * @param {any} config The model configuration.
   * @param {any} session The ONNX session containing the encoder weights.
   * @param {any} decoder_merged_session The ONNX session containing the merged decoder weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.decoder_layers;
    this.num_decoder_heads = this.config.decoder_attention_heads;
    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;
    this.num_encoder_layers = this.config.encoder_layers;
    this.num_encoder_heads = this.config.encoder_attention_heads;
    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;
  }
}
class RobertaPreTrainedModel extends PreTrainedModel {
}
class RobertaModel extends RobertaPreTrainedModel {
}
class RobertaForMaskedLM extends RobertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} returned object
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class RobertaForSequenceClassification extends RobertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} returned object
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class RobertaForTokenClassification extends RobertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class RobertaForQuestionAnswering extends RobertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} returned object
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class XLMPreTrainedModel extends PreTrainedModel {
}
class XLMModel extends XLMPreTrainedModel {
}
class XLMWithLMHeadModel extends XLMPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} returned object
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class XLMForSequenceClassification extends XLMPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} returned object
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class XLMForTokenClassification extends XLMPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class XLMForQuestionAnswering extends XLMPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} returned object
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class XLMRobertaPreTrainedModel extends PreTrainedModel {
}
class XLMRobertaModel extends XLMRobertaPreTrainedModel {
}
class XLMRobertaForMaskedLM extends XLMRobertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<MaskedLMOutput>} returned object
   */
  async _call(model_inputs) {
    return new MaskedLMOutput(await super._call(model_inputs));
  }
}
class XLMRobertaForSequenceClassification extends XLMRobertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} returned object
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class XLMRobertaForTokenClassification extends XLMRobertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class XLMRobertaForQuestionAnswering extends XLMRobertaPreTrainedModel {
  /**
   * Calls the model on new inputs.
   *
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<QuestionAnsweringModelOutput>} returned object
   */
  async _call(model_inputs) {
    return new QuestionAnsweringModelOutput(await super._call(model_inputs));
  }
}
class ASTPreTrainedModel extends PreTrainedModel {
}
class ASTModel extends ASTPreTrainedModel {
}
class ASTForAudioClassification extends ASTPreTrainedModel {
}
class WhisperPreTrainedModel extends PreTrainedModel {
}
class WhisperModel extends WhisperPreTrainedModel {
}
class WhisperForConditionalGeneration extends WhisperPreTrainedModel {
  /**
   * Creates a new instance of the `WhisperForConditionalGeneration` class.
   * @param {Object} config Configuration object for the model.
   * @param {Object} session ONNX Session object for the model.
   * @param {Object} decoder_merged_session ONNX Session object for the decoder.
   * @param {Object} generation_config Configuration object for the generation process.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    __publicField(this, "requires_attention_mask", false);
    __publicField(this, "main_input_name", "input_features");
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.decoder_layers;
    this.num_decoder_heads = this.config.decoder_attention_heads;
    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;
    this.num_encoder_layers = this.config.encoder_layers;
    this.num_encoder_heads = this.config.encoder_attention_heads;
    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;
  }
  /**
   * @typedef {Object} WhisperGenerationConfig
   * @extends GenerationConfig
   * @property {boolean} [return_timestamps=null] Whether to return the timestamps with the text. This enables the `WhisperTimestampsLogitsProcessor`.
   * @property {boolean} [return_token_timestamps=null] Whether to return token-level timestamps
   * with the text. This can be used with or without the `return_timestamps` option. To get word-level
   * timestamps, use the tokenizer to group the tokens into words.
   * @property {number} [num_frames=null]  The number of audio frames available in this chunk. This is only used generating word-level timestamps.
   */
  /**
   * Generates outputs based on input and generation configuration.
   * @param {Object} inputs Input data for the model.
   * @param {WhisperGenerationConfig} generation_config Configuration object for the generation process.
   * @param {Object} logits_processor Optional logits processor object.
   * @returns {Promise<Object>} Promise object represents the generated outputs.
   */
  async generate(inputs, generation_config = null, logits_processor = null) {
    generation_config = this._get_generation_config(generation_config);
    generation_config.return_timestamps ?? (generation_config.return_timestamps = false);
    if (generation_config.return_timestamps) {
      logits_processor = [new WhisperTimeStampLogitsProcessor(generation_config)];
    }
    if (generation_config.return_token_timestamps) {
      generation_config.output_attentions = true;
      generation_config.return_dict_in_generate = true;
      if (generation_config.task === "translate") {
        console.warn("Token-level timestamps may not be reliable for task 'translate'.");
      }
      if (!generation_config.alignment_heads) {
        throw new Error(
          "Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config."
        );
      }
    }
    const outputs = await super.generate(inputs, generation_config, logits_processor);
    if (generation_config.return_token_timestamps && generation_config.alignment_heads) {
      outputs["token_timestamps"] = this._extract_token_timestamps(
        outputs,
        generation_config.alignment_heads,
        generation_config.num_frames
      );
    }
    return outputs;
  }
  /**
   * Calculates token-level timestamps using the encoder-decoder cross-attentions and
   * dynamic time-warping (DTW) to map each output token to a position in the input audio.
   * @param {Object} generate_outputs Outputs generated by the model
   * @param {Tensor[][][]} generate_outputs.cross_attentions The cross attentions output by the model
   * @param {Tensor[][][]} generate_outputs.decoder_attentions The decoder attentions output by the model
   * @param {number[][]} generate_outputs.sequences The sequences output by the model
   * @param {number[][]} alignment_heads Alignment heads of the model
   * @param {number} [num_frames=null] Number of frames in the input audio.
   * @param {number} [time_precision=0.02] Precision of the timestamps in seconds
   * @returns {Tensor} tensor containing the timestamps in seconds for each predicted token
   */
  _extract_token_timestamps(generate_outputs, alignment_heads, num_frames = null, time_precision = 0.02) {
    if (!generate_outputs.cross_attentions) {
      throw new Error(
        "Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`."
      );
    }
    let median_filter_width = this.config.median_filter_width;
    if (median_filter_width === void 0) {
      console.warn("Model config has no `median_filter_width`, using default value of 7.");
      median_filter_width = 7;
    }
    const batchedMatrices = generate_outputs.cross_attentions.map((batch) => {
      let cross_attentions = Array.from(
        { length: this.config.decoder_layers },
        (_, i2) => cat(batch.map((x) => x[i2]), 2)
      );
      let weights = stack(alignment_heads.map(([l, h]) => {
        return num_frames ? cross_attentions[l].slice(null, h, null, [0, num_frames]) : cross_attentions[l].slice(null, h);
      }));
      weights = weights.transpose(1, 0, 2, 3);
      let [std, calculatedMean] = std_mean(weights, -2, 0, true);
      let smoothedWeights = weights.clone();
      for (let a = 0; a < smoothedWeights.dims[0]; ++a) {
        let aTensor = smoothedWeights[a];
        for (let b = 0; b < aTensor.dims[0]; ++b) {
          let bTensor = aTensor[b];
          const stdTensor = std[a][b][0];
          const meanTensor = calculatedMean[a][b][0];
          for (let c = 0; c < bTensor.dims[0]; ++c) {
            let cTensor = bTensor[c];
            for (let d = 0; d < cTensor.data.length; ++d) {
              cTensor.data[d] = (cTensor.data[d] - meanTensor.data[d]) / stdTensor.data[d];
            }
            cTensor.data.set(medianFilter(cTensor.data, median_filter_width));
          }
        }
      }
      const matrix = mean(smoothedWeights, 1);
      return matrix;
    });
    const timestampsShape = [generate_outputs.sequences.length, generate_outputs.sequences[0].length];
    const timestamps = new Tensor(
      "float32",
      new Float32Array(timestampsShape[0] * timestampsShape[1]),
      timestampsShape
    );
    for (let batch_idx = 0; batch_idx < timestampsShape[0]; ++batch_idx) {
      const matrix = batchedMatrices[batch_idx].neg().squeeze_(0);
      let [text_indices, time_indices] = dynamicTimeWarping(matrix);
      let diffs = Array.from({ length: text_indices.length - 1 }, (v, i2) => text_indices[i2 + 1] - text_indices[i2]);
      let jumps = mergeArrays([1], diffs).map((x) => !!x);
      let jump_times = [];
      for (let i2 = 0; i2 < jumps.length; ++i2) {
        if (jumps[i2]) {
          jump_times.push(time_indices[i2] * time_precision);
        }
      }
      timestamps[batch_idx].data.set(jump_times, 1);
    }
    return timestamps;
  }
}
class VisionEncoderDecoderModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `VisionEncoderDecoderModel` class.
   * @param {Object} config The configuration object specifying the hyperparameters and other model settings.
   * @param {Object} session The ONNX session containing the encoder model.
   * @param {any} decoder_merged_session The ONNX session containing the merged decoder model.
   * @param {Object} generation_config Configuration object for the generation process.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    __publicField(this, "main_input_name", "pixel_values");
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    const encoderConfig = this.config.encoder;
    const decoderConfig = this.config.decoder;
    const encoderModelType = encoderConfig.model_type;
    const encoderModel = MODEL_MAPPING_NAMES_ENCODER_ONLY.get(encoderModelType) ?? MODEL_MAPPING_NAMES_ENCODER_DECODER.get(encoderModelType);
    if (!encoderModel) {
      console.warn(`Model type for encoder '${encoderModelType}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`);
    }
    const decoderModel = MODEL_WITH_LM_HEAD_MAPPING_NAMES.get(decoderConfig.model_type);
    if (!decoderModel) {
      throw new Error(`Unable to construct \`VisionEncoderDecoder\` due to unsupported decoder: "${this.config.decoder.model_type}"`);
    }
    const decoderModelClass = decoderModel[1];
    const decoder = new decoderModelClass(decoderConfig, decoder_merged_session, generation_config);
    this.add_encoder_pkv = "num_decoder_layers" in decoder;
    if (this.add_encoder_pkv) {
      this.num_decoder_layers = decoder.num_decoder_layers;
      this.num_decoder_heads = decoder.num_decoder_heads;
      this.decoder_dim_kv = decoder.decoder_dim_kv;
      this.num_encoder_layers = decoder.num_encoder_layers;
      this.num_encoder_heads = decoder.num_encoder_heads;
      this.encoder_dim_kv = decoder.encoder_dim_kv;
    } else {
      this.num_layers = decoder.num_layers;
      this.num_heads = decoder.num_heads;
      this.dim_kv = decoder.dim_kv;
    }
  }
}
class CLIPPreTrainedModel extends PreTrainedModel {
}
class CLIPModel extends CLIPPreTrainedModel {
}
class CLIPTextModelWithProjection extends CLIPPreTrainedModel {
  /** @type {PreTrainedModel.from_pretrained} */
  static async from_pretrained(pretrained_model_name_or_path, options = {}) {
    options.model_file_name ?? (options.model_file_name = "text_model");
    return super.from_pretrained(pretrained_model_name_or_path, options);
  }
}
class CLIPVisionModelWithProjection extends CLIPPreTrainedModel {
  /** @type {PreTrainedModel.from_pretrained} */
  static async from_pretrained(pretrained_model_name_or_path, options = {}) {
    options.model_file_name ?? (options.model_file_name = "vision_model");
    return super.from_pretrained(pretrained_model_name_or_path, options);
  }
}
class SiglipPreTrainedModel extends PreTrainedModel {
}
class SiglipModel extends SiglipPreTrainedModel {
}
class SiglipTextModel extends SiglipPreTrainedModel {
  /** @type {PreTrainedModel.from_pretrained} */
  static async from_pretrained(pretrained_model_name_or_path, options = {}) {
    options.model_file_name ?? (options.model_file_name = "text_model");
    return super.from_pretrained(pretrained_model_name_or_path, options);
  }
}
class SiglipVisionModel extends CLIPPreTrainedModel {
  /** @type {PreTrainedModel.from_pretrained} */
  static async from_pretrained(pretrained_model_name_or_path, options = {}) {
    options.model_file_name ?? (options.model_file_name = "vision_model");
    return super.from_pretrained(pretrained_model_name_or_path, options);
  }
}
class ChineseCLIPPreTrainedModel extends PreTrainedModel {
}
class ChineseCLIPModel extends ChineseCLIPPreTrainedModel {
}
class CLIPSegPreTrainedModel extends PreTrainedModel {
}
class CLIPSegModel extends CLIPSegPreTrainedModel {
}
class CLIPSegForImageSegmentation extends CLIPSegPreTrainedModel {
}
class GPT2PreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `GPT2PreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.n_head;
    this.num_layers = this.config.n_layer;
    this.dim_kv = this.config.n_embd / this.num_heads;
  }
}
class GPT2Model extends GPT2PreTrainedModel {
}
class GPT2LMHeadModel extends GPT2PreTrainedModel {
}
class GPTNeoPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `GPTNeoPreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_heads;
    this.num_layers = this.config.num_layers;
    this.dim_kv = this.config.hidden_size / this.num_heads;
  }
}
class GPTNeoModel extends GPTNeoPreTrainedModel {
}
class GPTNeoForCausalLM extends GPTNeoPreTrainedModel {
}
class GPTNeoXPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `GPTNeoXPreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_attention_heads;
    this.num_layers = this.config.num_hidden_layers;
    this.dim_kv = this.config.hidden_size / this.num_heads;
  }
}
class GPTNeoXModel extends GPTNeoXPreTrainedModel {
}
class GPTNeoXForCausalLM extends GPTNeoXPreTrainedModel {
}
class GPTJPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `GPTJPreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.n_head;
    this.num_layers = this.config.n_layer;
    this.dim_kv = this.config.n_embd / this.num_heads;
  }
}
class GPTJModel extends GPTJPreTrainedModel {
}
class GPTJForCausalLM extends GPTJPreTrainedModel {
}
class GPTBigCodePreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `GPTBigCodePreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.n_head;
    this.num_layers = this.config.n_layer;
    this.dim_kv = this.config.n_embd / this.num_heads;
  }
}
class GPTBigCodeModel extends GPTBigCodePreTrainedModel {
}
class GPTBigCodeForCausalLM extends GPTBigCodePreTrainedModel {
}
class CodeGenPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `CodeGenPreTrainedModel` class.
   * @param {Object} config The model configuration object.
   * @param {Object} session The ONNX session object.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.n_head;
    this.num_layers = this.config.n_layer;
    this.dim_kv = this.config.n_embd / this.num_heads;
  }
}
class CodeGenModel extends CodeGenPreTrainedModel {
}
class CodeGenForCausalLM extends CodeGenPreTrainedModel {
}
class LlamaPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `LlamaPreTrainedModel` class.
   * @param {Object} config The model configuration object.
   * @param {Object} session The ONNX session object.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_key_value_heads ?? this.config.num_attention_heads;
    this.num_layers = this.config.num_hidden_layers;
    this.dim_kv = this.config.hidden_size / this.config.num_attention_heads;
  }
}
class LlamaModel extends LlamaPreTrainedModel {
}
class LlamaForCausalLM extends LlamaPreTrainedModel {
}
class Qwen2PreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `Qwen2PreTrainedModel` class.
   * @param {Object} config The model configuration object.
   * @param {Object} session The ONNX session object.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_key_value_heads ?? this.config.num_attention_heads;
    this.num_layers = this.config.num_hidden_layers;
    this.dim_kv = this.config.hidden_size / this.config.num_attention_heads;
  }
}
class Qwen2Model extends Qwen2PreTrainedModel {
}
class Qwen2ForCausalLM extends Qwen2PreTrainedModel {
}
class PhiPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `PhiPreTrainedModel` class.
   * @param {Object} config The model configuration object.
   * @param {Object} session The ONNX session object.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_attention_heads;
    this.num_layers = this.config.num_hidden_layers;
    this.dim_kv = this.config.hidden_size / this.num_heads;
  }
}
class PhiModel extends PhiPreTrainedModel {
}
class PhiForCausalLM extends PhiPreTrainedModel {
}
class BloomPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `BloomPreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.n_head;
    this.num_layers = this.config.n_layer;
    this.dim_kv = this.config.hidden_size / this.num_heads;
  }
}
class BloomModel extends BloomPreTrainedModel {
}
class BloomForCausalLM extends BloomPreTrainedModel {
}
class MptPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `MptPreTrainedModel` class.
   * @param {Object} config The model configuration object.
   * @param {Object} session The ONNX session object.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.n_heads;
    this.num_layers = this.config.n_layers;
    this.dim_kv = this.config.d_model / this.num_heads;
  }
}
class MptModel extends MptPreTrainedModel {
}
class MptForCausalLM extends MptPreTrainedModel {
}
class OPTPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `OPTPreTrainedModel` class.
   * @param {Object} config The model configuration object.
   * @param {Object} session The ONNX session object.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_attention_heads;
    this.num_layers = this.config.num_hidden_layers;
    this.dim_kv = this.config.hidden_size / this.num_heads;
  }
}
class OPTModel extends OPTPreTrainedModel {
}
class OPTForCausalLM extends OPTPreTrainedModel {
}
class ViTPreTrainedModel extends PreTrainedModel {
}
class ViTModel extends ViTPreTrainedModel {
}
class ViTForImageClassification extends ViTPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class FastViTPreTrainedModel extends PreTrainedModel {
}
class FastViTModel extends FastViTPreTrainedModel {
}
class FastViTForImageClassification extends FastViTPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class VitMattePreTrainedModel extends PreTrainedModel {
}
class VitMatteForImageMatting extends VitMattePreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new ImageMattingOutput(await super._call(model_inputs));
  }
}
class MobileViTPreTrainedModel extends PreTrainedModel {
}
class MobileViTModel extends MobileViTPreTrainedModel {
}
class MobileViTForImageClassification extends MobileViTPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class MobileViTV2PreTrainedModel extends PreTrainedModel {
}
class MobileViTV2Model extends MobileViTV2PreTrainedModel {
}
class MobileViTV2ForImageClassification extends MobileViTV2PreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class OwlViTPreTrainedModel extends PreTrainedModel {
}
class OwlViTModel extends OwlViTPreTrainedModel {
}
class OwlViTForObjectDetection extends OwlViTPreTrainedModel {
}
class Owlv2PreTrainedModel extends PreTrainedModel {
}
class Owlv2Model extends Owlv2PreTrainedModel {
}
class Owlv2ForObjectDetection extends Owlv2PreTrainedModel {
}
class BeitPreTrainedModel extends PreTrainedModel {
}
class BeitModel extends BeitPreTrainedModel {
}
class BeitForImageClassification extends BeitPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class DetrPreTrainedModel extends PreTrainedModel {
}
class DetrModel extends DetrPreTrainedModel {
}
class DetrForObjectDetection extends DetrPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new DetrObjectDetectionOutput(await super._call(model_inputs));
  }
}
class DetrForSegmentation extends DetrPreTrainedModel {
  /**
   * Runs the model with the provided inputs
   * @param {Object} model_inputs Model inputs
   * @returns {Promise<DetrSegmentationOutput>} Object containing segmentation outputs
   */
  async _call(model_inputs) {
    return new DetrSegmentationOutput(await super._call(model_inputs));
  }
}
class DetrObjectDetectionOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.logits Classification logits (including no-object) for all queries.
   * @param {Tensor} output.pred_boxes Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height).
   * These values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding possible padding).
   */
  constructor({ logits, pred_boxes }) {
    super();
    this.logits = logits;
    this.pred_boxes = pred_boxes;
  }
}
class DetrSegmentationOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.logits The output logits of the model.
   * @param {Tensor} output.pred_boxes Predicted boxes.
   * @param {Tensor} output.pred_masks Predicted masks.
   */
  constructor({ logits, pred_boxes, pred_masks }) {
    super();
    this.logits = logits;
    this.pred_boxes = pred_boxes;
    this.pred_masks = pred_masks;
  }
}
class TableTransformerPreTrainedModel extends PreTrainedModel {
}
class TableTransformerModel extends TableTransformerPreTrainedModel {
}
class TableTransformerForObjectDetection extends TableTransformerPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new TableTransformerObjectDetectionOutput(await super._call(model_inputs));
  }
}
class TableTransformerObjectDetectionOutput extends DetrObjectDetectionOutput {
}
class DeiTPreTrainedModel extends PreTrainedModel {
}
class DeiTModel extends DeiTPreTrainedModel {
}
class DeiTForImageClassification extends DeiTPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class ResNetPreTrainedModel extends PreTrainedModel {
}
class ResNetModel extends ResNetPreTrainedModel {
}
class ResNetForImageClassification extends ResNetPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class SwinPreTrainedModel extends PreTrainedModel {
}
class SwinModel extends SwinPreTrainedModel {
}
class SwinForImageClassification extends SwinPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class Swin2SRPreTrainedModel extends PreTrainedModel {
}
class Swin2SRModel extends Swin2SRPreTrainedModel {
}
class Swin2SRForImageSuperResolution extends Swin2SRPreTrainedModel {
}
class DPTPreTrainedModel extends PreTrainedModel {
}
class DPTModel extends DPTPreTrainedModel {
}
class DPTForDepthEstimation extends DPTPreTrainedModel {
}
class DepthAnythingPreTrainedModel extends PreTrainedModel {
}
class DepthAnythingForDepthEstimation extends DepthAnythingPreTrainedModel {
}
class GLPNPreTrainedModel extends PreTrainedModel {
}
class GLPNModel extends GLPNPreTrainedModel {
}
class GLPNForDepthEstimation extends GLPNPreTrainedModel {
}
class DonutSwinPreTrainedModel extends PreTrainedModel {
}
class DonutSwinModel extends DonutSwinPreTrainedModel {
}
class ConvNextPreTrainedModel extends PreTrainedModel {
}
class ConvNextModel extends ConvNextPreTrainedModel {
}
class ConvNextForImageClassification extends ConvNextPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class ConvNextV2PreTrainedModel extends PreTrainedModel {
}
class ConvNextV2Model extends ConvNextV2PreTrainedModel {
}
class ConvNextV2ForImageClassification extends ConvNextV2PreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class Dinov2PreTrainedModel extends PreTrainedModel {
}
class Dinov2Model extends Dinov2PreTrainedModel {
}
class Dinov2ForImageClassification extends Dinov2PreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class YolosPreTrainedModel extends PreTrainedModel {
}
class YolosModel extends YolosPreTrainedModel {
}
class YolosForObjectDetection extends YolosPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new YolosObjectDetectionOutput(await super._call(model_inputs));
  }
}
class YolosObjectDetectionOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.logits Classification logits (including no-object) for all queries.
   * @param {Tensor} output.pred_boxes Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height).
   * These values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding possible padding).
   */
  constructor({ logits, pred_boxes }) {
    super();
    this.logits = logits;
    this.pred_boxes = pred_boxes;
  }
}
class SamPreTrainedModel extends PreTrainedModel {
}
class SamModel extends SamPreTrainedModel {
  /**
   * Creates a new instance of the `SamModel` class.
   * @param {Object} config The configuration object specifying the hyperparameters and other model settings.
   * @param {Object} vision_encoder The ONNX session containing the vision encoder model.
   * @param {any} prompt_encoder_mask_decoder The ONNX session containing the prompt encoder and mask decoder model.
   */
  constructor(config2, vision_encoder, prompt_encoder_mask_decoder) {
    super(config2, vision_encoder);
    this.prompt_encoder_mask_decoder = prompt_encoder_mask_decoder;
  }
  /**
   * Compute image embeddings and positional image embeddings, given the pixel values of an image.
   * @param {Object} model_inputs Object containing the model inputs.
   * @param {Tensor} model_inputs.pixel_values Pixel values obtained using a `SamProcessor`.
   * @returns {Promise<{ image_embeddings: Tensor, image_positional_embeddings: Tensor }>} The image embeddings and positional image embeddings.
   */
  async get_image_embeddings({ pixel_values }) {
    return await encoderForward(this, { pixel_values });
  }
  /**
   * @typedef {Object} SamModelInputs Object containing the model inputs.
   * @property {Tensor} pixel_values Pixel values as a Tensor with shape `(batch_size, num_channels, height, width)`.
   * These can be obtained using a `SamProcessor`.
   * @property {Tensor} input_points Input 2D spatial points with shape `(batch_size, num_points, 2)`.
   * This is used by the prompt encoder to encode the prompt.
   * @property {Tensor} [input_labels] Input labels for the points, as a Tensor of shape `(batch_size, point_batch_size, num_points)`.
   * This is used by the prompt encoder to encode the prompt. There are 4 types of labels:
   *  - `1`: the point is a point that contains the object of interest
   *  - `0`: the point is a point that does not contain the object of interest
   *  - `-1`: the point corresponds to the background
   *  - `-10`: the point is a padding point, thus should be ignored by the prompt encoder
   * @property {Tensor} [image_embeddings] Image embeddings used by the mask decoder.
   * @property {Tensor} [image_positional_embeddings] Image positional embeddings used by the mask decoder.
   */
  /**
   * @param {SamModelInputs} model_inputs Object containing the model inputs.
   * @returns {Promise<Object>} The output of the model.
   */
  async forward(model_inputs) {
    if (!model_inputs.image_embeddings || !model_inputs.image_positional_embeddings) {
      model_inputs = {
        ...model_inputs,
        ...await this.get_image_embeddings(model_inputs)
      };
    }
    if (!model_inputs.input_labels) {
      const shape = model_inputs.input_points.dims.slice(0, -1);
      const numElements = shape.reduce((a, b) => a * b, 1);
      model_inputs.input_labels = new Tensor(
        "int64",
        new BigInt64Array(numElements).fill(1n),
        shape
      );
    }
    return await sessionRun(this.prompt_encoder_mask_decoder, {
      input_points: model_inputs.input_points,
      input_labels: model_inputs.input_labels,
      image_embeddings: model_inputs.image_embeddings,
      image_positional_embeddings: model_inputs.image_positional_embeddings
    });
  }
  /**
   * Runs the model with the provided inputs
   * @param {Object} model_inputs Model inputs
   * @returns {Promise<SamImageSegmentationOutput>} Object containing segmentation outputs
   */
  async _call(model_inputs) {
    return new SamImageSegmentationOutput(await super._call(model_inputs));
  }
}
class SamImageSegmentationOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.iou_scores The output logits of the model.
   * @param {Tensor} output.pred_masks Predicted boxes.
   */
  constructor({ iou_scores, pred_masks }) {
    super();
    this.iou_scores = iou_scores;
    this.pred_masks = pred_masks;
  }
}
class MarianPreTrainedModel extends PreTrainedModel {
}
class MarianModel extends MarianPreTrainedModel {
}
class MarianMTModel extends MarianPreTrainedModel {
  /**
   * Creates a new instance of the `MarianMTModel` class.
  * @param {Object} config The model configuration object.
  * @param {Object} session The ONNX session object.
  * @param {any} decoder_merged_session 
  * @param {any} generation_config 
  */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.decoder_layers;
    this.num_decoder_heads = this.config.decoder_attention_heads;
    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;
    this.num_encoder_layers = this.config.encoder_layers;
    this.num_encoder_heads = this.config.encoder_attention_heads;
    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;
  }
}
class M2M100PreTrainedModel extends PreTrainedModel {
}
class M2M100Model extends M2M100PreTrainedModel {
}
class M2M100ForConditionalGeneration extends M2M100PreTrainedModel {
  /**
   * Creates a new instance of the `M2M100ForConditionalGeneration` class.
  * @param {Object} config The model configuration object.
  * @param {Object} session The ONNX session object.
  * @param {any} decoder_merged_session 
  * @param {any} generation_config 
  */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.decoder_layers;
    this.num_decoder_heads = this.config.decoder_attention_heads;
    this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;
    this.num_encoder_layers = this.config.encoder_layers;
    this.num_encoder_heads = this.config.encoder_attention_heads;
    this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;
  }
}
class Wav2Vec2PreTrainedModel extends PreTrainedModel {
}
class Wav2Vec2Model extends Wav2Vec2PreTrainedModel {
}
class Wav2Vec2ForCTC extends Wav2Vec2PreTrainedModel {
  /**
   * @param {Object} model_inputs
   * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
   * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
   */
  async _call(model_inputs) {
    return new CausalLMOutput(await super._call(model_inputs));
  }
}
class Wav2Vec2ForSequenceClassification extends Wav2Vec2PreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class Wav2Vec2ForAudioFrameClassification extends Wav2Vec2PreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class UniSpeechPreTrainedModel extends PreTrainedModel {
}
class UniSpeechModel extends UniSpeechPreTrainedModel {
}
class UniSpeechForCTC extends UniSpeechPreTrainedModel {
  /**
   * @param {Object} model_inputs
   * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
   * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
   */
  async _call(model_inputs) {
    return new CausalLMOutput(await super._call(model_inputs));
  }
}
class UniSpeechForSequenceClassification extends UniSpeechPreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class UniSpeechSatPreTrainedModel extends PreTrainedModel {
}
class UniSpeechSatModel extends UniSpeechSatPreTrainedModel {
}
class UniSpeechSatForCTC extends UniSpeechSatPreTrainedModel {
  /**
   * @param {Object} model_inputs
   * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
   * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
   */
  async _call(model_inputs) {
    return new CausalLMOutput(await super._call(model_inputs));
  }
}
class UniSpeechSatForSequenceClassification extends UniSpeechSatPreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class UniSpeechSatForAudioFrameClassification extends UniSpeechSatPreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class Wav2Vec2BertPreTrainedModel extends PreTrainedModel {
}
class Wav2Vec2BertModel extends Wav2Vec2BertPreTrainedModel {
}
class Wav2Vec2BertForCTC extends Wav2Vec2BertPreTrainedModel {
  /**
   * @param {Object} model_inputs
   * @param {Tensor} model_inputs.input_features Float values of input mel-spectrogram.
   * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
   */
  async _call(model_inputs) {
    return new CausalLMOutput(await super._call(model_inputs));
  }
}
class Wav2Vec2BertForSequenceClassification extends Wav2Vec2BertPreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class HubertModel extends Wav2Vec2PreTrainedModel {
}
class HubertForCTC extends Wav2Vec2PreTrainedModel {
  /**
   * @param {Object} model_inputs
   * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
   * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
   */
  async _call(model_inputs) {
    return new CausalLMOutput(await super._call(model_inputs));
  }
}
class HubertForSequenceClassification extends Wav2Vec2PreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class WavLMPreTrainedModel extends PreTrainedModel {
}
class WavLMModel extends WavLMPreTrainedModel {
}
class WavLMForCTC extends WavLMPreTrainedModel {
  /**
   * @param {Object} model_inputs
   * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
   * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
   */
  async _call(model_inputs) {
    return new CausalLMOutput(await super._call(model_inputs));
  }
}
class WavLMForSequenceClassification extends WavLMPreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class WavLMForXVector extends WavLMPreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<XVectorOutput>} An object containing the model's output logits and speaker embeddings.
   */
  async _call(model_inputs) {
    return new XVectorOutput(await super._call(model_inputs));
  }
}
class WavLMForAudioFrameClassification extends WavLMPreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for sequence classification.
   */
  async _call(model_inputs) {
    return new TokenClassifierOutput(await super._call(model_inputs));
  }
}
class SpeechT5PreTrainedModel extends PreTrainedModel {
}
class SpeechT5ForSpeechToText extends SpeechT5PreTrainedModel {
}
class SpeechT5ForTextToSpeech extends SpeechT5PreTrainedModel {
  /**
   * Creates a new instance of the `SpeechT5ForTextToSpeech` class.
   * @param {Object} config The model configuration.
   * @param {any} session session for the model.
   * @param {any} decoder_merged_session session for the decoder.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, decoder_merged_session, generation_config) {
    super(config2, session);
    this.decoder_merged_session = decoder_merged_session;
    this.generation_config = generation_config;
    this.num_decoder_layers = this.config.decoder_layers;
    this.num_decoder_heads = this.config.decoder_attention_heads;
    this.decoder_dim_kv = this.config.hidden_size / this.num_decoder_heads;
    this.num_encoder_layers = this.config.encoder_layers;
    this.num_encoder_heads = this.config.encoder_attention_heads;
    this.encoder_dim_kv = this.config.hidden_size / this.num_encoder_heads;
  }
  /**
   * @typedef {Object} SpeechOutput
   * @property {Tensor} [spectrogram] The predicted log-mel spectrogram of shape
   * `(output_sequence_length, config.num_mel_bins)`. Returned when no `vocoder` is provided
   * @property {Tensor} [waveform] The predicted waveform of shape `(num_frames,)`. Returned when a `vocoder` is provided.
   * @property {Tensor} [cross_attentions] The outputs of the decoder's cross-attention layers of shape
   * `(config.decoder_layers, config.decoder_attention_heads, output_sequence_length, input_sequence_length)`. returned when `output_cross_attentions` is `true`.
   */
  /**
   * Converts a sequence of input tokens into a sequence of mel spectrograms, which are subsequently turned into a speech waveform using a vocoder.
   * @param {Tensor} input_values Indices of input sequence tokens in the vocabulary.
   * @param {Tensor} speaker_embeddings Tensor containing the speaker embeddings.
   * @param {Object} options Optional parameters for generating speech.
   * @param {number} [options.threshold=0.5] The generated sequence ends when the predicted stop token probability exceeds this value.
   * @param {number} [options.minlenratio=0.0] Used to calculate the minimum required length for the output sequence.
   * @param {number} [options.maxlenratio=20.0] Used to calculate the maximum allowed length for the output sequence.
   * @param {Object} [options.vocoder=null] The vocoder that converts the mel spectrogram into a speech waveform. If `null`, the output is the mel spectrogram.
   * @param {boolean} [options.output_cross_attentions=false] Whether or not to return the attentions tensors of the decoder's cross-attention layers.
   * @returns {Promise<SpeechOutput>} A promise which resolves to an object containing the spectrogram, waveform, and cross-attention tensors.
   */
  async generate_speech(input_values, speaker_embeddings, {
    threshold: threshold2 = 0.5,
    minlenratio = 0,
    maxlenratio = 20,
    vocoder = null
    // output_cross_attentions = false, // TODO add
  } = {}) {
    const model_inputs = {
      input_ids: input_values
    };
    const { encoder_outputs, encoder_attention_mask } = await encoderForward(this, model_inputs);
    const r = encoder_outputs.dims[1] / this.config.reduction_factor;
    const maxlen = Math.floor(r * maxlenratio);
    const minlen = Math.floor(r * minlenratio);
    const num_mel_bins = this.config.num_mel_bins;
    let spectrogramParts = [];
    let past_key_values = null;
    let decoder_outputs = null;
    let idx = 0;
    while (true) {
      ++idx;
      const use_cache_branch = boolTensor(!!decoder_outputs);
      let output_sequence;
      if (decoder_outputs) {
        output_sequence = decoder_outputs.output_sequence_out;
      } else {
        output_sequence = new Tensor(
          "float32",
          new Float32Array(num_mel_bins),
          [1, 1, num_mel_bins]
        );
      }
      let decoderFeeds = {
        use_cache_branch,
        output_sequence,
        encoder_attention_mask,
        speaker_embeddings,
        encoder_hidden_states: encoder_outputs
      };
      this.addPastKeyValues(decoderFeeds, past_key_values);
      decoder_outputs = await sessionRun(this.decoder_merged_session, decoderFeeds);
      past_key_values = this.getPastKeyValues(decoder_outputs, past_key_values);
      const { prob, spectrum } = decoder_outputs;
      spectrogramParts.push(spectrum);
      if (idx >= minlen && // Finished when stop token or maximum length is reached.
      (Array.from(prob.data).filter((p) => p >= threshold2).length > 0 || idx >= maxlen)) {
        break;
      }
    }
    const spectrogram2 = cat(spectrogramParts);
    const { waveform } = await sessionRun(vocoder.session, { spectrogram: spectrogram2 });
    return {
      spectrogram: spectrogram2,
      waveform
      // cross_attentions: null, // TODO add
    };
  }
}
class SpeechT5HifiGan extends PreTrainedModel {
  constructor() {
    super(...arguments);
    __publicField(this, "main_input_name", "spectrogram");
  }
}
class TrOCRPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `TrOCRPreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_encoder_layers = this.num_decoder_layers = this.config.decoder_layers;
    this.num_encoder_heads = this.num_decoder_heads = this.config.decoder_attention_heads;
    this.encoder_dim_kv = this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;
  }
}
class TrOCRForCausalLM extends TrOCRPreTrainedModel {
}
class MistralPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `MistralPreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_key_value_heads;
    this.num_layers = this.config.num_hidden_layers;
    this.dim_kv = this.config.hidden_size / this.config.num_attention_heads;
  }
}
class MistralModel extends MistralPreTrainedModel {
}
class MistralForCausalLM extends MistralPreTrainedModel {
}
class Starcoder2PreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `Starcoder2PreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_key_value_heads;
    this.num_layers = this.config.num_hidden_layers;
    this.dim_kv = this.config.hidden_size / this.config.num_attention_heads;
  }
}
class Starcoder2Model extends Starcoder2PreTrainedModel {
}
class Starcoder2ForCausalLM extends Starcoder2PreTrainedModel {
}
class FalconPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `FalconPreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_attention_heads;
    this.num_layers = this.config.num_hidden_layers;
    this.dim_kv = this.config.hidden_size / this.config.num_attention_heads;
  }
}
class FalconModel extends FalconPreTrainedModel {
}
class FalconForCausalLM extends FalconPreTrainedModel {
}
class ClapPreTrainedModel extends PreTrainedModel {
}
class ClapModel extends ClapPreTrainedModel {
}
class ClapTextModelWithProjection extends ClapPreTrainedModel {
  /** @type {PreTrainedModel.from_pretrained} */
  static async from_pretrained(pretrained_model_name_or_path, options = {}) {
    options.model_file_name ?? (options.model_file_name = "text_model");
    return super.from_pretrained(pretrained_model_name_or_path, options);
  }
}
class ClapAudioModelWithProjection extends ClapPreTrainedModel {
  /** @type {PreTrainedModel.from_pretrained} */
  static async from_pretrained(pretrained_model_name_or_path, options = {}) {
    options.model_file_name ?? (options.model_file_name = "audio_model");
    return super.from_pretrained(pretrained_model_name_or_path, options);
  }
}
class VitsPreTrainedModel extends PreTrainedModel {
}
class VitsModel extends VitsPreTrainedModel {
  /**
   * Calls the model on new inputs.
   * @param {Object} model_inputs The inputs to the model.
   * @returns {Promise<VitsModelOutput>} The outputs for the VITS model.
   */
  async _call(model_inputs) {
    return new VitsModelOutput(await super._call(model_inputs));
  }
}
class SegformerPreTrainedModel extends PreTrainedModel {
}
class SegformerForImageClassification extends SegformerPreTrainedModel {
}
class SegformerForSemanticSegmentation extends SegformerPreTrainedModel {
}
class StableLmPreTrainedModel extends PreTrainedModel {
  /**
   * Creates a new instance of the `StableLmPreTrainedModel` class.
   * @param {Object} config The configuration of the model.
   * @param {any} session The ONNX session containing the model weights.
   * @param {GenerationConfig} generation_config The generation configuration.
   */
  constructor(config2, session, generation_config) {
    super(config2, session);
    this.generation_config = generation_config;
    this.config.pad_token_id = this.config.eos_token_id;
    this.num_heads = this.config.num_attention_heads;
    this.num_layers = this.config.num_hidden_layers;
    this.dim_kv = this.config.hidden_size / this.num_heads;
  }
}
class StableLmForCausalLM extends StableLmPreTrainedModel {
}
class EfficientNetPreTrainedModel extends PreTrainedModel {
}
class EfficientNetModel extends EfficientNetPreTrainedModel {
}
class EfficientNetForImageClassification extends EfficientNetPreTrainedModel {
  /**
   * @param {any} model_inputs
   */
  async _call(model_inputs) {
    return new SequenceClassifierOutput(await super._call(model_inputs));
  }
}
class PretrainedMixin {
  /** @type {PreTrainedModel.from_pretrained} */
  static async from_pretrained(pretrained_model_name_or_path, {
    quantized = true,
    progress_callback = null,
    config: config2 = null,
    cache_dir = null,
    local_files_only = false,
    revision = "main",
    model_file_name = null
  } = {}) {
    let options = {
      quantized,
      progress_callback,
      config: config2,
      cache_dir,
      local_files_only,
      revision,
      model_file_name
    };
    config2 = await AutoConfig.from_pretrained(pretrained_model_name_or_path, options);
    if (!options.config) {
      options.config = config2;
    }
    if (!this.MODEL_CLASS_MAPPINGS) {
      throw new Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: " + this.name);
    }
    for (let MODEL_CLASS_MAPPING of this.MODEL_CLASS_MAPPINGS) {
      const modelInfo = MODEL_CLASS_MAPPING.get(config2.model_type);
      if (!modelInfo) {
        continue;
      }
      return await modelInfo[1].from_pretrained(pretrained_model_name_or_path, options);
    }
    if (this.BASE_IF_FAIL) {
      console.warn(`Unknown model class "${config2.model_type}", attempting to construct from base class.`);
      return await PreTrainedModel.from_pretrained(pretrained_model_name_or_path, options);
    } else {
      throw Error(`Unsupported model type: ${config2.model_type}`);
    }
  }
}
/**
 * Mapping from model type to model class.
 * @type {Map<string, Object>[]}
 */
__publicField(PretrainedMixin, "MODEL_CLASS_MAPPINGS", null);
/**
 * Whether to attempt to instantiate the base class (`PretrainedModel`) if 
 * the model type is not found in the mapping.
 */
__publicField(PretrainedMixin, "BASE_IF_FAIL", false);
const MODEL_MAPPING_NAMES_ENCODER_ONLY = /* @__PURE__ */ new Map([
  ["bert", ["BertModel", BertModel]],
  ["nomic_bert", ["NomicBertModel", NomicBertModel]],
  ["roformer", ["RoFormerModel", RoFormerModel]],
  ["electra", ["ElectraModel", ElectraModel]],
  ["esm", ["EsmModel", EsmModel]],
  ["convbert", ["ConvBertModel", ConvBertModel]],
  ["camembert", ["CamembertModel", CamembertModel]],
  ["deberta", ["DebertaModel", DebertaModel]],
  ["deberta-v2", ["DebertaV2Model", DebertaV2Model]],
  ["mpnet", ["MPNetModel", MPNetModel]],
  ["albert", ["AlbertModel", AlbertModel]],
  ["distilbert", ["DistilBertModel", DistilBertModel]],
  ["roberta", ["RobertaModel", RobertaModel]],
  ["xlm", ["XLMModel", XLMModel]],
  ["xlm-roberta", ["XLMRobertaModel", XLMRobertaModel]],
  ["clap", ["ClapModel", ClapModel]],
  ["clip", ["CLIPModel", CLIPModel]],
  ["clipseg", ["CLIPSegModel", CLIPSegModel]],
  ["chinese_clip", ["ChineseCLIPModel", ChineseCLIPModel]],
  ["siglip", ["SiglipModel", SiglipModel]],
  ["mobilebert", ["MobileBertModel", MobileBertModel]],
  ["squeezebert", ["SqueezeBertModel", SqueezeBertModel]],
  ["wav2vec2", ["Wav2Vec2Model", Wav2Vec2Model]],
  ["wav2vec2-bert", ["Wav2Vec2BertModel", Wav2Vec2BertModel]],
  ["unispeech", ["UniSpeechModel", UniSpeechModel]],
  ["unispeech-sat", ["UniSpeechSatModel", UniSpeechSatModel]],
  ["hubert", ["HubertModel", HubertModel]],
  ["wavlm", ["WavLMModel", WavLMModel]],
  ["audio-spectrogram-transformer", ["ASTModel", ASTModel]],
  ["vits", ["VitsModel", VitsModel]],
  ["detr", ["DetrModel", DetrModel]],
  ["table-transformer", ["TableTransformerModel", TableTransformerModel]],
  ["vit", ["ViTModel", ViTModel]],
  ["fastvit", ["FastViTModel", FastViTModel]],
  ["mobilevit", ["MobileViTModel", MobileViTModel]],
  ["mobilevitv2", ["MobileViTV2Model", MobileViTV2Model]],
  ["owlvit", ["OwlViTModel", OwlViTModel]],
  ["owlv2", ["Owlv2Model", Owlv2Model]],
  ["beit", ["BeitModel", BeitModel]],
  ["deit", ["DeiTModel", DeiTModel]],
  ["convnext", ["ConvNextModel", ConvNextModel]],
  ["convnextv2", ["ConvNextV2Model", ConvNextV2Model]],
  ["dinov2", ["Dinov2Model", Dinov2Model]],
  ["resnet", ["ResNetModel", ResNetModel]],
  ["swin", ["SwinModel", SwinModel]],
  ["swin2sr", ["Swin2SRModel", Swin2SRModel]],
  ["donut-swin", ["DonutSwinModel", DonutSwinModel]],
  ["yolos", ["YolosModel", YolosModel]],
  ["dpt", ["DPTModel", DPTModel]],
  ["glpn", ["GLPNModel", GLPNModel]],
  ["hifigan", ["SpeechT5HifiGan", SpeechT5HifiGan]],
  ["efficientnet", ["EfficientNetModel", EfficientNetModel]]
]);
const MODEL_MAPPING_NAMES_ENCODER_DECODER = /* @__PURE__ */ new Map([
  ["t5", ["T5Model", T5Model]],
  ["longt5", ["LongT5Model", LongT5Model]],
  ["mt5", ["MT5Model", MT5Model]],
  ["bart", ["BartModel", BartModel]],
  ["mbart", ["MBartModel", MBartModel]],
  ["marian", ["MarianModel", MarianModel]],
  ["whisper", ["WhisperModel", WhisperModel]],
  ["m2m_100", ["M2M100Model", M2M100Model]],
  ["blenderbot", ["BlenderbotModel", BlenderbotModel]],
  ["blenderbot-small", ["BlenderbotSmallModel", BlenderbotSmallModel]]
]);
const MODEL_MAPPING_NAMES_DECODER_ONLY = /* @__PURE__ */ new Map([
  ["bloom", ["BloomModel", BloomModel]],
  ["gpt2", ["GPT2Model", GPT2Model]],
  ["gptj", ["GPTJModel", GPTJModel]],
  ["gpt_bigcode", ["GPTBigCodeModel", GPTBigCodeModel]],
  ["gpt_neo", ["GPTNeoModel", GPTNeoModel]],
  ["gpt_neox", ["GPTNeoXModel", GPTNeoXModel]],
  ["codegen", ["CodeGenModel", CodeGenModel]],
  ["llama", ["LlamaModel", LlamaModel]],
  ["qwen2", ["Qwen2Model", Qwen2Model]],
  ["phi", ["PhiModel", PhiModel]],
  ["mpt", ["MptModel", MptModel]],
  ["opt", ["OPTModel", OPTModel]],
  ["mistral", ["MistralModel", MistralModel]],
  ["starcoder2", ["Starcoder2Model", Starcoder2Model]],
  ["falcon", ["FalconModel", FalconModel]]
]);
const MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["speecht5", ["SpeechT5ForSpeechToText", SpeechT5ForSpeechToText]],
  ["whisper", ["WhisperForConditionalGeneration", WhisperForConditionalGeneration]]
]);
const MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["speecht5", ["SpeechT5ForTextToSpeech", SpeechT5ForTextToSpeech]]
]);
const MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["vits", ["VitsModel", VitsModel]]
]);
const MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["bert", ["BertForSequenceClassification", BertForSequenceClassification]],
  ["roformer", ["RoFormerForSequenceClassification", RoFormerForSequenceClassification]],
  ["electra", ["ElectraForSequenceClassification", ElectraForSequenceClassification]],
  ["esm", ["EsmForSequenceClassification", EsmForSequenceClassification]],
  ["convbert", ["ConvBertForSequenceClassification", ConvBertForSequenceClassification]],
  ["camembert", ["CamembertForSequenceClassification", CamembertForSequenceClassification]],
  ["deberta", ["DebertaForSequenceClassification", DebertaForSequenceClassification]],
  ["deberta-v2", ["DebertaV2ForSequenceClassification", DebertaV2ForSequenceClassification]],
  ["mpnet", ["MPNetForSequenceClassification", MPNetForSequenceClassification]],
  ["albert", ["AlbertForSequenceClassification", AlbertForSequenceClassification]],
  ["distilbert", ["DistilBertForSequenceClassification", DistilBertForSequenceClassification]],
  ["roberta", ["RobertaForSequenceClassification", RobertaForSequenceClassification]],
  ["xlm", ["XLMForSequenceClassification", XLMForSequenceClassification]],
  ["xlm-roberta", ["XLMRobertaForSequenceClassification", XLMRobertaForSequenceClassification]],
  ["bart", ["BartForSequenceClassification", BartForSequenceClassification]],
  ["mbart", ["MBartForSequenceClassification", MBartForSequenceClassification]],
  ["mobilebert", ["MobileBertForSequenceClassification", MobileBertForSequenceClassification]],
  ["squeezebert", ["SqueezeBertForSequenceClassification", SqueezeBertForSequenceClassification]]
]);
const MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["bert", ["BertForTokenClassification", BertForTokenClassification]],
  ["roformer", ["RoFormerForTokenClassification", RoFormerForTokenClassification]],
  ["electra", ["ElectraForTokenClassification", ElectraForTokenClassification]],
  ["esm", ["EsmForTokenClassification", EsmForTokenClassification]],
  ["convbert", ["ConvBertForTokenClassification", ConvBertForTokenClassification]],
  ["camembert", ["CamembertForTokenClassification", CamembertForTokenClassification]],
  ["deberta", ["DebertaForTokenClassification", DebertaForTokenClassification]],
  ["deberta-v2", ["DebertaV2ForTokenClassification", DebertaV2ForTokenClassification]],
  ["mpnet", ["MPNetForTokenClassification", MPNetForTokenClassification]],
  ["distilbert", ["DistilBertForTokenClassification", DistilBertForTokenClassification]],
  ["roberta", ["RobertaForTokenClassification", RobertaForTokenClassification]],
  ["xlm", ["XLMForTokenClassification", XLMForTokenClassification]],
  ["xlm-roberta", ["XLMRobertaForTokenClassification", XLMRobertaForTokenClassification]]
]);
const MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["t5", ["T5ForConditionalGeneration", T5ForConditionalGeneration]],
  ["longt5", ["LongT5ForConditionalGeneration", LongT5ForConditionalGeneration]],
  ["mt5", ["MT5ForConditionalGeneration", MT5ForConditionalGeneration]],
  ["bart", ["BartForConditionalGeneration", BartForConditionalGeneration]],
  ["mbart", ["MBartForConditionalGeneration", MBartForConditionalGeneration]],
  ["marian", ["MarianMTModel", MarianMTModel]],
  ["m2m_100", ["M2M100ForConditionalGeneration", M2M100ForConditionalGeneration]],
  ["blenderbot", ["BlenderbotForConditionalGeneration", BlenderbotForConditionalGeneration]],
  ["blenderbot-small", ["BlenderbotSmallForConditionalGeneration", BlenderbotSmallForConditionalGeneration]]
]);
const MODEL_WITH_LM_HEAD_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["bloom", ["BloomForCausalLM", BloomForCausalLM]],
  ["gpt2", ["GPT2LMHeadModel", GPT2LMHeadModel]],
  ["gptj", ["GPTJForCausalLM", GPTJForCausalLM]],
  ["gpt_bigcode", ["GPTBigCodeForCausalLM", GPTBigCodeForCausalLM]],
  ["gpt_neo", ["GPTNeoForCausalLM", GPTNeoForCausalLM]],
  ["gpt_neox", ["GPTNeoXForCausalLM", GPTNeoXForCausalLM]],
  ["codegen", ["CodeGenForCausalLM", CodeGenForCausalLM]],
  ["llama", ["LlamaForCausalLM", LlamaForCausalLM]],
  ["qwen2", ["Qwen2ForCausalLM", Qwen2ForCausalLM]],
  ["phi", ["PhiForCausalLM", PhiForCausalLM]],
  ["mpt", ["MptForCausalLM", MptForCausalLM]],
  ["opt", ["OPTForCausalLM", OPTForCausalLM]],
  ["mbart", ["MBartForCausalLM", MBartForCausalLM]],
  ["mistral", ["MistralForCausalLM", MistralForCausalLM]],
  ["starcoder2", ["Starcoder2ForCausalLM", Starcoder2ForCausalLM]],
  ["falcon", ["FalconForCausalLM", FalconForCausalLM]],
  ["trocr", ["TrOCRForCausalLM", TrOCRForCausalLM]],
  ["stablelm", ["StableLmForCausalLM", StableLmForCausalLM]]
]);
const MODEL_FOR_MASKED_LM_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["bert", ["BertForMaskedLM", BertForMaskedLM]],
  ["roformer", ["RoFormerForMaskedLM", RoFormerForMaskedLM]],
  ["electra", ["ElectraForMaskedLM", ElectraForMaskedLM]],
  ["esm", ["EsmForMaskedLM", EsmForMaskedLM]],
  ["convbert", ["ConvBertForMaskedLM", ConvBertForMaskedLM]],
  ["camembert", ["CamembertForMaskedLM", CamembertForMaskedLM]],
  ["deberta", ["DebertaForMaskedLM", DebertaForMaskedLM]],
  ["deberta-v2", ["DebertaV2ForMaskedLM", DebertaV2ForMaskedLM]],
  ["mpnet", ["MPNetForMaskedLM", MPNetForMaskedLM]],
  ["albert", ["AlbertForMaskedLM", AlbertForMaskedLM]],
  ["distilbert", ["DistilBertForMaskedLM", DistilBertForMaskedLM]],
  ["roberta", ["RobertaForMaskedLM", RobertaForMaskedLM]],
  ["xlm", ["XLMWithLMHeadModel", XLMWithLMHeadModel]],
  ["xlm-roberta", ["XLMRobertaForMaskedLM", XLMRobertaForMaskedLM]],
  ["mobilebert", ["MobileBertForMaskedLM", MobileBertForMaskedLM]],
  ["squeezebert", ["SqueezeBertForMaskedLM", SqueezeBertForMaskedLM]]
]);
const MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["bert", ["BertForQuestionAnswering", BertForQuestionAnswering]],
  ["roformer", ["RoFormerForQuestionAnswering", RoFormerForQuestionAnswering]],
  ["electra", ["ElectraForQuestionAnswering", ElectraForQuestionAnswering]],
  ["convbert", ["ConvBertForQuestionAnswering", ConvBertForQuestionAnswering]],
  ["camembert", ["CamembertForQuestionAnswering", CamembertForQuestionAnswering]],
  ["deberta", ["DebertaForQuestionAnswering", DebertaForQuestionAnswering]],
  ["deberta-v2", ["DebertaV2ForQuestionAnswering", DebertaV2ForQuestionAnswering]],
  ["mpnet", ["MPNetForQuestionAnswering", MPNetForQuestionAnswering]],
  ["albert", ["AlbertForQuestionAnswering", AlbertForQuestionAnswering]],
  ["distilbert", ["DistilBertForQuestionAnswering", DistilBertForQuestionAnswering]],
  ["roberta", ["RobertaForQuestionAnswering", RobertaForQuestionAnswering]],
  ["xlm", ["XLMForQuestionAnswering", XLMForQuestionAnswering]],
  ["xlm-roberta", ["XLMRobertaForQuestionAnswering", XLMRobertaForQuestionAnswering]],
  ["mobilebert", ["MobileBertForQuestionAnswering", MobileBertForQuestionAnswering]],
  ["squeezebert", ["SqueezeBertForQuestionAnswering", SqueezeBertForQuestionAnswering]]
]);
const MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["vision-encoder-decoder", ["VisionEncoderDecoderModel", VisionEncoderDecoderModel]]
]);
const MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["vision-encoder-decoder", ["VisionEncoderDecoderModel", VisionEncoderDecoderModel]]
]);
const MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["vit", ["ViTForImageClassification", ViTForImageClassification]],
  ["fastvit", ["FastViTForImageClassification", FastViTForImageClassification]],
  ["mobilevit", ["MobileViTForImageClassification", MobileViTForImageClassification]],
  ["mobilevitv2", ["MobileViTV2ForImageClassification", MobileViTV2ForImageClassification]],
  ["beit", ["BeitForImageClassification", BeitForImageClassification]],
  ["deit", ["DeiTForImageClassification", DeiTForImageClassification]],
  ["convnext", ["ConvNextForImageClassification", ConvNextForImageClassification]],
  ["convnextv2", ["ConvNextV2ForImageClassification", ConvNextV2ForImageClassification]],
  ["dinov2", ["Dinov2ForImageClassification", Dinov2ForImageClassification]],
  ["resnet", ["ResNetForImageClassification", ResNetForImageClassification]],
  ["swin", ["SwinForImageClassification", SwinForImageClassification]],
  ["segformer", ["SegformerForImageClassification", SegformerForImageClassification]],
  ["efficientnet", ["EfficientNetForImageClassification", EfficientNetForImageClassification]]
]);
const MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["detr", ["DetrForObjectDetection", DetrForObjectDetection]],
  ["table-transformer", ["TableTransformerForObjectDetection", TableTransformerForObjectDetection]],
  ["yolos", ["YolosForObjectDetection", YolosForObjectDetection]]
]);
const MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["owlvit", ["OwlViTForObjectDetection", OwlViTForObjectDetection]],
  ["owlv2", ["Owlv2ForObjectDetection", Owlv2ForObjectDetection]]
]);
const MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["detr", ["DetrForSegmentation", DetrForSegmentation]],
  ["clipseg", ["CLIPSegForImageSegmentation", CLIPSegForImageSegmentation]]
]);
const MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["segformer", ["SegformerForSemanticSegmentation", SegformerForSemanticSegmentation]]
]);
const MODEL_FOR_MASK_GENERATION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["sam", ["SamModel", SamModel]]
]);
const MODEL_FOR_CTC_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["wav2vec2", ["Wav2Vec2ForCTC", Wav2Vec2ForCTC]],
  ["wav2vec2-bert", ["Wav2Vec2BertForCTC", Wav2Vec2BertForCTC]],
  ["unispeech", ["UniSpeechForCTC", UniSpeechForCTC]],
  ["unispeech-sat", ["UniSpeechSatForCTC", UniSpeechSatForCTC]],
  ["wavlm", ["WavLMForCTC", WavLMForCTC]],
  ["hubert", ["HubertForCTC", HubertForCTC]]
]);
const MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["wav2vec2", ["Wav2Vec2ForSequenceClassification", Wav2Vec2ForSequenceClassification]],
  ["wav2vec2-bert", ["Wav2Vec2BertForSequenceClassification", Wav2Vec2BertForSequenceClassification]],
  ["unispeech", ["UniSpeechForSequenceClassification", UniSpeechForSequenceClassification]],
  ["unispeech-sat", ["UniSpeechSatForSequenceClassification", UniSpeechSatForSequenceClassification]],
  ["wavlm", ["WavLMForSequenceClassification", WavLMForSequenceClassification]],
  ["hubert", ["HubertForSequenceClassification", HubertForSequenceClassification]],
  ["audio-spectrogram-transformer", ["ASTForAudioClassification", ASTForAudioClassification]]
]);
const MODEL_FOR_AUDIO_XVECTOR_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["wavlm", ["WavLMForXVector", WavLMForXVector]]
]);
const MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["unispeech-sat", ["UniSpeechSatForAudioFrameClassification", UniSpeechSatForAudioFrameClassification]],
  ["wavlm", ["WavLMForAudioFrameClassification", WavLMForAudioFrameClassification]],
  ["wav2vec2", ["Wav2Vec2ForAudioFrameClassification", Wav2Vec2ForAudioFrameClassification]]
]);
const MODEL_FOR_IMAGE_MATTING_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["vitmatte", ["VitMatteForImageMatting", VitMatteForImageMatting]]
]);
const MODEL_FOR_IMAGE_TO_IMAGE_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["swin2sr", ["Swin2SRForImageSuperResolution", Swin2SRForImageSuperResolution]]
]);
const MODEL_FOR_DEPTH_ESTIMATION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["dpt", ["DPTForDepthEstimation", DPTForDepthEstimation]],
  ["depth_anything", ["DepthAnythingForDepthEstimation", DepthAnythingForDepthEstimation]],
  ["glpn", ["GLPNForDepthEstimation", GLPNForDepthEstimation]]
]);
const MODEL_FOR_IMAGE_FEATURE_EXTRACTION_MAPPING_NAMES = /* @__PURE__ */ new Map([
  ["clip", ["CLIPVisionModelWithProjection", CLIPVisionModelWithProjection]],
  ["siglip", ["SiglipVisionModel", SiglipVisionModel]]
]);
const MODEL_CLASS_TYPE_MAPPING = [
  [MODEL_MAPPING_NAMES_ENCODER_ONLY, MODEL_TYPES.EncoderOnly],
  [MODEL_MAPPING_NAMES_ENCODER_DECODER, MODEL_TYPES.EncoderDecoder],
  [MODEL_MAPPING_NAMES_DECODER_ONLY, MODEL_TYPES.DecoderOnly],
  [MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES, MODEL_TYPES.Seq2Seq],
  [MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES, MODEL_TYPES.Seq2Seq],
  [MODEL_WITH_LM_HEAD_MAPPING_NAMES, MODEL_TYPES.DecoderOnly],
  [MODEL_FOR_MASKED_LM_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES, MODEL_TYPES.Vision2Seq],
  [MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_IMAGE_MATTING_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_IMAGE_TO_IMAGE_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_DEPTH_ESTIMATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_MASK_GENERATION_MAPPING_NAMES, MODEL_TYPES.MaskGeneration],
  [MODEL_FOR_CTC_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES, MODEL_TYPES.Seq2Seq],
  [MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_AUDIO_XVECTOR_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  [MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],
  // Custom:
  [MODEL_FOR_IMAGE_FEATURE_EXTRACTION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly]
];
for (const [mappings, type2] of MODEL_CLASS_TYPE_MAPPING) {
  for (const [name2, model] of mappings.values()) {
    MODEL_TYPE_MAPPING.set(name2, type2);
    MODEL_CLASS_TO_NAME_MAPPING.set(model, name2);
    MODEL_NAME_TO_CLASS_MAPPING.set(name2, model);
  }
}
const CUSTOM_MAPPING = [
  ["CLIPTextModelWithProjection", CLIPTextModelWithProjection, MODEL_TYPES.EncoderOnly],
  ["SiglipTextModel", SiglipTextModel, MODEL_TYPES.EncoderOnly],
  ["ClapTextModelWithProjection", ClapTextModelWithProjection, MODEL_TYPES.EncoderOnly],
  ["ClapAudioModelWithProjection", ClapAudioModelWithProjection, MODEL_TYPES.EncoderOnly]
];
for (const [name2, model, type2] of CUSTOM_MAPPING) {
  MODEL_TYPE_MAPPING.set(name2, type2);
  MODEL_CLASS_TO_NAME_MAPPING.set(model, name2);
  MODEL_NAME_TO_CLASS_MAPPING.set(name2, model);
}
class AutoModel extends PretrainedMixin {
}
/** @type {Map<string, Object>[]} */
// @ts-ignore
__publicField(AutoModel, "MODEL_CLASS_MAPPINGS", MODEL_CLASS_TYPE_MAPPING.map((x) => x[0]));
__publicField(AutoModel, "BASE_IF_FAIL", true);
class AutoModelForSequenceClassification extends PretrainedMixin {
}
__publicField(AutoModelForSequenceClassification, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES]);
class AutoModelForTokenClassification extends PretrainedMixin {
}
__publicField(AutoModelForTokenClassification, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES]);
class AutoModelForSeq2SeqLM extends PretrainedMixin {
}
__publicField(AutoModelForSeq2SeqLM, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES]);
class AutoModelForSpeechSeq2Seq extends PretrainedMixin {
}
__publicField(AutoModelForSpeechSeq2Seq, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES]);
class AutoModelForTextToSpectrogram extends PretrainedMixin {
}
__publicField(AutoModelForTextToSpectrogram, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES]);
class AutoModelForTextToWaveform extends PretrainedMixin {
}
__publicField(AutoModelForTextToWaveform, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING_NAMES]);
class AutoModelForCausalLM extends PretrainedMixin {
}
__publicField(AutoModelForCausalLM, "MODEL_CLASS_MAPPINGS", [MODEL_WITH_LM_HEAD_MAPPING_NAMES]);
class AutoModelForMaskedLM extends PretrainedMixin {
}
__publicField(AutoModelForMaskedLM, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_MASKED_LM_MAPPING_NAMES]);
class AutoModelForQuestionAnswering extends PretrainedMixin {
}
__publicField(AutoModelForQuestionAnswering, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES]);
class AutoModelForVision2Seq extends PretrainedMixin {
}
__publicField(AutoModelForVision2Seq, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES]);
class AutoModelForImageClassification extends PretrainedMixin {
}
__publicField(AutoModelForImageClassification, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES]);
class AutoModelForImageSegmentation extends PretrainedMixin {
}
__publicField(AutoModelForImageSegmentation, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES]);
class AutoModelForSemanticSegmentation extends PretrainedMixin {
}
__publicField(AutoModelForSemanticSegmentation, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING_NAMES]);
class AutoModelForObjectDetection extends PretrainedMixin {
}
__publicField(AutoModelForObjectDetection, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES]);
class AutoModelForZeroShotObjectDetection extends PretrainedMixin {
}
__publicField(AutoModelForZeroShotObjectDetection, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING_NAMES]);
class AutoModelForCTC extends PretrainedMixin {
}
__publicField(AutoModelForCTC, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_CTC_MAPPING_NAMES]);
class AutoModelForAudioClassification extends PretrainedMixin {
}
__publicField(AutoModelForAudioClassification, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES]);
class AutoModelForDocumentQuestionAnswering extends PretrainedMixin {
}
__publicField(AutoModelForDocumentQuestionAnswering, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING_NAMES]);
class AutoModelForImageToImage extends PretrainedMixin {
}
__publicField(AutoModelForImageToImage, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_IMAGE_TO_IMAGE_MAPPING_NAMES]);
class AutoModelForDepthEstimation extends PretrainedMixin {
}
__publicField(AutoModelForDepthEstimation, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_DEPTH_ESTIMATION_MAPPING_NAMES]);
class AutoModelForImageFeatureExtraction extends PretrainedMixin {
}
__publicField(AutoModelForImageFeatureExtraction, "MODEL_CLASS_MAPPINGS", [MODEL_FOR_IMAGE_FEATURE_EXTRACTION_MAPPING_NAMES]);
class Seq2SeqLMOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.logits The output logits of the model.
   * @param {Tensor} output.past_key_values An tensor of key/value pairs that represent the previous state of the model.
   * @param {Tensor} output.encoder_outputs The output of the encoder in a sequence-to-sequence model.
   * @param {Tensor} [output.decoder_attentions] Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the self-attention heads.
   * @param {Tensor} [output.cross_attentions] Attentions weights of the decoder's cross-attention layer, after the attention softmax, used to compute the weighted average in the cross-attention heads.
   */
  constructor({ logits, past_key_values, encoder_outputs, decoder_attentions = null, cross_attentions = null }) {
    super();
    this.logits = logits;
    this.past_key_values = past_key_values;
    this.encoder_outputs = encoder_outputs;
    this.decoder_attentions = decoder_attentions;
    this.cross_attentions = cross_attentions;
  }
}
class SequenceClassifierOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.logits classification (or regression if config.num_labels==1) scores (before SoftMax).
   */
  constructor({ logits }) {
    super();
    this.logits = logits;
  }
}
class XVectorOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.logits Classification hidden states before AMSoftmax, of shape `(batch_size, config.xvector_output_dim)`.
   * @param {Tensor} output.embeddings Utterance embeddings used for vector similarity-based retrieval, of shape `(batch_size, config.xvector_output_dim)`.
   */
  constructor({ logits, embeddings }) {
    super();
    this.logits = logits;
    this.embeddings = embeddings;
  }
}
class TokenClassifierOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.logits Classification scores (before SoftMax).
   */
  constructor({ logits }) {
    super();
    this.logits = logits;
  }
}
class MaskedLMOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).
   */
  constructor({ logits }) {
    super();
    this.logits = logits;
  }
}
class QuestionAnsweringModelOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.start_logits Span-start scores (before SoftMax).
   * @param {Tensor} output.end_logits Span-end scores (before SoftMax).
   */
  constructor({ start_logits, end_logits }) {
    super();
    this.start_logits = start_logits;
    this.end_logits = end_logits;
  }
}
class CausalLMOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before softmax).
   */
  constructor({ logits }) {
    super();
    this.logits = logits;
  }
}
class ImageMattingOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.alphas Estimated alpha values, of shape `(batch_size, num_channels, height, width)`.
   */
  constructor({ alphas }) {
    super();
    this.alphas = alphas;
  }
}
class VitsModelOutput extends ModelOutput {
  /**
   * @param {Object} output The output of the model.
   * @param {Tensor} output.waveform The final audio waveform predicted by the model, of shape `(batch_size, sequence_length)`.
   * @param {Tensor} output.spectrogram The log-mel spectrogram predicted at the output of the flow model.
   * This spectrogram is passed to the Hi-Fi GAN decoder model to obtain the final audio waveform.
   */
  constructor({ waveform, spectrogram: spectrogram2 }) {
    super();
    this.waveform = waveform;
    this.spectrogram = spectrogram2;
  }
}
const defined = function(val) {
  return typeof val !== "undefined" && val !== null;
};
const object = function(val) {
  return typeof val === "object";
};
const plainObject = function(val) {
  return Object.prototype.toString.call(val) === "[object Object]";
};
const fn = function(val) {
  return typeof val === "function";
};
const bool$1 = function(val) {
  return typeof val === "boolean";
};
const buffer = function(val) {
  return val instanceof Buffer;
};
const typedArray = function(val) {
  if (defined(val)) {
    switch (val.constructor) {
      case Uint8Array:
      case Uint8ClampedArray:
      case Int8Array:
      case Uint16Array:
      case Int16Array:
      case Uint32Array:
      case Int32Array:
      case Float32Array:
      case Float64Array:
        return true;
    }
  }
  return false;
};
const arrayBuffer = function(val) {
  return val instanceof ArrayBuffer;
};
const string = function(val) {
  return typeof val === "string" && val.length > 0;
};
const number = function(val) {
  return typeof val === "number" && !Number.isNaN(val);
};
const integer = function(val) {
  return Number.isInteger(val);
};
const inRange = function(val, min2, max2) {
  return val >= min2 && val <= max2;
};
const inArray = function(val, list) {
  return list.includes(val);
};
const invalidParameterError = function(name2, expected, actual) {
  return new Error(
    `Expected ${expected} for ${name2} but received ${actual} of type ${typeof actual}`
  );
};
var is$9 = {
  defined,
  object,
  plainObject,
  fn,
  bool: bool$1,
  buffer,
  typedArray,
  arrayBuffer,
  string,
  number,
  integer,
  inRange,
  inArray,
  invalidParameterError
};
const debug$1 = typeof process === "object" && process.env && process.env.NODE_DEBUG && /\bsemver\b/i.test(process.env.NODE_DEBUG) ? (...args) => console.error("SEMVER", ...args) : () => {
};
var debug_1 = debug$1;
const MAX_LENGTH$2 = 256;
const MAX_SAFE_INTEGER$1 = Number.MAX_SAFE_INTEGER || /* istanbul ignore next */
9007199254740991;
const MAX_SAFE_COMPONENT_LENGTH = 16;
const MAX_SAFE_BUILD_LENGTH = MAX_LENGTH$2 - 6;
var constants = {
  MAX_LENGTH: MAX_LENGTH$2,
  MAX_SAFE_COMPONENT_LENGTH,
  MAX_SAFE_BUILD_LENGTH,
  MAX_SAFE_INTEGER: MAX_SAFE_INTEGER$1
};
var re$2 = { exports: {} };
(function(module2, exports$12) {
  const {
    MAX_SAFE_COMPONENT_LENGTH: MAX_SAFE_COMPONENT_LENGTH2,
    MAX_SAFE_BUILD_LENGTH: MAX_SAFE_BUILD_LENGTH2,
    MAX_LENGTH: MAX_LENGTH2
  } = constants;
  const debug2 = debug_1;
  exports$12 = module2.exports = {};
  const re2 = exports$12.re = [];
  const safeRe = exports$12.safeRe = [];
  const src = exports$12.src = [];
  const safeSrc = exports$12.safeSrc = [];
  const t2 = exports$12.t = {};
  let R = 0;
  const LETTERDASHNUMBER = "[a-zA-Z0-9-]";
  const safeRegexReplacements = [
    ["\\s", 1],
    ["\\d", MAX_LENGTH2],
    [LETTERDASHNUMBER, MAX_SAFE_BUILD_LENGTH2]
  ];
  const makeSafeRegex = (value) => {
    for (const [token, max2] of safeRegexReplacements) {
      value = value.split(`${token}*`).join(`${token}{0,${max2}}`).split(`${token}+`).join(`${token}{1,${max2}}`);
    }
    return value;
  };
  const createToken = (name2, value, isGlobal) => {
    const safe = makeSafeRegex(value);
    const index2 = R++;
    debug2(name2, index2, value);
    t2[name2] = index2;
    src[index2] = value;
    safeSrc[index2] = safe;
    re2[index2] = new RegExp(value, isGlobal ? "g" : void 0);
    safeRe[index2] = new RegExp(safe, isGlobal ? "g" : void 0);
  };
  createToken("NUMERICIDENTIFIER", "0|[1-9]\\d*");
  createToken("NUMERICIDENTIFIERLOOSE", "\\d+");
  createToken("NONNUMERICIDENTIFIER", `\\d*[a-zA-Z-]${LETTERDASHNUMBER}*`);
  createToken("MAINVERSION", `(${src[t2.NUMERICIDENTIFIER]})\\.(${src[t2.NUMERICIDENTIFIER]})\\.(${src[t2.NUMERICIDENTIFIER]})`);
  createToken("MAINVERSIONLOOSE", `(${src[t2.NUMERICIDENTIFIERLOOSE]})\\.(${src[t2.NUMERICIDENTIFIERLOOSE]})\\.(${src[t2.NUMERICIDENTIFIERLOOSE]})`);
  createToken("PRERELEASEIDENTIFIER", `(?:${src[t2.NONNUMERICIDENTIFIER]}|${src[t2.NUMERICIDENTIFIER]})`);
  createToken("PRERELEASEIDENTIFIERLOOSE", `(?:${src[t2.NONNUMERICIDENTIFIER]}|${src[t2.NUMERICIDENTIFIERLOOSE]})`);
  createToken("PRERELEASE", `(?:-(${src[t2.PRERELEASEIDENTIFIER]}(?:\\.${src[t2.PRERELEASEIDENTIFIER]})*))`);
  createToken("PRERELEASELOOSE", `(?:-?(${src[t2.PRERELEASEIDENTIFIERLOOSE]}(?:\\.${src[t2.PRERELEASEIDENTIFIERLOOSE]})*))`);
  createToken("BUILDIDENTIFIER", `${LETTERDASHNUMBER}+`);
  createToken("BUILD", `(?:\\+(${src[t2.BUILDIDENTIFIER]}(?:\\.${src[t2.BUILDIDENTIFIER]})*))`);
  createToken("FULLPLAIN", `v?${src[t2.MAINVERSION]}${src[t2.PRERELEASE]}?${src[t2.BUILD]}?`);
  createToken("FULL", `^${src[t2.FULLPLAIN]}$`);
  createToken("LOOSEPLAIN", `[v=\\s]*${src[t2.MAINVERSIONLOOSE]}${src[t2.PRERELEASELOOSE]}?${src[t2.BUILD]}?`);
  createToken("LOOSE", `^${src[t2.LOOSEPLAIN]}$`);
  createToken("GTLT", "((?:<|>)?=?)");
  createToken("XRANGEIDENTIFIERLOOSE", `${src[t2.NUMERICIDENTIFIERLOOSE]}|x|X|\\*`);
  createToken("XRANGEIDENTIFIER", `${src[t2.NUMERICIDENTIFIER]}|x|X|\\*`);
  createToken("XRANGEPLAIN", `[v=\\s]*(${src[t2.XRANGEIDENTIFIER]})(?:\\.(${src[t2.XRANGEIDENTIFIER]})(?:\\.(${src[t2.XRANGEIDENTIFIER]})(?:${src[t2.PRERELEASE]})?${src[t2.BUILD]}?)?)?`);
  createToken("XRANGEPLAINLOOSE", `[v=\\s]*(${src[t2.XRANGEIDENTIFIERLOOSE]})(?:\\.(${src[t2.XRANGEIDENTIFIERLOOSE]})(?:\\.(${src[t2.XRANGEIDENTIFIERLOOSE]})(?:${src[t2.PRERELEASELOOSE]})?${src[t2.BUILD]}?)?)?`);
  createToken("XRANGE", `^${src[t2.GTLT]}\\s*${src[t2.XRANGEPLAIN]}$`);
  createToken("XRANGELOOSE", `^${src[t2.GTLT]}\\s*${src[t2.XRANGEPLAINLOOSE]}$`);
  createToken("COERCEPLAIN", `${"(^|[^\\d])(\\d{1,"}${MAX_SAFE_COMPONENT_LENGTH2}})(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH2}}))?(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH2}}))?`);
  createToken("COERCE", `${src[t2.COERCEPLAIN]}(?:$|[^\\d])`);
  createToken("COERCEFULL", src[t2.COERCEPLAIN] + `(?:${src[t2.PRERELEASE]})?(?:${src[t2.BUILD]})?(?:$|[^\\d])`);
  createToken("COERCERTL", src[t2.COERCE], true);
  createToken("COERCERTLFULL", src[t2.COERCEFULL], true);
  createToken("LONETILDE", "(?:~>?)");
  createToken("TILDETRIM", `(\\s*)${src[t2.LONETILDE]}\\s+`, true);
  exports$12.tildeTrimReplace = "$1~";
  createToken("TILDE", `^${src[t2.LONETILDE]}${src[t2.XRANGEPLAIN]}$`);
  createToken("TILDELOOSE", `^${src[t2.LONETILDE]}${src[t2.XRANGEPLAINLOOSE]}$`);
  createToken("LONECARET", "(?:\\^)");
  createToken("CARETTRIM", `(\\s*)${src[t2.LONECARET]}\\s+`, true);
  exports$12.caretTrimReplace = "$1^";
  createToken("CARET", `^${src[t2.LONECARET]}${src[t2.XRANGEPLAIN]}$`);
  createToken("CARETLOOSE", `^${src[t2.LONECARET]}${src[t2.XRANGEPLAINLOOSE]}$`);
  createToken("COMPARATORLOOSE", `^${src[t2.GTLT]}\\s*(${src[t2.LOOSEPLAIN]})$|^$`);
  createToken("COMPARATOR", `^${src[t2.GTLT]}\\s*(${src[t2.FULLPLAIN]})$|^$`);
  createToken("COMPARATORTRIM", `(\\s*)${src[t2.GTLT]}\\s*(${src[t2.LOOSEPLAIN]}|${src[t2.XRANGEPLAIN]})`, true);
  exports$12.comparatorTrimReplace = "$1$2$3";
  createToken("HYPHENRANGE", `^\\s*(${src[t2.XRANGEPLAIN]})\\s+-\\s+(${src[t2.XRANGEPLAIN]})\\s*$`);
  createToken("HYPHENRANGELOOSE", `^\\s*(${src[t2.XRANGEPLAINLOOSE]})\\s+-\\s+(${src[t2.XRANGEPLAINLOOSE]})\\s*$`);
  createToken("STAR", "(<|>)?=?\\s*\\*");
  createToken("GTE0", "^\\s*>=\\s*0\\.0\\.0\\s*$");
  createToken("GTE0PRE", "^\\s*>=\\s*0\\.0\\.0-0\\s*$");
})(re$2, re$2.exports);
var reExports = re$2.exports;
const looseOption = Object.freeze({ loose: true });
const emptyOpts = Object.freeze({});
const parseOptions$1 = (options) => {
  if (!options) {
    return emptyOpts;
  }
  if (typeof options !== "object") {
    return looseOption;
  }
  return options;
};
var parseOptions_1 = parseOptions$1;
const numeric = /^[0-9]+$/;
const compareIdentifiers$1 = (a, b) => {
  if (typeof a === "number" && typeof b === "number") {
    return a === b ? 0 : a < b ? -1 : 1;
  }
  const anum = numeric.test(a);
  const bnum = numeric.test(b);
  if (anum && bnum) {
    a = +a;
    b = +b;
  }
  return a === b ? 0 : anum && !bnum ? -1 : bnum && !anum ? 1 : a < b ? -1 : 1;
};
var identifiers = {
  compareIdentifiers: compareIdentifiers$1
};
const debug = debug_1;
const { MAX_LENGTH: MAX_LENGTH$1, MAX_SAFE_INTEGER } = constants;
const { safeRe: re$1, t: t$1 } = reExports;
const parseOptions = parseOptions_1;
const { compareIdentifiers } = identifiers;
let SemVer$3 = class SemVer3 {
  constructor(version2, options) {
    options = parseOptions(options);
    if (version2 instanceof SemVer3) {
      if (version2.loose === !!options.loose && version2.includePrerelease === !!options.includePrerelease) {
        return version2;
      } else {
        version2 = version2.version;
      }
    } else if (typeof version2 !== "string") {
      throw new TypeError(`Invalid version. Must be a string. Got type "${typeof version2}".`);
    }
    if (version2.length > MAX_LENGTH$1) {
      throw new TypeError(
        `version is longer than ${MAX_LENGTH$1} characters`
      );
    }
    debug("SemVer", version2, options);
    this.options = options;
    this.loose = !!options.loose;
    this.includePrerelease = !!options.includePrerelease;
    const m = version2.trim().match(options.loose ? re$1[t$1.LOOSE] : re$1[t$1.FULL]);
    if (!m) {
      throw new TypeError(`Invalid Version: ${version2}`);
    }
    this.raw = version2;
    this.major = +m[1];
    this.minor = +m[2];
    this.patch = +m[3];
    if (this.major > MAX_SAFE_INTEGER || this.major < 0) {
      throw new TypeError("Invalid major version");
    }
    if (this.minor > MAX_SAFE_INTEGER || this.minor < 0) {
      throw new TypeError("Invalid minor version");
    }
    if (this.patch > MAX_SAFE_INTEGER || this.patch < 0) {
      throw new TypeError("Invalid patch version");
    }
    if (!m[4]) {
      this.prerelease = [];
    } else {
      this.prerelease = m[4].split(".").map((id2) => {
        if (/^[0-9]+$/.test(id2)) {
          const num = +id2;
          if (num >= 0 && num < MAX_SAFE_INTEGER) {
            return num;
          }
        }
        return id2;
      });
    }
    this.build = m[5] ? m[5].split(".") : [];
    this.format();
  }
  format() {
    this.version = `${this.major}.${this.minor}.${this.patch}`;
    if (this.prerelease.length) {
      this.version += `-${this.prerelease.join(".")}`;
    }
    return this.version;
  }
  toString() {
    return this.version;
  }
  compare(other) {
    debug("SemVer.compare", this.version, this.options, other);
    if (!(other instanceof SemVer3)) {
      if (typeof other === "string" && other === this.version) {
        return 0;
      }
      other = new SemVer3(other, this.options);
    }
    if (other.version === this.version) {
      return 0;
    }
    return this.compareMain(other) || this.comparePre(other);
  }
  compareMain(other) {
    if (!(other instanceof SemVer3)) {
      other = new SemVer3(other, this.options);
    }
    if (this.major < other.major) {
      return -1;
    }
    if (this.major > other.major) {
      return 1;
    }
    if (this.minor < other.minor) {
      return -1;
    }
    if (this.minor > other.minor) {
      return 1;
    }
    if (this.patch < other.patch) {
      return -1;
    }
    if (this.patch > other.patch) {
      return 1;
    }
    return 0;
  }
  comparePre(other) {
    if (!(other instanceof SemVer3)) {
      other = new SemVer3(other, this.options);
    }
    if (this.prerelease.length && !other.prerelease.length) {
      return -1;
    } else if (!this.prerelease.length && other.prerelease.length) {
      return 1;
    } else if (!this.prerelease.length && !other.prerelease.length) {
      return 0;
    }
    let i2 = 0;
    do {
      const a = this.prerelease[i2];
      const b = other.prerelease[i2];
      debug("prerelease compare", i2, a, b);
      if (a === void 0 && b === void 0) {
        return 0;
      } else if (b === void 0) {
        return 1;
      } else if (a === void 0) {
        return -1;
      } else if (a === b) {
        continue;
      } else {
        return compareIdentifiers(a, b);
      }
    } while (++i2);
  }
  compareBuild(other) {
    if (!(other instanceof SemVer3)) {
      other = new SemVer3(other, this.options);
    }
    let i2 = 0;
    do {
      const a = this.build[i2];
      const b = other.build[i2];
      debug("build compare", i2, a, b);
      if (a === void 0 && b === void 0) {
        return 0;
      } else if (b === void 0) {
        return 1;
      } else if (a === void 0) {
        return -1;
      } else if (a === b) {
        continue;
      } else {
        return compareIdentifiers(a, b);
      }
    } while (++i2);
  }
  // preminor will bump the version up to the next minor release, and immediately
  // down to pre-release. premajor and prepatch work the same way.
  inc(release, identifier, identifierBase) {
    if (release.startsWith("pre")) {
      if (!identifier && identifierBase === false) {
        throw new Error("invalid increment argument: identifier is empty");
      }
      if (identifier) {
        const match = `-${identifier}`.match(this.options.loose ? re$1[t$1.PRERELEASELOOSE] : re$1[t$1.PRERELEASE]);
        if (!match || match[1] !== identifier) {
          throw new Error(`invalid identifier: ${identifier}`);
        }
      }
    }
    switch (release) {
      case "premajor":
        this.prerelease.length = 0;
        this.patch = 0;
        this.minor = 0;
        this.major++;
        this.inc("pre", identifier, identifierBase);
        break;
      case "preminor":
        this.prerelease.length = 0;
        this.patch = 0;
        this.minor++;
        this.inc("pre", identifier, identifierBase);
        break;
      case "prepatch":
        this.prerelease.length = 0;
        this.inc("patch", identifier, identifierBase);
        this.inc("pre", identifier, identifierBase);
        break;
      case "prerelease":
        if (this.prerelease.length === 0) {
          this.inc("patch", identifier, identifierBase);
        }
        this.inc("pre", identifier, identifierBase);
        break;
      case "release":
        if (this.prerelease.length === 0) {
          throw new Error(`version ${this.raw} is not a prerelease`);
        }
        this.prerelease.length = 0;
        break;
      case "major":
        if (this.minor !== 0 || this.patch !== 0 || this.prerelease.length === 0) {
          this.major++;
        }
        this.minor = 0;
        this.patch = 0;
        this.prerelease = [];
        break;
      case "minor":
        if (this.patch !== 0 || this.prerelease.length === 0) {
          this.minor++;
        }
        this.patch = 0;
        this.prerelease = [];
        break;
      case "patch":
        if (this.prerelease.length === 0) {
          this.patch++;
        }
        this.prerelease = [];
        break;
      case "pre": {
        const base = Number(identifierBase) ? 1 : 0;
        if (this.prerelease.length === 0) {
          this.prerelease = [base];
        } else {
          let i2 = this.prerelease.length;
          while (--i2 >= 0) {
            if (typeof this.prerelease[i2] === "number") {
              this.prerelease[i2]++;
              i2 = -2;
            }
          }
          if (i2 === -1) {
            if (identifier === this.prerelease.join(".") && identifierBase === false) {
              throw new Error("invalid increment argument: identifier already exists");
            }
            this.prerelease.push(base);
          }
        }
        if (identifier) {
          let prerelease2 = [identifier, base];
          if (identifierBase === false) {
            prerelease2 = [identifier];
          }
          if (compareIdentifiers(this.prerelease[0], identifier) === 0) {
            if (isNaN(this.prerelease[1])) {
              this.prerelease = prerelease2;
            }
          } else {
            this.prerelease = prerelease2;
          }
        }
        break;
      }
      default:
        throw new Error(`invalid increment argument: ${release}`);
    }
    this.raw = this.format();
    if (this.build.length) {
      this.raw += `+${this.build.join(".")}`;
    }
    return this;
  }
};
var semver = SemVer$3;
const SemVer$2 = semver;
const parse$1 = (version2, options, throwErrors = false) => {
  if (version2 instanceof SemVer$2) {
    return version2;
  }
  try {
    return new SemVer$2(version2, options);
  } catch (er) {
    if (!throwErrors) {
      return null;
    }
    throw er;
  }
};
var parse_1 = parse$1;
const SemVer$1 = semver;
const parse = parse_1;
const { safeRe: re, t } = reExports;
const coerce = (version2, options) => {
  if (version2 instanceof SemVer$1) {
    return version2;
  }
  if (typeof version2 === "number") {
    version2 = String(version2);
  }
  if (typeof version2 !== "string") {
    return null;
  }
  options = options || {};
  let match = null;
  if (!options.rtl) {
    match = version2.match(options.includePrerelease ? re[t.COERCEFULL] : re[t.COERCE]);
  } else {
    const coerceRtlRegex = options.includePrerelease ? re[t.COERCERTLFULL] : re[t.COERCERTL];
    let next2;
    while ((next2 = coerceRtlRegex.exec(version2)) && (!match || match.index + match[0].length !== version2.length)) {
      if (!match || next2.index + next2[0].length !== match.index + match[0].length) {
        match = next2;
      }
      coerceRtlRegex.lastIndex = next2.index + next2[1].length + next2[2].length;
    }
    coerceRtlRegex.lastIndex = -1;
  }
  if (match === null) {
    return null;
  }
  const major2 = match[2];
  const minor2 = match[3] || "0";
  const patch2 = match[4] || "0";
  const prerelease2 = options.includePrerelease && match[5] ? `-${match[5]}` : "";
  const build = options.includePrerelease && match[6] ? `+${match[6]}` : "";
  return parse(`${major2}.${minor2}.${patch2}${prerelease2}${build}`, options);
};
var coerce_1 = coerce;
const SemVer = semver;
const compare$1 = (a, b, loose) => new SemVer(a, loose).compare(new SemVer(b, loose));
var compare_1 = compare$1;
const compare = compare_1;
const gte = (a, b, loose) => compare(a, b, loose) >= 0;
var gte_1 = gte;
const isLinux$1 = () => process.platform === "linux";
let report = null;
const getReport$1 = () => {
  if (!report) {
    if (isLinux$1() && process.report) {
      const orig = process.report.excludeNetwork;
      process.report.excludeNetwork = true;
      report = process.report.getReport();
      process.report.excludeNetwork = orig;
    } else {
      report = {};
    }
  }
  return report;
};
var process_1 = { isLinux: isLinux$1, getReport: getReport$1 };
const fs$2 = fs$4;
const LDD_PATH$1 = "/usr/bin/ldd";
const SELF_PATH$1 = "/proc/self/exe";
const MAX_LENGTH = 2048;
const readFileSync$1 = (path2) => {
  const fd = fs$2.openSync(path2, "r");
  const buffer2 = Buffer.alloc(MAX_LENGTH);
  const bytesRead = fs$2.readSync(fd, buffer2, 0, MAX_LENGTH, 0);
  fs$2.close(fd, () => {
  });
  return buffer2.subarray(0, bytesRead);
};
const readFile$1 = (path2) => new Promise((resolve2, reject) => {
  fs$2.open(path2, "r", (err, fd) => {
    if (err) {
      reject(err);
    } else {
      const buffer2 = Buffer.alloc(MAX_LENGTH);
      fs$2.read(fd, buffer2, 0, MAX_LENGTH, 0, (_, bytesRead) => {
        resolve2(buffer2.subarray(0, bytesRead));
        fs$2.close(fd, () => {
        });
      });
    }
  });
});
var filesystem = {
  LDD_PATH: LDD_PATH$1,
  SELF_PATH: SELF_PATH$1,
  readFileSync: readFileSync$1,
  readFile: readFile$1
};
const interpreterPath$1 = (elf2) => {
  if (elf2.length < 64) {
    return null;
  }
  if (elf2.readUInt32BE(0) !== 2135247942) {
    return null;
  }
  if (elf2.readUInt8(4) !== 2) {
    return null;
  }
  if (elf2.readUInt8(5) !== 1) {
    return null;
  }
  const offset = elf2.readUInt32LE(32);
  const size = elf2.readUInt16LE(54);
  const count = elf2.readUInt16LE(56);
  for (let i2 = 0; i2 < count; i2++) {
    const headerOffset = offset + i2 * size;
    const type2 = elf2.readUInt32LE(headerOffset);
    if (type2 === 3) {
      const fileOffset = elf2.readUInt32LE(headerOffset + 8);
      const fileSize = elf2.readUInt32LE(headerOffset + 32);
      return elf2.subarray(fileOffset, fileOffset + fileSize).toString().replace(/\0.*$/g, "");
    }
  }
  return null;
};
var elf = {
  interpreterPath: interpreterPath$1
};
const childProcess = require$$0$1;
const { isLinux, getReport } = process_1;
const { LDD_PATH, SELF_PATH, readFile, readFileSync } = filesystem;
const { interpreterPath } = elf;
let cachedFamilyInterpreter;
let cachedFamilyFilesystem;
let cachedVersionFilesystem;
const command = "getconf GNU_LIBC_VERSION 2>&1 || true; ldd --version 2>&1 || true";
let commandOut = "";
const safeCommand = () => {
  if (!commandOut) {
    return new Promise((resolve2) => {
      childProcess.exec(command, (err, out) => {
        commandOut = err ? " " : out;
        resolve2(commandOut);
      });
    });
  }
  return commandOut;
};
const safeCommandSync = () => {
  if (!commandOut) {
    try {
      commandOut = childProcess.execSync(command, { encoding: "utf8" });
    } catch (_err) {
      commandOut = " ";
    }
  }
  return commandOut;
};
const GLIBC = "glibc";
const RE_GLIBC_VERSION = /LIBC[a-z0-9 \-).]*?(\d+\.\d+)/i;
const MUSL = "musl";
const isFileMusl = (f) => f.includes("libc.musl-") || f.includes("ld-musl-");
const familyFromReport = () => {
  const report2 = getReport();
  if (report2.header && report2.header.glibcVersionRuntime) {
    return GLIBC;
  }
  if (Array.isArray(report2.sharedObjects)) {
    if (report2.sharedObjects.some(isFileMusl)) {
      return MUSL;
    }
  }
  return null;
};
const familyFromCommand = (out) => {
  const [getconf, ldd1] = out.split(/[\r\n]+/);
  if (getconf && getconf.includes(GLIBC)) {
    return GLIBC;
  }
  if (ldd1 && ldd1.includes(MUSL)) {
    return MUSL;
  }
  return null;
};
const familyFromInterpreterPath = (path2) => {
  if (path2) {
    if (path2.includes("/ld-musl-")) {
      return MUSL;
    } else if (path2.includes("/ld-linux-")) {
      return GLIBC;
    }
  }
  return null;
};
const getFamilyFromLddContent = (content2) => {
  content2 = content2.toString();
  if (content2.includes("musl")) {
    return MUSL;
  }
  if (content2.includes("GNU C Library")) {
    return GLIBC;
  }
  return null;
};
const familyFromFilesystem = async () => {
  if (cachedFamilyFilesystem !== void 0) {
    return cachedFamilyFilesystem;
  }
  cachedFamilyFilesystem = null;
  try {
    const lddContent = await readFile(LDD_PATH);
    cachedFamilyFilesystem = getFamilyFromLddContent(lddContent);
  } catch (e) {
  }
  return cachedFamilyFilesystem;
};
const familyFromFilesystemSync = () => {
  if (cachedFamilyFilesystem !== void 0) {
    return cachedFamilyFilesystem;
  }
  cachedFamilyFilesystem = null;
  try {
    const lddContent = readFileSync(LDD_PATH);
    cachedFamilyFilesystem = getFamilyFromLddContent(lddContent);
  } catch (e) {
  }
  return cachedFamilyFilesystem;
};
const familyFromInterpreter = async () => {
  if (cachedFamilyInterpreter !== void 0) {
    return cachedFamilyInterpreter;
  }
  cachedFamilyInterpreter = null;
  try {
    const selfContent = await readFile(SELF_PATH);
    const path2 = interpreterPath(selfContent);
    cachedFamilyInterpreter = familyFromInterpreterPath(path2);
  } catch (e) {
  }
  return cachedFamilyInterpreter;
};
const familyFromInterpreterSync = () => {
  if (cachedFamilyInterpreter !== void 0) {
    return cachedFamilyInterpreter;
  }
  cachedFamilyInterpreter = null;
  try {
    const selfContent = readFileSync(SELF_PATH);
    const path2 = interpreterPath(selfContent);
    cachedFamilyInterpreter = familyFromInterpreterPath(path2);
  } catch (e) {
  }
  return cachedFamilyInterpreter;
};
const family = async () => {
  let family2 = null;
  if (isLinux()) {
    family2 = await familyFromInterpreter();
    if (!family2) {
      family2 = await familyFromFilesystem();
      if (!family2) {
        family2 = familyFromReport();
      }
      if (!family2) {
        const out = await safeCommand();
        family2 = familyFromCommand(out);
      }
    }
  }
  return family2;
};
const familySync = () => {
  let family2 = null;
  if (isLinux()) {
    family2 = familyFromInterpreterSync();
    if (!family2) {
      family2 = familyFromFilesystemSync();
      if (!family2) {
        family2 = familyFromReport();
      }
      if (!family2) {
        const out = safeCommandSync();
        family2 = familyFromCommand(out);
      }
    }
  }
  return family2;
};
const isNonGlibcLinux = async () => isLinux() && await family() !== GLIBC;
const isNonGlibcLinuxSync = () => isLinux() && familySync() !== GLIBC;
const versionFromFilesystem = async () => {
  if (cachedVersionFilesystem !== void 0) {
    return cachedVersionFilesystem;
  }
  cachedVersionFilesystem = null;
  try {
    const lddContent = await readFile(LDD_PATH);
    const versionMatch = lddContent.match(RE_GLIBC_VERSION);
    if (versionMatch) {
      cachedVersionFilesystem = versionMatch[1];
    }
  } catch (e) {
  }
  return cachedVersionFilesystem;
};
const versionFromFilesystemSync = () => {
  if (cachedVersionFilesystem !== void 0) {
    return cachedVersionFilesystem;
  }
  cachedVersionFilesystem = null;
  try {
    const lddContent = readFileSync(LDD_PATH);
    const versionMatch = lddContent.match(RE_GLIBC_VERSION);
    if (versionMatch) {
      cachedVersionFilesystem = versionMatch[1];
    }
  } catch (e) {
  }
  return cachedVersionFilesystem;
};
const versionFromReport = () => {
  const report2 = getReport();
  if (report2.header && report2.header.glibcVersionRuntime) {
    return report2.header.glibcVersionRuntime;
  }
  return null;
};
const versionSuffix = (s) => s.trim().split(/\s+/)[1];
const versionFromCommand = (out) => {
  const [getconf, ldd1, ldd2] = out.split(/[\r\n]+/);
  if (getconf && getconf.includes(GLIBC)) {
    return versionSuffix(getconf);
  }
  if (ldd1 && ldd2 && ldd1.includes(MUSL)) {
    return versionSuffix(ldd2);
  }
  return null;
};
const version$1 = async () => {
  let version2 = null;
  if (isLinux()) {
    version2 = await versionFromFilesystem();
    if (!version2) {
      version2 = versionFromReport();
    }
    if (!version2) {
      const out = await safeCommand();
      version2 = versionFromCommand(out);
    }
  }
  return version2;
};
const versionSync = () => {
  let version2 = null;
  if (isLinux()) {
    version2 = versionFromFilesystemSync();
    if (!version2) {
      version2 = versionFromReport();
    }
    if (!version2) {
      const out = safeCommandSync();
      version2 = versionFromCommand(out);
    }
  }
  return version2;
};
var detectLibc$2 = {
  GLIBC,
  MUSL,
  family,
  familySync,
  isNonGlibcLinux,
  isNonGlibcLinuxSync,
  version: version$1,
  versionSync
};
const detectLibc$1 = detectLibc$2;
const env$1 = process.env;
var platform$1 = function() {
  const arch = env$1.npm_config_arch || process.arch;
  const platform2 = env$1.npm_config_platform || process.platform;
  const libc = process.env.npm_config_libc || /* istanbul ignore next */
  (detectLibc$1.isNonGlibcLinuxSync() ? detectLibc$1.familySync() : "");
  const libcId = platform2 !== "linux" || libc === detectLibc$1.GLIBC ? "" : libc;
  const platformId = [`${platform2}${libcId}`];
  if (arch === "arm") {
    const fallback = process.versions.electron ? "7" : "6";
    platformId.push(`armv${env$1.npm_config_arm_version || process.config.variables.arm_version || fallback}`);
  } else if (arch === "arm64") {
    platformId.push(`arm64v${env$1.npm_config_arm_version || "8"}`);
  } else {
    platformId.push(arch);
  }
  return platformId.join("-");
};
const version = "0.32.6";
const config$1 = {
  libvips: "8.14.5",
  integrity: {
    "darwin-arm64v8": "sha512-1QZzICfCJd4wAO0P6qmYI5e5VFMt9iCE4QgefI8VMMbdSzjIXA9L/ARN6pkMQPZ3h20Y9RtJ2W1skgCsvCIccw==",
    "darwin-x64": "sha512-sMIKMYXsdU9FlIfztj6Kt/SfHlhlDpP0Ups7ftVFqwjaszmYmpI9y/d/q3mLb4jrzuSiSUEislSWCwBnW7MPTw==",
    "linux-arm64v8": "sha512-CD8owELzkDumaom+O3jJ8fKamILAQdj+//KK/VNcHK3sngUcFpdjx36C8okwbux9sml/T7GTB/gzpvReDrAejQ==",
    "linux-armv6": "sha512-wk6IPHatDFVWKJy7lI1TJezHGHPQut1wF2bwx256KlZwXUQU3fcVcMpV1zxXjgLFewHq2+uhyMkoSGBPahWzlA==",
    "linux-armv7": "sha512-HEZC9KYtkmBK5rUR2MqBhrVarnQVZ/TwLUeLkKq0XuoM2pc/eXI6N0Fh5NGEFwdXI2XE8g1ySf+OYS6DDi+xCQ==",
    "linux-x64": "sha512-SlFWrITSW5XVUkaFPQOySAaSGXnhkGJCj8X2wGYYta9hk5piZldQyMp4zwy0z6UeRu1qKTKtZvmq28W3Gnh9xA==",
    "linuxmusl-arm64v8": "sha512-ga9iX7WUva3sG/VsKkOD318InLlCfPIztvzCZKZ2/+izQXRbQi8VoXWMHgEN4KHACv45FTl7mJ/8CRqUzhS8wQ==",
    "linuxmusl-x64": "sha512-yeaHnpfee1hrZLok2l4eFceHzlfq8gN3QOu0R4Mh8iMK5O5vAUu97bdtxeZZeJJvHw8tfh2/msGi0qysxKN8bw==",
    "win32-arm64v8": "sha512-kR91hy9w1+GEXK56hLh51+hBCBo7T+ijM4Slkmvb/2PsYZySq5H7s61n99iDYl6kTJP2y9sW5Xcvm3uuXDaDgg==",
    "win32-ia32": "sha512-HrnofEbzHNpHJ0vVnjsTj5yfgVdcqdWshXuwFO2zc8xlEjA83BvXZ0lVj9MxPxkxJ2ta+/UlLr+CFzc5bOceMw==",
    "win32-x64": "sha512-BwKckinJZ0Fu/EcunqiLPwOLEBWp4xf8GV7nvmVuKKz5f6B+GxoA2k9aa2wueqv4r4RJVgV/aWXZWFKOIjre/Q=="
  }
};
const require$$7 = {
  version,
  config: config$1
};
const fs$1 = fs$4;
const os = require$$1$1;
const path$2 = path$4;
const spawnSync = require$$0$1.spawnSync;
const semverCoerce = coerce_1;
const semverGreaterThanOrEqualTo = gte_1;
const platform = platform$1;
const { config } = require$$7;
const env = process.env;
const minimumLibvipsVersionLabelled = env.npm_package_config_libvips || /* istanbul ignore next */
config.libvips;
const minimumLibvipsVersion = semverCoerce(minimumLibvipsVersionLabelled).version;
const spawnSyncOptions = {
  encoding: "utf8",
  shell: true
};
const vendorPath = path$2.join(__dirname, "..", "vendor", minimumLibvipsVersion, platform());
const mkdirSync = function(dirPath) {
  try {
    fs$1.mkdirSync(dirPath, { recursive: true });
  } catch (err) {
    if (err.code !== "EEXIST") {
      throw err;
    }
  }
};
const cachePath = function() {
  const npmCachePath = env.npm_config_cache || /* istanbul ignore next */
  (env.APPDATA ? path$2.join(env.APPDATA, "npm-cache") : path$2.join(os.homedir(), ".npm"));
  mkdirSync(npmCachePath);
  const libvipsCachePath = path$2.join(npmCachePath, "_libvips");
  mkdirSync(libvipsCachePath);
  return libvipsCachePath;
};
const integrity = function(platformAndArch2) {
  return env[`npm_package_config_integrity_${platformAndArch2.replace("-", "_")}`] || config.integrity[platformAndArch2];
};
const log = function(item) {
  if (item instanceof Error) {
    console.error(`sharp: Installation error: ${item.message}`);
  } else {
    console.log(`sharp: ${item}`);
  }
};
const isRosetta = function() {
  if (process.platform === "darwin" && process.arch === "x64") {
    const translated = spawnSync("sysctl sysctl.proc_translated", spawnSyncOptions).stdout;
    return (translated || "").trim() === "sysctl.proc_translated: 1";
  }
  return false;
};
const globalLibvipsVersion = function() {
  if (process.platform !== "win32") {
    const globalLibvipsVersion2 = spawnSync("pkg-config --modversion vips-cpp", {
      ...spawnSyncOptions,
      env: {
        ...env,
        PKG_CONFIG_PATH: pkgConfigPath()
      }
    }).stdout;
    return (globalLibvipsVersion2 || "").trim();
  } else {
    return "";
  }
};
const hasVendoredLibvips = function() {
  return fs$1.existsSync(vendorPath);
};
const removeVendoredLibvips = function() {
  fs$1.rmSync(vendorPath, { recursive: true, maxRetries: 3, force: true });
};
const pkgConfigPath = function() {
  if (process.platform !== "win32") {
    const brewPkgConfigPath = spawnSync(
      'which brew >/dev/null 2>&1 && brew environment --plain | grep PKG_CONFIG_LIBDIR | cut -d" " -f2',
      spawnSyncOptions
    ).stdout || "";
    return [
      brewPkgConfigPath.trim(),
      env.PKG_CONFIG_PATH,
      "/usr/local/lib/pkgconfig",
      "/usr/lib/pkgconfig",
      "/usr/local/libdata/pkgconfig",
      "/usr/libdata/pkgconfig"
    ].filter(Boolean).join(":");
  } else {
    return "";
  }
};
const useGlobalLibvips = function() {
  if (Boolean(env.SHARP_IGNORE_GLOBAL_LIBVIPS) === true) {
    return false;
  }
  if (isRosetta()) {
    log("Detected Rosetta, skipping search for globally-installed libvips");
    return false;
  }
  const globalVipsVersion = globalLibvipsVersion();
  return !!globalVipsVersion && /* istanbul ignore next */
  semverGreaterThanOrEqualTo(globalVipsVersion, minimumLibvipsVersion);
};
var libvips = {
  minimumLibvipsVersion,
  minimumLibvipsVersionLabelled,
  cachePath,
  integrity,
  log,
  globalLibvipsVersion,
  hasVendoredLibvips,
  removeVendoredLibvips,
  pkgConfigPath,
  useGlobalLibvips,
  mkdirSync
};
var sharp$4 = { exports: {} };
const platformAndArch$1 = platform$1();
try {
  sharp$4.exports = commonjsRequire(`../build/Release/sharp-${platformAndArch$1}.node`);
} catch (err) {
  const help = ["", 'Something went wrong installing the "sharp" module', "", err.message, "", "Possible solutions:"];
  if (/dylib/.test(err.message) && /Incompatible library version/.test(err.message)) {
    help.push('- Update Homebrew: "brew update && brew upgrade vips"');
  } else {
    const [platform2, arch] = platformAndArch$1.split("-");
    if (platform2 === "linux" && /Module did not self-register/.test(err.message)) {
      help.push("- Using worker threads? See https://sharp.pixelplumbing.com/install#worker-threads");
    }
    help.push(
      '- Install with verbose logging and look for errors: "npm install --ignore-scripts=false --foreground-scripts --verbose sharp"',
      `- Install for the current ${platformAndArch$1} runtime: "npm install --platform=${platform2} --arch=${arch} sharp"`
    );
  }
  help.push(
    "- Consult the installation documentation: https://sharp.pixelplumbing.com/install"
  );
  if (process.platform === "win32" || /symbol/.test(err.message)) {
    const loadedModule = Object.keys(require.cache).find((i2) => /[\\/]build[\\/]Release[\\/]sharp(.*)\.node$/.test(i2));
    if (loadedModule) {
      const [, loadedPackage] = loadedModule.match(/node_modules[\\/]([^\\/]+)[\\/]/);
      help.push(`- Ensure the version of sharp aligns with the ${loadedPackage} package: "npm ls sharp"`);
    }
  }
  throw new Error(help.join("\n"));
}
var sharpExports = sharp$4.exports;
const util = require$$4$1;
const stream = require$$1$2;
const is$8 = is$9;
libvips.hasVendoredLibvips();
const debuglog = util.debuglog("sharp");
const Sharp$1 = function(input2, options) {
  if (arguments.length === 1 && !is$8.defined(input2)) {
    throw new Error("Invalid input");
  }
  if (!(this instanceof Sharp$1)) {
    return new Sharp$1(input2, options);
  }
  stream.Duplex.call(this);
  this.options = {
    // resize options
    topOffsetPre: -1,
    leftOffsetPre: -1,
    widthPre: -1,
    heightPre: -1,
    topOffsetPost: -1,
    leftOffsetPost: -1,
    widthPost: -1,
    heightPost: -1,
    width: -1,
    height: -1,
    canvas: "crop",
    position: 0,
    resizeBackground: [0, 0, 0, 255],
    useExifOrientation: false,
    angle: 0,
    rotationAngle: 0,
    rotationBackground: [0, 0, 0, 255],
    rotateBeforePreExtract: false,
    flip: false,
    flop: false,
    extendTop: 0,
    extendBottom: 0,
    extendLeft: 0,
    extendRight: 0,
    extendBackground: [0, 0, 0, 255],
    extendWith: "background",
    withoutEnlargement: false,
    withoutReduction: false,
    affineMatrix: [],
    affineBackground: [0, 0, 0, 255],
    affineIdx: 0,
    affineIdy: 0,
    affineOdx: 0,
    affineOdy: 0,
    affineInterpolator: this.constructor.interpolators.bilinear,
    kernel: "lanczos3",
    fastShrinkOnLoad: true,
    // operations
    tintA: 128,
    tintB: 128,
    flatten: false,
    flattenBackground: [0, 0, 0],
    unflatten: false,
    negate: false,
    negateAlpha: true,
    medianSize: 0,
    blurSigma: 0,
    sharpenSigma: 0,
    sharpenM1: 1,
    sharpenM2: 2,
    sharpenX1: 2,
    sharpenY2: 10,
    sharpenY3: 20,
    threshold: 0,
    thresholdGrayscale: true,
    trimBackground: [],
    trimThreshold: 0,
    gamma: 0,
    gammaOut: 0,
    greyscale: false,
    normalise: false,
    normaliseLower: 1,
    normaliseUpper: 99,
    claheWidth: 0,
    claheHeight: 0,
    claheMaxSlope: 3,
    brightness: 1,
    saturation: 1,
    hue: 0,
    lightness: 0,
    booleanBufferIn: null,
    booleanFileIn: "",
    joinChannelIn: [],
    extractChannel: -1,
    removeAlpha: false,
    ensureAlpha: -1,
    colourspace: "srgb",
    colourspaceInput: "last",
    composite: [],
    // output
    fileOut: "",
    formatOut: "input",
    streamOut: false,
    withMetadata: false,
    withMetadataOrientation: -1,
    withMetadataDensity: 0,
    withMetadataIcc: "",
    withMetadataStrs: {},
    resolveWithObject: false,
    // output format
    jpegQuality: 80,
    jpegProgressive: false,
    jpegChromaSubsampling: "4:2:0",
    jpegTrellisQuantisation: false,
    jpegOvershootDeringing: false,
    jpegOptimiseScans: false,
    jpegOptimiseCoding: true,
    jpegQuantisationTable: 0,
    pngProgressive: false,
    pngCompressionLevel: 6,
    pngAdaptiveFiltering: false,
    pngPalette: false,
    pngQuality: 100,
    pngEffort: 7,
    pngBitdepth: 8,
    pngDither: 1,
    jp2Quality: 80,
    jp2TileHeight: 512,
    jp2TileWidth: 512,
    jp2Lossless: false,
    jp2ChromaSubsampling: "4:4:4",
    webpQuality: 80,
    webpAlphaQuality: 100,
    webpLossless: false,
    webpNearLossless: false,
    webpSmartSubsample: false,
    webpPreset: "default",
    webpEffort: 4,
    webpMinSize: false,
    webpMixed: false,
    gifBitdepth: 8,
    gifEffort: 7,
    gifDither: 1,
    gifInterFrameMaxError: 0,
    gifInterPaletteMaxError: 3,
    gifReuse: true,
    gifProgressive: false,
    tiffQuality: 80,
    tiffCompression: "jpeg",
    tiffPredictor: "horizontal",
    tiffPyramid: false,
    tiffBitdepth: 8,
    tiffTile: false,
    tiffTileHeight: 256,
    tiffTileWidth: 256,
    tiffXres: 1,
    tiffYres: 1,
    tiffResolutionUnit: "inch",
    heifQuality: 50,
    heifLossless: false,
    heifCompression: "av1",
    heifEffort: 4,
    heifChromaSubsampling: "4:4:4",
    jxlDistance: 1,
    jxlDecodingTier: 0,
    jxlEffort: 7,
    jxlLossless: false,
    rawDepth: "uchar",
    tileSize: 256,
    tileOverlap: 0,
    tileContainer: "fs",
    tileLayout: "dz",
    tileFormat: "last",
    tileDepth: "last",
    tileAngle: 0,
    tileSkipBlanks: -1,
    tileBackground: [255, 255, 255, 255],
    tileCentre: false,
    tileId: "https://example.com/iiif",
    tileBasename: "",
    timeoutSeconds: 0,
    linearA: [],
    linearB: [],
    // Function to notify of libvips warnings
    debuglog: (warning) => {
      this.emit("warning", warning);
      debuglog(warning);
    },
    // Function to notify of queue length changes
    queueListener: function(queueLength) {
      Sharp$1.queue.emit("change", queueLength);
    }
  };
  this.options.input = this._createInputDescriptor(input2, options, { allowStream: true });
  return this;
};
Object.setPrototypeOf(Sharp$1.prototype, stream.Duplex.prototype);
Object.setPrototypeOf(Sharp$1, stream.Duplex);
function clone() {
  const clone2 = this.constructor.call();
  clone2.options = Object.assign({}, this.options);
  if (this._isStreamInput()) {
    this.on("finish", () => {
      this._flattenBufferIn();
      clone2.options.bufferIn = this.options.bufferIn;
      clone2.emit("finish");
    });
  }
  return clone2;
}
Object.assign(Sharp$1.prototype, { clone });
var constructor = Sharp$1;
var colorString$1 = { exports: {} };
var colorName = {
  "aliceblue": [240, 248, 255],
  "antiquewhite": [250, 235, 215],
  "aqua": [0, 255, 255],
  "aquamarine": [127, 255, 212],
  "azure": [240, 255, 255],
  "beige": [245, 245, 220],
  "bisque": [255, 228, 196],
  "black": [0, 0, 0],
  "blanchedalmond": [255, 235, 205],
  "blue": [0, 0, 255],
  "blueviolet": [138, 43, 226],
  "brown": [165, 42, 42],
  "burlywood": [222, 184, 135],
  "cadetblue": [95, 158, 160],
  "chartreuse": [127, 255, 0],
  "chocolate": [210, 105, 30],
  "coral": [255, 127, 80],
  "cornflowerblue": [100, 149, 237],
  "cornsilk": [255, 248, 220],
  "crimson": [220, 20, 60],
  "cyan": [0, 255, 255],
  "darkblue": [0, 0, 139],
  "darkcyan": [0, 139, 139],
  "darkgoldenrod": [184, 134, 11],
  "darkgray": [169, 169, 169],
  "darkgreen": [0, 100, 0],
  "darkgrey": [169, 169, 169],
  "darkkhaki": [189, 183, 107],
  "darkmagenta": [139, 0, 139],
  "darkolivegreen": [85, 107, 47],
  "darkorange": [255, 140, 0],
  "darkorchid": [153, 50, 204],
  "darkred": [139, 0, 0],
  "darksalmon": [233, 150, 122],
  "darkseagreen": [143, 188, 143],
  "darkslateblue": [72, 61, 139],
  "darkslategray": [47, 79, 79],
  "darkslategrey": [47, 79, 79],
  "darkturquoise": [0, 206, 209],
  "darkviolet": [148, 0, 211],
  "deeppink": [255, 20, 147],
  "deepskyblue": [0, 191, 255],
  "dimgray": [105, 105, 105],
  "dimgrey": [105, 105, 105],
  "dodgerblue": [30, 144, 255],
  "firebrick": [178, 34, 34],
  "floralwhite": [255, 250, 240],
  "forestgreen": [34, 139, 34],
  "fuchsia": [255, 0, 255],
  "gainsboro": [220, 220, 220],
  "ghostwhite": [248, 248, 255],
  "gold": [255, 215, 0],
  "goldenrod": [218, 165, 32],
  "gray": [128, 128, 128],
  "green": [0, 128, 0],
  "greenyellow": [173, 255, 47],
  "grey": [128, 128, 128],
  "honeydew": [240, 255, 240],
  "hotpink": [255, 105, 180],
  "indianred": [205, 92, 92],
  "indigo": [75, 0, 130],
  "ivory": [255, 255, 240],
  "khaki": [240, 230, 140],
  "lavender": [230, 230, 250],
  "lavenderblush": [255, 240, 245],
  "lawngreen": [124, 252, 0],
  "lemonchiffon": [255, 250, 205],
  "lightblue": [173, 216, 230],
  "lightcoral": [240, 128, 128],
  "lightcyan": [224, 255, 255],
  "lightgoldenrodyellow": [250, 250, 210],
  "lightgray": [211, 211, 211],
  "lightgreen": [144, 238, 144],
  "lightgrey": [211, 211, 211],
  "lightpink": [255, 182, 193],
  "lightsalmon": [255, 160, 122],
  "lightseagreen": [32, 178, 170],
  "lightskyblue": [135, 206, 250],
  "lightslategray": [119, 136, 153],
  "lightslategrey": [119, 136, 153],
  "lightsteelblue": [176, 196, 222],
  "lightyellow": [255, 255, 224],
  "lime": [0, 255, 0],
  "limegreen": [50, 205, 50],
  "linen": [250, 240, 230],
  "magenta": [255, 0, 255],
  "maroon": [128, 0, 0],
  "mediumaquamarine": [102, 205, 170],
  "mediumblue": [0, 0, 205],
  "mediumorchid": [186, 85, 211],
  "mediumpurple": [147, 112, 219],
  "mediumseagreen": [60, 179, 113],
  "mediumslateblue": [123, 104, 238],
  "mediumspringgreen": [0, 250, 154],
  "mediumturquoise": [72, 209, 204],
  "mediumvioletred": [199, 21, 133],
  "midnightblue": [25, 25, 112],
  "mintcream": [245, 255, 250],
  "mistyrose": [255, 228, 225],
  "moccasin": [255, 228, 181],
  "navajowhite": [255, 222, 173],
  "navy": [0, 0, 128],
  "oldlace": [253, 245, 230],
  "olive": [128, 128, 0],
  "olivedrab": [107, 142, 35],
  "orange": [255, 165, 0],
  "orangered": [255, 69, 0],
  "orchid": [218, 112, 214],
  "palegoldenrod": [238, 232, 170],
  "palegreen": [152, 251, 152],
  "paleturquoise": [175, 238, 238],
  "palevioletred": [219, 112, 147],
  "papayawhip": [255, 239, 213],
  "peachpuff": [255, 218, 185],
  "peru": [205, 133, 63],
  "pink": [255, 192, 203],
  "plum": [221, 160, 221],
  "powderblue": [176, 224, 230],
  "purple": [128, 0, 128],
  "rebeccapurple": [102, 51, 153],
  "red": [255, 0, 0],
  "rosybrown": [188, 143, 143],
  "royalblue": [65, 105, 225],
  "saddlebrown": [139, 69, 19],
  "salmon": [250, 128, 114],
  "sandybrown": [244, 164, 96],
  "seagreen": [46, 139, 87],
  "seashell": [255, 245, 238],
  "sienna": [160, 82, 45],
  "silver": [192, 192, 192],
  "skyblue": [135, 206, 235],
  "slateblue": [106, 90, 205],
  "slategray": [112, 128, 144],
  "slategrey": [112, 128, 144],
  "snow": [255, 250, 250],
  "springgreen": [0, 255, 127],
  "steelblue": [70, 130, 180],
  "tan": [210, 180, 140],
  "teal": [0, 128, 128],
  "thistle": [216, 191, 216],
  "tomato": [255, 99, 71],
  "turquoise": [64, 224, 208],
  "violet": [238, 130, 238],
  "wheat": [245, 222, 179],
  "white": [255, 255, 255],
  "whitesmoke": [245, 245, 245],
  "yellow": [255, 255, 0],
  "yellowgreen": [154, 205, 50]
};
var simpleSwizzle = { exports: {} };
var isArrayish$1 = function isArrayish2(obj) {
  if (!obj || typeof obj === "string") {
    return false;
  }
  return obj instanceof Array || Array.isArray(obj) || obj.length >= 0 && (obj.splice instanceof Function || Object.getOwnPropertyDescriptor(obj, obj.length - 1) && obj.constructor.name !== "String");
};
var isArrayish = isArrayish$1;
var concat = Array.prototype.concat;
var slice = Array.prototype.slice;
var swizzle$1 = simpleSwizzle.exports = function swizzle2(args) {
  var results = [];
  for (var i2 = 0, len = args.length; i2 < len; i2++) {
    var arg = args[i2];
    if (isArrayish(arg)) {
      results = concat.call(results, slice.call(arg));
    } else {
      results.push(arg);
    }
  }
  return results;
};
swizzle$1.wrap = function(fn2) {
  return function() {
    return fn2(swizzle$1(arguments));
  };
};
var simpleSwizzleExports = simpleSwizzle.exports;
var colorNames = colorName;
var swizzle = simpleSwizzleExports;
var hasOwnProperty = Object.hasOwnProperty;
var reverseNames = /* @__PURE__ */ Object.create(null);
for (var name$1 in colorNames) {
  if (hasOwnProperty.call(colorNames, name$1)) {
    reverseNames[colorNames[name$1]] = name$1;
  }
}
var cs = colorString$1.exports = {
  to: {},
  get: {}
};
cs.get = function(string2) {
  var prefix = string2.substring(0, 3).toLowerCase();
  var val;
  var model;
  switch (prefix) {
    case "hsl":
      val = cs.get.hsl(string2);
      model = "hsl";
      break;
    case "hwb":
      val = cs.get.hwb(string2);
      model = "hwb";
      break;
    default:
      val = cs.get.rgb(string2);
      model = "rgb";
      break;
  }
  if (!val) {
    return null;
  }
  return { model, value: val };
};
cs.get.rgb = function(string2) {
  if (!string2) {
    return null;
  }
  var abbr = /^#([a-f0-9]{3,4})$/i;
  var hex = /^#([a-f0-9]{6})([a-f0-9]{2})?$/i;
  var rgba = /^rgba?\(\s*([+-]?\d+)(?=[\s,])\s*(?:,\s*)?([+-]?\d+)(?=[\s,])\s*(?:,\s*)?([+-]?\d+)\s*(?:[,|\/]\s*([+-]?[\d\.]+)(%?)\s*)?\)$/;
  var per = /^rgba?\(\s*([+-]?[\d\.]+)\%\s*,?\s*([+-]?[\d\.]+)\%\s*,?\s*([+-]?[\d\.]+)\%\s*(?:[,|\/]\s*([+-]?[\d\.]+)(%?)\s*)?\)$/;
  var keyword2 = /^(\w+)$/;
  var rgb = [0, 0, 0, 1];
  var match;
  var i2;
  var hexAlpha;
  if (match = string2.match(hex)) {
    hexAlpha = match[2];
    match = match[1];
    for (i2 = 0; i2 < 3; i2++) {
      var i22 = i2 * 2;
      rgb[i2] = parseInt(match.slice(i22, i22 + 2), 16);
    }
    if (hexAlpha) {
      rgb[3] = parseInt(hexAlpha, 16) / 255;
    }
  } else if (match = string2.match(abbr)) {
    match = match[1];
    hexAlpha = match[3];
    for (i2 = 0; i2 < 3; i2++) {
      rgb[i2] = parseInt(match[i2] + match[i2], 16);
    }
    if (hexAlpha) {
      rgb[3] = parseInt(hexAlpha + hexAlpha, 16) / 255;
    }
  } else if (match = string2.match(rgba)) {
    for (i2 = 0; i2 < 3; i2++) {
      rgb[i2] = parseInt(match[i2 + 1], 0);
    }
    if (match[4]) {
      if (match[5]) {
        rgb[3] = parseFloat(match[4]) * 0.01;
      } else {
        rgb[3] = parseFloat(match[4]);
      }
    }
  } else if (match = string2.match(per)) {
    for (i2 = 0; i2 < 3; i2++) {
      rgb[i2] = Math.round(parseFloat(match[i2 + 1]) * 2.55);
    }
    if (match[4]) {
      if (match[5]) {
        rgb[3] = parseFloat(match[4]) * 0.01;
      } else {
        rgb[3] = parseFloat(match[4]);
      }
    }
  } else if (match = string2.match(keyword2)) {
    if (match[1] === "transparent") {
      return [0, 0, 0, 0];
    }
    if (!hasOwnProperty.call(colorNames, match[1])) {
      return null;
    }
    rgb = colorNames[match[1]];
    rgb[3] = 1;
    return rgb;
  } else {
    return null;
  }
  for (i2 = 0; i2 < 3; i2++) {
    rgb[i2] = clamp(rgb[i2], 0, 255);
  }
  rgb[3] = clamp(rgb[3], 0, 1);
  return rgb;
};
cs.get.hsl = function(string2) {
  if (!string2) {
    return null;
  }
  var hsl = /^hsla?\(\s*([+-]?(?:\d{0,3}\.)?\d+)(?:deg)?\s*,?\s*([+-]?[\d\.]+)%\s*,?\s*([+-]?[\d\.]+)%\s*(?:[,|\/]\s*([+-]?(?=\.\d|\d)(?:0|[1-9]\d*)?(?:\.\d*)?(?:[eE][+-]?\d+)?)\s*)?\)$/;
  var match = string2.match(hsl);
  if (match) {
    var alpha = parseFloat(match[4]);
    var h = (parseFloat(match[1]) % 360 + 360) % 360;
    var s = clamp(parseFloat(match[2]), 0, 100);
    var l = clamp(parseFloat(match[3]), 0, 100);
    var a = clamp(isNaN(alpha) ? 1 : alpha, 0, 1);
    return [h, s, l, a];
  }
  return null;
};
cs.get.hwb = function(string2) {
  if (!string2) {
    return null;
  }
  var hwb = /^hwb\(\s*([+-]?\d{0,3}(?:\.\d+)?)(?:deg)?\s*,\s*([+-]?[\d\.]+)%\s*,\s*([+-]?[\d\.]+)%\s*(?:,\s*([+-]?(?=\.\d|\d)(?:0|[1-9]\d*)?(?:\.\d*)?(?:[eE][+-]?\d+)?)\s*)?\)$/;
  var match = string2.match(hwb);
  if (match) {
    var alpha = parseFloat(match[4]);
    var h = (parseFloat(match[1]) % 360 + 360) % 360;
    var w = clamp(parseFloat(match[2]), 0, 100);
    var b = clamp(parseFloat(match[3]), 0, 100);
    var a = clamp(isNaN(alpha) ? 1 : alpha, 0, 1);
    return [h, w, b, a];
  }
  return null;
};
cs.to.hex = function() {
  var rgba = swizzle(arguments);
  return "#" + hexDouble(rgba[0]) + hexDouble(rgba[1]) + hexDouble(rgba[2]) + (rgba[3] < 1 ? hexDouble(Math.round(rgba[3] * 255)) : "");
};
cs.to.rgb = function() {
  var rgba = swizzle(arguments);
  return rgba.length < 4 || rgba[3] === 1 ? "rgb(" + Math.round(rgba[0]) + ", " + Math.round(rgba[1]) + ", " + Math.round(rgba[2]) + ")" : "rgba(" + Math.round(rgba[0]) + ", " + Math.round(rgba[1]) + ", " + Math.round(rgba[2]) + ", " + rgba[3] + ")";
};
cs.to.rgb.percent = function() {
  var rgba = swizzle(arguments);
  var r = Math.round(rgba[0] / 255 * 100);
  var g = Math.round(rgba[1] / 255 * 100);
  var b = Math.round(rgba[2] / 255 * 100);
  return rgba.length < 4 || rgba[3] === 1 ? "rgb(" + r + "%, " + g + "%, " + b + "%)" : "rgba(" + r + "%, " + g + "%, " + b + "%, " + rgba[3] + ")";
};
cs.to.hsl = function() {
  var hsla = swizzle(arguments);
  return hsla.length < 4 || hsla[3] === 1 ? "hsl(" + hsla[0] + ", " + hsla[1] + "%, " + hsla[2] + "%)" : "hsla(" + hsla[0] + ", " + hsla[1] + "%, " + hsla[2] + "%, " + hsla[3] + ")";
};
cs.to.hwb = function() {
  var hwba = swizzle(arguments);
  var a = "";
  if (hwba.length >= 4 && hwba[3] !== 1) {
    a = ", " + hwba[3];
  }
  return "hwb(" + hwba[0] + ", " + hwba[1] + "%, " + hwba[2] + "%" + a + ")";
};
cs.to.keyword = function(rgb) {
  return reverseNames[rgb.slice(0, 3)];
};
function clamp(num, min2, max2) {
  return Math.min(Math.max(min2, num), max2);
}
function hexDouble(num) {
  var str = Math.round(num).toString(16).toUpperCase();
  return str.length < 2 ? "0" + str : str;
}
var colorStringExports = colorString$1.exports;
const cssKeywords = colorName;
const reverseKeywords = {};
for (const key of Object.keys(cssKeywords)) {
  reverseKeywords[cssKeywords[key]] = key;
}
const convert$2 = {
  rgb: { channels: 3, labels: "rgb" },
  hsl: { channels: 3, labels: "hsl" },
  hsv: { channels: 3, labels: "hsv" },
  hwb: { channels: 3, labels: "hwb" },
  cmyk: { channels: 4, labels: "cmyk" },
  xyz: { channels: 3, labels: "xyz" },
  lab: { channels: 3, labels: "lab" },
  lch: { channels: 3, labels: "lch" },
  hex: { channels: 1, labels: ["hex"] },
  keyword: { channels: 1, labels: ["keyword"] },
  ansi16: { channels: 1, labels: ["ansi16"] },
  ansi256: { channels: 1, labels: ["ansi256"] },
  hcg: { channels: 3, labels: ["h", "c", "g"] },
  apple: { channels: 3, labels: ["r16", "g16", "b16"] },
  gray: { channels: 1, labels: ["gray"] }
};
var conversions$2 = convert$2;
for (const model of Object.keys(convert$2)) {
  if (!("channels" in convert$2[model])) {
    throw new Error("missing channels property: " + model);
  }
  if (!("labels" in convert$2[model])) {
    throw new Error("missing channel labels property: " + model);
  }
  if (convert$2[model].labels.length !== convert$2[model].channels) {
    throw new Error("channel and label counts mismatch: " + model);
  }
  const { channels, labels } = convert$2[model];
  delete convert$2[model].channels;
  delete convert$2[model].labels;
  Object.defineProperty(convert$2[model], "channels", { value: channels });
  Object.defineProperty(convert$2[model], "labels", { value: labels });
}
convert$2.rgb.hsl = function(rgb) {
  const r = rgb[0] / 255;
  const g = rgb[1] / 255;
  const b = rgb[2] / 255;
  const min2 = Math.min(r, g, b);
  const max2 = Math.max(r, g, b);
  const delta = max2 - min2;
  let h;
  let s;
  if (max2 === min2) {
    h = 0;
  } else if (r === max2) {
    h = (g - b) / delta;
  } else if (g === max2) {
    h = 2 + (b - r) / delta;
  } else if (b === max2) {
    h = 4 + (r - g) / delta;
  }
  h = Math.min(h * 60, 360);
  if (h < 0) {
    h += 360;
  }
  const l = (min2 + max2) / 2;
  if (max2 === min2) {
    s = 0;
  } else if (l <= 0.5) {
    s = delta / (max2 + min2);
  } else {
    s = delta / (2 - max2 - min2);
  }
  return [h, s * 100, l * 100];
};
convert$2.rgb.hsv = function(rgb) {
  let rdif;
  let gdif;
  let bdif;
  let h;
  let s;
  const r = rgb[0] / 255;
  const g = rgb[1] / 255;
  const b = rgb[2] / 255;
  const v = Math.max(r, g, b);
  const diff2 = v - Math.min(r, g, b);
  const diffc = function(c) {
    return (v - c) / 6 / diff2 + 1 / 2;
  };
  if (diff2 === 0) {
    h = 0;
    s = 0;
  } else {
    s = diff2 / v;
    rdif = diffc(r);
    gdif = diffc(g);
    bdif = diffc(b);
    if (r === v) {
      h = bdif - gdif;
    } else if (g === v) {
      h = 1 / 3 + rdif - bdif;
    } else if (b === v) {
      h = 2 / 3 + gdif - rdif;
    }
    if (h < 0) {
      h += 1;
    } else if (h > 1) {
      h -= 1;
    }
  }
  return [
    h * 360,
    s * 100,
    v * 100
  ];
};
convert$2.rgb.hwb = function(rgb) {
  const r = rgb[0];
  const g = rgb[1];
  let b = rgb[2];
  const h = convert$2.rgb.hsl(rgb)[0];
  const w = 1 / 255 * Math.min(r, Math.min(g, b));
  b = 1 - 1 / 255 * Math.max(r, Math.max(g, b));
  return [h, w * 100, b * 100];
};
convert$2.rgb.cmyk = function(rgb) {
  const r = rgb[0] / 255;
  const g = rgb[1] / 255;
  const b = rgb[2] / 255;
  const k = Math.min(1 - r, 1 - g, 1 - b);
  const c = (1 - r - k) / (1 - k) || 0;
  const m = (1 - g - k) / (1 - k) || 0;
  const y = (1 - b - k) / (1 - k) || 0;
  return [c * 100, m * 100, y * 100, k * 100];
};
function comparativeDistance(x, y) {
  return (x[0] - y[0]) ** 2 + (x[1] - y[1]) ** 2 + (x[2] - y[2]) ** 2;
}
convert$2.rgb.keyword = function(rgb) {
  const reversed = reverseKeywords[rgb];
  if (reversed) {
    return reversed;
  }
  let currentClosestDistance = Infinity;
  let currentClosestKeyword;
  for (const keyword2 of Object.keys(cssKeywords)) {
    const value = cssKeywords[keyword2];
    const distance = comparativeDistance(rgb, value);
    if (distance < currentClosestDistance) {
      currentClosestDistance = distance;
      currentClosestKeyword = keyword2;
    }
  }
  return currentClosestKeyword;
};
convert$2.keyword.rgb = function(keyword2) {
  return cssKeywords[keyword2];
};
convert$2.rgb.xyz = function(rgb) {
  let r = rgb[0] / 255;
  let g = rgb[1] / 255;
  let b = rgb[2] / 255;
  r = r > 0.04045 ? ((r + 0.055) / 1.055) ** 2.4 : r / 12.92;
  g = g > 0.04045 ? ((g + 0.055) / 1.055) ** 2.4 : g / 12.92;
  b = b > 0.04045 ? ((b + 0.055) / 1.055) ** 2.4 : b / 12.92;
  const x = r * 0.4124 + g * 0.3576 + b * 0.1805;
  const y = r * 0.2126 + g * 0.7152 + b * 0.0722;
  const z = r * 0.0193 + g * 0.1192 + b * 0.9505;
  return [x * 100, y * 100, z * 100];
};
convert$2.rgb.lab = function(rgb) {
  const xyz = convert$2.rgb.xyz(rgb);
  let x = xyz[0];
  let y = xyz[1];
  let z = xyz[2];
  x /= 95.047;
  y /= 100;
  z /= 108.883;
  x = x > 8856e-6 ? x ** (1 / 3) : 7.787 * x + 16 / 116;
  y = y > 8856e-6 ? y ** (1 / 3) : 7.787 * y + 16 / 116;
  z = z > 8856e-6 ? z ** (1 / 3) : 7.787 * z + 16 / 116;
  const l = 116 * y - 16;
  const a = 500 * (x - y);
  const b = 200 * (y - z);
  return [l, a, b];
};
convert$2.hsl.rgb = function(hsl) {
  const h = hsl[0] / 360;
  const s = hsl[1] / 100;
  const l = hsl[2] / 100;
  let t2;
  let t3;
  let val;
  if (s === 0) {
    val = l * 255;
    return [val, val, val];
  }
  if (l < 0.5) {
    t2 = l * (1 + s);
  } else {
    t2 = l + s - l * s;
  }
  const t1 = 2 * l - t2;
  const rgb = [0, 0, 0];
  for (let i2 = 0; i2 < 3; i2++) {
    t3 = h + 1 / 3 * -(i2 - 1);
    if (t3 < 0) {
      t3++;
    }
    if (t3 > 1) {
      t3--;
    }
    if (6 * t3 < 1) {
      val = t1 + (t2 - t1) * 6 * t3;
    } else if (2 * t3 < 1) {
      val = t2;
    } else if (3 * t3 < 2) {
      val = t1 + (t2 - t1) * (2 / 3 - t3) * 6;
    } else {
      val = t1;
    }
    rgb[i2] = val * 255;
  }
  return rgb;
};
convert$2.hsl.hsv = function(hsl) {
  const h = hsl[0];
  let s = hsl[1] / 100;
  let l = hsl[2] / 100;
  let smin = s;
  const lmin = Math.max(l, 0.01);
  l *= 2;
  s *= l <= 1 ? l : 2 - l;
  smin *= lmin <= 1 ? lmin : 2 - lmin;
  const v = (l + s) / 2;
  const sv = l === 0 ? 2 * smin / (lmin + smin) : 2 * s / (l + s);
  return [h, sv * 100, v * 100];
};
convert$2.hsv.rgb = function(hsv) {
  const h = hsv[0] / 60;
  const s = hsv[1] / 100;
  let v = hsv[2] / 100;
  const hi = Math.floor(h) % 6;
  const f = h - Math.floor(h);
  const p = 255 * v * (1 - s);
  const q = 255 * v * (1 - s * f);
  const t2 = 255 * v * (1 - s * (1 - f));
  v *= 255;
  switch (hi) {
    case 0:
      return [v, t2, p];
    case 1:
      return [q, v, p];
    case 2:
      return [p, v, t2];
    case 3:
      return [p, q, v];
    case 4:
      return [t2, p, v];
    case 5:
      return [v, p, q];
  }
};
convert$2.hsv.hsl = function(hsv) {
  const h = hsv[0];
  const s = hsv[1] / 100;
  const v = hsv[2] / 100;
  const vmin = Math.max(v, 0.01);
  let sl;
  let l;
  l = (2 - s) * v;
  const lmin = (2 - s) * vmin;
  sl = s * vmin;
  sl /= lmin <= 1 ? lmin : 2 - lmin;
  sl = sl || 0;
  l /= 2;
  return [h, sl * 100, l * 100];
};
convert$2.hwb.rgb = function(hwb) {
  const h = hwb[0] / 360;
  let wh = hwb[1] / 100;
  let bl = hwb[2] / 100;
  const ratio = wh + bl;
  let f;
  if (ratio > 1) {
    wh /= ratio;
    bl /= ratio;
  }
  const i2 = Math.floor(6 * h);
  const v = 1 - bl;
  f = 6 * h - i2;
  if ((i2 & 1) !== 0) {
    f = 1 - f;
  }
  const n = wh + f * (v - wh);
  let r;
  let g;
  let b;
  switch (i2) {
    default:
    case 6:
    case 0:
      r = v;
      g = n;
      b = wh;
      break;
    case 1:
      r = n;
      g = v;
      b = wh;
      break;
    case 2:
      r = wh;
      g = v;
      b = n;
      break;
    case 3:
      r = wh;
      g = n;
      b = v;
      break;
    case 4:
      r = n;
      g = wh;
      b = v;
      break;
    case 5:
      r = v;
      g = wh;
      b = n;
      break;
  }
  return [r * 255, g * 255, b * 255];
};
convert$2.cmyk.rgb = function(cmyk) {
  const c = cmyk[0] / 100;
  const m = cmyk[1] / 100;
  const y = cmyk[2] / 100;
  const k = cmyk[3] / 100;
  const r = 1 - Math.min(1, c * (1 - k) + k);
  const g = 1 - Math.min(1, m * (1 - k) + k);
  const b = 1 - Math.min(1, y * (1 - k) + k);
  return [r * 255, g * 255, b * 255];
};
convert$2.xyz.rgb = function(xyz) {
  const x = xyz[0] / 100;
  const y = xyz[1] / 100;
  const z = xyz[2] / 100;
  let r;
  let g;
  let b;
  r = x * 3.2406 + y * -1.5372 + z * -0.4986;
  g = x * -0.9689 + y * 1.8758 + z * 0.0415;
  b = x * 0.0557 + y * -0.204 + z * 1.057;
  r = r > 31308e-7 ? 1.055 * r ** (1 / 2.4) - 0.055 : r * 12.92;
  g = g > 31308e-7 ? 1.055 * g ** (1 / 2.4) - 0.055 : g * 12.92;
  b = b > 31308e-7 ? 1.055 * b ** (1 / 2.4) - 0.055 : b * 12.92;
  r = Math.min(Math.max(0, r), 1);
  g = Math.min(Math.max(0, g), 1);
  b = Math.min(Math.max(0, b), 1);
  return [r * 255, g * 255, b * 255];
};
convert$2.xyz.lab = function(xyz) {
  let x = xyz[0];
  let y = xyz[1];
  let z = xyz[2];
  x /= 95.047;
  y /= 100;
  z /= 108.883;
  x = x > 8856e-6 ? x ** (1 / 3) : 7.787 * x + 16 / 116;
  y = y > 8856e-6 ? y ** (1 / 3) : 7.787 * y + 16 / 116;
  z = z > 8856e-6 ? z ** (1 / 3) : 7.787 * z + 16 / 116;
  const l = 116 * y - 16;
  const a = 500 * (x - y);
  const b = 200 * (y - z);
  return [l, a, b];
};
convert$2.lab.xyz = function(lab) {
  const l = lab[0];
  const a = lab[1];
  const b = lab[2];
  let x;
  let y;
  let z;
  y = (l + 16) / 116;
  x = a / 500 + y;
  z = y - b / 200;
  const y2 = y ** 3;
  const x2 = x ** 3;
  const z2 = z ** 3;
  y = y2 > 8856e-6 ? y2 : (y - 16 / 116) / 7.787;
  x = x2 > 8856e-6 ? x2 : (x - 16 / 116) / 7.787;
  z = z2 > 8856e-6 ? z2 : (z - 16 / 116) / 7.787;
  x *= 95.047;
  y *= 100;
  z *= 108.883;
  return [x, y, z];
};
convert$2.lab.lch = function(lab) {
  const l = lab[0];
  const a = lab[1];
  const b = lab[2];
  let h;
  const hr = Math.atan2(b, a);
  h = hr * 360 / 2 / Math.PI;
  if (h < 0) {
    h += 360;
  }
  const c = Math.sqrt(a * a + b * b);
  return [l, c, h];
};
convert$2.lch.lab = function(lch) {
  const l = lch[0];
  const c = lch[1];
  const h = lch[2];
  const hr = h / 360 * 2 * Math.PI;
  const a = c * Math.cos(hr);
  const b = c * Math.sin(hr);
  return [l, a, b];
};
convert$2.rgb.ansi16 = function(args, saturation = null) {
  const [r, g, b] = args;
  let value = saturation === null ? convert$2.rgb.hsv(args)[2] : saturation;
  value = Math.round(value / 50);
  if (value === 0) {
    return 30;
  }
  let ansi = 30 + (Math.round(b / 255) << 2 | Math.round(g / 255) << 1 | Math.round(r / 255));
  if (value === 2) {
    ansi += 60;
  }
  return ansi;
};
convert$2.hsv.ansi16 = function(args) {
  return convert$2.rgb.ansi16(convert$2.hsv.rgb(args), args[2]);
};
convert$2.rgb.ansi256 = function(args) {
  const r = args[0];
  const g = args[1];
  const b = args[2];
  if (r === g && g === b) {
    if (r < 8) {
      return 16;
    }
    if (r > 248) {
      return 231;
    }
    return Math.round((r - 8) / 247 * 24) + 232;
  }
  const ansi = 16 + 36 * Math.round(r / 255 * 5) + 6 * Math.round(g / 255 * 5) + Math.round(b / 255 * 5);
  return ansi;
};
convert$2.ansi16.rgb = function(args) {
  let color2 = args % 10;
  if (color2 === 0 || color2 === 7) {
    if (args > 50) {
      color2 += 3.5;
    }
    color2 = color2 / 10.5 * 255;
    return [color2, color2, color2];
  }
  const mult = (~~(args > 50) + 1) * 0.5;
  const r = (color2 & 1) * mult * 255;
  const g = (color2 >> 1 & 1) * mult * 255;
  const b = (color2 >> 2 & 1) * mult * 255;
  return [r, g, b];
};
convert$2.ansi256.rgb = function(args) {
  if (args >= 232) {
    const c = (args - 232) * 10 + 8;
    return [c, c, c];
  }
  args -= 16;
  let rem;
  const r = Math.floor(args / 36) / 5 * 255;
  const g = Math.floor((rem = args % 36) / 6) / 5 * 255;
  const b = rem % 6 / 5 * 255;
  return [r, g, b];
};
convert$2.rgb.hex = function(args) {
  const integer2 = ((Math.round(args[0]) & 255) << 16) + ((Math.round(args[1]) & 255) << 8) + (Math.round(args[2]) & 255);
  const string2 = integer2.toString(16).toUpperCase();
  return "000000".substring(string2.length) + string2;
};
convert$2.hex.rgb = function(args) {
  const match = args.toString(16).match(/[a-f0-9]{6}|[a-f0-9]{3}/i);
  if (!match) {
    return [0, 0, 0];
  }
  let colorString2 = match[0];
  if (match[0].length === 3) {
    colorString2 = colorString2.split("").map((char) => {
      return char + char;
    }).join("");
  }
  const integer2 = parseInt(colorString2, 16);
  const r = integer2 >> 16 & 255;
  const g = integer2 >> 8 & 255;
  const b = integer2 & 255;
  return [r, g, b];
};
convert$2.rgb.hcg = function(rgb) {
  const r = rgb[0] / 255;
  const g = rgb[1] / 255;
  const b = rgb[2] / 255;
  const max2 = Math.max(Math.max(r, g), b);
  const min2 = Math.min(Math.min(r, g), b);
  const chroma = max2 - min2;
  let grayscale2;
  let hue;
  if (chroma < 1) {
    grayscale2 = min2 / (1 - chroma);
  } else {
    grayscale2 = 0;
  }
  if (chroma <= 0) {
    hue = 0;
  } else if (max2 === r) {
    hue = (g - b) / chroma % 6;
  } else if (max2 === g) {
    hue = 2 + (b - r) / chroma;
  } else {
    hue = 4 + (r - g) / chroma;
  }
  hue /= 6;
  hue %= 1;
  return [hue * 360, chroma * 100, grayscale2 * 100];
};
convert$2.hsl.hcg = function(hsl) {
  const s = hsl[1] / 100;
  const l = hsl[2] / 100;
  const c = l < 0.5 ? 2 * s * l : 2 * s * (1 - l);
  let f = 0;
  if (c < 1) {
    f = (l - 0.5 * c) / (1 - c);
  }
  return [hsl[0], c * 100, f * 100];
};
convert$2.hsv.hcg = function(hsv) {
  const s = hsv[1] / 100;
  const v = hsv[2] / 100;
  const c = s * v;
  let f = 0;
  if (c < 1) {
    f = (v - c) / (1 - c);
  }
  return [hsv[0], c * 100, f * 100];
};
convert$2.hcg.rgb = function(hcg) {
  const h = hcg[0] / 360;
  const c = hcg[1] / 100;
  const g = hcg[2] / 100;
  if (c === 0) {
    return [g * 255, g * 255, g * 255];
  }
  const pure = [0, 0, 0];
  const hi = h % 1 * 6;
  const v = hi % 1;
  const w = 1 - v;
  let mg = 0;
  switch (Math.floor(hi)) {
    case 0:
      pure[0] = 1;
      pure[1] = v;
      pure[2] = 0;
      break;
    case 1:
      pure[0] = w;
      pure[1] = 1;
      pure[2] = 0;
      break;
    case 2:
      pure[0] = 0;
      pure[1] = 1;
      pure[2] = v;
      break;
    case 3:
      pure[0] = 0;
      pure[1] = w;
      pure[2] = 1;
      break;
    case 4:
      pure[0] = v;
      pure[1] = 0;
      pure[2] = 1;
      break;
    default:
      pure[0] = 1;
      pure[1] = 0;
      pure[2] = w;
  }
  mg = (1 - c) * g;
  return [
    (c * pure[0] + mg) * 255,
    (c * pure[1] + mg) * 255,
    (c * pure[2] + mg) * 255
  ];
};
convert$2.hcg.hsv = function(hcg) {
  const c = hcg[1] / 100;
  const g = hcg[2] / 100;
  const v = c + g * (1 - c);
  let f = 0;
  if (v > 0) {
    f = c / v;
  }
  return [hcg[0], f * 100, v * 100];
};
convert$2.hcg.hsl = function(hcg) {
  const c = hcg[1] / 100;
  const g = hcg[2] / 100;
  const l = g * (1 - c) + 0.5 * c;
  let s = 0;
  if (l > 0 && l < 0.5) {
    s = c / (2 * l);
  } else if (l >= 0.5 && l < 1) {
    s = c / (2 * (1 - l));
  }
  return [hcg[0], s * 100, l * 100];
};
convert$2.hcg.hwb = function(hcg) {
  const c = hcg[1] / 100;
  const g = hcg[2] / 100;
  const v = c + g * (1 - c);
  return [hcg[0], (v - c) * 100, (1 - v) * 100];
};
convert$2.hwb.hcg = function(hwb) {
  const w = hwb[1] / 100;
  const b = hwb[2] / 100;
  const v = 1 - b;
  const c = v - w;
  let g = 0;
  if (c < 1) {
    g = (v - c) / (1 - c);
  }
  return [hwb[0], c * 100, g * 100];
};
convert$2.apple.rgb = function(apple) {
  return [apple[0] / 65535 * 255, apple[1] / 65535 * 255, apple[2] / 65535 * 255];
};
convert$2.rgb.apple = function(rgb) {
  return [rgb[0] / 255 * 65535, rgb[1] / 255 * 65535, rgb[2] / 255 * 65535];
};
convert$2.gray.rgb = function(args) {
  return [args[0] / 100 * 255, args[0] / 100 * 255, args[0] / 100 * 255];
};
convert$2.gray.hsl = function(args) {
  return [0, 0, args[0]];
};
convert$2.gray.hsv = convert$2.gray.hsl;
convert$2.gray.hwb = function(gray) {
  return [0, 100, gray[0]];
};
convert$2.gray.cmyk = function(gray) {
  return [0, 0, 0, gray[0]];
};
convert$2.gray.lab = function(gray) {
  return [gray[0], 0, 0];
};
convert$2.gray.hex = function(gray) {
  const val = Math.round(gray[0] / 100 * 255) & 255;
  const integer2 = (val << 16) + (val << 8) + val;
  const string2 = integer2.toString(16).toUpperCase();
  return "000000".substring(string2.length) + string2;
};
convert$2.rgb.gray = function(rgb) {
  const val = (rgb[0] + rgb[1] + rgb[2]) / 3;
  return [val / 255 * 100];
};
const conversions$1 = conversions$2;
function buildGraph() {
  const graph = {};
  const models2 = Object.keys(conversions$1);
  for (let len = models2.length, i2 = 0; i2 < len; i2++) {
    graph[models2[i2]] = {
      // http://jsperf.com/1-vs-infinity
      // micro-opt, but this is simple.
      distance: -1,
      parent: null
    };
  }
  return graph;
}
function deriveBFS(fromModel) {
  const graph = buildGraph();
  const queue2 = [fromModel];
  graph[fromModel].distance = 0;
  while (queue2.length) {
    const current = queue2.pop();
    const adjacents = Object.keys(conversions$1[current]);
    for (let len = adjacents.length, i2 = 0; i2 < len; i2++) {
      const adjacent = adjacents[i2];
      const node = graph[adjacent];
      if (node.distance === -1) {
        node.distance = graph[current].distance + 1;
        node.parent = current;
        queue2.unshift(adjacent);
      }
    }
  }
  return graph;
}
function link(from, to) {
  return function(args) {
    return to(from(args));
  };
}
function wrapConversion(toModel, graph) {
  const path2 = [graph[toModel].parent, toModel];
  let fn2 = conversions$1[graph[toModel].parent][toModel];
  let cur = graph[toModel].parent;
  while (graph[cur].parent) {
    path2.unshift(graph[cur].parent);
    fn2 = link(conversions$1[graph[cur].parent][cur], fn2);
    cur = graph[cur].parent;
  }
  fn2.conversion = path2;
  return fn2;
}
var route$1 = function(fromModel) {
  const graph = deriveBFS(fromModel);
  const conversion = {};
  const models2 = Object.keys(graph);
  for (let len = models2.length, i2 = 0; i2 < len; i2++) {
    const toModel = models2[i2];
    const node = graph[toModel];
    if (node.parent === null) {
      continue;
    }
    conversion[toModel] = wrapConversion(toModel, graph);
  }
  return conversion;
};
const conversions = conversions$2;
const route = route$1;
const convert$1 = {};
const models = Object.keys(conversions);
function wrapRaw(fn2) {
  const wrappedFn = function(...args) {
    const arg0 = args[0];
    if (arg0 === void 0 || arg0 === null) {
      return arg0;
    }
    if (arg0.length > 1) {
      args = arg0;
    }
    return fn2(args);
  };
  if ("conversion" in fn2) {
    wrappedFn.conversion = fn2.conversion;
  }
  return wrappedFn;
}
function wrapRounded(fn2) {
  const wrappedFn = function(...args) {
    const arg0 = args[0];
    if (arg0 === void 0 || arg0 === null) {
      return arg0;
    }
    if (arg0.length > 1) {
      args = arg0;
    }
    const result = fn2(args);
    if (typeof result === "object") {
      for (let len = result.length, i2 = 0; i2 < len; i2++) {
        result[i2] = Math.round(result[i2]);
      }
    }
    return result;
  };
  if ("conversion" in fn2) {
    wrappedFn.conversion = fn2.conversion;
  }
  return wrappedFn;
}
models.forEach((fromModel) => {
  convert$1[fromModel] = {};
  Object.defineProperty(convert$1[fromModel], "channels", { value: conversions[fromModel].channels });
  Object.defineProperty(convert$1[fromModel], "labels", { value: conversions[fromModel].labels });
  const routes = route(fromModel);
  const routeModels = Object.keys(routes);
  routeModels.forEach((toModel) => {
    const fn2 = routes[toModel];
    convert$1[fromModel][toModel] = wrapRounded(fn2);
    convert$1[fromModel][toModel].raw = wrapRaw(fn2);
  });
});
var colorConvert = convert$1;
const colorString = colorStringExports;
const convert = colorConvert;
const skippedModels = [
  // To be honest, I don't really feel like keyword belongs in color convert, but eh.
  "keyword",
  // Gray conflicts with some method names, and has its own method defined.
  "gray",
  // Shouldn't really be in color-convert either...
  "hex"
];
const hashedModelKeys = {};
for (const model of Object.keys(convert)) {
  hashedModelKeys[[...convert[model].labels].sort().join("")] = model;
}
const limiters = {};
function Color(object2, model) {
  if (!(this instanceof Color)) {
    return new Color(object2, model);
  }
  if (model && model in skippedModels) {
    model = null;
  }
  if (model && !(model in convert)) {
    throw new Error("Unknown model: " + model);
  }
  let i2;
  let channels;
  if (object2 == null) {
    this.model = "rgb";
    this.color = [0, 0, 0];
    this.valpha = 1;
  } else if (object2 instanceof Color) {
    this.model = object2.model;
    this.color = [...object2.color];
    this.valpha = object2.valpha;
  } else if (typeof object2 === "string") {
    const result = colorString.get(object2);
    if (result === null) {
      throw new Error("Unable to parse color from string: " + object2);
    }
    this.model = result.model;
    channels = convert[this.model].channels;
    this.color = result.value.slice(0, channels);
    this.valpha = typeof result.value[channels] === "number" ? result.value[channels] : 1;
  } else if (object2.length > 0) {
    this.model = model || "rgb";
    channels = convert[this.model].channels;
    const newArray = Array.prototype.slice.call(object2, 0, channels);
    this.color = zeroArray(newArray, channels);
    this.valpha = typeof object2[channels] === "number" ? object2[channels] : 1;
  } else if (typeof object2 === "number") {
    this.model = "rgb";
    this.color = [
      object2 >> 16 & 255,
      object2 >> 8 & 255,
      object2 & 255
    ];
    this.valpha = 1;
  } else {
    this.valpha = 1;
    const keys = Object.keys(object2);
    if ("alpha" in object2) {
      keys.splice(keys.indexOf("alpha"), 1);
      this.valpha = typeof object2.alpha === "number" ? object2.alpha : 0;
    }
    const hashedKeys = keys.sort().join("");
    if (!(hashedKeys in hashedModelKeys)) {
      throw new Error("Unable to parse color from object: " + JSON.stringify(object2));
    }
    this.model = hashedModelKeys[hashedKeys];
    const { labels } = convert[this.model];
    const color2 = [];
    for (i2 = 0; i2 < labels.length; i2++) {
      color2.push(object2[labels[i2]]);
    }
    this.color = zeroArray(color2);
  }
  if (limiters[this.model]) {
    channels = convert[this.model].channels;
    for (i2 = 0; i2 < channels; i2++) {
      const limit2 = limiters[this.model][i2];
      if (limit2) {
        this.color[i2] = limit2(this.color[i2]);
      }
    }
  }
  this.valpha = Math.max(0, Math.min(1, this.valpha));
  if (Object.freeze) {
    Object.freeze(this);
  }
}
Color.prototype = {
  toString() {
    return this.string();
  },
  toJSON() {
    return this[this.model]();
  },
  string(places) {
    let self2 = this.model in colorString.to ? this : this.rgb();
    self2 = self2.round(typeof places === "number" ? places : 1);
    const args = self2.valpha === 1 ? self2.color : [...self2.color, this.valpha];
    return colorString.to[self2.model](args);
  },
  percentString(places) {
    const self2 = this.rgb().round(typeof places === "number" ? places : 1);
    const args = self2.valpha === 1 ? self2.color : [...self2.color, this.valpha];
    return colorString.to.rgb.percent(args);
  },
  array() {
    return this.valpha === 1 ? [...this.color] : [...this.color, this.valpha];
  },
  object() {
    const result = {};
    const { channels } = convert[this.model];
    const { labels } = convert[this.model];
    for (let i2 = 0; i2 < channels; i2++) {
      result[labels[i2]] = this.color[i2];
    }
    if (this.valpha !== 1) {
      result.alpha = this.valpha;
    }
    return result;
  },
  unitArray() {
    const rgb = this.rgb().color;
    rgb[0] /= 255;
    rgb[1] /= 255;
    rgb[2] /= 255;
    if (this.valpha !== 1) {
      rgb.push(this.valpha);
    }
    return rgb;
  },
  unitObject() {
    const rgb = this.rgb().object();
    rgb.r /= 255;
    rgb.g /= 255;
    rgb.b /= 255;
    if (this.valpha !== 1) {
      rgb.alpha = this.valpha;
    }
    return rgb;
  },
  round(places) {
    places = Math.max(places || 0, 0);
    return new Color([...this.color.map(roundToPlace(places)), this.valpha], this.model);
  },
  alpha(value) {
    if (value !== void 0) {
      return new Color([...this.color, Math.max(0, Math.min(1, value))], this.model);
    }
    return this.valpha;
  },
  // Rgb
  red: getset("rgb", 0, maxfn(255)),
  green: getset("rgb", 1, maxfn(255)),
  blue: getset("rgb", 2, maxfn(255)),
  hue: getset(["hsl", "hsv", "hsl", "hwb", "hcg"], 0, (value) => (value % 360 + 360) % 360),
  saturationl: getset("hsl", 1, maxfn(100)),
  lightness: getset("hsl", 2, maxfn(100)),
  saturationv: getset("hsv", 1, maxfn(100)),
  value: getset("hsv", 2, maxfn(100)),
  chroma: getset("hcg", 1, maxfn(100)),
  gray: getset("hcg", 2, maxfn(100)),
  white: getset("hwb", 1, maxfn(100)),
  wblack: getset("hwb", 2, maxfn(100)),
  cyan: getset("cmyk", 0, maxfn(100)),
  magenta: getset("cmyk", 1, maxfn(100)),
  yellow: getset("cmyk", 2, maxfn(100)),
  black: getset("cmyk", 3, maxfn(100)),
  x: getset("xyz", 0, maxfn(95.047)),
  y: getset("xyz", 1, maxfn(100)),
  z: getset("xyz", 2, maxfn(108.833)),
  l: getset("lab", 0, maxfn(100)),
  a: getset("lab", 1),
  b: getset("lab", 2),
  keyword(value) {
    if (value !== void 0) {
      return new Color(value);
    }
    return convert[this.model].keyword(this.color);
  },
  hex(value) {
    if (value !== void 0) {
      return new Color(value);
    }
    return colorString.to.hex(this.rgb().round().color);
  },
  hexa(value) {
    if (value !== void 0) {
      return new Color(value);
    }
    const rgbArray = this.rgb().round().color;
    let alphaHex = Math.round(this.valpha * 255).toString(16).toUpperCase();
    if (alphaHex.length === 1) {
      alphaHex = "0" + alphaHex;
    }
    return colorString.to.hex(rgbArray) + alphaHex;
  },
  rgbNumber() {
    const rgb = this.rgb().color;
    return (rgb[0] & 255) << 16 | (rgb[1] & 255) << 8 | rgb[2] & 255;
  },
  luminosity() {
    const rgb = this.rgb().color;
    const lum = [];
    for (const [i2, element] of rgb.entries()) {
      const chan = element / 255;
      lum[i2] = chan <= 0.04045 ? chan / 12.92 : ((chan + 0.055) / 1.055) ** 2.4;
    }
    return 0.2126 * lum[0] + 0.7152 * lum[1] + 0.0722 * lum[2];
  },
  contrast(color2) {
    const lum1 = this.luminosity();
    const lum2 = color2.luminosity();
    if (lum1 > lum2) {
      return (lum1 + 0.05) / (lum2 + 0.05);
    }
    return (lum2 + 0.05) / (lum1 + 0.05);
  },
  level(color2) {
    const contrastRatio = this.contrast(color2);
    if (contrastRatio >= 7) {
      return "AAA";
    }
    return contrastRatio >= 4.5 ? "AA" : "";
  },
  isDark() {
    const rgb = this.rgb().color;
    const yiq = (rgb[0] * 2126 + rgb[1] * 7152 + rgb[2] * 722) / 1e4;
    return yiq < 128;
  },
  isLight() {
    return !this.isDark();
  },
  negate() {
    const rgb = this.rgb();
    for (let i2 = 0; i2 < 3; i2++) {
      rgb.color[i2] = 255 - rgb.color[i2];
    }
    return rgb;
  },
  lighten(ratio) {
    const hsl = this.hsl();
    hsl.color[2] += hsl.color[2] * ratio;
    return hsl;
  },
  darken(ratio) {
    const hsl = this.hsl();
    hsl.color[2] -= hsl.color[2] * ratio;
    return hsl;
  },
  saturate(ratio) {
    const hsl = this.hsl();
    hsl.color[1] += hsl.color[1] * ratio;
    return hsl;
  },
  desaturate(ratio) {
    const hsl = this.hsl();
    hsl.color[1] -= hsl.color[1] * ratio;
    return hsl;
  },
  whiten(ratio) {
    const hwb = this.hwb();
    hwb.color[1] += hwb.color[1] * ratio;
    return hwb;
  },
  blacken(ratio) {
    const hwb = this.hwb();
    hwb.color[2] += hwb.color[2] * ratio;
    return hwb;
  },
  grayscale() {
    const rgb = this.rgb().color;
    const value = rgb[0] * 0.3 + rgb[1] * 0.59 + rgb[2] * 0.11;
    return Color.rgb(value, value, value);
  },
  fade(ratio) {
    return this.alpha(this.valpha - this.valpha * ratio);
  },
  opaquer(ratio) {
    return this.alpha(this.valpha + this.valpha * ratio);
  },
  rotate(degrees) {
    const hsl = this.hsl();
    let hue = hsl.color[0];
    hue = (hue + degrees) % 360;
    hue = hue < 0 ? 360 + hue : hue;
    hsl.color[0] = hue;
    return hsl;
  },
  mix(mixinColor, weight) {
    if (!mixinColor || !mixinColor.rgb) {
      throw new Error('Argument to "mix" was not a Color instance, but rather an instance of ' + typeof mixinColor);
    }
    const color1 = mixinColor.rgb();
    const color2 = this.rgb();
    const p = weight === void 0 ? 0.5 : weight;
    const w = 2 * p - 1;
    const a = color1.alpha() - color2.alpha();
    const w1 = ((w * a === -1 ? w : (w + a) / (1 + w * a)) + 1) / 2;
    const w2 = 1 - w1;
    return Color.rgb(
      w1 * color1.red() + w2 * color2.red(),
      w1 * color1.green() + w2 * color2.green(),
      w1 * color1.blue() + w2 * color2.blue(),
      color1.alpha() * p + color2.alpha() * (1 - p)
    );
  }
};
for (const model of Object.keys(convert)) {
  if (skippedModels.includes(model)) {
    continue;
  }
  const { channels } = convert[model];
  Color.prototype[model] = function(...args) {
    if (this.model === model) {
      return new Color(this);
    }
    if (args.length > 0) {
      return new Color(args, model);
    }
    return new Color([...assertArray(convert[this.model][model].raw(this.color)), this.valpha], model);
  };
  Color[model] = function(...args) {
    let color2 = args[0];
    if (typeof color2 === "number") {
      color2 = zeroArray(args, channels);
    }
    return new Color(color2, model);
  };
}
function roundTo(number2, places) {
  return Number(number2.toFixed(places));
}
function roundToPlace(places) {
  return function(number2) {
    return roundTo(number2, places);
  };
}
function getset(model, channel2, modifier) {
  model = Array.isArray(model) ? model : [model];
  for (const m of model) {
    (limiters[m] || (limiters[m] = []))[channel2] = modifier;
  }
  model = model[0];
  return function(value) {
    let result;
    if (value !== void 0) {
      if (modifier) {
        value = modifier(value);
      }
      result = this[model]();
      result.color[channel2] = value;
      return result;
    }
    result = this[model]().color[channel2];
    if (modifier) {
      result = modifier(result);
    }
    return result;
  };
}
function maxfn(max2) {
  return function(v) {
    return Math.max(0, Math.min(max2, v));
  };
}
function assertArray(value) {
  return Array.isArray(value) ? value : [value];
}
function zeroArray(array, length) {
  for (let i2 = 0; i2 < length; i2++) {
    if (typeof array[i2] !== "number") {
      array[i2] = 0;
    }
  }
  return array;
}
var color$3 = Color;
const color$2 = color$3;
const is$7 = is$9;
const sharp$3 = sharpExports;
const align = {
  left: "low",
  center: "centre",
  centre: "centre",
  right: "high"
};
function _inputOptionsFromObject(obj) {
  const { raw: raw2, density, limitInputPixels, ignoreIcc, unlimited, sequentialRead, failOn, failOnError, animated, page, pages, subifd } = obj;
  return [raw2, density, limitInputPixels, ignoreIcc, unlimited, sequentialRead, failOn, failOnError, animated, page, pages, subifd].some(is$7.defined) ? { raw: raw2, density, limitInputPixels, ignoreIcc, unlimited, sequentialRead, failOn, failOnError, animated, page, pages, subifd } : void 0;
}
function _createInputDescriptor(input2, inputOptions, containerOptions) {
  const inputDescriptor = {
    failOn: "warning",
    limitInputPixels: Math.pow(16383, 2),
    ignoreIcc: false,
    unlimited: false,
    sequentialRead: true
  };
  if (is$7.string(input2)) {
    inputDescriptor.file = input2;
  } else if (is$7.buffer(input2)) {
    if (input2.length === 0) {
      throw Error("Input Buffer is empty");
    }
    inputDescriptor.buffer = input2;
  } else if (is$7.arrayBuffer(input2)) {
    if (input2.byteLength === 0) {
      throw Error("Input bit Array is empty");
    }
    inputDescriptor.buffer = Buffer.from(input2, 0, input2.byteLength);
  } else if (is$7.typedArray(input2)) {
    if (input2.length === 0) {
      throw Error("Input Bit Array is empty");
    }
    inputDescriptor.buffer = Buffer.from(input2.buffer, input2.byteOffset, input2.byteLength);
  } else if (is$7.plainObject(input2) && !is$7.defined(inputOptions)) {
    inputOptions = input2;
    if (_inputOptionsFromObject(inputOptions)) {
      inputDescriptor.buffer = [];
    }
  } else if (!is$7.defined(input2) && !is$7.defined(inputOptions) && is$7.object(containerOptions) && containerOptions.allowStream) {
    inputDescriptor.buffer = [];
  } else {
    throw new Error(`Unsupported input '${input2}' of type ${typeof input2}${is$7.defined(inputOptions) ? ` when also providing options of type ${typeof inputOptions}` : ""}`);
  }
  if (is$7.object(inputOptions)) {
    if (is$7.defined(inputOptions.failOnError)) {
      if (is$7.bool(inputOptions.failOnError)) {
        inputDescriptor.failOn = inputOptions.failOnError ? "warning" : "none";
      } else {
        throw is$7.invalidParameterError("failOnError", "boolean", inputOptions.failOnError);
      }
    }
    if (is$7.defined(inputOptions.failOn)) {
      if (is$7.string(inputOptions.failOn) && is$7.inArray(inputOptions.failOn, ["none", "truncated", "error", "warning"])) {
        inputDescriptor.failOn = inputOptions.failOn;
      } else {
        throw is$7.invalidParameterError("failOn", "one of: none, truncated, error, warning", inputOptions.failOn);
      }
    }
    if (is$7.defined(inputOptions.density)) {
      if (is$7.inRange(inputOptions.density, 1, 1e5)) {
        inputDescriptor.density = inputOptions.density;
      } else {
        throw is$7.invalidParameterError("density", "number between 1 and 100000", inputOptions.density);
      }
    }
    if (is$7.defined(inputOptions.ignoreIcc)) {
      if (is$7.bool(inputOptions.ignoreIcc)) {
        inputDescriptor.ignoreIcc = inputOptions.ignoreIcc;
      } else {
        throw is$7.invalidParameterError("ignoreIcc", "boolean", inputOptions.ignoreIcc);
      }
    }
    if (is$7.defined(inputOptions.limitInputPixels)) {
      if (is$7.bool(inputOptions.limitInputPixels)) {
        inputDescriptor.limitInputPixels = inputOptions.limitInputPixels ? Math.pow(16383, 2) : 0;
      } else if (is$7.integer(inputOptions.limitInputPixels) && is$7.inRange(inputOptions.limitInputPixels, 0, Number.MAX_SAFE_INTEGER)) {
        inputDescriptor.limitInputPixels = inputOptions.limitInputPixels;
      } else {
        throw is$7.invalidParameterError("limitInputPixels", "positive integer", inputOptions.limitInputPixels);
      }
    }
    if (is$7.defined(inputOptions.unlimited)) {
      if (is$7.bool(inputOptions.unlimited)) {
        inputDescriptor.unlimited = inputOptions.unlimited;
      } else {
        throw is$7.invalidParameterError("unlimited", "boolean", inputOptions.unlimited);
      }
    }
    if (is$7.defined(inputOptions.sequentialRead)) {
      if (is$7.bool(inputOptions.sequentialRead)) {
        inputDescriptor.sequentialRead = inputOptions.sequentialRead;
      } else {
        throw is$7.invalidParameterError("sequentialRead", "boolean", inputOptions.sequentialRead);
      }
    }
    if (is$7.defined(inputOptions.raw)) {
      if (is$7.object(inputOptions.raw) && is$7.integer(inputOptions.raw.width) && inputOptions.raw.width > 0 && is$7.integer(inputOptions.raw.height) && inputOptions.raw.height > 0 && is$7.integer(inputOptions.raw.channels) && is$7.inRange(inputOptions.raw.channels, 1, 4)) {
        inputDescriptor.rawWidth = inputOptions.raw.width;
        inputDescriptor.rawHeight = inputOptions.raw.height;
        inputDescriptor.rawChannels = inputOptions.raw.channels;
        inputDescriptor.rawPremultiplied = !!inputOptions.raw.premultiplied;
        switch (input2.constructor) {
          case Uint8Array:
          case Uint8ClampedArray:
            inputDescriptor.rawDepth = "uchar";
            break;
          case Int8Array:
            inputDescriptor.rawDepth = "char";
            break;
          case Uint16Array:
            inputDescriptor.rawDepth = "ushort";
            break;
          case Int16Array:
            inputDescriptor.rawDepth = "short";
            break;
          case Uint32Array:
            inputDescriptor.rawDepth = "uint";
            break;
          case Int32Array:
            inputDescriptor.rawDepth = "int";
            break;
          case Float32Array:
            inputDescriptor.rawDepth = "float";
            break;
          case Float64Array:
            inputDescriptor.rawDepth = "double";
            break;
          default:
            inputDescriptor.rawDepth = "uchar";
            break;
        }
      } else {
        throw new Error("Expected width, height and channels for raw pixel input");
      }
    }
    if (is$7.defined(inputOptions.animated)) {
      if (is$7.bool(inputOptions.animated)) {
        inputDescriptor.pages = inputOptions.animated ? -1 : 1;
      } else {
        throw is$7.invalidParameterError("animated", "boolean", inputOptions.animated);
      }
    }
    if (is$7.defined(inputOptions.pages)) {
      if (is$7.integer(inputOptions.pages) && is$7.inRange(inputOptions.pages, -1, 1e5)) {
        inputDescriptor.pages = inputOptions.pages;
      } else {
        throw is$7.invalidParameterError("pages", "integer between -1 and 100000", inputOptions.pages);
      }
    }
    if (is$7.defined(inputOptions.page)) {
      if (is$7.integer(inputOptions.page) && is$7.inRange(inputOptions.page, 0, 1e5)) {
        inputDescriptor.page = inputOptions.page;
      } else {
        throw is$7.invalidParameterError("page", "integer between 0 and 100000", inputOptions.page);
      }
    }
    if (is$7.defined(inputOptions.level)) {
      if (is$7.integer(inputOptions.level) && is$7.inRange(inputOptions.level, 0, 256)) {
        inputDescriptor.level = inputOptions.level;
      } else {
        throw is$7.invalidParameterError("level", "integer between 0 and 256", inputOptions.level);
      }
    }
    if (is$7.defined(inputOptions.subifd)) {
      if (is$7.integer(inputOptions.subifd) && is$7.inRange(inputOptions.subifd, -1, 1e5)) {
        inputDescriptor.subifd = inputOptions.subifd;
      } else {
        throw is$7.invalidParameterError("subifd", "integer between -1 and 100000", inputOptions.subifd);
      }
    }
    if (is$7.defined(inputOptions.create)) {
      if (is$7.object(inputOptions.create) && is$7.integer(inputOptions.create.width) && inputOptions.create.width > 0 && is$7.integer(inputOptions.create.height) && inputOptions.create.height > 0 && is$7.integer(inputOptions.create.channels)) {
        inputDescriptor.createWidth = inputOptions.create.width;
        inputDescriptor.createHeight = inputOptions.create.height;
        inputDescriptor.createChannels = inputOptions.create.channels;
        if (is$7.defined(inputOptions.create.noise)) {
          if (!is$7.object(inputOptions.create.noise)) {
            throw new Error("Expected noise to be an object");
          }
          if (!is$7.inArray(inputOptions.create.noise.type, ["gaussian"])) {
            throw new Error("Only gaussian noise is supported at the moment");
          }
          if (!is$7.inRange(inputOptions.create.channels, 1, 4)) {
            throw is$7.invalidParameterError("create.channels", "number between 1 and 4", inputOptions.create.channels);
          }
          inputDescriptor.createNoiseType = inputOptions.create.noise.type;
          if (is$7.number(inputOptions.create.noise.mean) && is$7.inRange(inputOptions.create.noise.mean, 0, 1e4)) {
            inputDescriptor.createNoiseMean = inputOptions.create.noise.mean;
          } else {
            throw is$7.invalidParameterError("create.noise.mean", "number between 0 and 10000", inputOptions.create.noise.mean);
          }
          if (is$7.number(inputOptions.create.noise.sigma) && is$7.inRange(inputOptions.create.noise.sigma, 0, 1e4)) {
            inputDescriptor.createNoiseSigma = inputOptions.create.noise.sigma;
          } else {
            throw is$7.invalidParameterError("create.noise.sigma", "number between 0 and 10000", inputOptions.create.noise.sigma);
          }
        } else if (is$7.defined(inputOptions.create.background)) {
          if (!is$7.inRange(inputOptions.create.channels, 3, 4)) {
            throw is$7.invalidParameterError("create.channels", "number between 3 and 4", inputOptions.create.channels);
          }
          const background = color$2(inputOptions.create.background);
          inputDescriptor.createBackground = [
            background.red(),
            background.green(),
            background.blue(),
            Math.round(background.alpha() * 255)
          ];
        } else {
          throw new Error("Expected valid noise or background to create a new input image");
        }
        delete inputDescriptor.buffer;
      } else {
        throw new Error("Expected valid width, height and channels to create a new input image");
      }
    }
    if (is$7.defined(inputOptions.text)) {
      if (is$7.object(inputOptions.text) && is$7.string(inputOptions.text.text)) {
        inputDescriptor.textValue = inputOptions.text.text;
        if (is$7.defined(inputOptions.text.height) && is$7.defined(inputOptions.text.dpi)) {
          throw new Error("Expected only one of dpi or height");
        }
        if (is$7.defined(inputOptions.text.font)) {
          if (is$7.string(inputOptions.text.font)) {
            inputDescriptor.textFont = inputOptions.text.font;
          } else {
            throw is$7.invalidParameterError("text.font", "string", inputOptions.text.font);
          }
        }
        if (is$7.defined(inputOptions.text.fontfile)) {
          if (is$7.string(inputOptions.text.fontfile)) {
            inputDescriptor.textFontfile = inputOptions.text.fontfile;
          } else {
            throw is$7.invalidParameterError("text.fontfile", "string", inputOptions.text.fontfile);
          }
        }
        if (is$7.defined(inputOptions.text.width)) {
          if (is$7.number(inputOptions.text.width)) {
            inputDescriptor.textWidth = inputOptions.text.width;
          } else {
            throw is$7.invalidParameterError("text.textWidth", "number", inputOptions.text.width);
          }
        }
        if (is$7.defined(inputOptions.text.height)) {
          if (is$7.number(inputOptions.text.height)) {
            inputDescriptor.textHeight = inputOptions.text.height;
          } else {
            throw is$7.invalidParameterError("text.height", "number", inputOptions.text.height);
          }
        }
        if (is$7.defined(inputOptions.text.align)) {
          if (is$7.string(inputOptions.text.align) && is$7.string(this.constructor.align[inputOptions.text.align])) {
            inputDescriptor.textAlign = this.constructor.align[inputOptions.text.align];
          } else {
            throw is$7.invalidParameterError("text.align", "valid alignment", inputOptions.text.align);
          }
        }
        if (is$7.defined(inputOptions.text.justify)) {
          if (is$7.bool(inputOptions.text.justify)) {
            inputDescriptor.textJustify = inputOptions.text.justify;
          } else {
            throw is$7.invalidParameterError("text.justify", "boolean", inputOptions.text.justify);
          }
        }
        if (is$7.defined(inputOptions.text.dpi)) {
          if (is$7.number(inputOptions.text.dpi) && is$7.inRange(inputOptions.text.dpi, 1, 1e5)) {
            inputDescriptor.textDpi = inputOptions.text.dpi;
          } else {
            throw is$7.invalidParameterError("text.dpi", "number between 1 and 100000", inputOptions.text.dpi);
          }
        }
        if (is$7.defined(inputOptions.text.rgba)) {
          if (is$7.bool(inputOptions.text.rgba)) {
            inputDescriptor.textRgba = inputOptions.text.rgba;
          } else {
            throw is$7.invalidParameterError("text.rgba", "bool", inputOptions.text.rgba);
          }
        }
        if (is$7.defined(inputOptions.text.spacing)) {
          if (is$7.number(inputOptions.text.spacing)) {
            inputDescriptor.textSpacing = inputOptions.text.spacing;
          } else {
            throw is$7.invalidParameterError("text.spacing", "number", inputOptions.text.spacing);
          }
        }
        if (is$7.defined(inputOptions.text.wrap)) {
          if (is$7.string(inputOptions.text.wrap) && is$7.inArray(inputOptions.text.wrap, ["word", "char", "wordChar", "none"])) {
            inputDescriptor.textWrap = inputOptions.text.wrap;
          } else {
            throw is$7.invalidParameterError("text.wrap", "one of: word, char, wordChar, none", inputOptions.text.wrap);
          }
        }
        delete inputDescriptor.buffer;
      } else {
        throw new Error("Expected a valid string to create an image with text.");
      }
    }
  } else if (is$7.defined(inputOptions)) {
    throw new Error("Invalid input options " + inputOptions);
  }
  return inputDescriptor;
}
function _write(chunk, encoding, callback) {
  if (Array.isArray(this.options.input.buffer)) {
    if (is$7.buffer(chunk)) {
      if (this.options.input.buffer.length === 0) {
        this.on("finish", () => {
          this.streamInFinished = true;
        });
      }
      this.options.input.buffer.push(chunk);
      callback();
    } else {
      callback(new Error("Non-Buffer data on Writable Stream"));
    }
  } else {
    callback(new Error("Unexpected data on Writable Stream"));
  }
}
function _flattenBufferIn() {
  if (this._isStreamInput()) {
    this.options.input.buffer = Buffer.concat(this.options.input.buffer);
  }
}
function _isStreamInput() {
  return Array.isArray(this.options.input.buffer);
}
function metadata(callback) {
  if (is$7.fn(callback)) {
    if (this._isStreamInput()) {
      this.on("finish", () => {
        this._flattenBufferIn();
        sharp$3.metadata(this.options, callback);
      });
    } else {
      sharp$3.metadata(this.options, callback);
    }
    return this;
  } else {
    if (this._isStreamInput()) {
      return new Promise((resolve2, reject) => {
        const finished = () => {
          this._flattenBufferIn();
          sharp$3.metadata(this.options, (err, metadata2) => {
            if (err) {
              reject(err);
            } else {
              resolve2(metadata2);
            }
          });
        };
        if (this.writableFinished) {
          finished();
        } else {
          this.once("finish", finished);
        }
      });
    } else {
      return new Promise((resolve2, reject) => {
        sharp$3.metadata(this.options, (err, metadata2) => {
          if (err) {
            reject(err);
          } else {
            resolve2(metadata2);
          }
        });
      });
    }
  }
}
function stats(callback) {
  if (is$7.fn(callback)) {
    if (this._isStreamInput()) {
      this.on("finish", () => {
        this._flattenBufferIn();
        sharp$3.stats(this.options, callback);
      });
    } else {
      sharp$3.stats(this.options, callback);
    }
    return this;
  } else {
    if (this._isStreamInput()) {
      return new Promise((resolve2, reject) => {
        this.on("finish", function() {
          this._flattenBufferIn();
          sharp$3.stats(this.options, (err, stats2) => {
            if (err) {
              reject(err);
            } else {
              resolve2(stats2);
            }
          });
        });
      });
    } else {
      return new Promise((resolve2, reject) => {
        sharp$3.stats(this.options, (err, stats2) => {
          if (err) {
            reject(err);
          } else {
            resolve2(stats2);
          }
        });
      });
    }
  }
}
var input = function(Sharp2) {
  Object.assign(Sharp2.prototype, {
    // Private
    _inputOptionsFromObject,
    _createInputDescriptor,
    _write,
    _flattenBufferIn,
    _isStreamInput,
    // Public
    metadata,
    stats
  });
  Sharp2.align = align;
};
const is$6 = is$9;
const gravity = {
  center: 0,
  centre: 0,
  north: 1,
  east: 2,
  south: 3,
  west: 4,
  northeast: 5,
  southeast: 6,
  southwest: 7,
  northwest: 8
};
const position = {
  top: 1,
  right: 2,
  bottom: 3,
  left: 4,
  "right top": 5,
  "right bottom": 6,
  "left bottom": 7,
  "left top": 8
};
const extendWith = {
  background: "background",
  copy: "copy",
  repeat: "repeat",
  mirror: "mirror"
};
const strategy = {
  entropy: 16,
  attention: 17
};
const kernel = {
  nearest: "nearest",
  cubic: "cubic",
  mitchell: "mitchell",
  lanczos2: "lanczos2",
  lanczos3: "lanczos3"
};
const fit = {
  contain: "contain",
  cover: "cover",
  fill: "fill",
  inside: "inside",
  outside: "outside"
};
const mapFitToCanvas = {
  contain: "embed",
  cover: "crop",
  fill: "ignore_aspect",
  inside: "max",
  outside: "min"
};
function isRotationExpected(options) {
  return options.angle % 360 !== 0 || options.useExifOrientation === true || options.rotationAngle !== 0;
}
function isResizeExpected(options) {
  return options.width !== -1 || options.height !== -1;
}
function resize(widthOrOptions, height, options) {
  if (isResizeExpected(this.options)) {
    this.options.debuglog("ignoring previous resize options");
  }
  if (is$6.defined(widthOrOptions)) {
    if (is$6.object(widthOrOptions) && !is$6.defined(options)) {
      options = widthOrOptions;
    } else if (is$6.integer(widthOrOptions) && widthOrOptions > 0) {
      this.options.width = widthOrOptions;
    } else {
      throw is$6.invalidParameterError("width", "positive integer", widthOrOptions);
    }
  } else {
    this.options.width = -1;
  }
  if (is$6.defined(height)) {
    if (is$6.integer(height) && height > 0) {
      this.options.height = height;
    } else {
      throw is$6.invalidParameterError("height", "positive integer", height);
    }
  } else {
    this.options.height = -1;
  }
  if (is$6.object(options)) {
    if (is$6.defined(options.width)) {
      if (is$6.integer(options.width) && options.width > 0) {
        this.options.width = options.width;
      } else {
        throw is$6.invalidParameterError("width", "positive integer", options.width);
      }
    }
    if (is$6.defined(options.height)) {
      if (is$6.integer(options.height) && options.height > 0) {
        this.options.height = options.height;
      } else {
        throw is$6.invalidParameterError("height", "positive integer", options.height);
      }
    }
    if (is$6.defined(options.fit)) {
      const canvas = mapFitToCanvas[options.fit];
      if (is$6.string(canvas)) {
        this.options.canvas = canvas;
      } else {
        throw is$6.invalidParameterError("fit", "valid fit", options.fit);
      }
    }
    if (is$6.defined(options.position)) {
      const pos = is$6.integer(options.position) ? options.position : strategy[options.position] || position[options.position] || gravity[options.position];
      if (is$6.integer(pos) && (is$6.inRange(pos, 0, 8) || is$6.inRange(pos, 16, 17))) {
        this.options.position = pos;
      } else {
        throw is$6.invalidParameterError("position", "valid position/gravity/strategy", options.position);
      }
    }
    this._setBackgroundColourOption("resizeBackground", options.background);
    if (is$6.defined(options.kernel)) {
      if (is$6.string(kernel[options.kernel])) {
        this.options.kernel = kernel[options.kernel];
      } else {
        throw is$6.invalidParameterError("kernel", "valid kernel name", options.kernel);
      }
    }
    if (is$6.defined(options.withoutEnlargement)) {
      this._setBooleanOption("withoutEnlargement", options.withoutEnlargement);
    }
    if (is$6.defined(options.withoutReduction)) {
      this._setBooleanOption("withoutReduction", options.withoutReduction);
    }
    if (is$6.defined(options.fastShrinkOnLoad)) {
      this._setBooleanOption("fastShrinkOnLoad", options.fastShrinkOnLoad);
    }
  }
  if (isRotationExpected(this.options) && isResizeExpected(this.options)) {
    this.options.rotateBeforePreExtract = true;
  }
  return this;
}
function extend(extend2) {
  if (is$6.integer(extend2) && extend2 > 0) {
    this.options.extendTop = extend2;
    this.options.extendBottom = extend2;
    this.options.extendLeft = extend2;
    this.options.extendRight = extend2;
  } else if (is$6.object(extend2)) {
    if (is$6.defined(extend2.top)) {
      if (is$6.integer(extend2.top) && extend2.top >= 0) {
        this.options.extendTop = extend2.top;
      } else {
        throw is$6.invalidParameterError("top", "positive integer", extend2.top);
      }
    }
    if (is$6.defined(extend2.bottom)) {
      if (is$6.integer(extend2.bottom) && extend2.bottom >= 0) {
        this.options.extendBottom = extend2.bottom;
      } else {
        throw is$6.invalidParameterError("bottom", "positive integer", extend2.bottom);
      }
    }
    if (is$6.defined(extend2.left)) {
      if (is$6.integer(extend2.left) && extend2.left >= 0) {
        this.options.extendLeft = extend2.left;
      } else {
        throw is$6.invalidParameterError("left", "positive integer", extend2.left);
      }
    }
    if (is$6.defined(extend2.right)) {
      if (is$6.integer(extend2.right) && extend2.right >= 0) {
        this.options.extendRight = extend2.right;
      } else {
        throw is$6.invalidParameterError("right", "positive integer", extend2.right);
      }
    }
    this._setBackgroundColourOption("extendBackground", extend2.background);
    if (is$6.defined(extend2.extendWith)) {
      if (is$6.string(extendWith[extend2.extendWith])) {
        this.options.extendWith = extendWith[extend2.extendWith];
      } else {
        throw is$6.invalidParameterError("extendWith", "one of: background, copy, repeat, mirror", extend2.extendWith);
      }
    }
  } else {
    throw is$6.invalidParameterError("extend", "integer or object", extend2);
  }
  return this;
}
function extract(options) {
  const suffix = isResizeExpected(this.options) || this.options.widthPre !== -1 ? "Post" : "Pre";
  if (this.options[`width${suffix}`] !== -1) {
    this.options.debuglog("ignoring previous extract options");
  }
  ["left", "top", "width", "height"].forEach(function(name2) {
    const value = options[name2];
    if (is$6.integer(value) && value >= 0) {
      this.options[name2 + (name2 === "left" || name2 === "top" ? "Offset" : "") + suffix] = value;
    } else {
      throw is$6.invalidParameterError(name2, "integer", value);
    }
  }, this);
  if (isRotationExpected(this.options) && !isResizeExpected(this.options)) {
    if (this.options.widthPre === -1 || this.options.widthPost === -1) {
      this.options.rotateBeforePreExtract = true;
    }
  }
  return this;
}
function trim(trim2) {
  if (!is$6.defined(trim2)) {
    this.options.trimThreshold = 10;
  } else if (is$6.string(trim2)) {
    this._setBackgroundColourOption("trimBackground", trim2);
    this.options.trimThreshold = 10;
  } else if (is$6.number(trim2)) {
    if (trim2 >= 0) {
      this.options.trimThreshold = trim2;
    } else {
      throw is$6.invalidParameterError("threshold", "positive number", trim2);
    }
  } else if (is$6.object(trim2)) {
    this._setBackgroundColourOption("trimBackground", trim2.background);
    if (!is$6.defined(trim2.threshold)) {
      this.options.trimThreshold = 10;
    } else if (is$6.number(trim2.threshold) && trim2.threshold >= 0) {
      this.options.trimThreshold = trim2.threshold;
    } else {
      throw is$6.invalidParameterError("threshold", "positive number", trim2);
    }
  } else {
    throw is$6.invalidParameterError("trim", "string, number or object", trim2);
  }
  if (isRotationExpected(this.options)) {
    this.options.rotateBeforePreExtract = true;
  }
  return this;
}
var resize_1 = function(Sharp2) {
  Object.assign(Sharp2.prototype, {
    resize,
    extend,
    extract,
    trim
  });
  Sharp2.gravity = gravity;
  Sharp2.strategy = strategy;
  Sharp2.kernel = kernel;
  Sharp2.fit = fit;
  Sharp2.position = position;
};
const is$5 = is$9;
const blend = {
  clear: "clear",
  source: "source",
  over: "over",
  in: "in",
  out: "out",
  atop: "atop",
  dest: "dest",
  "dest-over": "dest-over",
  "dest-in": "dest-in",
  "dest-out": "dest-out",
  "dest-atop": "dest-atop",
  xor: "xor",
  add: "add",
  saturate: "saturate",
  multiply: "multiply",
  screen: "screen",
  overlay: "overlay",
  darken: "darken",
  lighten: "lighten",
  "colour-dodge": "colour-dodge",
  "color-dodge": "colour-dodge",
  "colour-burn": "colour-burn",
  "color-burn": "colour-burn",
  "hard-light": "hard-light",
  "soft-light": "soft-light",
  difference: "difference",
  exclusion: "exclusion"
};
function composite(images) {
  if (!Array.isArray(images)) {
    throw is$5.invalidParameterError("images to composite", "array", images);
  }
  this.options.composite = images.map((image) => {
    if (!is$5.object(image)) {
      throw is$5.invalidParameterError("image to composite", "object", image);
    }
    const inputOptions = this._inputOptionsFromObject(image);
    const composite2 = {
      input: this._createInputDescriptor(image.input, inputOptions, { allowStream: false }),
      blend: "over",
      tile: false,
      left: 0,
      top: 0,
      hasOffset: false,
      gravity: 0,
      premultiplied: false
    };
    if (is$5.defined(image.blend)) {
      if (is$5.string(blend[image.blend])) {
        composite2.blend = blend[image.blend];
      } else {
        throw is$5.invalidParameterError("blend", "valid blend name", image.blend);
      }
    }
    if (is$5.defined(image.tile)) {
      if (is$5.bool(image.tile)) {
        composite2.tile = image.tile;
      } else {
        throw is$5.invalidParameterError("tile", "boolean", image.tile);
      }
    }
    if (is$5.defined(image.left)) {
      if (is$5.integer(image.left)) {
        composite2.left = image.left;
      } else {
        throw is$5.invalidParameterError("left", "integer", image.left);
      }
    }
    if (is$5.defined(image.top)) {
      if (is$5.integer(image.top)) {
        composite2.top = image.top;
      } else {
        throw is$5.invalidParameterError("top", "integer", image.top);
      }
    }
    if (is$5.defined(image.top) !== is$5.defined(image.left)) {
      throw new Error("Expected both left and top to be set");
    } else {
      composite2.hasOffset = is$5.integer(image.top) && is$5.integer(image.left);
    }
    if (is$5.defined(image.gravity)) {
      if (is$5.integer(image.gravity) && is$5.inRange(image.gravity, 0, 8)) {
        composite2.gravity = image.gravity;
      } else if (is$5.string(image.gravity) && is$5.integer(this.constructor.gravity[image.gravity])) {
        composite2.gravity = this.constructor.gravity[image.gravity];
      } else {
        throw is$5.invalidParameterError("gravity", "valid gravity", image.gravity);
      }
    }
    if (is$5.defined(image.premultiplied)) {
      if (is$5.bool(image.premultiplied)) {
        composite2.premultiplied = image.premultiplied;
      } else {
        throw is$5.invalidParameterError("premultiplied", "boolean", image.premultiplied);
      }
    }
    return composite2;
  });
  return this;
}
var composite_1 = function(Sharp2) {
  Sharp2.prototype.composite = composite;
  Sharp2.blend = blend;
};
const color$1 = color$3;
const is$4 = is$9;
function rotate(angle, options) {
  if (this.options.useExifOrientation || this.options.angle || this.options.rotationAngle) {
    this.options.debuglog("ignoring previous rotate options");
  }
  if (!is$4.defined(angle)) {
    this.options.useExifOrientation = true;
  } else if (is$4.integer(angle) && !(angle % 90)) {
    this.options.angle = angle;
  } else if (is$4.number(angle)) {
    this.options.rotationAngle = angle;
    if (is$4.object(options) && options.background) {
      const backgroundColour = color$1(options.background);
      this.options.rotationBackground = [
        backgroundColour.red(),
        backgroundColour.green(),
        backgroundColour.blue(),
        Math.round(backgroundColour.alpha() * 255)
      ];
    }
  } else {
    throw is$4.invalidParameterError("angle", "numeric", angle);
  }
  return this;
}
function flip(flip2) {
  this.options.flip = is$4.bool(flip2) ? flip2 : true;
  return this;
}
function flop(flop2) {
  this.options.flop = is$4.bool(flop2) ? flop2 : true;
  return this;
}
function affine(matrix, options) {
  const flatMatrix = [].concat(...matrix);
  if (flatMatrix.length === 4 && flatMatrix.every(is$4.number)) {
    this.options.affineMatrix = flatMatrix;
  } else {
    throw is$4.invalidParameterError("matrix", "1x4 or 2x2 array", matrix);
  }
  if (is$4.defined(options)) {
    if (is$4.object(options)) {
      this._setBackgroundColourOption("affineBackground", options.background);
      if (is$4.defined(options.idx)) {
        if (is$4.number(options.idx)) {
          this.options.affineIdx = options.idx;
        } else {
          throw is$4.invalidParameterError("options.idx", "number", options.idx);
        }
      }
      if (is$4.defined(options.idy)) {
        if (is$4.number(options.idy)) {
          this.options.affineIdy = options.idy;
        } else {
          throw is$4.invalidParameterError("options.idy", "number", options.idy);
        }
      }
      if (is$4.defined(options.odx)) {
        if (is$4.number(options.odx)) {
          this.options.affineOdx = options.odx;
        } else {
          throw is$4.invalidParameterError("options.odx", "number", options.odx);
        }
      }
      if (is$4.defined(options.ody)) {
        if (is$4.number(options.ody)) {
          this.options.affineOdy = options.ody;
        } else {
          throw is$4.invalidParameterError("options.ody", "number", options.ody);
        }
      }
      if (is$4.defined(options.interpolator)) {
        if (is$4.inArray(options.interpolator, Object.values(this.constructor.interpolators))) {
          this.options.affineInterpolator = options.interpolator;
        } else {
          throw is$4.invalidParameterError("options.interpolator", "valid interpolator name", options.interpolator);
        }
      }
    } else {
      throw is$4.invalidParameterError("options", "object", options);
    }
  }
  return this;
}
function sharpen(options, flat, jagged) {
  if (!is$4.defined(options)) {
    this.options.sharpenSigma = -1;
  } else if (is$4.bool(options)) {
    this.options.sharpenSigma = options ? -1 : 0;
  } else if (is$4.number(options) && is$4.inRange(options, 0.01, 1e4)) {
    this.options.sharpenSigma = options;
    if (is$4.defined(flat)) {
      if (is$4.number(flat) && is$4.inRange(flat, 0, 1e4)) {
        this.options.sharpenM1 = flat;
      } else {
        throw is$4.invalidParameterError("flat", "number between 0 and 10000", flat);
      }
    }
    if (is$4.defined(jagged)) {
      if (is$4.number(jagged) && is$4.inRange(jagged, 0, 1e4)) {
        this.options.sharpenM2 = jagged;
      } else {
        throw is$4.invalidParameterError("jagged", "number between 0 and 10000", jagged);
      }
    }
  } else if (is$4.plainObject(options)) {
    if (is$4.number(options.sigma) && is$4.inRange(options.sigma, 1e-6, 10)) {
      this.options.sharpenSigma = options.sigma;
    } else {
      throw is$4.invalidParameterError("options.sigma", "number between 0.000001 and 10", options.sigma);
    }
    if (is$4.defined(options.m1)) {
      if (is$4.number(options.m1) && is$4.inRange(options.m1, 0, 1e6)) {
        this.options.sharpenM1 = options.m1;
      } else {
        throw is$4.invalidParameterError("options.m1", "number between 0 and 1000000", options.m1);
      }
    }
    if (is$4.defined(options.m2)) {
      if (is$4.number(options.m2) && is$4.inRange(options.m2, 0, 1e6)) {
        this.options.sharpenM2 = options.m2;
      } else {
        throw is$4.invalidParameterError("options.m2", "number between 0 and 1000000", options.m2);
      }
    }
    if (is$4.defined(options.x1)) {
      if (is$4.number(options.x1) && is$4.inRange(options.x1, 0, 1e6)) {
        this.options.sharpenX1 = options.x1;
      } else {
        throw is$4.invalidParameterError("options.x1", "number between 0 and 1000000", options.x1);
      }
    }
    if (is$4.defined(options.y2)) {
      if (is$4.number(options.y2) && is$4.inRange(options.y2, 0, 1e6)) {
        this.options.sharpenY2 = options.y2;
      } else {
        throw is$4.invalidParameterError("options.y2", "number between 0 and 1000000", options.y2);
      }
    }
    if (is$4.defined(options.y3)) {
      if (is$4.number(options.y3) && is$4.inRange(options.y3, 0, 1e6)) {
        this.options.sharpenY3 = options.y3;
      } else {
        throw is$4.invalidParameterError("options.y3", "number between 0 and 1000000", options.y3);
      }
    }
  } else {
    throw is$4.invalidParameterError("sigma", "number between 0.01 and 10000", options);
  }
  return this;
}
function median(size) {
  if (!is$4.defined(size)) {
    this.options.medianSize = 3;
  } else if (is$4.integer(size) && is$4.inRange(size, 1, 1e3)) {
    this.options.medianSize = size;
  } else {
    throw is$4.invalidParameterError("size", "integer between 1 and 1000", size);
  }
  return this;
}
function blur(sigma) {
  if (!is$4.defined(sigma)) {
    this.options.blurSigma = -1;
  } else if (is$4.bool(sigma)) {
    this.options.blurSigma = sigma ? -1 : 0;
  } else if (is$4.number(sigma) && is$4.inRange(sigma, 0.3, 1e3)) {
    this.options.blurSigma = sigma;
  } else {
    throw is$4.invalidParameterError("sigma", "number between 0.3 and 1000", sigma);
  }
  return this;
}
function flatten(options) {
  this.options.flatten = is$4.bool(options) ? options : true;
  if (is$4.object(options)) {
    this._setBackgroundColourOption("flattenBackground", options.background);
  }
  return this;
}
function unflatten() {
  this.options.unflatten = true;
  return this;
}
function gamma(gamma2, gammaOut) {
  if (!is$4.defined(gamma2)) {
    this.options.gamma = 2.2;
  } else if (is$4.number(gamma2) && is$4.inRange(gamma2, 1, 3)) {
    this.options.gamma = gamma2;
  } else {
    throw is$4.invalidParameterError("gamma", "number between 1.0 and 3.0", gamma2);
  }
  if (!is$4.defined(gammaOut)) {
    this.options.gammaOut = this.options.gamma;
  } else if (is$4.number(gammaOut) && is$4.inRange(gammaOut, 1, 3)) {
    this.options.gammaOut = gammaOut;
  } else {
    throw is$4.invalidParameterError("gammaOut", "number between 1.0 and 3.0", gammaOut);
  }
  return this;
}
function negate(options) {
  this.options.negate = is$4.bool(options) ? options : true;
  if (is$4.plainObject(options) && "alpha" in options) {
    if (!is$4.bool(options.alpha)) {
      throw is$4.invalidParameterError("alpha", "should be boolean value", options.alpha);
    } else {
      this.options.negateAlpha = options.alpha;
    }
  }
  return this;
}
function normalise(options) {
  if (is$4.plainObject(options)) {
    if (is$4.defined(options.lower)) {
      if (is$4.number(options.lower) && is$4.inRange(options.lower, 0, 99)) {
        this.options.normaliseLower = options.lower;
      } else {
        throw is$4.invalidParameterError("lower", "number between 0 and 99", options.lower);
      }
    }
    if (is$4.defined(options.upper)) {
      if (is$4.number(options.upper) && is$4.inRange(options.upper, 1, 100)) {
        this.options.normaliseUpper = options.upper;
      } else {
        throw is$4.invalidParameterError("upper", "number between 1 and 100", options.upper);
      }
    }
  }
  if (this.options.normaliseLower >= this.options.normaliseUpper) {
    throw is$4.invalidParameterError(
      "range",
      "lower to be less than upper",
      `${this.options.normaliseLower} >= ${this.options.normaliseUpper}`
    );
  }
  this.options.normalise = true;
  return this;
}
function normalize(options) {
  return this.normalise(options);
}
function clahe(options) {
  if (is$4.plainObject(options)) {
    if (is$4.integer(options.width) && options.width > 0) {
      this.options.claheWidth = options.width;
    } else {
      throw is$4.invalidParameterError("width", "integer greater than zero", options.width);
    }
    if (is$4.integer(options.height) && options.height > 0) {
      this.options.claheHeight = options.height;
    } else {
      throw is$4.invalidParameterError("height", "integer greater than zero", options.height);
    }
    if (is$4.defined(options.maxSlope)) {
      if (is$4.integer(options.maxSlope) && is$4.inRange(options.maxSlope, 0, 100)) {
        this.options.claheMaxSlope = options.maxSlope;
      } else {
        throw is$4.invalidParameterError("maxSlope", "integer between 0 and 100", options.maxSlope);
      }
    }
  } else {
    throw is$4.invalidParameterError("options", "plain object", options);
  }
  return this;
}
function convolve(kernel2) {
  if (!is$4.object(kernel2) || !Array.isArray(kernel2.kernel) || !is$4.integer(kernel2.width) || !is$4.integer(kernel2.height) || !is$4.inRange(kernel2.width, 3, 1001) || !is$4.inRange(kernel2.height, 3, 1001) || kernel2.height * kernel2.width !== kernel2.kernel.length) {
    throw new Error("Invalid convolution kernel");
  }
  if (!is$4.integer(kernel2.scale)) {
    kernel2.scale = kernel2.kernel.reduce(function(a, b) {
      return a + b;
    }, 0);
  }
  if (kernel2.scale < 1) {
    kernel2.scale = 1;
  }
  if (!is$4.integer(kernel2.offset)) {
    kernel2.offset = 0;
  }
  this.options.convKernel = kernel2;
  return this;
}
function threshold(threshold2, options) {
  if (!is$4.defined(threshold2)) {
    this.options.threshold = 128;
  } else if (is$4.bool(threshold2)) {
    this.options.threshold = threshold2 ? 128 : 0;
  } else if (is$4.integer(threshold2) && is$4.inRange(threshold2, 0, 255)) {
    this.options.threshold = threshold2;
  } else {
    throw is$4.invalidParameterError("threshold", "integer between 0 and 255", threshold2);
  }
  if (!is$4.object(options) || options.greyscale === true || options.grayscale === true) {
    this.options.thresholdGrayscale = true;
  } else {
    this.options.thresholdGrayscale = false;
  }
  return this;
}
function boolean(operand, operator, options) {
  this.options.boolean = this._createInputDescriptor(operand, options);
  if (is$4.string(operator) && is$4.inArray(operator, ["and", "or", "eor"])) {
    this.options.booleanOp = operator;
  } else {
    throw is$4.invalidParameterError("operator", "one of: and, or, eor", operator);
  }
  return this;
}
function linear(a, b) {
  if (!is$4.defined(a) && is$4.number(b)) {
    a = 1;
  } else if (is$4.number(a) && !is$4.defined(b)) {
    b = 0;
  }
  if (!is$4.defined(a)) {
    this.options.linearA = [];
  } else if (is$4.number(a)) {
    this.options.linearA = [a];
  } else if (Array.isArray(a) && a.length && a.every(is$4.number)) {
    this.options.linearA = a;
  } else {
    throw is$4.invalidParameterError("a", "number or array of numbers", a);
  }
  if (!is$4.defined(b)) {
    this.options.linearB = [];
  } else if (is$4.number(b)) {
    this.options.linearB = [b];
  } else if (Array.isArray(b) && b.length && b.every(is$4.number)) {
    this.options.linearB = b;
  } else {
    throw is$4.invalidParameterError("b", "number or array of numbers", b);
  }
  if (this.options.linearA.length !== this.options.linearB.length) {
    throw new Error("Expected a and b to be arrays of the same length");
  }
  return this;
}
function recomb(inputMatrix) {
  if (!Array.isArray(inputMatrix) || inputMatrix.length !== 3 || inputMatrix[0].length !== 3 || inputMatrix[1].length !== 3 || inputMatrix[2].length !== 3) {
    throw new Error("Invalid recombination matrix");
  }
  this.options.recombMatrix = [
    inputMatrix[0][0],
    inputMatrix[0][1],
    inputMatrix[0][2],
    inputMatrix[1][0],
    inputMatrix[1][1],
    inputMatrix[1][2],
    inputMatrix[2][0],
    inputMatrix[2][1],
    inputMatrix[2][2]
  ].map(Number);
  return this;
}
function modulate(options) {
  if (!is$4.plainObject(options)) {
    throw is$4.invalidParameterError("options", "plain object", options);
  }
  if ("brightness" in options) {
    if (is$4.number(options.brightness) && options.brightness >= 0) {
      this.options.brightness = options.brightness;
    } else {
      throw is$4.invalidParameterError("brightness", "number above zero", options.brightness);
    }
  }
  if ("saturation" in options) {
    if (is$4.number(options.saturation) && options.saturation >= 0) {
      this.options.saturation = options.saturation;
    } else {
      throw is$4.invalidParameterError("saturation", "number above zero", options.saturation);
    }
  }
  if ("hue" in options) {
    if (is$4.integer(options.hue)) {
      this.options.hue = options.hue % 360;
    } else {
      throw is$4.invalidParameterError("hue", "number", options.hue);
    }
  }
  if ("lightness" in options) {
    if (is$4.number(options.lightness)) {
      this.options.lightness = options.lightness;
    } else {
      throw is$4.invalidParameterError("lightness", "number", options.lightness);
    }
  }
  return this;
}
var operation = function(Sharp2) {
  Object.assign(Sharp2.prototype, {
    rotate,
    flip,
    flop,
    affine,
    sharpen,
    median,
    blur,
    flatten,
    unflatten,
    gamma,
    negate,
    normalise,
    normalize,
    clahe,
    convolve,
    threshold,
    boolean,
    linear,
    recomb,
    modulate
  });
};
const color = color$3;
const is$3 = is$9;
const colourspace = {
  multiband: "multiband",
  "b-w": "b-w",
  bw: "b-w",
  cmyk: "cmyk",
  srgb: "srgb"
};
function tint(rgb) {
  const colour2 = color(rgb);
  this.options.tintA = colour2.a();
  this.options.tintB = colour2.b();
  return this;
}
function greyscale(greyscale2) {
  this.options.greyscale = is$3.bool(greyscale2) ? greyscale2 : true;
  return this;
}
function grayscale(grayscale2) {
  return this.greyscale(grayscale2);
}
function pipelineColourspace(colourspace2) {
  if (!is$3.string(colourspace2)) {
    throw is$3.invalidParameterError("colourspace", "string", colourspace2);
  }
  this.options.colourspaceInput = colourspace2;
  return this;
}
function pipelineColorspace(colorspace) {
  return this.pipelineColourspace(colorspace);
}
function toColourspace(colourspace2) {
  if (!is$3.string(colourspace2)) {
    throw is$3.invalidParameterError("colourspace", "string", colourspace2);
  }
  this.options.colourspace = colourspace2;
  return this;
}
function toColorspace(colorspace) {
  return this.toColourspace(colorspace);
}
function _setBackgroundColourOption(key, value) {
  if (is$3.defined(value)) {
    if (is$3.object(value) || is$3.string(value)) {
      const colour2 = color(value);
      this.options[key] = [
        colour2.red(),
        colour2.green(),
        colour2.blue(),
        Math.round(colour2.alpha() * 255)
      ];
    } else {
      throw is$3.invalidParameterError("background", "object or string", value);
    }
  }
}
var colour = function(Sharp2) {
  Object.assign(Sharp2.prototype, {
    // Public
    tint,
    greyscale,
    grayscale,
    pipelineColourspace,
    pipelineColorspace,
    toColourspace,
    toColorspace,
    // Private
    _setBackgroundColourOption
  });
  Sharp2.colourspace = colourspace;
  Sharp2.colorspace = colourspace;
};
const is$2 = is$9;
const bool = {
  and: "and",
  or: "or",
  eor: "eor"
};
function removeAlpha() {
  this.options.removeAlpha = true;
  return this;
}
function ensureAlpha(alpha) {
  if (is$2.defined(alpha)) {
    if (is$2.number(alpha) && is$2.inRange(alpha, 0, 1)) {
      this.options.ensureAlpha = alpha;
    } else {
      throw is$2.invalidParameterError("alpha", "number between 0 and 1", alpha);
    }
  } else {
    this.options.ensureAlpha = 1;
  }
  return this;
}
function extractChannel(channel2) {
  const channelMap = { red: 0, green: 1, blue: 2, alpha: 3 };
  if (Object.keys(channelMap).includes(channel2)) {
    channel2 = channelMap[channel2];
  }
  if (is$2.integer(channel2) && is$2.inRange(channel2, 0, 4)) {
    this.options.extractChannel = channel2;
  } else {
    throw is$2.invalidParameterError("channel", "integer or one of: red, green, blue, alpha", channel2);
  }
  return this;
}
function joinChannel(images, options) {
  if (Array.isArray(images)) {
    images.forEach(function(image) {
      this.options.joinChannelIn.push(this._createInputDescriptor(image, options));
    }, this);
  } else {
    this.options.joinChannelIn.push(this._createInputDescriptor(images, options));
  }
  return this;
}
function bandbool(boolOp) {
  if (is$2.string(boolOp) && is$2.inArray(boolOp, ["and", "or", "eor"])) {
    this.options.bandBoolOp = boolOp;
  } else {
    throw is$2.invalidParameterError("boolOp", "one of: and, or, eor", boolOp);
  }
  return this;
}
var channel = function(Sharp2) {
  Object.assign(Sharp2.prototype, {
    // Public instance functions
    removeAlpha,
    ensureAlpha,
    extractChannel,
    joinChannel,
    bandbool
  });
  Sharp2.bool = bool;
};
const path$1 = path$4;
const is$1 = is$9;
const sharp$2 = sharpExports;
const formats = /* @__PURE__ */ new Map([
  ["heic", "heif"],
  ["heif", "heif"],
  ["avif", "avif"],
  ["jpeg", "jpeg"],
  ["jpg", "jpeg"],
  ["jpe", "jpeg"],
  ["tile", "tile"],
  ["dz", "tile"],
  ["png", "png"],
  ["raw", "raw"],
  ["tiff", "tiff"],
  ["tif", "tiff"],
  ["webp", "webp"],
  ["gif", "gif"],
  ["jp2", "jp2"],
  ["jpx", "jp2"],
  ["j2k", "jp2"],
  ["j2c", "jp2"],
  ["jxl", "jxl"]
]);
const jp2Regex = /\.(jp[2x]|j2[kc])$/i;
const errJp2Save = () => new Error("JP2 output requires libvips with support for OpenJPEG");
const bitdepthFromColourCount = (colours) => 1 << 31 - Math.clz32(Math.ceil(Math.log2(colours)));
function toFile(fileOut, callback) {
  let err;
  if (!is$1.string(fileOut)) {
    err = new Error("Missing output file path");
  } else if (is$1.string(this.options.input.file) && path$1.resolve(this.options.input.file) === path$1.resolve(fileOut)) {
    err = new Error("Cannot use same file for input and output");
  } else if (jp2Regex.test(path$1.extname(fileOut)) && !this.constructor.format.jp2k.output.file) {
    err = errJp2Save();
  }
  if (err) {
    if (is$1.fn(callback)) {
      callback(err);
    } else {
      return Promise.reject(err);
    }
  } else {
    this.options.fileOut = fileOut;
    return this._pipeline(callback);
  }
  return this;
}
function toBuffer(options, callback) {
  if (is$1.object(options)) {
    this._setBooleanOption("resolveWithObject", options.resolveWithObject);
  } else if (this.options.resolveWithObject) {
    this.options.resolveWithObject = false;
  }
  this.options.fileOut = "";
  return this._pipeline(is$1.fn(options) ? options : callback);
}
function withMetadata(options) {
  this.options.withMetadata = is$1.bool(options) ? options : true;
  if (is$1.object(options)) {
    if (is$1.defined(options.orientation)) {
      if (is$1.integer(options.orientation) && is$1.inRange(options.orientation, 1, 8)) {
        this.options.withMetadataOrientation = options.orientation;
      } else {
        throw is$1.invalidParameterError("orientation", "integer between 1 and 8", options.orientation);
      }
    }
    if (is$1.defined(options.density)) {
      if (is$1.number(options.density) && options.density > 0) {
        this.options.withMetadataDensity = options.density;
      } else {
        throw is$1.invalidParameterError("density", "positive number", options.density);
      }
    }
    if (is$1.defined(options.icc)) {
      if (is$1.string(options.icc)) {
        this.options.withMetadataIcc = options.icc;
      } else {
        throw is$1.invalidParameterError("icc", "string filesystem path to ICC profile", options.icc);
      }
    }
    if (is$1.defined(options.exif)) {
      if (is$1.object(options.exif)) {
        for (const [ifd, entries] of Object.entries(options.exif)) {
          if (is$1.object(entries)) {
            for (const [k, v] of Object.entries(entries)) {
              if (is$1.string(v)) {
                this.options.withMetadataStrs[`exif-${ifd.toLowerCase()}-${k}`] = v;
              } else {
                throw is$1.invalidParameterError(`exif.${ifd}.${k}`, "string", v);
              }
            }
          } else {
            throw is$1.invalidParameterError(`exif.${ifd}`, "object", entries);
          }
        }
      } else {
        throw is$1.invalidParameterError("exif", "object", options.exif);
      }
    }
  }
  return this;
}
function toFormat(format2, options) {
  const actualFormat = formats.get((is$1.object(format2) && is$1.string(format2.id) ? format2.id : format2).toLowerCase());
  if (!actualFormat) {
    throw is$1.invalidParameterError("format", `one of: ${[...formats.keys()].join(", ")}`, format2);
  }
  return this[actualFormat](options);
}
function jpeg(options) {
  if (is$1.object(options)) {
    if (is$1.defined(options.quality)) {
      if (is$1.integer(options.quality) && is$1.inRange(options.quality, 1, 100)) {
        this.options.jpegQuality = options.quality;
      } else {
        throw is$1.invalidParameterError("quality", "integer between 1 and 100", options.quality);
      }
    }
    if (is$1.defined(options.progressive)) {
      this._setBooleanOption("jpegProgressive", options.progressive);
    }
    if (is$1.defined(options.chromaSubsampling)) {
      if (is$1.string(options.chromaSubsampling) && is$1.inArray(options.chromaSubsampling, ["4:2:0", "4:4:4"])) {
        this.options.jpegChromaSubsampling = options.chromaSubsampling;
      } else {
        throw is$1.invalidParameterError("chromaSubsampling", "one of: 4:2:0, 4:4:4", options.chromaSubsampling);
      }
    }
    const optimiseCoding = is$1.bool(options.optimizeCoding) ? options.optimizeCoding : options.optimiseCoding;
    if (is$1.defined(optimiseCoding)) {
      this._setBooleanOption("jpegOptimiseCoding", optimiseCoding);
    }
    if (is$1.defined(options.mozjpeg)) {
      if (is$1.bool(options.mozjpeg)) {
        if (options.mozjpeg) {
          this.options.jpegTrellisQuantisation = true;
          this.options.jpegOvershootDeringing = true;
          this.options.jpegOptimiseScans = true;
          this.options.jpegProgressive = true;
          this.options.jpegQuantisationTable = 3;
        }
      } else {
        throw is$1.invalidParameterError("mozjpeg", "boolean", options.mozjpeg);
      }
    }
    const trellisQuantisation = is$1.bool(options.trellisQuantization) ? options.trellisQuantization : options.trellisQuantisation;
    if (is$1.defined(trellisQuantisation)) {
      this._setBooleanOption("jpegTrellisQuantisation", trellisQuantisation);
    }
    if (is$1.defined(options.overshootDeringing)) {
      this._setBooleanOption("jpegOvershootDeringing", options.overshootDeringing);
    }
    const optimiseScans = is$1.bool(options.optimizeScans) ? options.optimizeScans : options.optimiseScans;
    if (is$1.defined(optimiseScans)) {
      this._setBooleanOption("jpegOptimiseScans", optimiseScans);
      if (optimiseScans) {
        this.options.jpegProgressive = true;
      }
    }
    const quantisationTable = is$1.number(options.quantizationTable) ? options.quantizationTable : options.quantisationTable;
    if (is$1.defined(quantisationTable)) {
      if (is$1.integer(quantisationTable) && is$1.inRange(quantisationTable, 0, 8)) {
        this.options.jpegQuantisationTable = quantisationTable;
      } else {
        throw is$1.invalidParameterError("quantisationTable", "integer between 0 and 8", quantisationTable);
      }
    }
  }
  return this._updateFormatOut("jpeg", options);
}
function png(options) {
  if (is$1.object(options)) {
    if (is$1.defined(options.progressive)) {
      this._setBooleanOption("pngProgressive", options.progressive);
    }
    if (is$1.defined(options.compressionLevel)) {
      if (is$1.integer(options.compressionLevel) && is$1.inRange(options.compressionLevel, 0, 9)) {
        this.options.pngCompressionLevel = options.compressionLevel;
      } else {
        throw is$1.invalidParameterError("compressionLevel", "integer between 0 and 9", options.compressionLevel);
      }
    }
    if (is$1.defined(options.adaptiveFiltering)) {
      this._setBooleanOption("pngAdaptiveFiltering", options.adaptiveFiltering);
    }
    const colours = options.colours || options.colors;
    if (is$1.defined(colours)) {
      if (is$1.integer(colours) && is$1.inRange(colours, 2, 256)) {
        this.options.pngBitdepth = bitdepthFromColourCount(colours);
      } else {
        throw is$1.invalidParameterError("colours", "integer between 2 and 256", colours);
      }
    }
    if (is$1.defined(options.palette)) {
      this._setBooleanOption("pngPalette", options.palette);
    } else if ([options.quality, options.effort, options.colours, options.colors, options.dither].some(is$1.defined)) {
      this._setBooleanOption("pngPalette", true);
    }
    if (this.options.pngPalette) {
      if (is$1.defined(options.quality)) {
        if (is$1.integer(options.quality) && is$1.inRange(options.quality, 0, 100)) {
          this.options.pngQuality = options.quality;
        } else {
          throw is$1.invalidParameterError("quality", "integer between 0 and 100", options.quality);
        }
      }
      if (is$1.defined(options.effort)) {
        if (is$1.integer(options.effort) && is$1.inRange(options.effort, 1, 10)) {
          this.options.pngEffort = options.effort;
        } else {
          throw is$1.invalidParameterError("effort", "integer between 1 and 10", options.effort);
        }
      }
      if (is$1.defined(options.dither)) {
        if (is$1.number(options.dither) && is$1.inRange(options.dither, 0, 1)) {
          this.options.pngDither = options.dither;
        } else {
          throw is$1.invalidParameterError("dither", "number between 0.0 and 1.0", options.dither);
        }
      }
    }
  }
  return this._updateFormatOut("png", options);
}
function webp(options) {
  if (is$1.object(options)) {
    if (is$1.defined(options.quality)) {
      if (is$1.integer(options.quality) && is$1.inRange(options.quality, 1, 100)) {
        this.options.webpQuality = options.quality;
      } else {
        throw is$1.invalidParameterError("quality", "integer between 1 and 100", options.quality);
      }
    }
    if (is$1.defined(options.alphaQuality)) {
      if (is$1.integer(options.alphaQuality) && is$1.inRange(options.alphaQuality, 0, 100)) {
        this.options.webpAlphaQuality = options.alphaQuality;
      } else {
        throw is$1.invalidParameterError("alphaQuality", "integer between 0 and 100", options.alphaQuality);
      }
    }
    if (is$1.defined(options.lossless)) {
      this._setBooleanOption("webpLossless", options.lossless);
    }
    if (is$1.defined(options.nearLossless)) {
      this._setBooleanOption("webpNearLossless", options.nearLossless);
    }
    if (is$1.defined(options.smartSubsample)) {
      this._setBooleanOption("webpSmartSubsample", options.smartSubsample);
    }
    if (is$1.defined(options.preset)) {
      if (is$1.string(options.preset) && is$1.inArray(options.preset, ["default", "photo", "picture", "drawing", "icon", "text"])) {
        this.options.webpPreset = options.preset;
      } else {
        throw is$1.invalidParameterError("preset", "one of: default, photo, picture, drawing, icon, text", options.preset);
      }
    }
    if (is$1.defined(options.effort)) {
      if (is$1.integer(options.effort) && is$1.inRange(options.effort, 0, 6)) {
        this.options.webpEffort = options.effort;
      } else {
        throw is$1.invalidParameterError("effort", "integer between 0 and 6", options.effort);
      }
    }
    if (is$1.defined(options.minSize)) {
      this._setBooleanOption("webpMinSize", options.minSize);
    }
    if (is$1.defined(options.mixed)) {
      this._setBooleanOption("webpMixed", options.mixed);
    }
  }
  trySetAnimationOptions(options, this.options);
  return this._updateFormatOut("webp", options);
}
function gif(options) {
  if (is$1.object(options)) {
    if (is$1.defined(options.reuse)) {
      this._setBooleanOption("gifReuse", options.reuse);
    }
    if (is$1.defined(options.progressive)) {
      this._setBooleanOption("gifProgressive", options.progressive);
    }
    const colours = options.colours || options.colors;
    if (is$1.defined(colours)) {
      if (is$1.integer(colours) && is$1.inRange(colours, 2, 256)) {
        this.options.gifBitdepth = bitdepthFromColourCount(colours);
      } else {
        throw is$1.invalidParameterError("colours", "integer between 2 and 256", colours);
      }
    }
    if (is$1.defined(options.effort)) {
      if (is$1.number(options.effort) && is$1.inRange(options.effort, 1, 10)) {
        this.options.gifEffort = options.effort;
      } else {
        throw is$1.invalidParameterError("effort", "integer between 1 and 10", options.effort);
      }
    }
    if (is$1.defined(options.dither)) {
      if (is$1.number(options.dither) && is$1.inRange(options.dither, 0, 1)) {
        this.options.gifDither = options.dither;
      } else {
        throw is$1.invalidParameterError("dither", "number between 0.0 and 1.0", options.dither);
      }
    }
    if (is$1.defined(options.interFrameMaxError)) {
      if (is$1.number(options.interFrameMaxError) && is$1.inRange(options.interFrameMaxError, 0, 32)) {
        this.options.gifInterFrameMaxError = options.interFrameMaxError;
      } else {
        throw is$1.invalidParameterError("interFrameMaxError", "number between 0.0 and 32.0", options.interFrameMaxError);
      }
    }
    if (is$1.defined(options.interPaletteMaxError)) {
      if (is$1.number(options.interPaletteMaxError) && is$1.inRange(options.interPaletteMaxError, 0, 256)) {
        this.options.gifInterPaletteMaxError = options.interPaletteMaxError;
      } else {
        throw is$1.invalidParameterError("interPaletteMaxError", "number between 0.0 and 256.0", options.interPaletteMaxError);
      }
    }
  }
  trySetAnimationOptions(options, this.options);
  return this._updateFormatOut("gif", options);
}
function jp2(options) {
  if (!this.constructor.format.jp2k.output.buffer) {
    throw errJp2Save();
  }
  if (is$1.object(options)) {
    if (is$1.defined(options.quality)) {
      if (is$1.integer(options.quality) && is$1.inRange(options.quality, 1, 100)) {
        this.options.jp2Quality = options.quality;
      } else {
        throw is$1.invalidParameterError("quality", "integer between 1 and 100", options.quality);
      }
    }
    if (is$1.defined(options.lossless)) {
      if (is$1.bool(options.lossless)) {
        this.options.jp2Lossless = options.lossless;
      } else {
        throw is$1.invalidParameterError("lossless", "boolean", options.lossless);
      }
    }
    if (is$1.defined(options.tileWidth)) {
      if (is$1.integer(options.tileWidth) && is$1.inRange(options.tileWidth, 1, 32768)) {
        this.options.jp2TileWidth = options.tileWidth;
      } else {
        throw is$1.invalidParameterError("tileWidth", "integer between 1 and 32768", options.tileWidth);
      }
    }
    if (is$1.defined(options.tileHeight)) {
      if (is$1.integer(options.tileHeight) && is$1.inRange(options.tileHeight, 1, 32768)) {
        this.options.jp2TileHeight = options.tileHeight;
      } else {
        throw is$1.invalidParameterError("tileHeight", "integer between 1 and 32768", options.tileHeight);
      }
    }
    if (is$1.defined(options.chromaSubsampling)) {
      if (is$1.string(options.chromaSubsampling) && is$1.inArray(options.chromaSubsampling, ["4:2:0", "4:4:4"])) {
        this.options.jp2ChromaSubsampling = options.chromaSubsampling;
      } else {
        throw is$1.invalidParameterError("chromaSubsampling", "one of: 4:2:0, 4:4:4", options.chromaSubsampling);
      }
    }
  }
  return this._updateFormatOut("jp2", options);
}
function trySetAnimationOptions(source, target) {
  if (is$1.object(source) && is$1.defined(source.loop)) {
    if (is$1.integer(source.loop) && is$1.inRange(source.loop, 0, 65535)) {
      target.loop = source.loop;
    } else {
      throw is$1.invalidParameterError("loop", "integer between 0 and 65535", source.loop);
    }
  }
  if (is$1.object(source) && is$1.defined(source.delay)) {
    if (is$1.integer(source.delay) && is$1.inRange(source.delay, 0, 65535)) {
      target.delay = [source.delay];
    } else if (Array.isArray(source.delay) && source.delay.every(is$1.integer) && source.delay.every((v) => is$1.inRange(v, 0, 65535))) {
      target.delay = source.delay;
    } else {
      throw is$1.invalidParameterError("delay", "integer or an array of integers between 0 and 65535", source.delay);
    }
  }
}
function tiff(options) {
  if (is$1.object(options)) {
    if (is$1.defined(options.quality)) {
      if (is$1.integer(options.quality) && is$1.inRange(options.quality, 1, 100)) {
        this.options.tiffQuality = options.quality;
      } else {
        throw is$1.invalidParameterError("quality", "integer between 1 and 100", options.quality);
      }
    }
    if (is$1.defined(options.bitdepth)) {
      if (is$1.integer(options.bitdepth) && is$1.inArray(options.bitdepth, [1, 2, 4, 8])) {
        this.options.tiffBitdepth = options.bitdepth;
      } else {
        throw is$1.invalidParameterError("bitdepth", "1, 2, 4 or 8", options.bitdepth);
      }
    }
    if (is$1.defined(options.tile)) {
      this._setBooleanOption("tiffTile", options.tile);
    }
    if (is$1.defined(options.tileWidth)) {
      if (is$1.integer(options.tileWidth) && options.tileWidth > 0) {
        this.options.tiffTileWidth = options.tileWidth;
      } else {
        throw is$1.invalidParameterError("tileWidth", "integer greater than zero", options.tileWidth);
      }
    }
    if (is$1.defined(options.tileHeight)) {
      if (is$1.integer(options.tileHeight) && options.tileHeight > 0) {
        this.options.tiffTileHeight = options.tileHeight;
      } else {
        throw is$1.invalidParameterError("tileHeight", "integer greater than zero", options.tileHeight);
      }
    }
    if (is$1.defined(options.pyramid)) {
      this._setBooleanOption("tiffPyramid", options.pyramid);
    }
    if (is$1.defined(options.xres)) {
      if (is$1.number(options.xres) && options.xres > 0) {
        this.options.tiffXres = options.xres;
      } else {
        throw is$1.invalidParameterError("xres", "number greater than zero", options.xres);
      }
    }
    if (is$1.defined(options.yres)) {
      if (is$1.number(options.yres) && options.yres > 0) {
        this.options.tiffYres = options.yres;
      } else {
        throw is$1.invalidParameterError("yres", "number greater than zero", options.yres);
      }
    }
    if (is$1.defined(options.compression)) {
      if (is$1.string(options.compression) && is$1.inArray(options.compression, ["none", "jpeg", "deflate", "packbits", "ccittfax4", "lzw", "webp", "zstd", "jp2k"])) {
        this.options.tiffCompression = options.compression;
      } else {
        throw is$1.invalidParameterError("compression", "one of: none, jpeg, deflate, packbits, ccittfax4, lzw, webp, zstd, jp2k", options.compression);
      }
    }
    if (is$1.defined(options.predictor)) {
      if (is$1.string(options.predictor) && is$1.inArray(options.predictor, ["none", "horizontal", "float"])) {
        this.options.tiffPredictor = options.predictor;
      } else {
        throw is$1.invalidParameterError("predictor", "one of: none, horizontal, float", options.predictor);
      }
    }
    if (is$1.defined(options.resolutionUnit)) {
      if (is$1.string(options.resolutionUnit) && is$1.inArray(options.resolutionUnit, ["inch", "cm"])) {
        this.options.tiffResolutionUnit = options.resolutionUnit;
      } else {
        throw is$1.invalidParameterError("resolutionUnit", "one of: inch, cm", options.resolutionUnit);
      }
    }
  }
  return this._updateFormatOut("tiff", options);
}
function avif(options) {
  return this.heif({ ...options, compression: "av1" });
}
function heif(options) {
  if (is$1.object(options)) {
    if (is$1.defined(options.quality)) {
      if (is$1.integer(options.quality) && is$1.inRange(options.quality, 1, 100)) {
        this.options.heifQuality = options.quality;
      } else {
        throw is$1.invalidParameterError("quality", "integer between 1 and 100", options.quality);
      }
    }
    if (is$1.defined(options.lossless)) {
      if (is$1.bool(options.lossless)) {
        this.options.heifLossless = options.lossless;
      } else {
        throw is$1.invalidParameterError("lossless", "boolean", options.lossless);
      }
    }
    if (is$1.defined(options.compression)) {
      if (is$1.string(options.compression) && is$1.inArray(options.compression, ["av1", "hevc"])) {
        this.options.heifCompression = options.compression;
      } else {
        throw is$1.invalidParameterError("compression", "one of: av1, hevc", options.compression);
      }
    }
    if (is$1.defined(options.effort)) {
      if (is$1.integer(options.effort) && is$1.inRange(options.effort, 0, 9)) {
        this.options.heifEffort = options.effort;
      } else {
        throw is$1.invalidParameterError("effort", "integer between 0 and 9", options.effort);
      }
    }
    if (is$1.defined(options.chromaSubsampling)) {
      if (is$1.string(options.chromaSubsampling) && is$1.inArray(options.chromaSubsampling, ["4:2:0", "4:4:4"])) {
        this.options.heifChromaSubsampling = options.chromaSubsampling;
      } else {
        throw is$1.invalidParameterError("chromaSubsampling", "one of: 4:2:0, 4:4:4", options.chromaSubsampling);
      }
    }
  }
  return this._updateFormatOut("heif", options);
}
function jxl(options) {
  if (is$1.object(options)) {
    if (is$1.defined(options.quality)) {
      if (is$1.integer(options.quality) && is$1.inRange(options.quality, 1, 100)) {
        this.options.jxlDistance = options.quality >= 30 ? 0.1 + (100 - options.quality) * 0.09 : 53 / 3e3 * options.quality * options.quality - 23 / 20 * options.quality + 25;
      } else {
        throw is$1.invalidParameterError("quality", "integer between 1 and 100", options.quality);
      }
    } else if (is$1.defined(options.distance)) {
      if (is$1.number(options.distance) && is$1.inRange(options.distance, 0, 15)) {
        this.options.jxlDistance = options.distance;
      } else {
        throw is$1.invalidParameterError("distance", "number between 0.0 and 15.0", options.distance);
      }
    }
    if (is$1.defined(options.decodingTier)) {
      if (is$1.integer(options.decodingTier) && is$1.inRange(options.decodingTier, 0, 4)) {
        this.options.jxlDecodingTier = options.decodingTier;
      } else {
        throw is$1.invalidParameterError("decodingTier", "integer between 0 and 4", options.decodingTier);
      }
    }
    if (is$1.defined(options.lossless)) {
      if (is$1.bool(options.lossless)) {
        this.options.jxlLossless = options.lossless;
      } else {
        throw is$1.invalidParameterError("lossless", "boolean", options.lossless);
      }
    }
    if (is$1.defined(options.effort)) {
      if (is$1.integer(options.effort) && is$1.inRange(options.effort, 3, 9)) {
        this.options.jxlEffort = options.effort;
      } else {
        throw is$1.invalidParameterError("effort", "integer between 3 and 9", options.effort);
      }
    }
  }
  return this._updateFormatOut("jxl", options);
}
function raw(options) {
  if (is$1.object(options)) {
    if (is$1.defined(options.depth)) {
      if (is$1.string(options.depth) && is$1.inArray(
        options.depth,
        ["char", "uchar", "short", "ushort", "int", "uint", "float", "complex", "double", "dpcomplex"]
      )) {
        this.options.rawDepth = options.depth;
      } else {
        throw is$1.invalidParameterError("depth", "one of: char, uchar, short, ushort, int, uint, float, complex, double, dpcomplex", options.depth);
      }
    }
  }
  return this._updateFormatOut("raw");
}
function tile(options) {
  if (is$1.object(options)) {
    if (is$1.defined(options.size)) {
      if (is$1.integer(options.size) && is$1.inRange(options.size, 1, 8192)) {
        this.options.tileSize = options.size;
      } else {
        throw is$1.invalidParameterError("size", "integer between 1 and 8192", options.size);
      }
    }
    if (is$1.defined(options.overlap)) {
      if (is$1.integer(options.overlap) && is$1.inRange(options.overlap, 0, 8192)) {
        if (options.overlap > this.options.tileSize) {
          throw is$1.invalidParameterError("overlap", `<= size (${this.options.tileSize})`, options.overlap);
        }
        this.options.tileOverlap = options.overlap;
      } else {
        throw is$1.invalidParameterError("overlap", "integer between 0 and 8192", options.overlap);
      }
    }
    if (is$1.defined(options.container)) {
      if (is$1.string(options.container) && is$1.inArray(options.container, ["fs", "zip"])) {
        this.options.tileContainer = options.container;
      } else {
        throw is$1.invalidParameterError("container", "one of: fs, zip", options.container);
      }
    }
    if (is$1.defined(options.layout)) {
      if (is$1.string(options.layout) && is$1.inArray(options.layout, ["dz", "google", "iiif", "iiif3", "zoomify"])) {
        this.options.tileLayout = options.layout;
      } else {
        throw is$1.invalidParameterError("layout", "one of: dz, google, iiif, iiif3, zoomify", options.layout);
      }
    }
    if (is$1.defined(options.angle)) {
      if (is$1.integer(options.angle) && !(options.angle % 90)) {
        this.options.tileAngle = options.angle;
      } else {
        throw is$1.invalidParameterError("angle", "positive/negative multiple of 90", options.angle);
      }
    }
    this._setBackgroundColourOption("tileBackground", options.background);
    if (is$1.defined(options.depth)) {
      if (is$1.string(options.depth) && is$1.inArray(options.depth, ["onepixel", "onetile", "one"])) {
        this.options.tileDepth = options.depth;
      } else {
        throw is$1.invalidParameterError("depth", "one of: onepixel, onetile, one", options.depth);
      }
    }
    if (is$1.defined(options.skipBlanks)) {
      if (is$1.integer(options.skipBlanks) && is$1.inRange(options.skipBlanks, -1, 65535)) {
        this.options.tileSkipBlanks = options.skipBlanks;
      } else {
        throw is$1.invalidParameterError("skipBlanks", "integer between -1 and 255/65535", options.skipBlanks);
      }
    } else if (is$1.defined(options.layout) && options.layout === "google") {
      this.options.tileSkipBlanks = 5;
    }
    const centre = is$1.bool(options.center) ? options.center : options.centre;
    if (is$1.defined(centre)) {
      this._setBooleanOption("tileCentre", centre);
    }
    if (is$1.defined(options.id)) {
      if (is$1.string(options.id)) {
        this.options.tileId = options.id;
      } else {
        throw is$1.invalidParameterError("id", "string", options.id);
      }
    }
    if (is$1.defined(options.basename)) {
      if (is$1.string(options.basename)) {
        this.options.tileBasename = options.basename;
      } else {
        throw is$1.invalidParameterError("basename", "string", options.basename);
      }
    }
  }
  if (is$1.inArray(this.options.formatOut, ["jpeg", "png", "webp"])) {
    this.options.tileFormat = this.options.formatOut;
  } else if (this.options.formatOut !== "input") {
    throw is$1.invalidParameterError("format", "one of: jpeg, png, webp", this.options.formatOut);
  }
  return this._updateFormatOut("dz");
}
function timeout(options) {
  if (!is$1.plainObject(options)) {
    throw is$1.invalidParameterError("options", "object", options);
  }
  if (is$1.integer(options.seconds) && is$1.inRange(options.seconds, 0, 3600)) {
    this.options.timeoutSeconds = options.seconds;
  } else {
    throw is$1.invalidParameterError("seconds", "integer between 0 and 3600", options.seconds);
  }
  return this;
}
function _updateFormatOut(formatOut, options) {
  if (!(is$1.object(options) && options.force === false)) {
    this.options.formatOut = formatOut;
  }
  return this;
}
function _setBooleanOption(key, val) {
  if (is$1.bool(val)) {
    this.options[key] = val;
  } else {
    throw is$1.invalidParameterError(key, "boolean", val);
  }
}
function _read() {
  if (!this.options.streamOut) {
    this.options.streamOut = true;
    this._pipeline();
  }
}
function _pipeline(callback) {
  if (typeof callback === "function") {
    if (this._isStreamInput()) {
      this.on("finish", () => {
        this._flattenBufferIn();
        sharp$2.pipeline(this.options, callback);
      });
    } else {
      sharp$2.pipeline(this.options, callback);
    }
    return this;
  } else if (this.options.streamOut) {
    if (this._isStreamInput()) {
      this.once("finish", () => {
        this._flattenBufferIn();
        sharp$2.pipeline(this.options, (err, data, info) => {
          if (err) {
            this.emit("error", err);
          } else {
            this.emit("info", info);
            this.push(data);
          }
          this.push(null);
          this.on("end", () => this.emit("close"));
        });
      });
      if (this.streamInFinished) {
        this.emit("finish");
      }
    } else {
      sharp$2.pipeline(this.options, (err, data, info) => {
        if (err) {
          this.emit("error", err);
        } else {
          this.emit("info", info);
          this.push(data);
        }
        this.push(null);
        this.on("end", () => this.emit("close"));
      });
    }
    return this;
  } else {
    if (this._isStreamInput()) {
      return new Promise((resolve2, reject) => {
        this.once("finish", () => {
          this._flattenBufferIn();
          sharp$2.pipeline(this.options, (err, data, info) => {
            if (err) {
              reject(err);
            } else {
              if (this.options.resolveWithObject) {
                resolve2({ data, info });
              } else {
                resolve2(data);
              }
            }
          });
        });
      });
    } else {
      return new Promise((resolve2, reject) => {
        sharp$2.pipeline(this.options, (err, data, info) => {
          if (err) {
            reject(err);
          } else {
            if (this.options.resolveWithObject) {
              resolve2({ data, info });
            } else {
              resolve2(data);
            }
          }
        });
      });
    }
  }
}
var output = function(Sharp2) {
  Object.assign(Sharp2.prototype, {
    // Public
    toFile,
    toBuffer,
    withMetadata,
    toFormat,
    jpeg,
    jp2,
    png,
    webp,
    tiff,
    avif,
    heif,
    jxl,
    gif,
    raw,
    tile,
    timeout,
    // Private
    _updateFormatOut,
    _setBooleanOption,
    _read,
    _pipeline
  });
};
const fs = fs$4;
const path = path$4;
const events = require$$2$1;
const detectLibc = detectLibc$2;
const is = is$9;
const platformAndArch = platform$1();
const sharp$1 = sharpExports;
const format = sharp$1.format();
format.heif.output.alias = ["avif", "heic"];
format.jpeg.output.alias = ["jpe", "jpg"];
format.tiff.output.alias = ["tif"];
format.jp2k.output.alias = ["j2c", "j2k", "jp2", "jpx"];
const interpolators = {
  /** [Nearest neighbour interpolation](http://en.wikipedia.org/wiki/Nearest-neighbor_interpolation). Suitable for image enlargement only. */
  nearest: "nearest",
  /** [Bilinear interpolation](http://en.wikipedia.org/wiki/Bilinear_interpolation). Faster than bicubic but with less smooth results. */
  bilinear: "bilinear",
  /** [Bicubic interpolation](http://en.wikipedia.org/wiki/Bicubic_interpolation) (the default). */
  bicubic: "bicubic",
  /** [LBB interpolation](https://github.com/libvips/libvips/blob/master/libvips/resample/lbb.cpp#L100). Prevents some "[acutance](http://en.wikipedia.org/wiki/Acutance)" but typically reduces performance by a factor of 2. */
  locallyBoundedBicubic: "lbb",
  /** [Nohalo interpolation](http://eprints.soton.ac.uk/268086/). Prevents acutance but typically reduces performance by a factor of 3. */
  nohalo: "nohalo",
  /** [VSQBS interpolation](https://github.com/libvips/libvips/blob/master/libvips/resample/vsqbs.cpp#L48). Prevents "staircasing" when enlarging. */
  vertexSplitQuadraticBasisSpline: "vsqbs"
};
let versions = {
  vips: sharp$1.libvipsVersion()
};
try {
  versions = commonjsRequire(`../vendor/${versions.vips}/${platformAndArch}/versions.json`);
} catch (_err) {
}
versions.sharp = require$$7.version;
const vendor = {
  current: platformAndArch,
  installed: []
};
try {
  vendor.installed = fs.readdirSync(path.join(__dirname, `../vendor/${versions.vips}`));
} catch (_err) {
}
function cache(options) {
  if (is.bool(options)) {
    if (options) {
      return sharp$1.cache(50, 20, 100);
    } else {
      return sharp$1.cache(0, 0, 0);
    }
  } else if (is.object(options)) {
    return sharp$1.cache(options.memory, options.files, options.items);
  } else {
    return sharp$1.cache();
  }
}
cache(true);
function concurrency(concurrency2) {
  return sharp$1.concurrency(is.integer(concurrency2) ? concurrency2 : null);
}
if (detectLibc.familySync() === detectLibc.GLIBC && !sharp$1._isUsingJemalloc()) {
  sharp$1.concurrency(1);
}
const queue = new events.EventEmitter();
function counters() {
  return sharp$1.counters();
}
function simd(simd2) {
  return sharp$1.simd(is.bool(simd2) ? simd2 : null);
}
simd(true);
function block(options) {
  if (is.object(options)) {
    if (Array.isArray(options.operation) && options.operation.every(is.string)) {
      sharp$1.block(options.operation, true);
    } else {
      throw is.invalidParameterError("operation", "Array<string>", options.operation);
    }
  } else {
    throw is.invalidParameterError("options", "object", options);
  }
}
function unblock(options) {
  if (is.object(options)) {
    if (Array.isArray(options.operation) && options.operation.every(is.string)) {
      sharp$1.block(options.operation, false);
    } else {
      throw is.invalidParameterError("operation", "Array<string>", options.operation);
    }
  } else {
    throw is.invalidParameterError("options", "object", options);
  }
}
var utility = function(Sharp2) {
  Sharp2.cache = cache;
  Sharp2.concurrency = concurrency;
  Sharp2.counters = counters;
  Sharp2.simd = simd;
  Sharp2.format = format;
  Sharp2.interpolators = interpolators;
  Sharp2.versions = versions;
  Sharp2.vendor = vendor;
  Sharp2.queue = queue;
  Sharp2.block = block;
  Sharp2.unblock = unblock;
};
const Sharp = constructor;
input(Sharp);
resize_1(Sharp);
composite_1(Sharp);
operation(Sharp);
colour(Sharp);
channel(Sharp);
output(Sharp);
utility(Sharp);
var lib = Sharp;
const sharp = /* @__PURE__ */ getDefaultExportFromCjs(lib);
const BROWSER_ENV = typeof self !== "undefined";
const WEBWORKER_ENV = BROWSER_ENV && self.constructor.name === "DedicatedWorkerGlobalScope";
let createCanvasFunction;
let ImageDataClass;
let loadImageFunction;
if (BROWSER_ENV) {
  createCanvasFunction = (width, height) => {
    if (!self.OffscreenCanvas) {
      throw new Error("OffscreenCanvas not supported by this browser.");
    }
    return new self.OffscreenCanvas(width, height);
  };
  loadImageFunction = self.createImageBitmap;
  ImageDataClass = self.ImageData;
} else if (sharp) {
  loadImageFunction = async (img) => {
    const metadata2 = await img.metadata();
    const rawChannels = metadata2.channels;
    let { data, info } = await img.rotate().raw().toBuffer({ resolveWithObject: true });
    const newImage = new RawImage(new Uint8ClampedArray(data), info.width, info.height, info.channels);
    if (rawChannels !== void 0 && rawChannels !== info.channels) {
      newImage.convert(rawChannels);
    }
    return newImage;
  };
} else {
  throw new Error("Unable to load image processing library.");
}
const RESAMPLING_MAPPING = {
  0: "nearest",
  1: "lanczos",
  2: "bilinear",
  3: "bicubic",
  4: "box",
  5: "hamming"
};
const CONTENT_TYPE_MAP = /* @__PURE__ */ new Map([
  ["png", "image/png"],
  ["jpg", "image/jpeg"],
  ["jpeg", "image/jpeg"],
  ["gif", "image/gif"]
]);
class RawImage {
  /**
   * Create a new `RawImage` object.
   * @param {Uint8ClampedArray|Uint8Array} data The pixel data.
   * @param {number} width The width of the image.
   * @param {number} height The height of the image.
   * @param {1|2|3|4} channels The number of channels.
   */
  constructor(data, width, height, channels) {
    this.data = data;
    this.width = width;
    this.height = height;
    this.channels = channels;
  }
  /** 
   * Returns the size of the image (width, height).
   * @returns {[number, number]} The size of the image (width, height).
   */
  get size() {
    return [this.width, this.height];
  }
  /**
   * Helper method for reading an image from a variety of input types.
   * @param {RawImage|string|URL} input 
   * @returns The image object.
   * 
   * **Example:** Read image from a URL.
   * ```javascript
   * let image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');
   * // RawImage {
   * //   "data": Uint8ClampedArray [ 25, 25, 25, 19, 19, 19, ... ],
   * //   "width": 800,
   * //   "height": 533,
   * //   "channels": 3
   * // }
   * ```
   */
  static async read(input2) {
    if (input2 instanceof RawImage) {
      return input2;
    } else if (typeof input2 === "string" || input2 instanceof URL) {
      return await this.fromURL(input2);
    } else {
      throw new Error(`Unsupported input type: ${typeof input2}`);
    }
  }
  /**
   * Read an image from a URL or file path.
   * @param {string|URL} url The URL or file path to read the image from.
   * @returns {Promise<RawImage>} The image object.
   */
  static async fromURL(url2) {
    let response = await getFile(url2);
    if (response.status !== 200) {
      throw new Error(`Unable to read image from "${url2}" (${response.status} ${response.statusText})`);
    }
    let blob = await response.blob();
    return this.fromBlob(blob);
  }
  /**
   * Helper method to create a new Image from a blob.
   * @param {Blob} blob The blob to read the image from.
   * @returns {Promise<RawImage>} The image object.
   */
  static async fromBlob(blob) {
    if (BROWSER_ENV) {
      let img = await loadImageFunction(blob);
      const ctx = createCanvasFunction(img.width, img.height).getContext("2d");
      ctx.drawImage(img, 0, 0);
      return new this(ctx.getImageData(0, 0, img.width, img.height).data, img.width, img.height, 4);
    } else {
      let img = sharp(await blob.arrayBuffer());
      return await loadImageFunction(img);
    }
  }
  /**
   * Helper method to create a new Image from a tensor
   * @param {Tensor} tensor 
   */
  static fromTensor(tensor, channel_format = "CHW") {
    if (tensor.dims.length !== 3) {
      throw new Error(`Tensor should have 3 dimensions, but has ${tensor.dims.length} dimensions.`);
    }
    if (channel_format === "CHW") {
      tensor = tensor.transpose(1, 2, 0);
    } else if (channel_format === "HWC") ;
    else {
      throw new Error(`Unsupported channel format: ${channel_format}`);
    }
    if (!(tensor.data instanceof Uint8ClampedArray || tensor.data instanceof Uint8Array)) {
      throw new Error(`Unsupported tensor type: ${tensor.type}`);
    }
    switch (tensor.dims[2]) {
      case 1:
      case 2:
      case 3:
      case 4:
        return new RawImage(tensor.data, tensor.dims[1], tensor.dims[0], tensor.dims[2]);
      default:
        throw new Error(`Unsupported number of channels: ${tensor.dims[2]}`);
    }
  }
  /**
   * Convert the image to grayscale format.
   * @returns {RawImage} `this` to support chaining.
   */
  grayscale() {
    if (this.channels === 1) {
      return this;
    }
    let newData = new Uint8ClampedArray(this.width * this.height * 1);
    switch (this.channels) {
      case 3:
      case 4:
        for (let i2 = 0, offset = 0; i2 < this.data.length; i2 += this.channels) {
          const red = this.data[i2];
          const green = this.data[i2 + 1];
          const blue = this.data[i2 + 2];
          newData[offset++] = Math.round(0.2989 * red + 0.587 * green + 0.114 * blue);
        }
        break;
      default:
        throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
    }
    return this._update(newData, this.width, this.height, 1);
  }
  /**
   * Convert the image to RGB format.
   * @returns {RawImage} `this` to support chaining.
   */
  rgb() {
    if (this.channels === 3) {
      return this;
    }
    let newData = new Uint8ClampedArray(this.width * this.height * 3);
    switch (this.channels) {
      case 1:
        for (let i2 = 0, offset = 0; i2 < this.data.length; ++i2) {
          newData[offset++] = this.data[i2];
          newData[offset++] = this.data[i2];
          newData[offset++] = this.data[i2];
        }
        break;
      case 4:
        for (let i2 = 0, offset = 0; i2 < this.data.length; i2 += 4) {
          newData[offset++] = this.data[i2];
          newData[offset++] = this.data[i2 + 1];
          newData[offset++] = this.data[i2 + 2];
        }
        break;
      default:
        throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
    }
    return this._update(newData, this.width, this.height, 3);
  }
  /**
   * Convert the image to RGBA format.
   * @returns {RawImage} `this` to support chaining.
   */
  rgba() {
    if (this.channels === 4) {
      return this;
    }
    let newData = new Uint8ClampedArray(this.width * this.height * 4);
    switch (this.channels) {
      case 1:
        for (let i2 = 0, offset = 0; i2 < this.data.length; ++i2) {
          newData[offset++] = this.data[i2];
          newData[offset++] = this.data[i2];
          newData[offset++] = this.data[i2];
          newData[offset++] = 255;
        }
        break;
      case 3:
        for (let i2 = 0, offset = 0; i2 < this.data.length; i2 += 3) {
          newData[offset++] = this.data[i2];
          newData[offset++] = this.data[i2 + 1];
          newData[offset++] = this.data[i2 + 2];
          newData[offset++] = 255;
        }
        break;
      default:
        throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
    }
    return this._update(newData, this.width, this.height, 4);
  }
  /**
   * Resize the image to the given dimensions. This method uses the canvas API to perform the resizing.
   * @param {number} width The width of the new image.
   * @param {number} height The height of the new image.
   * @param {Object} options Additional options for resizing.
   * @param {0|1|2|3|4|5|string} [options.resample] The resampling method to use.
   * @returns {Promise<RawImage>} `this` to support chaining.
   */
  async resize(width, height, {
    resample = 2
  } = {}) {
    let resampleMethod = RESAMPLING_MAPPING[resample] ?? resample;
    if (BROWSER_ENV) {
      let numChannels = this.channels;
      let canvas = this.toCanvas();
      const ctx = createCanvasFunction(width, height).getContext("2d");
      ctx.drawImage(canvas, 0, 0, width, height);
      let resizedImage = new RawImage(ctx.getImageData(0, 0, width, height).data, width, height, 4);
      return resizedImage.convert(numChannels);
    } else {
      let img = this.toSharp();
      switch (resampleMethod) {
        case "box":
        case "hamming":
          if (resampleMethod === "box" || resampleMethod === "hamming") {
            console.warn(`Resampling method ${resampleMethod} is not yet supported. Using bilinear instead.`);
            resampleMethod = "bilinear";
          }
        case "nearest":
        case "bilinear":
        case "bicubic":
          img = img.affine([width / this.width, 0, 0, height / this.height], {
            interpolator: resampleMethod
          });
          break;
        case "lanczos":
          img = img.resize({
            width,
            height,
            fit: "fill",
            kernel: "lanczos3"
            // PIL Lanczos uses a kernel size of 3 
          });
          break;
        default:
          throw new Error(`Resampling method ${resampleMethod} is not supported.`);
      }
      return await loadImageFunction(img);
    }
  }
  async pad([left, right, top, bottom]) {
    left = Math.max(left, 0);
    right = Math.max(right, 0);
    top = Math.max(top, 0);
    bottom = Math.max(bottom, 0);
    if (left === 0 && right === 0 && top === 0 && bottom === 0) {
      return this;
    }
    if (BROWSER_ENV) {
      let numChannels = this.channels;
      let canvas = this.toCanvas();
      let newWidth = this.width + left + right;
      let newHeight = this.height + top + bottom;
      const ctx = createCanvasFunction(newWidth, newHeight).getContext("2d");
      ctx.drawImage(
        canvas,
        0,
        0,
        this.width,
        this.height,
        left,
        top,
        newWidth,
        newHeight
      );
      let paddedImage = new RawImage(
        ctx.getImageData(0, 0, newWidth, newHeight).data,
        newWidth,
        newHeight,
        4
      );
      return paddedImage.convert(numChannels);
    } else {
      let img = this.toSharp().extend({ left, right, top, bottom });
      return await loadImageFunction(img);
    }
  }
  async crop([x_min, y_min, x_max, y_max]) {
    x_min = Math.max(x_min, 0);
    y_min = Math.max(y_min, 0);
    x_max = Math.min(x_max, this.width - 1);
    y_max = Math.min(y_max, this.height - 1);
    if (x_min === 0 && y_min === 0 && x_max === this.width - 1 && y_max === this.height - 1) {
      return this;
    }
    const crop_width = x_max - x_min + 1;
    const crop_height = y_max - y_min + 1;
    if (BROWSER_ENV) {
      const numChannels = this.channels;
      const canvas = this.toCanvas();
      const ctx = createCanvasFunction(crop_width, crop_height).getContext("2d");
      ctx.drawImage(
        canvas,
        x_min,
        y_min,
        crop_width,
        crop_height,
        0,
        0,
        crop_width,
        crop_height
      );
      const resizedImage = new RawImage(ctx.getImageData(0, 0, crop_width, crop_height).data, crop_width, crop_height, 4);
      return resizedImage.convert(numChannels);
    } else {
      const img = this.toSharp().extract({
        left: x_min,
        top: y_min,
        width: crop_width,
        height: crop_height
      });
      return await loadImageFunction(img);
    }
  }
  async center_crop(crop_width, crop_height) {
    if (this.width === crop_width && this.height === crop_height) {
      return this;
    }
    let width_offset = (this.width - crop_width) / 2;
    let height_offset = (this.height - crop_height) / 2;
    if (BROWSER_ENV) {
      let numChannels = this.channels;
      let canvas = this.toCanvas();
      const ctx = createCanvasFunction(crop_width, crop_height).getContext("2d");
      let sourceX = 0;
      let sourceY = 0;
      let destX = 0;
      let destY = 0;
      if (width_offset >= 0) {
        sourceX = width_offset;
      } else {
        destX = -width_offset;
      }
      if (height_offset >= 0) {
        sourceY = height_offset;
      } else {
        destY = -height_offset;
      }
      ctx.drawImage(
        canvas,
        sourceX,
        sourceY,
        crop_width,
        crop_height,
        destX,
        destY,
        crop_width,
        crop_height
      );
      let resizedImage = new RawImage(ctx.getImageData(0, 0, crop_width, crop_height).data, crop_width, crop_height, 4);
      return resizedImage.convert(numChannels);
    } else {
      let img = this.toSharp();
      if (width_offset >= 0 && height_offset >= 0) {
        img = img.extract({
          left: Math.floor(width_offset),
          top: Math.floor(height_offset),
          width: crop_width,
          height: crop_height
        });
      } else if (width_offset <= 0 && height_offset <= 0) {
        let top = Math.floor(-height_offset);
        let left = Math.floor(-width_offset);
        img = img.extend({
          top,
          left,
          // Ensures the resulting image has the desired dimensions
          right: crop_width - this.width - left,
          bottom: crop_height - this.height - top
        });
      } else {
        let y_padding = [0, 0];
        let y_extract = 0;
        if (height_offset < 0) {
          y_padding[0] = Math.floor(-height_offset);
          y_padding[1] = crop_height - this.height - y_padding[0];
        } else {
          y_extract = Math.floor(height_offset);
        }
        let x_padding = [0, 0];
        let x_extract = 0;
        if (width_offset < 0) {
          x_padding[0] = Math.floor(-width_offset);
          x_padding[1] = crop_width - this.width - x_padding[0];
        } else {
          x_extract = Math.floor(width_offset);
        }
        img = img.extend({
          top: y_padding[0],
          bottom: y_padding[1],
          left: x_padding[0],
          right: x_padding[1]
        }).extract({
          left: x_extract,
          top: y_extract,
          width: crop_width,
          height: crop_height
        });
      }
      return await loadImageFunction(img);
    }
  }
  async toBlob(type2 = "image/png", quality = 1) {
    if (!BROWSER_ENV) {
      throw new Error("toBlob() is only supported in browser environments.");
    }
    const canvas = this.toCanvas();
    return await canvas.convertToBlob({ type: type2, quality });
  }
  toTensor(channel_format = "CHW") {
    let tensor = new Tensor(
      "uint8",
      new Uint8Array(this.data),
      [this.height, this.width, this.channels]
    );
    if (channel_format === "HWC") ;
    else if (channel_format === "CHW") {
      tensor = tensor.permute(2, 0, 1);
    } else {
      throw new Error(`Unsupported channel format: ${channel_format}`);
    }
    return tensor;
  }
  toCanvas() {
    if (!BROWSER_ENV) {
      throw new Error("toCanvas() is only supported in browser environments.");
    }
    let cloned = this.clone().rgba();
    let clonedCanvas = createCanvasFunction(cloned.width, cloned.height);
    let data = new ImageDataClass(cloned.data, cloned.width, cloned.height);
    clonedCanvas.getContext("2d").putImageData(data, 0, 0);
    return clonedCanvas;
  }
  /**
   * Helper method to update the image data.
   * @param {Uint8ClampedArray} data The new image data.
   * @param {number} width The new width of the image.
   * @param {number} height The new height of the image.
   * @param {1|2|3|4|null} [channels] The new number of channels of the image.
   * @private
   */
  _update(data, width, height, channels = null) {
    this.data = data;
    this.width = width;
    this.height = height;
    if (channels !== null) {
      this.channels = channels;
    }
    return this;
  }
  /**
   * Clone the image
   * @returns {RawImage} The cloned image
   */
  clone() {
    return new RawImage(this.data.slice(), this.width, this.height, this.channels);
  }
  /**
   * Helper method for converting image to have a certain number of channels
   * @param {number} numChannels The number of channels. Must be 1, 3, or 4.
   * @returns {RawImage} `this` to support chaining.
   */
  convert(numChannels) {
    if (this.channels === numChannels) return this;
    switch (numChannels) {
      case 1:
        this.grayscale();
        break;
      case 3:
        this.rgb();
        break;
      case 4:
        this.rgba();
        break;
      default:
        throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
    }
    return this;
  }
  /**
   * Save the image to the given path.
   * @param {string} path The path to save the image to.
   */
  async save(path2) {
    if (BROWSER_ENV) {
      if (WEBWORKER_ENV) {
        throw new Error("Unable to save an image from a Web Worker.");
      }
      const extension = path2.split(".").pop().toLowerCase();
      const mime = CONTENT_TYPE_MAP.get(extension) ?? "image/png";
      const blob = await this.toBlob(mime);
      const dataURL = URL.createObjectURL(blob);
      const downloadLink = document.createElement("a");
      downloadLink.href = dataURL;
      downloadLink.download = path2;
      downloadLink.click();
      downloadLink.remove();
    } else if (!env$3.useFS) {
      throw new Error("Unable to save the image because filesystem is disabled in this environment.");
    } else {
      const img = this.toSharp();
      return await img.toFile(path2);
    }
  }
  toSharp() {
    if (BROWSER_ENV) {
      throw new Error("toSharp() is only supported in server-side environments.");
    }
    return sharp(this.data, {
      raw: {
        width: this.width,
        height: this.height,
        channels: this.channels
      }
    });
  }
}
async function read_audio(url2, sampling_rate) {
  if (typeof AudioContext === "undefined") {
    throw Error(
      "Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing."
    );
  }
  const response = await (await getFile(url2)).arrayBuffer();
  const audioCTX = new AudioContext({ sampleRate: sampling_rate });
  if (typeof sampling_rate === "undefined") {
    console.warn(`No sampling rate provided, using default of ${audioCTX.sampleRate}Hz.`);
  }
  const decoded = await audioCTX.decodeAudioData(response);
  let audio;
  if (decoded.numberOfChannels === 2) {
    const SCALING_FACTOR = Math.sqrt(2);
    const left = decoded.getChannelData(0);
    const right = decoded.getChannelData(1);
    audio = new Float32Array(left.length);
    for (let i2 = 0; i2 < decoded.length; ++i2) {
      audio[i2] = SCALING_FACTOR * (left[i2] + right[i2]) / 2;
    }
  } else {
    audio = decoded.getChannelData(0);
  }
  return audio;
}
function hanning(M) {
  if (M < 1) {
    return new Float64Array();
  }
  if (M === 1) {
    return new Float64Array([1]);
  }
  const denom = M - 1;
  const factor = Math.PI / denom;
  const cos_vals = new Float64Array(M);
  for (let i2 = 0; i2 < M; ++i2) {
    const n = 2 * i2 - denom;
    cos_vals[i2] = 0.5 + 0.5 * Math.cos(factor * n);
  }
  return cos_vals;
}
const HERTZ_TO_MEL_MAPPING = {
  "htk": (freq) => 2595 * Math.log10(1 + freq / 700),
  "kaldi": (freq) => 1127 * Math.log(1 + freq / 700),
  "slaney": (freq, min_log_hertz = 1e3, min_log_mel = 15, logstep = 27 / Math.log(6.4)) => freq >= min_log_hertz ? min_log_mel + Math.log(freq / min_log_hertz) * logstep : 3 * freq / 200
};
function hertz_to_mel(freq, mel_scale = "htk") {
  const fn2 = HERTZ_TO_MEL_MAPPING[mel_scale];
  if (!fn2) {
    throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');
  }
  return typeof freq === "number" ? fn2(freq) : freq.map((x) => fn2(x));
}
const MEL_TO_HERTZ_MAPPING = {
  "htk": (mels) => 700 * (10 ** (mels / 2595) - 1),
  "kaldi": (mels) => 700 * (Math.exp(mels / 1127) - 1),
  "slaney": (mels, min_log_hertz = 1e3, min_log_mel = 15, logstep = Math.log(6.4) / 27) => mels >= min_log_mel ? min_log_hertz * Math.exp(logstep * (mels - min_log_mel)) : 200 * mels / 3
};
function mel_to_hertz(mels, mel_scale = "htk") {
  const fn2 = MEL_TO_HERTZ_MAPPING[mel_scale];
  if (!fn2) {
    throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');
  }
  return typeof mels === "number" ? fn2(mels) : mels.map((x) => fn2(x));
}
function _create_triangular_filter_bank(fft_freqs, filter_freqs) {
  const filter_diff = Float64Array.from(
    { length: filter_freqs.length - 1 },
    (_, i2) => filter_freqs[i2 + 1] - filter_freqs[i2]
  );
  const slopes = Array.from({
    length: fft_freqs.length
  }, () => new Array(filter_freqs.length));
  for (let j = 0; j < fft_freqs.length; ++j) {
    const slope = slopes[j];
    for (let i2 = 0; i2 < filter_freqs.length; ++i2) {
      slope[i2] = filter_freqs[i2] - fft_freqs[j];
    }
  }
  const numFreqs = filter_freqs.length - 2;
  const ret = Array.from({ length: numFreqs }, () => new Array(fft_freqs.length));
  for (let j = 0; j < fft_freqs.length; ++j) {
    const slope = slopes[j];
    for (let i2 = 0; i2 < numFreqs; ++i2) {
      const down = -slope[i2] / filter_diff[i2];
      const up = slope[i2 + 2] / filter_diff[i2 + 1];
      ret[i2][j] = Math.max(0, Math.min(down, up));
    }
  }
  return ret;
}
function linspace(start, end, num) {
  const step = (end - start) / (num - 1);
  return Float64Array.from({ length: num }, (_, i2) => start + step * i2);
}
function mel_filter_bank(num_frequency_bins, num_mel_filters, min_frequency, max_frequency, sampling_rate, norm = null, mel_scale = "htk", triangularize_in_mel_space = false) {
  if (norm !== null && norm !== "slaney") {
    throw new Error('norm must be one of null or "slaney"');
  }
  const mel_min = hertz_to_mel(min_frequency, mel_scale);
  const mel_max = hertz_to_mel(max_frequency, mel_scale);
  const mel_freqs = linspace(mel_min, mel_max, num_mel_filters + 2);
  let filter_freqs = mel_to_hertz(mel_freqs, mel_scale);
  let fft_freqs;
  if (triangularize_in_mel_space) {
    const fft_bin_width = sampling_rate / (num_frequency_bins * 2);
    fft_freqs = hertz_to_mel(Float64Array.from({ length: num_frequency_bins }, (_, i2) => i2 * fft_bin_width), mel_scale);
    filter_freqs = mel_freqs;
  } else {
    fft_freqs = linspace(0, Math.floor(sampling_rate / 2), num_frequency_bins);
  }
  const mel_filters = _create_triangular_filter_bank(fft_freqs, filter_freqs);
  if (norm !== null && norm === "slaney") {
    for (let i2 = 0; i2 < num_mel_filters; ++i2) {
      const filter = mel_filters[i2];
      const enorm = 2 / (filter_freqs[i2 + 2] - filter_freqs[i2]);
      for (let j = 0; j < num_frequency_bins; ++j) {
        filter[j] *= enorm;
      }
    }
  }
  return mel_filters;
}
function padReflect(array, left, right) {
  const padded = new array.constructor(array.length + left + right);
  const w = array.length - 1;
  for (let i2 = 0; i2 < array.length; ++i2) {
    padded[left + i2] = array[i2];
  }
  for (let i2 = 1; i2 <= left; ++i2) {
    padded[left - i2] = array[calculateReflectOffset(i2, w)];
  }
  for (let i2 = 1; i2 <= right; ++i2) {
    padded[w + left + i2] = array[calculateReflectOffset(w - i2, w)];
  }
  return padded;
}
function _db_conversion_helper(spectrogram2, factor, reference, min_value, db_range) {
  if (reference <= 0) {
    throw new Error("reference must be greater than zero");
  }
  if (min_value <= 0) {
    throw new Error("min_value must be greater than zero");
  }
  reference = Math.max(min_value, reference);
  const logReference = Math.log10(reference);
  for (let i2 = 0; i2 < spectrogram2.length; ++i2) {
    spectrogram2[i2] = factor * Math.log10(Math.max(min_value, spectrogram2[i2]) - logReference);
  }
  if (db_range !== null) {
    if (db_range <= 0) {
      throw new Error("db_range must be greater than zero");
    }
    const maxValue = max(spectrogram2)[0] - db_range;
    for (let i2 = 0; i2 < spectrogram2.length; ++i2) {
      spectrogram2[i2] = Math.max(spectrogram2[i2], maxValue);
    }
  }
  return spectrogram2;
}
function amplitude_to_db(spectrogram2, reference = 1, min_value = 1e-5, db_range = null) {
  return _db_conversion_helper(spectrogram2, 20, reference, min_value, db_range);
}
function power_to_db(spectrogram2, reference = 1, min_value = 1e-10, db_range = null) {
  return _db_conversion_helper(spectrogram2, 10, reference, min_value, db_range);
}
function spectrogram(waveform, window2, frame_length, hop_length, {
  fft_length = null,
  power = 1,
  center = true,
  pad_mode = "reflect",
  onesided = true,
  preemphasis = null,
  mel_filters = null,
  mel_floor = 1e-10,
  log_mel = null,
  reference = 1,
  min_value = 1e-10,
  db_range = null,
  remove_dc_offset = null,
  // Custom parameters for efficiency reasons
  max_num_frames = null,
  do_pad = true,
  transpose = false
} = {}) {
  const window_length = window2.length;
  if (fft_length === null) {
    fft_length = frame_length;
  }
  if (frame_length > fft_length) {
    throw Error(`frame_length (${frame_length}) may not be larger than fft_length (${fft_length})`);
  }
  if (window_length !== frame_length) {
    throw new Error(`Length of the window (${window_length}) must equal frame_length (${frame_length})`);
  }
  if (hop_length <= 0) {
    throw new Error("hop_length must be greater than zero");
  }
  if (power === null && mel_filters !== null) {
    throw new Error(
      "You have provided `mel_filters` but `power` is `None`. Mel spectrogram computation is not yet supported for complex-valued spectrogram. Specify `power` to fix this issue."
    );
  }
  if (center) {
    if (pad_mode !== "reflect") {
      throw new Error(`pad_mode="${pad_mode}" not implemented yet.`);
    }
    const half_window = Math.floor((fft_length - 1) / 2) + 1;
    waveform = padReflect(waveform, half_window, half_window);
  }
  const num_frames = Math.floor(1 + Math.floor((waveform.length - frame_length) / hop_length));
  const num_frequency_bins = onesided ? Math.floor(fft_length / 2) + 1 : fft_length;
  let d1 = num_frames;
  let d1Max = num_frames;
  if (max_num_frames !== null) {
    if (max_num_frames > num_frames) {
      if (do_pad) {
        d1Max = max_num_frames;
      }
    } else {
      d1Max = d1 = max_num_frames;
    }
  }
  const fft = new FFT(fft_length);
  const inputBuffer = new Float64Array(fft_length);
  const outputBuffer = new Float64Array(fft.outputBufferSize);
  const magnitudes = new Array(d1);
  for (let i2 = 0; i2 < d1; ++i2) {
    const offset = i2 * hop_length;
    for (let j = 0; j < frame_length; ++j) {
      inputBuffer[j] = waveform[offset + j];
    }
    if (remove_dc_offset) {
      let sum = 0;
      for (let j = 0; j < frame_length; ++j) {
        sum += inputBuffer[j];
      }
      const mean2 = sum / frame_length;
      for (let j = 0; j < frame_length; ++j) {
        inputBuffer[j] -= mean2;
      }
    }
    if (preemphasis !== null) {
      for (let j = frame_length - 1; j >= 1; --j) {
        inputBuffer[j] -= preemphasis * inputBuffer[j - 1];
      }
      inputBuffer[0] *= 1 - preemphasis;
    }
    for (let j = 0; j < window2.length; ++j) {
      inputBuffer[j] *= window2[j];
    }
    fft.realTransform(outputBuffer, inputBuffer);
    const row = new Array(num_frequency_bins);
    for (let j = 0; j < row.length; ++j) {
      const j2 = j << 1;
      row[j] = outputBuffer[j2] ** 2 + outputBuffer[j2 + 1] ** 2;
    }
    magnitudes[i2] = row;
  }
  if (power !== null && power !== 2) {
    const pow = 2 / power;
    for (let i2 = 0; i2 < magnitudes.length; ++i2) {
      const magnitude = magnitudes[i2];
      for (let j = 0; j < magnitude.length; ++j) {
        magnitude[j] **= pow;
      }
    }
  }
  const num_mel_filters = mel_filters.length;
  const mel_spec = new Float32Array(num_mel_filters * d1Max);
  const dims = transpose ? [d1Max, num_mel_filters] : [num_mel_filters, d1Max];
  for (let i2 = 0; i2 < num_mel_filters; ++i2) {
    const filter = mel_filters[i2];
    for (let j = 0; j < d1; ++j) {
      const magnitude = magnitudes[j];
      let sum = 0;
      for (let k = 0; k < num_frequency_bins; ++k) {
        sum += filter[k] * magnitude[k];
      }
      mel_spec[transpose ? j * num_mel_filters + i2 : i2 * d1 + j] = Math.max(mel_floor, sum);
    }
  }
  if (power !== null && log_mel !== null) {
    const o = Math.min(mel_spec.length, d1 * num_mel_filters);
    switch (log_mel) {
      case "log":
        for (let i2 = 0; i2 < o; ++i2) {
          mel_spec[i2] = Math.log(mel_spec[i2]);
        }
        break;
      case "log10":
        for (let i2 = 0; i2 < o; ++i2) {
          mel_spec[i2] = Math.log10(mel_spec[i2]);
        }
        break;
      case "dB":
        if (power === 1) {
          amplitude_to_db(mel_spec, reference, min_value, db_range);
        } else if (power === 2) {
          power_to_db(mel_spec, reference, min_value, db_range);
        } else {
          throw new Error(`Cannot use log_mel option '${log_mel}' with power ${power}`);
        }
        break;
      default:
        throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${log_mel}'`);
    }
  }
  return { data: mel_spec, dims };
}
function window_function(window_length, name2, {
  periodic = true,
  frame_length = null,
  center = true
} = {}) {
  const length = periodic ? window_length + 1 : window_length;
  let window2;
  switch (name2) {
    case "boxcar":
      window2 = new Float64Array(length).fill(1);
      break;
    case "hann":
    case "hann_window":
      window2 = hanning(length);
      break;
    case "povey":
      window2 = hanning(length).map((x) => Math.pow(x, 0.85));
      break;
    default:
      throw new Error(`Unknown window type ${name2}.`);
  }
  if (periodic) {
    window2 = window2.subarray(0, window_length);
  }
  if (frame_length === null) {
    return window2;
  }
  if (window_length > frame_length) {
    throw new Error(`Length of the window (${window_length}) may not be larger than frame_length (${frame_length})`);
  }
  return window2;
}
function center_to_corners_format([centerX, centerY, width, height]) {
  return [
    centerX - width / 2,
    centerY - height / 2,
    centerX + width / 2,
    centerY + height / 2
  ];
}
function post_process_object_detection(outputs, threshold2 = 0.5, target_sizes = null, is_zero_shot = false) {
  const out_logits = outputs.logits;
  const out_bbox = outputs.pred_boxes;
  const [batch_size, num_boxes, num_classes] = out_logits.dims;
  if (target_sizes !== null && target_sizes.length !== batch_size) {
    throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
  }
  let toReturn = [];
  for (let i2 = 0; i2 < batch_size; ++i2) {
    let target_size = target_sizes !== null ? target_sizes[i2] : null;
    let info = {
      boxes: [],
      classes: [],
      scores: []
    };
    let logits = out_logits[i2];
    let bbox = out_bbox[i2];
    for (let j = 0; j < num_boxes; ++j) {
      let logit = logits[j];
      let indices = [];
      let probs;
      if (is_zero_shot) {
        probs = logit.sigmoid().data;
        for (let k = 0; k < probs.length; ++k) {
          if (probs[k] > threshold2) {
            indices.push(k);
          }
        }
      } else {
        let maxIndex = max(logit.data)[1];
        if (maxIndex === num_classes - 1) {
          continue;
        }
        indices.push(maxIndex);
        probs = softmax(logit.data);
      }
      for (const index2 of indices) {
        let box = bbox[j].data;
        box = center_to_corners_format(box);
        if (target_size !== null) {
          box = box.map((x, i3) => x * target_size[(i3 + 1) % 2]);
        }
        info.boxes.push(box);
        info.classes.push(index2);
        info.scores.push(probs[index2]);
      }
    }
    toReturn.push(info);
  }
  return toReturn;
}
function validate_audio_inputs(audio, feature_extractor) {
  var _a2;
  if (!(audio instanceof Float32Array || audio instanceof Float64Array)) {
    throw new Error(
      `${feature_extractor} expects input to be a Float32Array or a Float64Array, but got ${((_a2 = audio == null ? void 0 : audio.constructor) == null ? void 0 : _a2.name) ?? typeof audio} instead. If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`
    );
  }
}
function constraint_to_multiple_of(val, multiple, minVal = 0, maxVal = null) {
  const a = val / multiple;
  let x = bankers_round(a) * multiple;
  if (maxVal !== null && x > maxVal) {
    x = Math.floor(a) * multiple;
  }
  if (x < minVal) {
    x = Math.ceil(a) * multiple;
  }
  return x;
}
function enforce_size_divisibility([width, height], divisor) {
  return [
    Math.max(Math.floor(width / divisor), 1) * divisor,
    Math.max(Math.floor(height / divisor), 1) * divisor
  ];
}
class FeatureExtractor extends Callable {
  /**
   * Constructs a new FeatureExtractor instance.
   *
   * @param {Object} config The configuration for the feature extractor.
   */
  constructor(config2) {
    super();
    this.config = config2;
  }
}
class ImageFeatureExtractor extends FeatureExtractor {
  /**
   * Constructs a new ImageFeatureExtractor instance.
   *
   * @param {Object} config The configuration for the feature extractor.
   * @param {number[]} config.image_mean The mean values for image normalization.
   * @param {number[]} config.image_std The standard deviation values for image normalization.
   * @param {boolean} config.do_rescale Whether to rescale the image pixel values to the [0,1] range.
   * @param {number} config.rescale_factor The factor to use for rescaling the image pixel values.
   * @param {boolean} config.do_normalize Whether to normalize the image pixel values.
   * @param {boolean} config.do_resize Whether to resize the image.
   * @param {number} config.resample What method to use for resampling.
   * @param {number|Object} config.size The size to resize the image to.
   * @param {boolean} [config.do_flip_channel_order=false] Whether to flip the color channels from RGB to BGR.
   * Can be overridden by the `do_flip_channel_order` parameter in the `preprocess` method.
   */
  constructor(config2) {
    super(config2);
    this.image_mean = this.config.image_mean ?? this.config.mean;
    this.image_std = this.config.image_std ?? this.config.std;
    this.resample = this.config.resample ?? 2;
    this.do_rescale = this.config.do_rescale ?? true;
    this.rescale_factor = this.config.rescale_factor ?? 1 / 255;
    this.do_normalize = this.config.do_normalize;
    this.do_resize = this.config.do_resize;
    this.do_thumbnail = this.config.do_thumbnail;
    this.size = this.config.size;
    this.size_divisibility = this.config.size_divisibility ?? this.config.size_divisor;
    this.do_center_crop = this.config.do_center_crop;
    this.crop_size = this.config.crop_size;
    this.do_convert_rgb = this.config.do_convert_rgb ?? true;
    this.do_crop_margin = this.config.do_crop_margin;
    this.pad_size = this.config.pad_size;
    this.do_pad = this.config.do_pad;
    if (this.do_pad && !this.pad_size && this.size && this.size.width !== void 0 && this.size.height !== void 0) {
      this.pad_size = this.size;
    }
    this.do_flip_channel_order = this.config.do_flip_channel_order ?? false;
  }
  /**
   * Resize the image to make a thumbnail. The image is resized so that no dimension is larger than any
   * corresponding dimension of the specified size.
   * @param {RawImage} image The image to be resized.
   * @param {{height:number, width:number}} size The size `{"height": h, "width": w}` to resize the image to.
   * @param {string | 0 | 1 | 2 | 3 | 4 | 5} [resample=2] The resampling filter to use.
   * @returns {Promise<RawImage>} The resized image.
   */
  async thumbnail(image, size, resample = 2) {
    const input_height = image.height;
    const input_width = image.width;
    const output_height = size.height;
    const output_width = size.width;
    let height = Math.min(input_height, output_height);
    let width = Math.min(input_width, output_width);
    if (height === input_height && width === input_width) {
      return image;
    }
    if (input_height > input_width) {
      width = Math.floor(input_width * height / input_height);
    } else if (input_width > input_height) {
      height = Math.floor(input_height * width / input_width);
    }
    return await image.resize(width, height, { resample });
  }
  /**
   * Crops the margin of the image. Gray pixels are considered margin (i.e., pixels with a value below the threshold).
   * @param {RawImage} image The image to be cropped.
   * @param {number} gray_threshold Value below which pixels are considered to be gray.
   * @returns {Promise<RawImage>} The cropped image.
   */
  async crop_margin(image, gray_threshold = 200) {
    const gray_image = image.clone().grayscale();
    const minValue = min(gray_image.data)[0];
    const maxValue = max(gray_image.data)[0];
    const diff2 = maxValue - minValue;
    if (diff2 === 0) {
      return image;
    }
    const threshold2 = gray_threshold / 255;
    let x_min = gray_image.width, y_min = gray_image.height, x_max = 0, y_max = 0;
    for (let j = 0; j < gray_image.height; ++j) {
      const row = j * gray_image.width;
      for (let i2 = 0; i2 < gray_image.width; ++i2) {
        if ((gray_image.data[row + i2] - minValue) / diff2 < threshold2) {
          x_min = Math.min(x_min, i2);
          y_min = Math.min(y_min, j);
          x_max = Math.max(x_max, i2);
          y_max = Math.max(y_max, j);
        }
      }
    }
    image = await image.crop([x_min, y_min, x_max, y_max]);
    return image;
  }
  /**
   * Pad the image by a certain amount.
   * @param {Float32Array} pixelData The pixel data to pad.
   * @param {number[]} imgDims The dimensions of the image (height, width, channels).
   * @param {{width:number; height:number}|number} padSize The dimensions of the padded image.
   * @param {Object} options The options for padding.
   * @param {'constant'|'symmetric'} [options.mode='constant'] The type of padding to add.
   * @param {boolean} [options.center=false] Whether to center the image.
   * @param {number} [options.constant_values=0] The constant value to use for padding.
   * @returns {[Float32Array, number[]]} The padded pixel data and image dimensions.
   */
  pad_image(pixelData, imgDims, padSize, {
    mode = "constant",
    center = false,
    constant_values = 0
  } = {}) {
    const [imageHeight, imageWidth, imageChannels] = imgDims;
    let paddedImageWidth, paddedImageHeight;
    if (typeof padSize === "number") {
      paddedImageWidth = padSize;
      paddedImageHeight = padSize;
    } else {
      paddedImageWidth = padSize.width;
      paddedImageHeight = padSize.height;
    }
    if (paddedImageWidth !== imageWidth || paddedImageHeight !== imageHeight) {
      const paddedPixelData = new Float32Array(paddedImageWidth * paddedImageHeight * imageChannels);
      if (Array.isArray(constant_values)) {
        for (let i2 = 0; i2 < paddedPixelData.length; ++i2) {
          paddedPixelData[i2] = constant_values[i2 % imageChannels];
        }
      } else if (constant_values !== 0) {
        paddedPixelData.fill(constant_values);
      }
      const [left, top] = center ? [Math.floor((paddedImageWidth - imageWidth) / 2), Math.floor((paddedImageHeight - imageHeight) / 2)] : [0, 0];
      for (let i2 = 0; i2 < imageHeight; ++i2) {
        const a = (i2 + top) * paddedImageWidth;
        const b = i2 * imageWidth;
        for (let j = 0; j < imageWidth; ++j) {
          const c = (a + j + left) * imageChannels;
          const d = (b + j) * imageChannels;
          for (let k = 0; k < imageChannels; ++k) {
            paddedPixelData[c + k] = pixelData[d + k];
          }
        }
      }
      if (mode === "symmetric") {
        if (center) {
          throw new Error("`center` padding is not supported when `mode` is set to `symmetric`.");
        }
        const h1 = imageHeight - 1;
        const w1 = imageWidth - 1;
        for (let i2 = 0; i2 < paddedImageHeight; ++i2) {
          const a = i2 * paddedImageWidth;
          const b = calculateReflectOffset(i2, h1) * imageWidth;
          for (let j = 0; j < paddedImageWidth; ++j) {
            if (i2 < imageHeight && j < imageWidth) continue;
            const c = (a + j) * imageChannels;
            const d = (b + calculateReflectOffset(j, w1)) * imageChannels;
            for (let k = 0; k < imageChannels; ++k) {
              paddedPixelData[c + k] = pixelData[d + k];
            }
          }
        }
      }
      pixelData = paddedPixelData;
      imgDims = [paddedImageHeight, paddedImageWidth, imageChannels];
    }
    return [pixelData, imgDims];
  }
  /**
   * Rescale the image' pixel values by `this.rescale_factor`.
   * @param {Float32Array} pixelData The pixel data to rescale.
   * @returns {void}
   */
  rescale(pixelData) {
    for (let i2 = 0; i2 < pixelData.length; ++i2) {
      pixelData[i2] = this.rescale_factor * pixelData[i2];
    }
  }
  /**
   * Find the target (width, height) dimension of the output image after
   * resizing given the input image and the desired size.
   * @param {RawImage} image The image to resize.
   * @param {any} size The size to use for resizing the image. 
   * @returns {[number, number]} The target (width, height) dimension of the output image after resizing.
   */
  get_resize_output_image_size(image, size) {
    const [srcWidth, srcHeight] = image.size;
    let shortest_edge;
    let longest_edge;
    if (this.do_thumbnail) {
      const { height, width } = size;
      shortest_edge = Math.min(height, width);
    } else if (Number.isInteger(size)) {
      shortest_edge = size;
      longest_edge = this.config.max_size ?? shortest_edge;
    } else if (size !== void 0) {
      shortest_edge = size.shortest_edge;
      longest_edge = size.longest_edge;
    }
    if (shortest_edge !== void 0 || longest_edge !== void 0) {
      const shortResizeFactor = shortest_edge === void 0 ? 1 : Math.max(shortest_edge / srcWidth, shortest_edge / srcHeight);
      const newWidth = srcWidth * shortResizeFactor;
      const newHeight = srcHeight * shortResizeFactor;
      const longResizeFactor = longest_edge === void 0 ? 1 : Math.min(longest_edge / newWidth, longest_edge / newHeight);
      let finalWidth = Math.floor(Number((newWidth * longResizeFactor).toFixed(2)));
      let finalHeight = Math.floor(Number((newHeight * longResizeFactor).toFixed(2)));
      if (this.size_divisibility !== void 0) {
        [finalWidth, finalHeight] = enforce_size_divisibility([finalWidth, finalHeight], this.size_divisibility);
      }
      return [finalWidth, finalHeight];
    } else if (size !== void 0 && size.width !== void 0 && size.height !== void 0) {
      let newWidth = size.width;
      let newHeight = size.height;
      if (this.config.keep_aspect_ratio && this.config.ensure_multiple_of) {
        let scale_height = newHeight / srcHeight;
        let scale_width = newWidth / srcWidth;
        if (Math.abs(1 - scale_width) < Math.abs(1 - scale_height)) {
          scale_height = scale_width;
        } else {
          scale_width = scale_height;
        }
        newHeight = constraint_to_multiple_of(scale_height * srcHeight, this.config.ensure_multiple_of);
        newWidth = constraint_to_multiple_of(scale_width * srcWidth, this.config.ensure_multiple_of);
      }
      return [newWidth, newHeight];
    } else if (this.size_divisibility !== void 0) {
      return enforce_size_divisibility([srcWidth, srcHeight], this.size_divisibility);
    } else {
      throw new Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(size)}`);
    }
  }
  /**
   * Resizes the image.
   * @param {RawImage} image The image to resize.
   * @returns {Promise<RawImage>} The resized image.
   */
  async resize(image) {
    const [newWidth, newHeight] = this.get_resize_output_image_size(image, this.size);
    return await image.resize(newWidth, newHeight, {
      resample: this.resample
    });
  }
  /**
   * @typedef {object} PreprocessedImage
   * @property {HeightWidth} original_size The original size of the image.
   * @property {HeightWidth} reshaped_input_size The reshaped input size of the image.
   * @property {Tensor} pixel_values The pixel values of the preprocessed image.
   */
  /**
   * Preprocesses the given image.
   *
   * @param {RawImage} image The image to preprocess.
   * @param {Object} overrides The overrides for the preprocessing options.
   * @returns {Promise<PreprocessedImage>} The preprocessed image.
   */
  async preprocess(image, {
    do_normalize = null,
    do_pad = null,
    do_convert_rgb = null,
    do_convert_grayscale = null,
    do_flip_channel_order = null
  } = {}) {
    if (this.do_crop_margin) {
      image = await this.crop_margin(image);
    }
    const [srcWidth, srcHeight] = image.size;
    if (do_convert_rgb ?? this.do_convert_rgb) {
      image = image.rgb();
    } else if (do_convert_grayscale) {
      image = image.grayscale();
    }
    if (this.do_resize) {
      image = await this.resize(image);
    }
    if (this.do_thumbnail) {
      image = await this.thumbnail(image, this.size, this.resample);
    }
    if (this.do_center_crop) {
      let crop_width;
      let crop_height;
      if (Number.isInteger(this.crop_size)) {
        crop_width = this.crop_size;
        crop_height = this.crop_size;
      } else {
        crop_width = this.crop_size.width;
        crop_height = this.crop_size.height;
      }
      image = await image.center_crop(crop_width, crop_height);
    }
    const reshaped_input_size = [image.height, image.width];
    let pixelData = Float32Array.from(image.data);
    let imgDims = [image.height, image.width, image.channels];
    if (this.do_rescale) {
      this.rescale(pixelData);
    }
    if (do_normalize ?? this.do_normalize) {
      let image_mean = this.image_mean;
      if (!Array.isArray(this.image_mean)) {
        image_mean = new Array(image.channels).fill(image_mean);
      }
      let image_std = this.image_std;
      if (!Array.isArray(this.image_std)) {
        image_std = new Array(image.channels).fill(image_mean);
      }
      if (image_mean.length !== image.channels || image_std.length !== image.channels) {
        throw new Error(`When set to arrays, the length of \`image_mean\` (${image_mean.length}) and \`image_std\` (${image_std.length}) must match the number of channels in the image (${image.channels}).`);
      }
      for (let i2 = 0; i2 < pixelData.length; i2 += image.channels) {
        for (let j = 0; j < image.channels; ++j) {
          pixelData[i2 + j] = (pixelData[i2 + j] - image_mean[j]) / image_std[j];
        }
      }
    }
    if (do_pad ?? this.do_pad) {
      if (this.pad_size) {
        const padded = this.pad_image(pixelData, [image.height, image.width, image.channels], this.pad_size);
        [pixelData, imgDims] = padded;
      } else if (this.size_divisibility) {
        const [paddedWidth, paddedHeight] = enforce_size_divisibility([imgDims[1], imgDims[0]], this.size_divisibility);
        [pixelData, imgDims] = this.pad_image(pixelData, imgDims, { width: paddedWidth, height: paddedHeight });
      }
    }
    if (do_flip_channel_order ?? this.do_flip_channel_order) {
      if (imgDims[2] !== 3) {
        throw new Error("Flipping channel order is only supported for RGB images.");
      }
      for (let i2 = 0; i2 < pixelData.length; i2 += 3) {
        const temp = pixelData[i2];
        pixelData[i2] = pixelData[i2 + 2];
        pixelData[i2 + 2] = temp;
      }
    }
    const pixel_values = new Tensor("float32", pixelData, imgDims).permute(2, 0, 1);
    return {
      original_size: [srcHeight, srcWidth],
      reshaped_input_size,
      pixel_values
    };
  }
  /**
   * Calls the feature extraction process on an array of images,
   * preprocesses each image, and concatenates the resulting
   * features into a single Tensor.
   * @param {RawImage[]} images The image(s) to extract features from.
   * @param {...any} args Additional arguments.
   * @returns {Promise<ImageFeatureExtractorResult>} An object containing the concatenated pixel values (and other metadata) of the preprocessed images.
   */
  async _call(images, ...args) {
    if (!Array.isArray(images)) {
      images = [images];
    }
    const imageData = await Promise.all(images.map((x) => this.preprocess(x)));
    const pixel_values = stack(imageData.map((x) => x.pixel_values), 0);
    return {
      pixel_values,
      // Original sizes of images
      original_sizes: imageData.map((x) => x.original_size),
      // Reshaped sizes of images, before padding or cropping
      reshaped_input_sizes: imageData.map((x) => x.reshaped_input_size)
    };
  }
}
class SegformerFeatureExtractor extends ImageFeatureExtractor {
  /**
   * Converts the output of `SegformerForSemanticSegmentation` into semantic segmentation maps.
   * @param {*} outputs Raw outputs of the model.
   * @param {number[][]} [target_sizes=null] List of tuples corresponding to the requested final size
   * (height, width) of each prediction. If unset, predictions will not be resized.
   * @returns {{segmentation: Tensor; labels: number[]}[]} The semantic segmentation maps.
   */
  post_process_semantic_segmentation(outputs, target_sizes = null) {
    const logits = outputs.logits;
    const batch_size = logits.dims[0];
    if (target_sizes !== null && target_sizes.length !== batch_size) {
      throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
    }
    const toReturn = [];
    for (let i2 = 0; i2 < batch_size; ++i2) {
      const target_size = target_sizes !== null ? target_sizes[i2] : null;
      let data = logits[i2];
      if (target_size !== null) {
        data = interpolate(data, target_size, "bilinear", false);
      }
      const [height, width] = target_size ?? data.dims.slice(-2);
      const segmentation = new Tensor(
        "int32",
        new Int32Array(height * width),
        [height, width]
      );
      const buffer2 = data[0].data;
      for (let j = 1; j < data.dims[0]; ++j) {
        const row = data[j].data;
        for (let k = 0; k < row.length; ++k) {
          if (row[k] > buffer2[k]) {
            buffer2[k] = row[k];
            segmentation.data[k] = j;
          }
        }
      }
      const hasLabel = new Array(data.dims[0]);
      const out = segmentation.data;
      for (let j = 0; j < out.length; ++j) {
        const index2 = out[j];
        hasLabel[index2] = index2;
      }
      const labels = hasLabel.filter((x) => x !== void 0);
      toReturn.push({ segmentation, labels });
    }
    return toReturn;
  }
}
class DPTFeatureExtractor extends ImageFeatureExtractor {
}
class DPTImageProcessor extends DPTFeatureExtractor {
}
class BitImageProcessor extends ImageFeatureExtractor {
}
class GLPNFeatureExtractor extends ImageFeatureExtractor {
}
class CLIPFeatureExtractor extends ImageFeatureExtractor {
}
class ChineseCLIPFeatureExtractor extends ImageFeatureExtractor {
}
class SiglipImageProcessor extends ImageFeatureExtractor {
}
class ConvNextFeatureExtractor extends ImageFeatureExtractor {
  constructor(config2) {
    super(config2);
    this.crop_pct = this.config.crop_pct ?? 224 / 256;
  }
  async resize(image) {
    var _a2;
    const shortest_edge = (_a2 = this.size) == null ? void 0 : _a2.shortest_edge;
    if (shortest_edge === void 0) {
      throw new Error(`Size dictionary must contain 'shortest_edge' key.`);
    }
    if (shortest_edge < 384) {
      const resize_shortest_edge = Math.floor(shortest_edge / this.crop_pct);
      const [newWidth, newHeight] = this.get_resize_output_image_size(image, {
        shortest_edge: resize_shortest_edge
      });
      image = await image.resize(newWidth, newHeight, {
        resample: this.resample
      });
      image = await image.center_crop(shortest_edge, shortest_edge);
    } else {
      image = await image.resize(shortest_edge, shortest_edge, {
        resample: this.resample
      });
    }
    return image;
  }
}
class ConvNextImageProcessor extends ConvNextFeatureExtractor {
}
class ViTFeatureExtractor extends ImageFeatureExtractor {
}
class ViTImageProcessor extends ImageFeatureExtractor {
}
class EfficientNetImageProcessor extends ImageFeatureExtractor {
  constructor(config2) {
    super(config2);
    this.include_top = this.config.include_top ?? true;
    if (this.include_top) {
      this.image_std = this.image_std.map((x) => x * x);
    }
  }
}
class MobileViTFeatureExtractor extends ImageFeatureExtractor {
}
class MobileViTImageProcessor extends MobileViTFeatureExtractor {
}
class OwlViTFeatureExtractor extends ImageFeatureExtractor {
  /** @type {post_process_object_detection} */
  post_process_object_detection(...args) {
    return post_process_object_detection(...args);
  }
}
class Owlv2ImageProcessor extends OwlViTFeatureExtractor {
}
class DeiTFeatureExtractor extends ImageFeatureExtractor {
}
class BeitFeatureExtractor extends ImageFeatureExtractor {
}
class DonutFeatureExtractor extends ImageFeatureExtractor {
  pad_image(pixelData, imgDims, padSize, options = {}) {
    const [imageHeight, imageWidth, imageChannels] = imgDims;
    let image_mean = this.image_mean;
    if (!Array.isArray(this.image_mean)) {
      image_mean = new Array(imageChannels).fill(image_mean);
    }
    let image_std = this.image_std;
    if (!Array.isArray(image_std)) {
      image_std = new Array(imageChannels).fill(image_mean);
    }
    const constant_values = image_mean.map((x, i2) => -x / image_std[i2]);
    return super.pad_image(pixelData, imgDims, padSize, {
      center: true,
      // Since normalization is done after padding, we need to use certain constant values to ensure the same behaviour is observed.
      // For more information, see https://github.com/huggingface/transformers/blob/main/src/transformers/models/donut/image_processing_donut.py#L433-L451
      constant_values,
      ...options
    });
  }
}
class NougatImageProcessor extends DonutFeatureExtractor {
}
class DetrFeatureExtractor extends ImageFeatureExtractor {
  /**
   * Calls the feature extraction process on an array of images, preprocesses
   * each image, and concatenates the resulting features into a single Tensor.
   * @param {RawImage[]} images The image(s) to extract features from.
   * @returns {Promise<DetrFeatureExtractorResult>} An object containing the concatenated pixel values of the preprocessed images.
   */
  async _call(images) {
    const result = await super._call(images);
    const maskSize = [result.pixel_values.dims[0], 64, 64];
    const pixel_mask = new Tensor(
      "int64",
      new BigInt64Array(maskSize.reduce((a, b) => a * b)).fill(1n),
      maskSize
    );
    return { ...result, pixel_mask };
  }
  /**
   * Post-processes the outputs of the model (for object detection).
   * @param {Object} outputs The outputs of the model that must be post-processed
   * @param {Tensor} outputs.logits The logits
   * @param {Tensor} outputs.pred_boxes The predicted boxes.
   * @return {Object[]} An array of objects containing the post-processed outputs.
   */
  /** @type {post_process_object_detection} */
  post_process_object_detection(...args) {
    return post_process_object_detection(...args);
  }
  /**
   * Binarize the given masks using `object_mask_threshold`, it returns the associated values of `masks`, `scores` and `labels`.
   * @param {Tensor} class_logits The class logits.
   * @param {Tensor} mask_logits The mask logits.
   * @param {number} object_mask_threshold A number between 0 and 1 used to binarize the masks.
   * @param {number} num_labels The number of labels.
   * @returns {[Tensor[], number[], number[]]} The binarized masks, the scores, and the labels.
   */
  remove_low_and_no_objects(class_logits, mask_logits, object_mask_threshold, num_labels) {
    let mask_probs_item = [];
    let pred_scores_item = [];
    let pred_labels_item = [];
    for (let j = 0; j < class_logits.dims[0]; ++j) {
      let cls = class_logits[j];
      let mask = mask_logits[j];
      let pred_label = max(cls.data)[1];
      if (pred_label === num_labels) {
        continue;
      }
      let scores = softmax(cls.data);
      let pred_score = scores[pred_label];
      if (pred_score > object_mask_threshold) {
        mask_probs_item.push(mask);
        pred_scores_item.push(pred_score);
        pred_labels_item.push(pred_label);
      }
    }
    return [mask_probs_item, pred_scores_item, pred_labels_item];
  }
  /**
   * Checks whether the segment is valid or not.
   * @param {Int32Array} mask_labels Labels for each pixel in the mask.
   * @param {Tensor[]} mask_probs Probabilities for each pixel in the masks.
   * @param {number} k The class id of the segment.
   * @param {number} mask_threshold The mask threshold.
   * @param {number} overlap_mask_area_threshold The overlap mask area threshold.
   * @returns {[boolean, number[]]} Whether the segment is valid or not, and the indices of the valid labels.
   */
  check_segment_validity(mask_labels, mask_probs, k, mask_threshold = 0.5, overlap_mask_area_threshold = 0.8) {
    let mask_k = [];
    let mask_k_area = 0;
    let original_area = 0;
    for (let i2 = 0; i2 < mask_labels.length; ++i2) {
      if (mask_labels[i2] === k) {
        mask_k.push(i2);
        ++mask_k_area;
      }
      if (mask_probs[k].data[i2] >= mask_threshold) {
        ++original_area;
      }
    }
    let mask_exists = mask_k_area > 0 && original_area > 0;
    if (mask_exists) {
      let area_ratio = mask_k_area / original_area;
      mask_exists = area_ratio > overlap_mask_area_threshold;
    }
    return [mask_exists, mask_k];
  }
  /**
   * Computes the segments.
   * @param {Tensor[]} mask_probs The mask probabilities.
   * @param {number[]} pred_scores The predicted scores.
   * @param {number[]} pred_labels The predicted labels.
   * @param {number} mask_threshold The mask threshold.
   * @param {number} overlap_mask_area_threshold The overlap mask area threshold.
   * @param {Set<number>} label_ids_to_fuse The label ids to fuse.
   * @param {number[]} target_size The target size of the image.
   * @returns {[Tensor, Array<{id: number, label_id: number, score: number}>]} The computed segments.
   */
  compute_segments(mask_probs, pred_scores, pred_labels, mask_threshold, overlap_mask_area_threshold, label_ids_to_fuse = null, target_size = null) {
    let [height, width] = target_size ?? mask_probs[0].dims;
    let segmentation = new Tensor(
      "int32",
      new Int32Array(height * width),
      [height, width]
    );
    let segments = [];
    if (target_size !== null) {
      for (let i2 = 0; i2 < mask_probs.length; ++i2) {
        mask_probs[i2] = interpolate(mask_probs[i2], target_size, "bilinear", false);
      }
    }
    let mask_labels = new Int32Array(mask_probs[0].data.length);
    let bestScores = new Float32Array(mask_probs[0].data.length);
    for (let i2 = 0; i2 < mask_probs.length; ++i2) {
      let score = pred_scores[i2];
      for (let j = 0; j < mask_probs[i2].data.length; ++j) {
        mask_probs[i2].data[j] *= score;
        if (mask_probs[i2].data[j] > bestScores[j]) {
          mask_labels[j] = i2;
          bestScores[j] = mask_probs[i2].data[j];
        }
      }
    }
    let current_segment_id = 0;
    for (let k = 0; k < pred_labels.length; ++k) {
      let pred_class = pred_labels[k];
      let [mask_exists, mask_k] = this.check_segment_validity(
        mask_labels,
        mask_probs,
        k,
        mask_threshold,
        overlap_mask_area_threshold
      );
      if (!mask_exists) {
        continue;
      }
      ++current_segment_id;
      for (let index2 of mask_k) {
        segmentation.data[index2] = current_segment_id;
      }
      segments.push({
        id: current_segment_id,
        label_id: pred_class,
        // was_fused: should_fuse, TODO
        score: pred_scores[k]
      });
    }
    return [segmentation, segments];
  }
  /**
   * Post-process the model output to generate the final panoptic segmentation.
   * @param {*} outputs The model output to post process
   * @param {number} [threshold=0.5] The probability score threshold to keep predicted instance masks.
   * @param {number} [mask_threshold=0.5] Threshold to use when turning the predicted masks into binary values.
   * @param {number} [overlap_mask_area_threshold=0.8] The overlap mask area threshold to merge or discard small disconnected parts within each binary instance mask.
   * @param {Set<number>} [label_ids_to_fuse=null] The labels in this state will have all their instances be fused together.
   * @param {number[][]} [target_sizes=null] The target sizes to resize the masks to.
   * @returns {Array<{ segmentation: Tensor, segments_info: Array<{id: number, label_id: number, score: number}>}>}
   */
  post_process_panoptic_segmentation(outputs, threshold2 = 0.5, mask_threshold = 0.5, overlap_mask_area_threshold = 0.8, label_ids_to_fuse = null, target_sizes = null) {
    if (label_ids_to_fuse === null) {
      console.warn("`label_ids_to_fuse` unset. No instance will be fused.");
      label_ids_to_fuse = /* @__PURE__ */ new Set();
    }
    const class_queries_logits = outputs.logits;
    const masks_queries_logits = outputs.pred_masks;
    const mask_probs = masks_queries_logits.sigmoid();
    let [batch_size, num_queries, num_labels] = class_queries_logits.dims;
    num_labels -= 1;
    if (target_sizes !== null && target_sizes.length !== batch_size) {
      throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
    }
    let toReturn = [];
    for (let i2 = 0; i2 < batch_size; ++i2) {
      let target_size = target_sizes !== null ? target_sizes[i2] : null;
      let class_logits = class_queries_logits[i2];
      let mask_logits = mask_probs[i2];
      let [mask_probs_item, pred_scores_item, pred_labels_item] = this.remove_low_and_no_objects(class_logits, mask_logits, threshold2, num_labels);
      if (pred_labels_item.length === 0) {
        let [height, width] = target_size ?? mask_logits.dims.slice(-2);
        let segmentation2 = new Tensor(
          "int32",
          new Int32Array(height * width).fill(-1),
          [height, width]
        );
        toReturn.push({
          segmentation: segmentation2,
          segments_info: []
        });
        continue;
      }
      let [segmentation, segments] = this.compute_segments(
        mask_probs_item,
        pred_scores_item,
        pred_labels_item,
        mask_threshold,
        overlap_mask_area_threshold,
        label_ids_to_fuse,
        target_size
      );
      toReturn.push({
        segmentation,
        segments_info: segments
      });
    }
    return toReturn;
  }
  post_process_instance_segmentation() {
    throw Error("Not implemented yet");
  }
}
class YolosFeatureExtractor extends ImageFeatureExtractor {
  /** @type {post_process_object_detection} */
  post_process_object_detection(...args) {
    return post_process_object_detection(...args);
  }
}
class SamImageProcessor extends ImageFeatureExtractor {
  /**
   * 
   * @param {any} input_points 
   * @param {HeightWidth[]} original_sizes 
   * @param {HeightWidth[]} reshaped_input_sizes 
   * @returns {Tensor}
   */
  reshape_input_points(input_points, original_sizes, reshaped_input_sizes) {
    input_points = structuredClone(input_points);
    let shape = calculateDimensions(input_points);
    if (shape.length === 3) {
      shape = [1, ...shape];
      input_points = [input_points];
    } else if (shape.length !== 4) {
      throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");
    }
    for (let i2 = 0; i2 < input_points.length; ++i2) {
      let originalImageSize = original_sizes[i2];
      let reshapedImageSize = reshaped_input_sizes[i2];
      let resizeFactors = [
        reshapedImageSize[0] / originalImageSize[0],
        reshapedImageSize[1] / originalImageSize[1]
      ];
      for (let j = 0; j < input_points[i2].length; ++j) {
        for (let k = 0; k < input_points[i2][j].length; ++k) {
          for (let w = 0; w < input_points[i2][j][k].length; ++w) {
            input_points[i2][j][k][w] *= resizeFactors[w];
          }
        }
      }
    }
    return new Tensor(
      "float32",
      Float32Array.from(input_points.flat(Infinity)),
      shape
    );
  }
  /**
   * 
   * @param {any} input_labels 
   * @param {Tensor} input_points 
   * @returns {Tensor}
   */
  add_input_labels(input_labels, input_points) {
    let shape = calculateDimensions(input_labels);
    if (shape.length === 2) {
      shape = [1, ...shape];
      input_labels = [input_labels];
    } else if (shape.length !== 3) {
      throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");
    }
    if (shape.some((x, i2) => x !== input_points.dims[i2])) {
      throw Error(`The first ${shape.length} dimensions of 'input_points' and 'input_labels' must be the same.`);
    }
    return new Tensor(
      "int64",
      input_labels.flat(Infinity).map(BigInt),
      shape
    );
  }
  /**
   * @param {any[]} images The URL(s) of the image(s) to extract features from.
   * @param {any} [input_points] A 3D or 4D array, representing the input points provided by the user.
   * - 3D: `[point_batch_size, nb_points_per_image, 2]`. In this case, `batch_size` is assumed to be 1.
   * - 4D: `[batch_size, point_batch_size, nb_points_per_image, 2]`.
   * @param {any} [input_labels] A 2D or 3D array, representing the input labels for the points, used by the prompt encoder to encode the prompt.
   * - 2D: `[point_batch_size, nb_points_per_image]`. In this case, `batch_size` is assumed to be 1.
   * - 3D: `[batch_size, point_batch_size, nb_points_per_image]`.
   * @returns {Promise<SamImageProcessorResult>}
   */
  async _call(images, input_points = null, input_labels = null) {
    const processed = await super._call(images);
    if (input_points) {
      processed.input_points = this.reshape_input_points(
        input_points,
        processed.original_sizes,
        processed.reshaped_input_sizes
      );
    }
    if (input_labels) {
      if (!processed.input_points) {
        throw Error("`input_points` must be provided if `input_labels` are provided.");
      }
      processed.input_labels = this.add_input_labels(input_labels, processed.input_points);
    }
    return processed;
  }
  /**
   * Remove padding and upscale masks to the original image size.
   * @param {Tensor} masks Batched masks from the mask_decoder in (batch_size, num_channels, height, width) format.
   * @param {number[][]} original_sizes The original sizes of each image before it was resized to the model's expected input shape, in (height, width) format.
   * @param {number[][]} reshaped_input_sizes The size of each image as it is fed to the model, in (height, width) format. Used to remove padding.
   * @param {Object} options Optional parameters for post-processing.
   * @param {number} [options.mask_threshold] The threshold to use for binarizing the masks.
   * @param {boolean} [options.binarize] Whether to binarize the masks.
   * @param {Object} [options.pad_size] The target size the images were padded to before being passed to the model. If `null`, the target size is assumed to be the processor's `pad_size`.
   * @param {number} [options.pad_size.height] The height the images were padded to.
   * @param {number} [options.pad_size.width] The width the images were padded to.
   * @returns {Tensor[]} Batched masks in batch_size, num_channels, height, width) format, where (height, width) is given by original_size.
   */
  post_process_masks(masks, original_sizes, reshaped_input_sizes, {
    mask_threshold = 0,
    binarize = true,
    pad_size = null
  } = {}) {
    const output_masks = [];
    pad_size = pad_size ?? this.pad_size;
    const target_image_size = [pad_size.height, pad_size.width];
    for (let i2 = 0; i2 < original_sizes.length; ++i2) {
      const original_size = original_sizes[i2];
      const reshaped_input_size = reshaped_input_sizes[i2];
      const mask = masks[i2];
      const interpolated_masks = [];
      for (let j = 0; j < mask.dims[0]; ++j) {
        const m = mask[j];
        let interpolated_mask = interpolate(m, target_image_size, "bilinear", false);
        interpolated_mask = interpolated_mask.slice(null, [0, reshaped_input_size[0]], [0, reshaped_input_size[1]]);
        interpolated_mask = interpolate(interpolated_mask, original_size, "bilinear", false);
        if (binarize) {
          const binarizedMaskData = new Uint8Array(interpolated_mask.data.length);
          for (let i3 = 0; i3 < interpolated_mask.data.length; ++i3) {
            if (interpolated_mask.data[i3] > mask_threshold) {
              binarizedMaskData[i3] = 1;
            }
          }
          interpolated_mask = new Tensor(
            "bool",
            binarizedMaskData,
            interpolated_mask.dims
          );
        }
        interpolated_masks.push(interpolated_mask);
      }
      output_masks.push(stack(interpolated_masks));
    }
    return output_masks;
  }
}
class Swin2SRImageProcessor extends ImageFeatureExtractor {
  pad_image(pixelData, imgDims, padSize, options = {}) {
    const [imageHeight, imageWidth, imageChannels] = imgDims;
    return super.pad_image(pixelData, imgDims, {
      // NOTE: For Swin2SR models, the original python implementation adds padding even when the image's width/height is already
      // a multiple of `pad_size`. However, this is most likely a bug (PR: https://github.com/mv-lab/swin2sr/pull/19).
      // For this reason, we only add padding when the image's width/height is not a multiple of `pad_size`.
      width: imageWidth + (padSize - imageWidth % padSize) % padSize,
      height: imageHeight + (padSize - imageHeight % padSize) % padSize
    }, {
      mode: "symmetric",
      center: false,
      constant_values: -1,
      ...options
    });
  }
}
class VitMatteImageProcessor extends ImageFeatureExtractor {
  /**
   * Calls the feature extraction process on an array of images, preprocesses
   * each image, and concatenates the resulting features into a single Tensor.
   * @param {RawImage[]} images The image(s) to extract features from.
   * @param {RawImage[]} trimaps The trimaps(s) to extract features from.
   * @returns {Promise<ImageFeatureExtractorResult>} An object containing the concatenated pixel values of the preprocessed images.
   */
  async _call(images, trimaps) {
    if (!Array.isArray(images)) {
      images = [images];
    }
    if (!Array.isArray(trimaps)) {
      trimaps = [trimaps];
    }
    const imageData = await Promise.all(images.map((x) => this.preprocess(x)));
    const trimapData = await Promise.all(trimaps.map((x) => this.preprocess(x, {
      do_normalize: false,
      do_convert_rgb: false,
      do_convert_grayscale: true
    })));
    const pixel_values = stack(imageData.map(
      // Concatenate images and trimaps
      (x, i2) => cat([x.pixel_values, trimapData[i2].pixel_values], 0)
    ), 0);
    return {
      pixel_values,
      // Original sizes of images
      original_sizes: imageData.map((x) => x.original_size),
      // Reshaped sizes of images, before padding or cropping
      reshaped_input_sizes: imageData.map((x) => x.reshaped_input_size)
    };
  }
}
class WhisperFeatureExtractor extends FeatureExtractor {
  constructor(config2) {
    var _a2;
    super(config2);
    (_a2 = this.config).mel_filters ?? (_a2.mel_filters = mel_filter_bank(
      Math.floor(1 + this.config.n_fft / 2),
      // num_frequency_bins
      this.config.feature_size,
      // num_mel_filters
      0,
      // min_frequency
      8e3,
      // max_frequency
      this.config.sampling_rate,
      // sampling_rate
      "slaney",
      // norm
      "slaney"
      // mel_scale
    ));
    this.window = window_function(this.config.n_fft, "hann");
  }
  /**
   * Computes the log-Mel spectrogram of the provided audio waveform.
   * @param {Float32Array|Float64Array} waveform The audio waveform to process.
   * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
   */
  _extract_fbank_features(waveform) {
    const { data, dims } = spectrogram(
      waveform,
      this.window,
      // window
      this.config.n_fft,
      // frame_length
      this.config.hop_length,
      // hop_length
      {
        power: 2,
        mel_filters: this.config.mel_filters,
        log_mel: "log10",
        // Custom
        max_num_frames: this.config.nb_max_frames
        // 3000
      }
    );
    const maxValue = max(data)[0];
    for (let i2 = 0; i2 < data.length; ++i2) {
      data[i2] = (Math.max(data[i2], maxValue - 8) + 4) / 4;
    }
    return { data, dims };
  }
  /**
   * Asynchronously extracts features from a given audio using the provided configuration.
   * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
   * @returns {Promise<{ input_features: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.
   */
  async _call(audio) {
    validate_audio_inputs(audio, "WhisperFeatureExtractor");
    let waveform;
    if (audio.length > this.config.n_samples) {
      console.warn(
        "Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."
      );
      waveform = audio.slice(0, this.config.n_samples);
    } else {
      waveform = new Float32Array(this.config.n_samples);
      waveform.set(audio);
    }
    const { data, dims } = this._extract_fbank_features(waveform);
    return {
      input_features: new Tensor(
        "float32",
        data,
        [1, ...dims]
      )
    };
  }
}
class Wav2Vec2FeatureExtractor extends FeatureExtractor {
  /**
   * @param {Float32Array} input_values 
   * @returns {Float32Array} 
   */
  _zero_mean_unit_var_norm(input_values) {
    const sum = input_values.reduce((a, b) => a + b, 0);
    const mean2 = sum / input_values.length;
    const variance = input_values.reduce((a, b) => a + (b - mean2) ** 2, 0) / input_values.length;
    return input_values.map((x) => (x - mean2) / Math.sqrt(variance + 1e-7));
  }
  /**
   * Asynchronously extracts features from a given audio using the provided configuration.
   * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
   * @returns {Promise<{ input_values: Tensor; attention_mask: Tensor }>} A Promise resolving to an object containing the extracted input features and attention mask as Tensors.
   */
  async _call(audio) {
    validate_audio_inputs(audio, "Wav2Vec2FeatureExtractor");
    if (audio instanceof Float64Array) {
      audio = new Float32Array(audio);
    }
    let input_values = audio;
    if (this.config.do_normalize) {
      input_values = this._zero_mean_unit_var_norm(input_values);
    }
    const shape = [1, input_values.length];
    return {
      input_values: new Tensor("float32", input_values, shape),
      attention_mask: new Tensor("int64", new BigInt64Array(input_values.length).fill(1n), shape)
    };
  }
}
class SeamlessM4TFeatureExtractor extends FeatureExtractor {
  constructor(config2) {
    super(config2);
    const sampling_rate = this.config.sampling_rate;
    const mel_filters = mel_filter_bank(
      256,
      // num_frequency_bins
      this.config.num_mel_bins,
      // num_mel_filters
      20,
      // min_frequency
      Math.floor(sampling_rate / 2),
      // max_frequency
      sampling_rate,
      // sampling_rate
      null,
      // norm
      "kaldi",
      // mel_scale
      true
      // triangularize_in_mel_space
    );
    for (let i2 = 0; i2 < mel_filters.length; ++i2) {
      mel_filters[i2].push(0);
    }
    this.mel_filters = mel_filters;
    this.window = window_function(400, "povey", {
      periodic: false
    });
  }
  /**
   * Computes the log-Mel spectrogram of the provided audio waveform.
   * @param {Float32Array|Float64Array} waveform The audio waveform to process.
   * @param {number} max_length The maximum number of frames to return.
   * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
   */
  _extract_fbank_features(waveform, max_length) {
    waveform = waveform.map((x) => x * 32768);
    return spectrogram(
      waveform,
      this.window,
      // window
      400,
      // frame_length
      160,
      // hop_length
      {
        fft_length: 512,
        power: 2,
        center: false,
        preemphasis: 0.97,
        mel_filters: this.mel_filters,
        log_mel: "log",
        mel_floor: 1192092955078125e-22,
        remove_dc_offset: true,
        // Custom
        max_num_frames: max_length,
        transpose: true
      }
    );
  }
  /**
   * Asynchronously extracts features from a given audio using the provided configuration.
   * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
   * @param {Object} options Optional parameters for feature extraction.
   * @param {boolean} [options.padding=true] Whether to pad the sequence to a multiple of `pad_to_multiple_of`.
   * @param {number} [options.pad_to_multiple_of=2] The number to pad the sequence to a multiple of.
   * @param {boolean} [options.do_normalize_per_mel_bins=true] Whether or not to zero-mean unit-variance normalize the input per mel-channel.
   * @param {boolean} [options.return_attention_mask=true] Whether to return the attention mask.
   * @returns {Promise<{ input_features: Tensor, attention_mask?: Tensor }>} A Promise resolving to an object containing the extracted input features and attention masks as Tensors.
   */
  async _call(audio, {
    padding = true,
    pad_to_multiple_of = 2,
    do_normalize_per_mel_bins = true,
    return_attention_mask = true
  } = {}) {
    validate_audio_inputs(audio, "SeamlessM4TFeatureExtractor");
    let features = this._extract_fbank_features(audio, this.config.max_length);
    if (do_normalize_per_mel_bins) {
      const [num_features, feature_size] = features.dims;
      for (let i2 = 0; i2 < feature_size; ++i2) {
        let sum = 0;
        for (let j = 0; j < num_features; ++j) {
          sum += features.data[j * feature_size + i2];
        }
        const mean2 = sum / num_features;
        let variance = 0;
        for (let j = 0; j < num_features; ++j) {
          variance += (features.data[j * feature_size + i2] - mean2) ** 2;
        }
        variance /= num_features - 1;
        const std = Math.sqrt(variance + 1e-7);
        for (let j = 0; j < num_features; ++j) {
          const index2 = j * feature_size + i2;
          features.data[index2] = (features.data[index2] - mean2) / std;
        }
      }
    }
    let padded_attention_mask;
    if (padding) {
      const [num_frames2, num_channels2] = features.dims;
      const pad_size = num_frames2 % pad_to_multiple_of;
      if (pad_size > 0) {
        const padded_data = new Float32Array(num_channels2 * (num_frames2 + pad_size));
        padded_data.set(features.data);
        padded_data.fill(this.config.padding_value, features.data.length);
        const numPaddedFrames = num_frames2 + pad_size;
        features = {
          data: padded_data,
          dims: [numPaddedFrames, num_channels2]
        };
        if (return_attention_mask) {
          padded_attention_mask = new Tensor(
            "int64",
            new BigInt64Array(numPaddedFrames),
            [1, numPaddedFrames]
          );
          padded_attention_mask.data.fill(1n, 0, num_frames2);
        }
      }
    }
    const [num_frames, num_channels] = features.dims;
    const stride = this.config.stride;
    const remainder = num_frames % stride;
    if (remainder !== 0) {
      throw new Error(`The number of frames (${num_frames}) must be a multiple of the stride (${stride}).`);
    }
    const input_features = new Tensor(
      "float32",
      features.data,
      features.dims
    ).view(
      1,
      Math.floor(num_frames / stride),
      num_channels * stride
    );
    const result = { input_features };
    if (return_attention_mask) {
      const reshapedNumFrames = input_features.dims[1];
      const attention_mask = new Tensor(
        "int64",
        new BigInt64Array(reshapedNumFrames),
        [1, reshapedNumFrames]
      );
      if (padded_attention_mask) {
        for (let i2 = 1, j = 0; i2 < num_frames; i2 += stride, ++j) {
          attention_mask.data[j] = padded_attention_mask.data[i2];
        }
      } else {
        attention_mask.data.fill(1n);
      }
      result.attention_mask = attention_mask;
    }
    return result;
  }
}
class ASTFeatureExtractor extends FeatureExtractor {
  constructor(config2) {
    super(config2);
    const sampling_rate = this.config.sampling_rate;
    const mel_filters = mel_filter_bank(
      256,
      // num_frequency_bins
      this.config.num_mel_bins,
      // num_mel_filters
      20,
      // min_frequency
      Math.floor(sampling_rate / 2),
      // max_frequency
      sampling_rate,
      // sampling_rate
      null,
      // norm
      "kaldi",
      // mel_scale
      true
      // triangularize_in_mel_space
    );
    for (let i2 = 0; i2 < mel_filters.length; ++i2) {
      mel_filters[i2].push(0);
    }
    this.mel_filters = mel_filters;
    this.window = window_function(400, "hann", {
      periodic: false
    });
    this.mean = this.config.mean;
    this.std = this.config.std;
  }
  /**
   * Computes the log-Mel spectrogram of the provided audio waveform.
   * @param {Float32Array|Float64Array} waveform The audio waveform to process.
   * @param {number} max_length The maximum number of frames to return.
   * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
   */
  _extract_fbank_features(waveform, max_length) {
    return spectrogram(
      waveform,
      this.window,
      // window
      400,
      // frame_length
      160,
      // hop_length
      {
        fft_length: 512,
        power: 2,
        center: false,
        preemphasis: 0.97,
        mel_filters: this.mel_filters,
        log_mel: "log",
        mel_floor: 1192092955078125e-22,
        remove_dc_offset: true,
        // Custom
        max_num_frames: max_length,
        transpose: true
      }
    );
  }
  /**
   * Asynchronously extracts features from a given audio using the provided configuration.
   * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
   * @returns {Promise<{ input_values: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.
   */
  async _call(audio) {
    validate_audio_inputs(audio, "ASTFeatureExtractor");
    const features = this._extract_fbank_features(audio, this.config.max_length);
    if (this.config.do_normalize) {
      const denom = this.std * 2;
      for (let i2 = 0; i2 < features.data.length; ++i2) {
        features.data[i2] = (features.data[i2] - this.mean) / denom;
      }
    }
    return {
      input_values: new Tensor(
        "float32",
        features.data,
        [1, ...features.dims]
      )
    };
  }
}
class ClapFeatureExtractor extends FeatureExtractor {
  constructor(config2) {
    super(config2);
    this.mel_filters = mel_filter_bank(
      this.config.nb_frequency_bins,
      // num_frequency_bins
      this.config.feature_size,
      // num_mel_filters
      this.config.frequency_min,
      // min_frequency
      this.config.frequency_max,
      // max_frequency
      this.config.sampling_rate,
      // sampling_rate
      null,
      // norm
      "htk"
      // mel_scale
    );
    this.mel_filters_slaney = mel_filter_bank(
      this.config.nb_frequency_bins,
      // num_frequency_bins
      this.config.feature_size,
      // num_mel_filters
      this.config.frequency_min,
      // min_frequency
      this.config.frequency_max,
      // max_frequency
      this.config.sampling_rate,
      // sampling_rate
      "slaney",
      // norm
      "slaney"
      // mel_scale
    );
    this.window = window_function(this.config.fft_window_size, "hann");
  }
  /**
   * Extracts the mel spectrogram and prepares it for the mode based on the `truncation` and `padding` arguments.
   * 
   * Four different path are possible:
   *   - `truncation="fusion"` and the length of the waveform is greater than the max length: the mel spectrogram
   *     will be computed on the entire audio. 3 random crops and a dowsampled version of the full mel spectrogram
   *     are then stacked together. They will later be used for `feature_fusion`.
   *   - `truncation="rand_trunc"` and the length of the waveform is smaller than the max length: the audio is
   *     padded based on `padding`.
   *   - `truncation="fusion"` and the length of the waveform is smaller than the max length: the audio is padded
   *     based on `padding`, and is repeated `4` times.
   *   - `truncation="rand_trunc"` and the length of the waveform is greater than the max length: the mel
   *     spectrogram will be computed on a random crop of the waveform.
   * 
   * @param {Float32Array|Float64Array} waveform The input waveform.
   * @param {number} max_length The maximum length of the waveform.
   * @param {string} truncation The truncation strategy to use.
   * @param {string} padding The padding strategy to use.
   * @returns {{ data: Float32Array; dims: number[]; longer: boolean; }} An object containing the mel spectrogram data as a Float32Array, its dimensions as an array of numbers, and a boolean indicating whether the waveform was longer than the max length.
   */
  _get_input_mel(waveform, max_length, truncation, padding) {
    let input_mel;
    let longer = false;
    const diff2 = waveform.length - max_length;
    if (diff2 > 0) {
      if (truncation === "rand_trunc") {
        longer = true;
        const idx = Math.floor(Math.random() * (diff2 + 1));
        waveform = waveform.subarray(idx, idx + max_length);
        input_mel = this._extract_fbank_features(waveform, this.mel_filters_slaney, this.config.nb_max_samples);
        input_mel.dims = [1, ...input_mel.dims];
      } else {
        throw new Error(`Truncation strategy "${truncation}" not implemented`);
      }
    } else {
      if (diff2 < 0) {
        let padded = new Float64Array(max_length);
        padded.set(waveform);
        if (padding === "repeat") {
          for (let i2 = waveform.length; i2 < max_length; i2 += waveform.length) {
            padded.set(waveform.subarray(0, Math.min(waveform.length, max_length - i2)), i2);
          }
        } else if (padding === "repeatpad") {
          for (let i2 = waveform.length; i2 < -diff2; i2 += waveform.length) {
            padded.set(waveform, i2);
          }
        }
        waveform = padded;
      }
      if (truncation === "fusion") {
        throw new Error(`Truncation strategy "${truncation}" not implemented`);
      }
      input_mel = this._extract_fbank_features(waveform, this.mel_filters_slaney, this.config.nb_max_samples);
      input_mel.dims = [1, ...input_mel.dims];
    }
    return {
      ...input_mel,
      longer
    };
  }
  /**
   * Compute the log-mel spectrogram of the provided `waveform` using the Hann window.
   * In CLAP, two different filter banks are used depending on the truncation pattern:
   *  - `self.mel_filters`: they correspond to the default parameters of `torchaudio` which can be obtained from
   *    calling `torchaudio.transforms.MelSpectrogram().mel_scale.fb`. These filters are used when `truncation`
   *    is set to `"fusion"`.
   *  - `self.mel_filteres_slaney` : they correspond to the default parameters of `librosa` which used
   *    `librosa.filters.mel` when computing the mel spectrogram. These filters were only used in the original
   *    implementation when the truncation mode is not `"fusion"`.
   * 
   * @param {Float32Array|Float64Array} waveform The audio waveform to process.
   * @param {number[][]} mel_filters The mel filters to use.
   * @param {number} [max_length=null] The maximum number of frames to return.
   * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
   */
  _extract_fbank_features(waveform, mel_filters, max_length = null) {
    return spectrogram(
      waveform,
      this.window,
      // window
      this.config.fft_window_size,
      // frame_length
      this.config.hop_length,
      // hop_length
      {
        power: 2,
        mel_filters,
        log_mel: "dB",
        // Custom
        max_num_frames: max_length,
        do_pad: false,
        transpose: true
      }
    );
  }
  /**
   * Asynchronously extracts features from a given audio using the provided configuration.
   * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
   * @returns {Promise<{ input_features: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.
   */
  async _call(audio, {
    max_length = null
  } = {}) {
    validate_audio_inputs(audio, "ClapFeatureExtractor");
    const padded_inputs = this._get_input_mel(
      audio,
      max_length ?? this.config.nb_max_samples,
      this.config.truncation,
      this.config.padding
    );
    return {
      input_features: new Tensor(
        "float32",
        padded_inputs.data,
        [1, ...padded_inputs.dims]
      )
    };
  }
}
class SpeechT5FeatureExtractor extends FeatureExtractor {
}
class Processor extends Callable {
  /**
   * Creates a new Processor with the given feature extractor.
   * @param {FeatureExtractor} feature_extractor The function used to extract features from the input.
   */
  constructor(feature_extractor) {
    super();
    this.feature_extractor = feature_extractor;
  }
  /**
   * Calls the feature_extractor function with the given input.
   * @param {any} input The input to extract features from.
   * @param {...any} args Additional arguments.
   * @returns {Promise<any>} A Promise that resolves with the extracted features.
   */
  async _call(input2, ...args) {
    return await this.feature_extractor(input2, ...args);
  }
}
class SamProcessor extends Processor {
  /**
   * @borrows SamImageProcessor#_call as _call
   */
  async _call(...args) {
    return await this.feature_extractor(...args);
  }
  /**
   * @borrows SamImageProcessor#post_process_masks as post_process_masks
   */
  post_process_masks(...args) {
    return this.feature_extractor.post_process_masks(...args);
  }
  /**
   * @borrows SamImageProcessor#reshape_input_points as reshape_input_points
   */
  reshape_input_points(...args) {
    return this.feature_extractor.reshape_input_points(...args);
  }
}
class WhisperProcessor extends Processor {
  /**
   * Calls the feature_extractor function with the given audio input.
   * @param {any} audio The audio input to extract features from.
   * @returns {Promise<any>} A Promise that resolves with the extracted features.
   */
  async _call(audio) {
    return await this.feature_extractor(audio);
  }
}
class Wav2Vec2ProcessorWithLM extends Processor {
  /**
   * Calls the feature_extractor function with the given audio input.
   * @param {any} audio The audio input to extract features from.
   * @returns {Promise<any>} A Promise that resolves with the extracted features.
   */
  async _call(audio) {
    return await this.feature_extractor(audio);
  }
}
class SpeechT5Processor extends Processor {
  /**
   * Calls the feature_extractor function with the given input.
   * @param {any} input The input to extract features from.
   * @returns {Promise<any>} A Promise that resolves with the extracted features.
   */
  async _call(input2) {
    return await this.feature_extractor(input2);
  }
}
class OwlViTProcessor extends Processor {
}
class AutoProcessor {
  /**
   * Instantiate one of the processor classes of the library from a pretrained model.
   * 
   * The processor class to instantiate is selected based on the `feature_extractor_type` property of the config object
   * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)
   * 
   * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:
   * - A string, the *model id* of a pretrained processor hosted inside a model repo on huggingface.co.
   *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a
   *   user or organization name, like `dbmdz/bert-base-german-cased`.
   * - A path to a *directory* containing processor files, e.g., `./my_model_directory/`.
   * @param {import('./utils/hub.js').PretrainedOptions} options Additional options for loading the processor.
   * 
   * @returns {Promise<Processor>} A new instance of the Processor class.
   */
  static async from_pretrained(pretrained_model_name_or_path, {
    progress_callback = null,
    config: config2 = null,
    cache_dir = null,
    local_files_only = false,
    revision = "main"
  } = {}) {
    let preprocessorConfig = config2 ?? await getModelJSON(pretrained_model_name_or_path, "preprocessor_config.json", true, {
      progress_callback,
      cache_dir,
      local_files_only,
      revision
    });
    let key = preprocessorConfig.feature_extractor_type ?? preprocessorConfig.image_processor_type;
    let feature_extractor_class = this.FEATURE_EXTRACTOR_CLASS_MAPPING[key];
    if (!feature_extractor_class) {
      if (preprocessorConfig.size !== void 0) {
        console.warn(`Feature extractor type "${key}" not found, assuming ImageFeatureExtractor due to size parameter in config.`);
        feature_extractor_class = ImageFeatureExtractor;
      } else {
        throw new Error(`Unknown Feature Extractor type: ${key}`);
      }
    }
    let processor_class = this.PROCESSOR_CLASS_MAPPING[preprocessorConfig.processor_class] ?? Processor;
    let feature_extractor = new feature_extractor_class(preprocessorConfig);
    return new processor_class(feature_extractor);
  }
}
__publicField(AutoProcessor, "FEATURE_EXTRACTOR_CLASS_MAPPING", {
  ImageFeatureExtractor,
  WhisperFeatureExtractor,
  ViTFeatureExtractor,
  MobileViTFeatureExtractor,
  MobileViTImageProcessor,
  OwlViTFeatureExtractor,
  Owlv2ImageProcessor,
  CLIPFeatureExtractor,
  ChineseCLIPFeatureExtractor,
  SiglipImageProcessor,
  ConvNextFeatureExtractor,
  ConvNextImageProcessor,
  SegformerFeatureExtractor,
  BitImageProcessor,
  DPTImageProcessor,
  DPTFeatureExtractor,
  GLPNFeatureExtractor,
  BeitFeatureExtractor,
  DeiTFeatureExtractor,
  DetrFeatureExtractor,
  YolosFeatureExtractor,
  DonutFeatureExtractor,
  NougatImageProcessor,
  EfficientNetImageProcessor,
  ViTImageProcessor,
  VitMatteImageProcessor,
  SamImageProcessor,
  Swin2SRImageProcessor,
  Wav2Vec2FeatureExtractor,
  SeamlessM4TFeatureExtractor,
  SpeechT5FeatureExtractor,
  ASTFeatureExtractor,
  ClapFeatureExtractor
});
__publicField(AutoProcessor, "PROCESSOR_CLASS_MAPPING", {
  WhisperProcessor,
  Wav2Vec2ProcessorWithLM,
  SamProcessor,
  SpeechT5Processor,
  OwlViTProcessor
});
async function prepareImages(images) {
  if (!Array.isArray(images)) {
    images = [images];
  }
  return await Promise.all(images.map((x) => RawImage.read(x)));
}
async function prepareAudios(audios, sampling_rate) {
  if (!Array.isArray(audios)) {
    audios = [audios];
  }
  return await Promise.all(audios.map((x) => {
    if (typeof x === "string" || x instanceof URL) {
      return read_audio(x, sampling_rate);
    } else if (x instanceof Float64Array) {
      return new Float32Array(x);
    }
    return x;
  }));
}
function get_bounding_box(box, asInteger) {
  if (asInteger) {
    box = box.map((x) => x | 0);
  }
  const [xmin, ymin, xmax, ymax] = box;
  return { xmin, ymin, xmax, ymax };
}
class Pipeline extends Callable {
  /**
   * Create a new Pipeline.
   * @param {Object} options An object containing the following properties:
   * @param {string} [options.task] The task of the pipeline. Useful for specifying subtasks.
   * @param {PreTrainedModel} [options.model] The model used by the pipeline.
   * @param {PreTrainedTokenizer} [options.tokenizer=null] The tokenizer used by the pipeline (if any).
   * @param {Processor} [options.processor=null] The processor used by the pipeline (if any).
   */
  constructor({ task, model, tokenizer = null, processor = null }) {
    super();
    this.task = task;
    this.model = model;
    this.tokenizer = tokenizer;
    this.processor = processor;
  }
  /** @type {DisposeType} */
  async dispose() {
    await this.model.dispose();
  }
}
class TextClassificationPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => TextClassificationPipelineType} */
Pipeline {
  /**
   * Create a new TextClassificationPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {TextClassificationPipelineCallback} */
  async _call(texts, {
    topk = 1
  } = {}) {
    const model_inputs = this.tokenizer(texts, {
      padding: true,
      truncation: true
    });
    const outputs = await this.model(model_inputs);
    const function_to_apply = this.model.config.problem_type === "multi_label_classification" ? (batch) => batch.sigmoid().data : (batch) => softmax(batch.data);
    const id2label = this.model.config.id2label;
    const toReturn = [];
    for (const batch of outputs.logits) {
      const output2 = function_to_apply(batch);
      const scores = getTopItems(output2, topk);
      const vals = scores.map((x) => ({
        label: id2label[x[0]],
        score: x[1]
      }));
      if (topk === 1) {
        toReturn.push(...vals);
      } else {
        toReturn.push(vals);
      }
    }
    return Array.isArray(texts) || topk === 1 ? (
      /** @type {TextClassificationOutput} */
      toReturn
    ) : (
      /** @type {TextClassificationOutput[]} */
      toReturn[0]
    );
  }
}
class TokenClassificationPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => TokenClassificationPipelineType} */
Pipeline {
  /**
   * Create a new TokenClassificationPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {TokenClassificationPipelineCallback} */
  async _call(texts, {
    ignore_labels = ["O"]
  } = {}) {
    const isBatched = Array.isArray(texts);
    const model_inputs = this.tokenizer(isBatched ? texts : [texts], {
      padding: true,
      truncation: true
    });
    const outputs = await this.model(model_inputs);
    const logits = outputs.logits;
    const id2label = this.model.config.id2label;
    const toReturn = [];
    for (let i2 = 0; i2 < logits.dims[0]; ++i2) {
      const ids = model_inputs.input_ids[i2];
      const batch = logits[i2];
      const tokens = [];
      for (let j = 0; j < batch.dims[0]; ++j) {
        const tokenData = batch[j];
        const topScoreIndex = max(tokenData.data)[1];
        const entity = id2label ? id2label[topScoreIndex] : `LABEL_${topScoreIndex}`;
        if (ignore_labels.includes(entity)) {
          continue;
        }
        const word = this.tokenizer.decode([ids[j].item()], { skip_special_tokens: true });
        if (word === "") {
          continue;
        }
        const scores = softmax(tokenData.data);
        tokens.push({
          entity,
          score: scores[topScoreIndex],
          index: j,
          word,
          // TODO: null for now, but will add
          start: null,
          end: null
        });
      }
      toReturn.push(tokens);
    }
    return isBatched ? toReturn : toReturn[0];
  }
}
class QuestionAnsweringPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => QuestionAnsweringPipelineType} */
Pipeline {
  /**
   * Create a new QuestionAnsweringPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {QuestionAnsweringPipelineCallback} */
  async _call(question, context, {
    topk = 1
  } = {}) {
    const inputs = this.tokenizer(question, {
      text_pair: context,
      padding: true,
      truncation: true
    });
    const output2 = await this.model(inputs);
    const toReturn = [];
    for (let j = 0; j < output2.start_logits.dims[0]; ++j) {
      const ids = inputs.input_ids[j];
      const sepIndex = ids.indexOf(this.tokenizer.sep_token_id);
      const s1 = Array.from(softmax(output2.start_logits[j].data)).map((x, i2) => [x, i2]).filter((x) => x[1] > sepIndex);
      const e1 = Array.from(softmax(output2.end_logits[j].data)).map((x, i2) => [x, i2]).filter((x) => x[1] > sepIndex);
      const options = product(s1, e1).filter((x) => x[0][1] <= x[1][1]).map((x) => [x[0][1], x[1][1], x[0][0] * x[1][0]]).sort((a, b) => b[2] - a[2]);
      for (let k = 0; k < Math.min(options.length, topk); ++k) {
        const [start, end, score] = options[k];
        const answer_tokens = [...ids].slice(start, end + 1);
        const answer = this.tokenizer.decode(answer_tokens, {
          skip_special_tokens: true
        });
        toReturn.push({
          answer,
          score
        });
      }
    }
    return topk === 1 ? toReturn[0] : toReturn;
  }
}
class FillMaskPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => FillMaskPipelineType} */
Pipeline {
  /**
   * Create a new FillMaskPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {FillMaskPipelineCallback} */
  async _call(texts, {
    topk = 5
  } = {}) {
    const model_inputs = this.tokenizer(texts, {
      padding: true,
      truncation: true
    });
    const outputs = await this.model(model_inputs);
    const toReturn = [];
    for (let i2 = 0; i2 < model_inputs.input_ids.dims[0]; ++i2) {
      const ids = model_inputs.input_ids[i2];
      const mask_token_index = ids.indexOf(this.tokenizer.mask_token_id);
      if (mask_token_index === -1) {
        throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);
      }
      const logits = outputs.logits[i2];
      const itemLogits = logits[mask_token_index];
      const scores = getTopItems(softmax(itemLogits.data), topk);
      toReturn.push(scores.map((x) => {
        const sequence = [...ids];
        sequence[mask_token_index] = x[0];
        return {
          score: x[1],
          token: x[0],
          token_str: this.tokenizer.model.vocab[x[0]],
          sequence: this.tokenizer.decode(sequence, { skip_special_tokens: true })
        };
      }));
    }
    return Array.isArray(texts) ? toReturn : toReturn[0];
  }
}
class Text2TextGenerationPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => Text2TextGenerationPipelineType} */
Pipeline {
  /**
   * Create a new Text2TextGenerationPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
    /** @type {'generated_text'} */
    __publicField(this, "_key", "generated_text");
  }
  /** @type {Text2TextGenerationPipelineCallback} */
  async _call(texts, generate_kwargs = {}) {
    if (!Array.isArray(texts)) {
      texts = [texts];
    }
    if (this.model.config.prefix) {
      texts = texts.map((x) => this.model.config.prefix + x);
    }
    const task_specific_params = this.model.config.task_specific_params;
    if (task_specific_params && task_specific_params[this.task]) {
      if (task_specific_params[this.task].prefix) {
        texts = texts.map((x) => task_specific_params[this.task].prefix + x);
      }
    }
    const tokenizer = this.tokenizer;
    const tokenizer_options = {
      padding: true,
      truncation: true
    };
    let input_ids;
    if (this instanceof TranslationPipeline && "_build_translation_inputs" in tokenizer) {
      input_ids = tokenizer._build_translation_inputs(texts, tokenizer_options, generate_kwargs).input_ids;
    } else {
      input_ids = tokenizer(texts, tokenizer_options).input_ids;
    }
    const outputTokenIds = await this.model.generate(input_ids, generate_kwargs);
    return tokenizer.batch_decode(outputTokenIds, {
      skip_special_tokens: true
    }).map((text) => ({ [this._key]: text }));
  }
}
class SummarizationPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => SummarizationPipelineType} */
/** @type {any} */
Text2TextGenerationPipeline {
  /**
   * Create a new SummarizationPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
    /** @type {'summary_text'} */
    __publicField(this, "_key", "summary_text");
  }
}
class TranslationPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => TranslationPipelineType} */
/** @type {any} */
Text2TextGenerationPipeline {
  /**
   * Create a new TranslationPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
    /** @type {'translation_text'} */
    __publicField(this, "_key", "translation_text");
  }
}
function isChat(x) {
  return Array.isArray(x) && x.every((x2) => "role" in x2 && "content" in x2);
}
class TextGenerationPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => TextGenerationPipelineType} */
Pipeline {
  /**
   * Create a new TextGenerationPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {TextGenerationPipelineCallback} */
  async _call(texts, generate_kwargs = {}) {
    let isBatched = false;
    let isChatInput = false;
    let inputs;
    if (typeof texts === "string") {
      inputs = texts = [texts];
    } else if (Array.isArray(texts) && texts.every((x) => typeof x === "string")) {
      isBatched = true;
      inputs = /** @type {string[]} */
      texts;
    } else {
      if (isChat(texts)) {
        texts = [
          /** @type {Chat} */
          texts
        ];
      } else if (Array.isArray(texts) && texts.every(isChat)) {
        isBatched = true;
      } else {
        throw new Error("Input must be a string, an array of strings, a Chat, or an array of Chats");
      }
      isChatInput = true;
      inputs = /** @type {string[]} */
      /** @type {Chat[]} */
      texts.map(
        (x) => this.tokenizer.apply_chat_template(x, {
          tokenize: false,
          add_generation_prompt: true
        })
      );
    }
    const add_special_tokens = generate_kwargs.add_special_tokens ?? false;
    const return_full_text = isChatInput ? false : generate_kwargs.return_full_text ?? true;
    this.tokenizer.padding_side = "left";
    const { input_ids, attention_mask } = this.tokenizer(inputs, {
      add_special_tokens,
      padding: true,
      truncation: true
    });
    const outputTokenIds = await this.model.generate(input_ids, generate_kwargs, null, {
      inputs_attention_mask: attention_mask
    });
    let decoded = this.tokenizer.batch_decode(outputTokenIds, {
      skip_special_tokens: true
    });
    let promptLengths;
    if (!return_full_text && input_ids.dims.at(-1) > 0) {
      promptLengths = this.tokenizer.batch_decode(input_ids, {
        skip_special_tokens: true
      }).map((x) => x.length);
    }
    const toReturn = Array.from({ length: texts.length }, (_) => []);
    for (let i2 = 0; i2 < decoded.length; ++i2) {
      const textIndex = Math.floor(i2 / outputTokenIds.length * texts.length);
      if (promptLengths) {
        decoded[i2] = decoded[i2].slice(promptLengths[textIndex]);
      }
      toReturn[textIndex].push({
        generated_text: isChatInput ? [
          .../** @type {Chat[]} */
          texts[textIndex],
          { role: "assistant", content: decoded[i2] }
        ] : decoded[i2]
      });
    }
    return !isBatched && toReturn.length === 1 ? toReturn[0] : toReturn;
  }
}
class ZeroShotClassificationPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => ZeroShotClassificationPipelineType} */
Pipeline {
  /**
   * Create a new ZeroShotClassificationPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
    this.label2id = Object.fromEntries(
      Object.entries(
        /** @type {any} */
        this.model.config.label2id
      ).map(
        ([k, v]) => [k.toLowerCase(), v]
      )
    );
    this.entailment_id = this.label2id["entailment"];
    if (this.entailment_id === void 0) {
      console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id.");
      this.entailment_id = 2;
    }
    this.contradiction_id = this.label2id["contradiction"] ?? this.label2id["not_entailment"];
    if (this.contradiction_id === void 0) {
      console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id.");
      this.contradiction_id = 0;
    }
  }
  /** @type {ZeroShotClassificationPipelineCallback} */
  async _call(texts, candidate_labels, {
    hypothesis_template = "This example is {}.",
    multi_label = false
  } = {}) {
    const isBatched = Array.isArray(texts);
    if (!isBatched) {
      texts = [
        /** @type {string} */
        texts
      ];
    }
    if (!Array.isArray(candidate_labels)) {
      candidate_labels = [candidate_labels];
    }
    const hypotheses = candidate_labels.map(
      (x) => hypothesis_template.replace("{}", x)
    );
    const softmaxEach = multi_label || candidate_labels.length === 1;
    const toReturn = [];
    for (const premise of texts) {
      const entails_logits = [];
      for (const hypothesis of hypotheses) {
        const inputs = this.tokenizer(premise, {
          text_pair: hypothesis,
          padding: true,
          truncation: true
        });
        const outputs = await this.model(inputs);
        if (softmaxEach) {
          entails_logits.push([
            outputs.logits.data[this.contradiction_id],
            outputs.logits.data[this.entailment_id]
          ]);
        } else {
          entails_logits.push(outputs.logits.data[this.entailment_id]);
        }
      }
      const scores = softmaxEach ? entails_logits.map((x) => softmax(x)[1]) : softmax(entails_logits);
      const scores_sorted = scores.map((x, i2) => [x, i2]).sort((a, b) => b[0] - a[0]);
      toReturn.push({
        sequence: premise,
        labels: scores_sorted.map((x) => candidate_labels[x[1]]),
        scores: scores_sorted.map((x) => x[0])
      });
    }
    return isBatched ? toReturn : toReturn[0];
  }
}
class FeatureExtractionPipeline extends /** @type {new (options: TextPipelineConstructorArgs) => FeatureExtractionPipelineType} */
Pipeline {
  /**
   * Create a new FeatureExtractionPipeline.
   * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {FeatureExtractionPipelineCallback} */
  async _call(texts, {
    pooling = (
      /** @type {'none'} */
      "none"
    ),
    normalize: normalize2 = false,
    quantize = false,
    precision = (
      /** @type {'binary'} */
      "binary"
    )
  } = {}) {
    const model_inputs = this.tokenizer(texts, {
      padding: true,
      truncation: true
    });
    const outputs = await this.model(model_inputs);
    let result = outputs.last_hidden_state ?? outputs.logits ?? outputs.token_embeddings;
    if (pooling === "none") ;
    else if (pooling === "mean") {
      result = mean_pooling(result, model_inputs.attention_mask);
    } else if (pooling === "cls") {
      result = result.slice(null, 0);
    } else {
      throw Error(`Pooling method '${pooling}' not supported.`);
    }
    if (normalize2) {
      result = result.normalize(2, -1);
    }
    if (quantize) {
      result = quantize_embeddings(result, precision);
    }
    return result;
  }
}
class ImageFeatureExtractionPipeline extends /** @type {new (options: ImagePipelineConstructorArgs) => ImageFeatureExtractionPipelineType} */
Pipeline {
  /**
   * Create a new ImageFeatureExtractionPipeline.
   * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {ImageFeatureExtractionPipelineCallback} */
  async _call(images, {
    pool = null
  } = {}) {
    const preparedImages = await prepareImages(images);
    const { pixel_values } = await this.processor(preparedImages);
    const outputs = await this.model({ pixel_values });
    let result;
    if (pool) {
      if (!("pooler_output" in outputs)) {
        throw Error(`No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.`);
      }
      result = outputs.pooler_output;
    } else {
      result = outputs.last_hidden_state ?? outputs.logits ?? outputs.image_embeds;
    }
    return result;
  }
}
class AudioClassificationPipeline extends /** @type {new (options: AudioPipelineConstructorArgs) => AudioClassificationPipelineType} */
Pipeline {
  /**
   * Create a new AudioClassificationPipeline.
   * @param {AudioPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {AudioClassificationPipelineCallback} */
  async _call(audio, {
    topk = null
  } = {}) {
    const single = !Array.isArray(audio);
    const sampling_rate = this.processor.feature_extractor.config.sampling_rate;
    const preparedAudios = await prepareAudios(audio, sampling_rate);
    const id2label = this.model.config.id2label;
    const toReturn = [];
    for (const aud of preparedAudios) {
      const inputs = await this.processor(aud);
      const output2 = await this.model(inputs);
      const logits = output2.logits[0];
      const scores = getTopItems(softmax(logits.data), topk);
      const vals = scores.map((x) => ({
        label: (
          /** @type {string} */
          id2label[x[0]]
        ),
        score: (
          /** @type {number} */
          x[1]
        )
      }));
      if (topk === 1) {
        toReturn.push(...vals);
      } else {
        toReturn.push(vals);
      }
    }
    return !single || topk === 1 ? (
      /** @type {AudioClassificationOutput} */
      toReturn
    ) : (
      /** @type {AudioClassificationOutput[]} */
      toReturn[0]
    );
  }
}
class ZeroShotAudioClassificationPipeline extends /** @type {new (options: TextAudioPipelineConstructorArgs) => ZeroShotAudioClassificationPipelineType} */
Pipeline {
  /**
   * Create a new ZeroShotAudioClassificationPipeline.
   * @param {TextAudioPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {ZeroShotAudioClassificationPipelineCallback} */
  async _call(audio, candidate_labels, {
    hypothesis_template = "This is a sound of {}."
  } = {}) {
    const single = !Array.isArray(audio);
    if (single) {
      audio = [
        /** @type {AudioInput} */
        audio
      ];
    }
    const texts = candidate_labels.map(
      (x) => hypothesis_template.replace("{}", x)
    );
    const text_inputs = this.tokenizer(texts, {
      padding: true,
      truncation: true
    });
    const sampling_rate = this.processor.feature_extractor.config.sampling_rate;
    const preparedAudios = await prepareAudios(audio, sampling_rate);
    const toReturn = [];
    for (const aud of preparedAudios) {
      const audio_inputs = await this.processor(aud);
      const output2 = await this.model({ ...text_inputs, ...audio_inputs });
      const probs = softmax(output2.logits_per_audio.data);
      toReturn.push([...probs].map((x, i2) => ({
        score: x,
        label: candidate_labels[i2]
      })));
    }
    return single ? toReturn[0] : toReturn;
  }
}
class AutomaticSpeechRecognitionPipeline extends /** @type {new (options: TextAudioPipelineConstructorArgs) => AutomaticSpeechRecognitionPipelineType} */
Pipeline {
  /**
   * Create a new AutomaticSpeechRecognitionPipeline.
   * @param {TextAudioPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {AutomaticSpeechRecognitionPipelineCallback} */
  async _call(audio, kwargs = {}) {
    switch (this.model.config.model_type) {
      case "whisper":
        return this._call_whisper(audio, kwargs);
      case "wav2vec2":
      case "wav2vec2-bert":
      case "unispeech":
      case "unispeech-sat":
      case "hubert":
        return this._call_wav2vec2(audio, kwargs);
      default:
        throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`);
    }
  }
  /**
   * @type {AutomaticSpeechRecognitionPipelineCallback}
   * @private
   */
  async _call_wav2vec2(audio, kwargs = {}) {
    if (kwargs.language) {
      console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".');
    }
    if (kwargs.task) {
      console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');
    }
    const single = !Array.isArray(audio);
    if (single) {
      audio = [
        /** @type {AudioInput} */
        audio
      ];
    }
    const sampling_rate = this.processor.feature_extractor.config.sampling_rate;
    const preparedAudios = await prepareAudios(audio, sampling_rate);
    const toReturn = [];
    for (const aud of preparedAudios) {
      const inputs = await this.processor(aud);
      const output2 = await this.model(inputs);
      const logits = output2.logits[0];
      const predicted_ids = [];
      for (const item of logits) {
        predicted_ids.push(max(item.data)[1]);
      }
      const predicted_sentences = this.tokenizer.decode(predicted_ids);
      toReturn.push({ text: predicted_sentences });
    }
    return single ? toReturn[0] : toReturn;
  }
  /**
   * @type {AutomaticSpeechRecognitionPipelineCallback}
   * @private
   */
  async _call_whisper(audio, kwargs = {}) {
    const return_timestamps = kwargs.return_timestamps ?? false;
    const chunk_length_s = kwargs.chunk_length_s ?? 0;
    const chunk_callback = kwargs.chunk_callback ?? null;
    const force_full_sequences = kwargs.force_full_sequences ?? false;
    let stride_length_s = kwargs.stride_length_s ?? null;
    if (return_timestamps === "word") {
      kwargs["return_token_timestamps"] = true;
    }
    const language = pop(kwargs, "language", null);
    const task = pop(kwargs, "task", null);
    if (language || task || return_timestamps) {
      if (kwargs.forced_decoder_ids) {
        throw new Error("Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.");
      }
      const decoder_prompt_ids = this.tokenizer.get_decoder_prompt_ids({ language, task, no_timestamps: !return_timestamps });
      if (decoder_prompt_ids.length > 0) {
        kwargs.forced_decoder_ids = decoder_prompt_ids;
      }
    }
    const single = !Array.isArray(audio);
    if (single) {
      audio = [
        /** @type {AudioInput} */
        audio
      ];
    }
    const time_precision = this.processor.feature_extractor.config.chunk_length / this.model.config.max_source_positions;
    const hop_length = this.processor.feature_extractor.config.hop_length;
    const sampling_rate = this.processor.feature_extractor.config.sampling_rate;
    const preparedAudios = await prepareAudios(audio, sampling_rate);
    const toReturn = [];
    for (const aud of preparedAudios) {
      let chunks = [];
      if (chunk_length_s > 0) {
        if (stride_length_s === null) {
          stride_length_s = chunk_length_s / 6;
        } else if (chunk_length_s <= stride_length_s) {
          throw Error("`chunk_length_s` must be larger than `stride_length_s`.");
        }
        const window2 = sampling_rate * chunk_length_s;
        const stride = sampling_rate * stride_length_s;
        const jump = window2 - 2 * stride;
        let offset = 0;
        while (offset < aud.length) {
          const subarr = aud.subarray(offset, offset + window2);
          const feature = await this.processor(subarr);
          const isFirst = offset === 0;
          const isLast = offset + jump >= aud.length;
          chunks.push({
            stride: [
              subarr.length,
              isFirst ? 0 : stride,
              isLast ? 0 : stride
            ],
            input_features: feature.input_features,
            is_last: isLast
          });
          offset += jump;
        }
      } else {
        chunks = [{
          stride: [aud.length, 0, 0],
          input_features: (await this.processor(aud)).input_features,
          is_last: true
        }];
      }
      for (const chunk of chunks) {
        kwargs.num_frames = Math.floor(chunk.stride[0] / hop_length);
        const data = await this.model.generate(chunk.input_features, kwargs);
        if (return_timestamps === "word") {
          chunk.tokens = data.sequences[0];
          chunk.token_timestamps = data.token_timestamps.tolist()[0].map(
            (x) => round(x, 2)
          );
        } else {
          chunk.tokens = data[0];
        }
        chunk.stride = chunk.stride.map((x) => x / sampling_rate);
        if (chunk_callback !== null) {
          chunk_callback(chunk);
        }
      }
      const [full_text, optional] = this.tokenizer._decode_asr(chunks, {
        time_precision,
        return_timestamps,
        force_full_sequences
      });
      toReturn.push({ text: full_text, ...optional });
    }
    return single ? toReturn[0] : toReturn;
  }
}
class ImageToTextPipeline extends /** @type {new (options: TextImagePipelineConstructorArgs) => ImageToTextPipelineType} */
Pipeline {
  /**
   * Create a new ImageToTextPipeline.
   * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {ImageToTextPipelineCallback} */
  async _call(images, generate_kwargs = {}) {
    const isBatched = Array.isArray(images);
    const preparedImages = await prepareImages(images);
    const { pixel_values } = await this.processor(preparedImages);
    const toReturn = [];
    for (const batch of pixel_values) {
      batch.dims = [1, ...batch.dims];
      const output2 = await this.model.generate(batch, generate_kwargs);
      const decoded = this.tokenizer.batch_decode(output2, {
        skip_special_tokens: true
      }).map((x) => ({ generated_text: x.trim() }));
      toReturn.push(decoded);
    }
    return isBatched ? toReturn : toReturn[0];
  }
}
class ImageClassificationPipeline extends /** @type {new (options: ImagePipelineConstructorArgs) => ImageClassificationPipelineType} */
Pipeline {
  /**
   * Create a new ImageClassificationPipeline.
   * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {ImageClassificationPipelineCallback} */
  async _call(images, {
    topk = 1
  } = {}) {
    const isBatched = Array.isArray(images);
    const preparedImages = await prepareImages(images);
    const { pixel_values } = await this.processor(preparedImages);
    const output2 = await this.model({ pixel_values });
    const id2label = this.model.config.id2label;
    const toReturn = [];
    for (const batch of output2.logits) {
      const scores = getTopItems(softmax(batch.data), topk);
      const vals = scores.map((x) => ({
        label: id2label[x[0]],
        score: x[1]
      }));
      if (topk === 1) {
        toReturn.push(...vals);
      } else {
        toReturn.push(vals);
      }
    }
    return isBatched || topk === 1 ? (
      /** @type {ImageClassificationOutput} */
      toReturn
    ) : (
      /** @type {ImageClassificationOutput[]} */
      toReturn[0]
    );
  }
}
class ImageSegmentationPipeline extends /** @type {new (options: ImagePipelineConstructorArgs) => ImageSegmentationPipelineType} */
Pipeline {
  /**
   * Create a new ImageSegmentationPipeline.
   * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
    this.subtasks_mapping = {
      // Mapping of subtasks to their corresponding post-processing function names.
      panoptic: "post_process_panoptic_segmentation",
      instance: "post_process_instance_segmentation",
      semantic: "post_process_semantic_segmentation"
    };
  }
  /** @type {ImageSegmentationPipelineCallback} */
  async _call(images, {
    threshold: threshold2 = 0.5,
    mask_threshold = 0.5,
    overlap_mask_area_threshold = 0.8,
    label_ids_to_fuse = null,
    target_sizes = null,
    subtask = null
  } = {}) {
    const isBatched = Array.isArray(images);
    if (isBatched && images.length !== 1) {
      throw Error("Image segmentation pipeline currently only supports a batch size of 1.");
    }
    const preparedImages = await prepareImages(images);
    const imageSizes = preparedImages.map((x) => [x.height, x.width]);
    const { pixel_values, pixel_mask } = await this.processor(preparedImages);
    const output2 = await this.model({ pixel_values, pixel_mask });
    let fn2 = null;
    if (subtask !== null) {
      fn2 = this.subtasks_mapping[subtask];
    } else {
      for (let [task, func] of Object.entries(this.subtasks_mapping)) {
        if (func in this.processor.feature_extractor) {
          fn2 = this.processor.feature_extractor[func].bind(this.processor.feature_extractor);
          subtask = task;
          break;
        }
      }
    }
    const id2label = this.model.config.id2label;
    const annotation = [];
    if (subtask === "panoptic" || subtask === "instance") {
      const processed = fn2(
        output2,
        threshold2,
        mask_threshold,
        overlap_mask_area_threshold,
        label_ids_to_fuse,
        target_sizes ?? imageSizes
        // TODO FIX?
      )[0];
      const segmentation = processed.segmentation;
      for (const segment of processed.segments_info) {
        const maskData = new Uint8ClampedArray(segmentation.data.length);
        for (let i2 = 0; i2 < segmentation.data.length; ++i2) {
          if (segmentation.data[i2] === segment.id) {
            maskData[i2] = 255;
          }
        }
        const mask = new RawImage(maskData, segmentation.dims[1], segmentation.dims[0], 1);
        annotation.push({
          score: segment.score,
          label: id2label[segment.label_id],
          mask
        });
      }
    } else if (subtask === "semantic") {
      const { segmentation, labels } = fn2(output2, target_sizes ?? imageSizes)[0];
      for (const label of labels) {
        const maskData = new Uint8ClampedArray(segmentation.data.length);
        for (let i2 = 0; i2 < segmentation.data.length; ++i2) {
          if (segmentation.data[i2] === label) {
            maskData[i2] = 255;
          }
        }
        const mask = new RawImage(maskData, segmentation.dims[1], segmentation.dims[0], 1);
        annotation.push({
          score: null,
          label: id2label[label],
          mask
        });
      }
    } else {
      throw Error(`Subtask ${subtask} not supported.`);
    }
    return annotation;
  }
}
class ZeroShotImageClassificationPipeline extends /** @type {new (options: TextImagePipelineConstructorArgs) => ZeroShotImageClassificationPipelineType} */
Pipeline {
  /**
   * Create a new ZeroShotImageClassificationPipeline.
   * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {ZeroShotImageClassificationPipelineCallback} */
  async _call(images, candidate_labels, {
    hypothesis_template = "This is a photo of {}"
  } = {}) {
    const isBatched = Array.isArray(images);
    const preparedImages = await prepareImages(images);
    const texts = candidate_labels.map(
      (x) => hypothesis_template.replace("{}", x)
    );
    const text_inputs = this.tokenizer(texts, {
      padding: this.model.config.model_type === "siglip" ? "max_length" : true,
      truncation: true
    });
    const { pixel_values } = await this.processor(preparedImages);
    const output2 = await this.model({ ...text_inputs, pixel_values });
    const function_to_apply = this.model.config.model_type === "siglip" ? (batch) => batch.sigmoid().data : (batch) => softmax(batch.data);
    const toReturn = [];
    for (const batch of output2.logits_per_image) {
      const probs = function_to_apply(batch);
      const result = [...probs].map((x, i2) => ({
        score: x,
        label: candidate_labels[i2]
      }));
      result.sort((a, b) => b.score - a.score);
      toReturn.push(result);
    }
    return isBatched ? toReturn : toReturn[0];
  }
}
class ObjectDetectionPipeline extends /** @type {new (options: ImagePipelineConstructorArgs) => ObjectDetectionPipelineType} */
Pipeline {
  /**
   * Create a new ObjectDetectionPipeline.
   * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {ObjectDetectionPipelineCallback} */
  async _call(images, {
    threshold: threshold2 = 0.9,
    percentage = false
  } = {}) {
    const isBatched = Array.isArray(images);
    if (isBatched && images.length !== 1) {
      throw Error("Object detection pipeline currently only supports a batch size of 1.");
    }
    const preparedImages = await prepareImages(images);
    const imageSizes = percentage ? null : preparedImages.map((x) => [x.height, x.width]);
    const { pixel_values, pixel_mask } = await this.processor(preparedImages);
    const output2 = await this.model({ pixel_values, pixel_mask });
    const processed = this.processor.feature_extractor.post_process_object_detection(output2, threshold2, imageSizes);
    const id2label = this.model.config.id2label;
    const result = processed.map((batch) => batch.boxes.map((box, i2) => ({
      score: batch.scores[i2],
      label: id2label[batch.classes[i2]],
      box: get_bounding_box(box, !percentage)
    })));
    return isBatched ? result : result[0];
  }
}
class ZeroShotObjectDetectionPipeline extends /** @type {new (options: TextImagePipelineConstructorArgs) => ZeroShotObjectDetectionPipelineType} */
Pipeline {
  /**
   * Create a new ZeroShotObjectDetectionPipeline.
   * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {ZeroShotObjectDetectionPipelineCallback} */
  async _call(images, candidate_labels, {
    threshold: threshold2 = 0.1,
    topk = null,
    percentage = false
  } = {}) {
    const isBatched = Array.isArray(images);
    const preparedImages = await prepareImages(images);
    const text_inputs = this.tokenizer(candidate_labels, {
      padding: true,
      truncation: true
    });
    const model_inputs = await this.processor(preparedImages);
    const toReturn = [];
    for (let i2 = 0; i2 < preparedImages.length; ++i2) {
      const image = preparedImages[i2];
      const imageSize = percentage ? null : [[image.height, image.width]];
      const pixel_values = model_inputs.pixel_values[i2].unsqueeze_(0);
      const output2 = await this.model({ ...text_inputs, pixel_values });
      const processed = this.processor.feature_extractor.post_process_object_detection(output2, threshold2, imageSize, true)[0];
      let result = processed.boxes.map((box, i3) => ({
        score: processed.scores[i3],
        label: candidate_labels[processed.classes[i3]],
        box: get_bounding_box(box, !percentage)
      })).sort((a, b) => b.score - a.score);
      if (topk !== null) {
        result = result.slice(0, topk);
      }
      toReturn.push(result);
    }
    return isBatched ? toReturn : toReturn[0];
  }
}
class DocumentQuestionAnsweringPipeline extends /** @type {new (options: TextImagePipelineConstructorArgs) => DocumentQuestionAnsweringPipelineType} */
Pipeline {
  /**
   * Create a new DocumentQuestionAnsweringPipeline.
   * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {DocumentQuestionAnsweringPipelineCallback} */
  async _call(image, question, generate_kwargs = {}) {
    const preparedImage = (await prepareImages(image))[0];
    const { pixel_values } = await this.processor(preparedImage);
    const task_prompt = `<s_docvqa><s_question>${question}</s_question><s_answer>`;
    const decoder_input_ids = this.tokenizer(task_prompt, {
      add_special_tokens: false,
      padding: true,
      truncation: true
    }).input_ids;
    const output2 = await this.model.generate(
      pixel_values,
      {
        ...generate_kwargs,
        decoder_input_ids,
        max_length: this.model.config.decoder.max_position_embeddings
      }
    );
    const decoded = this.tokenizer.batch_decode(output2)[0];
    const match = decoded.match(/<s_answer>(.*?)<\/s_answer>/);
    let answer = null;
    if (match && match.length >= 2) {
      answer = match[1].trim();
    }
    return [{ answer }];
  }
}
class TextToAudioPipeline extends /** @type {new (options: TextToAudioPipelineConstructorArgs) => TextToAudioPipelineType} */
Pipeline {
  /**
   * Create a new TextToAudioPipeline.
   * @param {TextToAudioPipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
    __publicField(this, "DEFAULT_VOCODER_ID", "Xenova/speecht5_hifigan");
    this.vocoder = options.vocoder ?? null;
  }
  /** @type {TextToAudioPipelineCallback} */
  async _call(text_inputs, {
    speaker_embeddings = null
  } = {}) {
    if (this.processor) {
      return this._call_text_to_spectrogram(text_inputs, { speaker_embeddings });
    } else {
      return this._call_text_to_waveform(text_inputs);
    }
  }
  async _call_text_to_waveform(text_inputs) {
    const inputs = this.tokenizer(text_inputs, {
      padding: true,
      truncation: true
    });
    const { waveform } = await this.model(inputs);
    const sampling_rate = this.model.config.sampling_rate;
    return {
      audio: waveform.data,
      sampling_rate
    };
  }
  async _call_text_to_spectrogram(text_inputs, { speaker_embeddings }) {
    if (!this.vocoder) {
      console.log("No vocoder specified, using default HifiGan vocoder.");
      this.vocoder = await AutoModel.from_pretrained(this.DEFAULT_VOCODER_ID, { quantized: false });
    }
    if (typeof speaker_embeddings === "string" || speaker_embeddings instanceof URL) {
      speaker_embeddings = new Float32Array(
        await (await fetch(speaker_embeddings)).arrayBuffer()
      );
    }
    if (speaker_embeddings instanceof Float32Array) {
      speaker_embeddings = new Tensor(
        "float32",
        speaker_embeddings,
        [1, speaker_embeddings.length]
      );
    } else if (!(speaker_embeddings instanceof Tensor)) {
      throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");
    }
    const { input_ids } = this.tokenizer(text_inputs, {
      padding: true,
      truncation: true
    });
    const { waveform } = await this.model.generate_speech(input_ids, speaker_embeddings, { vocoder: this.vocoder });
    const sampling_rate = this.processor.feature_extractor.config.sampling_rate;
    return {
      audio: waveform.data,
      sampling_rate
    };
  }
}
class ImageToImagePipeline extends /** @type {new (options: ImagePipelineConstructorArgs) => ImageToImagePipelineType} */
Pipeline {
  /**
   * Create a new ImageToImagePipeline.
   * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {ImageToImagePipelineCallback} */
  async _call(images) {
    const preparedImages = await prepareImages(images);
    const inputs = await this.processor(preparedImages);
    const outputs = await this.model(inputs);
    const toReturn = [];
    for (const batch of outputs.reconstruction) {
      const output2 = batch.squeeze().clamp_(0, 1).mul_(255).round_().to("uint8");
      toReturn.push(RawImage.fromTensor(output2));
    }
    return toReturn.length > 1 ? toReturn : toReturn[0];
  }
}
class DepthEstimationPipeline extends /** @type {new (options: ImagePipelineConstructorArgs) => DepthEstimationPipelineType} */
Pipeline {
  /**
   * Create a new DepthEstimationPipeline.
   * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
   */
  constructor(options) {
    super(options);
  }
  /** @type {DepthEstimationPipelineCallback} */
  async _call(images) {
    const preparedImages = await prepareImages(images);
    const inputs = await this.processor(preparedImages);
    const { predicted_depth } = await this.model(inputs);
    const toReturn = [];
    for (let i2 = 0; i2 < preparedImages.length; ++i2) {
      const prediction = interpolate(predicted_depth[i2], preparedImages[i2].size.reverse(), "bilinear", false);
      const formatted = prediction.mul_(255 / max(prediction.data)[0]).to("uint8");
      toReturn.push({
        predicted_depth: predicted_depth[i2],
        depth: RawImage.fromTensor(formatted)
      });
    }
    return toReturn.length > 1 ? toReturn : toReturn[0];
  }
}
const SUPPORTED_TASKS = Object.freeze({
  "text-classification": {
    "tokenizer": AutoTokenizer,
    "pipeline": TextClassificationPipeline,
    "model": AutoModelForSequenceClassification,
    "default": {
      // TODO: replace with original
      // "model": "distilbert-base-uncased-finetuned-sst-2-english",
      "model": "Xenova/distilbert-base-uncased-finetuned-sst-2-english"
    },
    "type": "text"
  },
  "token-classification": {
    "tokenizer": AutoTokenizer,
    "pipeline": TokenClassificationPipeline,
    "model": AutoModelForTokenClassification,
    "default": {
      // TODO: replace with original
      // "model": "Davlan/bert-base-multilingual-cased-ner-hrl",
      "model": "Xenova/bert-base-multilingual-cased-ner-hrl"
    },
    "type": "text"
  },
  "question-answering": {
    "tokenizer": AutoTokenizer,
    "pipeline": QuestionAnsweringPipeline,
    "model": AutoModelForQuestionAnswering,
    "default": {
      // TODO: replace with original
      // "model": "distilbert-base-cased-distilled-squad",
      "model": "Xenova/distilbert-base-cased-distilled-squad"
    },
    "type": "text"
  },
  "fill-mask": {
    "tokenizer": AutoTokenizer,
    "pipeline": FillMaskPipeline,
    "model": AutoModelForMaskedLM,
    "default": {
      // TODO: replace with original
      // "model": "bert-base-uncased",
      "model": "Xenova/bert-base-uncased"
    },
    "type": "text"
  },
  "summarization": {
    "tokenizer": AutoTokenizer,
    "pipeline": SummarizationPipeline,
    "model": AutoModelForSeq2SeqLM,
    "default": {
      // TODO: replace with original
      // "model": "sshleifer/distilbart-cnn-6-6",
      "model": "Xenova/distilbart-cnn-6-6"
    },
    "type": "text"
  },
  "translation": {
    "tokenizer": AutoTokenizer,
    "pipeline": TranslationPipeline,
    "model": AutoModelForSeq2SeqLM,
    "default": {
      // TODO: replace with original
      // "model": "t5-small",
      "model": "Xenova/t5-small"
    },
    "type": "text"
  },
  "text2text-generation": {
    "tokenizer": AutoTokenizer,
    "pipeline": Text2TextGenerationPipeline,
    "model": AutoModelForSeq2SeqLM,
    "default": {
      // TODO: replace with original
      // "model": "google/flan-t5-small",
      "model": "Xenova/flan-t5-small"
    },
    "type": "text"
  },
  "text-generation": {
    "tokenizer": AutoTokenizer,
    "pipeline": TextGenerationPipeline,
    "model": AutoModelForCausalLM,
    "default": {
      // TODO: replace with original
      // "model": "gpt2",
      "model": "Xenova/gpt2"
    },
    "type": "text"
  },
  "zero-shot-classification": {
    "tokenizer": AutoTokenizer,
    "pipeline": ZeroShotClassificationPipeline,
    "model": AutoModelForSequenceClassification,
    "default": {
      // TODO: replace with original
      // "model": "typeform/distilbert-base-uncased-mnli",
      "model": "Xenova/distilbert-base-uncased-mnli"
    },
    "type": "text"
  },
  "audio-classification": {
    "pipeline": AudioClassificationPipeline,
    "model": AutoModelForAudioClassification,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "superb/wav2vec2-base-superb-ks",
      "model": "Xenova/wav2vec2-base-superb-ks"
    },
    "type": "audio"
  },
  "zero-shot-audio-classification": {
    "tokenizer": AutoTokenizer,
    "pipeline": ZeroShotAudioClassificationPipeline,
    "model": AutoModel,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "laion/clap-htsat-fused",
      "model": "Xenova/clap-htsat-unfused"
    },
    "type": "multimodal"
  },
  "automatic-speech-recognition": {
    "tokenizer": AutoTokenizer,
    "pipeline": AutomaticSpeechRecognitionPipeline,
    "model": [AutoModelForSpeechSeq2Seq, AutoModelForCTC],
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "openai/whisper-tiny.en",
      "model": "Xenova/whisper-tiny.en"
    },
    "type": "multimodal"
  },
  "text-to-audio": {
    "tokenizer": AutoTokenizer,
    "pipeline": TextToAudioPipeline,
    "model": [AutoModelForTextToWaveform, AutoModelForTextToSpectrogram],
    "processor": [
      AutoProcessor,
      /* Some don't use a processor */
      null
    ],
    "default": {
      // TODO: replace with original
      // "model": "microsoft/speecht5_tts",
      "model": "Xenova/speecht5_tts"
    },
    "type": "text"
  },
  "image-to-text": {
    "tokenizer": AutoTokenizer,
    "pipeline": ImageToTextPipeline,
    "model": AutoModelForVision2Seq,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "nlpconnect/vit-gpt2-image-captioning",
      "model": "Xenova/vit-gpt2-image-captioning"
    },
    "type": "multimodal"
  },
  "image-classification": {
    // no tokenizer
    "pipeline": ImageClassificationPipeline,
    "model": AutoModelForImageClassification,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "google/vit-base-patch16-224",
      "model": "Xenova/vit-base-patch16-224"
    },
    "type": "multimodal"
  },
  "image-segmentation": {
    // no tokenizer
    "pipeline": ImageSegmentationPipeline,
    "model": [AutoModelForImageSegmentation, AutoModelForSemanticSegmentation],
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "facebook/detr-resnet-50-panoptic",
      "model": "Xenova/detr-resnet-50-panoptic"
    },
    "type": "multimodal"
  },
  "zero-shot-image-classification": {
    "tokenizer": AutoTokenizer,
    "pipeline": ZeroShotImageClassificationPipeline,
    "model": AutoModel,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "openai/clip-vit-base-patch32",
      "model": "Xenova/clip-vit-base-patch32"
    },
    "type": "multimodal"
  },
  "object-detection": {
    // no tokenizer
    "pipeline": ObjectDetectionPipeline,
    "model": AutoModelForObjectDetection,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "facebook/detr-resnet-50",
      "model": "Xenova/detr-resnet-50"
    },
    "type": "multimodal"
  },
  "zero-shot-object-detection": {
    "tokenizer": AutoTokenizer,
    "pipeline": ZeroShotObjectDetectionPipeline,
    "model": AutoModelForZeroShotObjectDetection,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "google/owlvit-base-patch32",
      "model": "Xenova/owlvit-base-patch32"
    },
    "type": "multimodal"
  },
  "document-question-answering": {
    "tokenizer": AutoTokenizer,
    "pipeline": DocumentQuestionAnsweringPipeline,
    "model": AutoModelForDocumentQuestionAnswering,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "naver-clova-ix/donut-base-finetuned-docvqa",
      "model": "Xenova/donut-base-finetuned-docvqa"
    },
    "type": "multimodal"
  },
  "image-to-image": {
    // no tokenizer
    "pipeline": ImageToImagePipeline,
    "model": AutoModelForImageToImage,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "caidas/swin2SR-classical-sr-x2-64",
      "model": "Xenova/swin2SR-classical-sr-x2-64"
    },
    "type": "image"
  },
  "depth-estimation": {
    // no tokenizer
    "pipeline": DepthEstimationPipeline,
    "model": AutoModelForDepthEstimation,
    "processor": AutoProcessor,
    "default": {
      // TODO: replace with original
      // "model": "Intel/dpt-large",
      "model": "Xenova/dpt-large"
    },
    "type": "image"
  },
  // This task serves as a useful interface for dealing with sentence-transformers (https://huggingface.co/sentence-transformers).
  "feature-extraction": {
    "tokenizer": AutoTokenizer,
    "pipeline": FeatureExtractionPipeline,
    "model": AutoModel,
    "default": {
      // TODO: replace with original
      // "model": "sentence-transformers/all-MiniLM-L6-v2",
      "model": "Xenova/all-MiniLM-L6-v2"
    },
    "type": "text"
  },
  "image-feature-extraction": {
    "processor": AutoProcessor,
    "pipeline": ImageFeatureExtractionPipeline,
    "model": [AutoModelForImageFeatureExtraction, AutoModel],
    "default": {
      // TODO: replace with original
      // "model": "google/vit-base-patch16-224",
      "model": "Xenova/vit-base-patch16-224-in21k"
    },
    "type": "image"
  }
});
const TASK_ALIASES = Object.freeze({
  "sentiment-analysis": "text-classification",
  "ner": "token-classification",
  // "vqa": "visual-question-answering", // TODO: Add
  "asr": "automatic-speech-recognition",
  "text-to-speech": "text-to-audio",
  // Add for backwards compatibility
  "embeddings": "feature-extraction"
});
async function pipeline(task, model = null, {
  quantized = true,
  progress_callback = null,
  config: config2 = null,
  cache_dir = null,
  local_files_only = false,
  revision = "main",
  model_file_name = null
} = {}) {
  task = TASK_ALIASES[task] ?? task;
  const pipelineInfo = SUPPORTED_TASKS[task.split("_", 1)[0]];
  if (!pipelineInfo) {
    throw Error(`Unsupported pipeline: ${task}. Must be one of [${Object.keys(SUPPORTED_TASKS)}]`);
  }
  if (!model) {
    model = pipelineInfo.default.model;
    console.log(`No model specified. Using default model: "${model}".`);
  }
  const pretrainedOptions = {
    quantized,
    progress_callback,
    config: config2,
    cache_dir,
    local_files_only,
    revision,
    model_file_name
  };
  const classes = /* @__PURE__ */ new Map([
    ["tokenizer", pipelineInfo.tokenizer],
    ["model", pipelineInfo.model],
    ["processor", pipelineInfo.processor]
  ]);
  const results = await loadItems(classes, model, pretrainedOptions);
  results.task = task;
  dispatchCallback(progress_callback, {
    "status": "ready",
    "task": task,
    "model": model
  });
  const pipelineClass = pipelineInfo.pipeline;
  return new pipelineClass(results);
}
async function loadItems(mapping, model, pretrainedOptions) {
  const result = /* @__PURE__ */ Object.create(null);
  const promises = [];
  for (let [name2, cls] of mapping.entries()) {
    if (!cls) continue;
    let promise;
    if (Array.isArray(cls)) {
      promise = new Promise(async (resolve2, reject) => {
        let e;
        for (let c of cls) {
          if (c === null) {
            resolve2(null);
            return;
          }
          try {
            resolve2(await c.from_pretrained(model, pretrainedOptions));
            return;
          } catch (err) {
            e = err;
          }
        }
        reject(e);
      });
    } else {
      promise = cls.from_pretrained(model, pretrainedOptions);
    }
    result[name2] = promise;
    promises.push(promise);
  }
  await Promise.all(promises);
  for (let [name2, promise] of Object.entries(result)) {
    result[name2] = await promise;
  }
  return result;
}
class MemoryBank {
  constructor(folderPath) {
    __publicField(this, "client");
    __publicField(this, "collection", null);
    __publicField(this, "embedder", null);
    __publicField(this, "isInitialized", false);
    if (!fs$4.existsSync(folderPath)) {
      fs$4.mkdirSync(folderPath, { recursive: true });
    }
    this.client = new ChromaClient({
      path: path$4.join(folderPath, "chroma")
    });
  }
  async initialize() {
    if (this.isInitialized) return;
    try {
      this.collection = await this.client.getOrCreateCollection({
        name: "comet_memory",
        metadata: { description: "Comet Search memory bank" }
      });
      this.embedder = await pipeline(
        "feature-extraction",
        "Xenova/all-MiniLM-L6-v2",
        { quantized: true }
        // Use quantized model for faster loading
      );
      this.isInitialized = true;
      console.log("Memory bank initialized successfully");
    } catch (error2) {
      console.error("Failed to initialize memory bank:", error2);
      throw error2;
    }
  }
  async generateEmbedding(text) {
    if (!this.embedder) {
      throw new Error("Embedder not initialized");
    }
    const output2 = await this.embedder(text, { pooling: "mean", normalize: true });
    return Array.from(output2.data);
  }
  async add(type2, content2, metadata2 = {}) {
    if (!this.collection || !this.isInitialized) {
      throw new Error("Memory bank not initialized");
    }
    const id2 = `${type2}_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const timestamp = Date.now();
    try {
      const embedding = await this.generateEmbedding(content2);
      await this.collection.add({
        ids: [id2],
        embeddings: [embedding],
        documents: [content2],
        metadatas: [{
          type: type2,
          timestamp,
          ...metadata2
        }]
      });
      return id2;
    } catch (error2) {
      console.error("Failed to add memory:", error2);
      throw error2;
    }
  }
  async search(query, limit2 = 5) {
    var _a2, _b, _c, _d;
    if (!this.collection || !this.isInitialized) {
      throw new Error("Memory bank not initialized");
    }
    try {
      const embedding = await this.generateEmbedding(query);
      const results = await this.collection.query({
        queryEmbeddings: [embedding],
        nResults: limit2
      });
      const items2 = [];
      if (results.ids[0]) {
        for (let i2 = 0; i2 < results.ids[0].length; i2++) {
          items2.push({
            id: results.ids[0][i2],
            content: ((_a2 = results.documents[0]) == null ? void 0 : _a2[i2]) || "",
            score: ((_c = (_b = results.distances) == null ? void 0 : _b[0]) == null ? void 0 : _c[i2]) || 0,
            metadata: ((_d = results.metadatas[0]) == null ? void 0 : _d[i2]) || {}
          });
        }
      }
      return items2;
    } catch (error2) {
      console.error("Failed to search memory:", error2);
      throw error2;
    }
  }
  async getRecent(limit2 = 10) {
    if (!this.collection || !this.isInitialized) {
      throw new Error("Memory bank not initialized");
    }
    try {
      const results = await this.collection.get({
        limit: limit2,
        include: [IncludeEnum.Documents, IncludeEnum.Metadatas]
      });
      const items2 = results.ids.map((id2, index2) => {
        var _a2, _b;
        return {
          id: id2,
          content: results.documents[index2] || "",
          timestamp: Number(((_a2 = results.metadatas[index2]) == null ? void 0 : _a2.timestamp) || 0),
          type: String(((_b = results.metadatas[index2]) == null ? void 0 : _b.type) || "unknown")
        };
      });
      return items2.sort((a, b) => b.timestamp - a.timestamp);
    } catch (error2) {
      console.error("Failed to get recent memories:", error2);
      throw error2;
    }
  }
  async delete(id2) {
    if (!this.collection || !this.isInitialized) {
      throw new Error("Memory bank not initialized");
    }
    try {
      await this.collection.delete({ ids: [id2] });
      return true;
    } catch (error2) {
      console.error("Failed to delete memory:", error2);
      return false;
    }
  }
  async clear() {
    if (!this.collection || !this.isInitialized) {
      throw new Error("Memory bank not initialized");
    }
    try {
      await this.client.deleteCollection({ name: "comet_memory" });
      this.collection = await this.client.getOrCreateCollection({
        name: "comet_memory",
        metadata: { description: "Comet Search memory bank" }
      });
      return true;
    } catch (error2) {
      console.error("Failed to clear memory:", error2);
      return false;
    }
  }
  async getStats() {
    if (!this.collection || !this.isInitialized) {
      throw new Error("Memory bank not initialized");
    }
    try {
      const results = await this.collection.get({
        include: [IncludeEnum.Metadatas]
      });
      let conversations = 0;
      let searches = 0;
      for (const metadata2 of results.metadatas) {
        if ((metadata2 == null ? void 0 : metadata2.type) === "conversation") conversations++;
        if ((metadata2 == null ? void 0 : metadata2.type) === "search") searches++;
      }
      return {
        total: results.ids.length,
        conversations,
        searches
      };
    } catch (error2) {
      console.error("Failed to get memory stats:", error2);
      return { total: 0, conversations: 0, searches: 0 };
    }
  }
  async close() {
    this.isInitialized = false;
    this.collection = null;
    this.embedder = null;
  }
}
const __filename$1 = fileURLToPath(import.meta.url);
const __dirname$1 = path$4.dirname(__filename$1);
const store = new ElectronStore({
  defaults: {
    downloadFolder: path$4.join(app$1.getPath("downloads"), "comet-search"),
    memoryBankFolder: path$4.join(app$1.getPath("userData"), "memory-bank"),
    memoryEnabled: true,
    memoryMaxItems: 1e3,
    braveApiKey: "",
    kimiApiKey: "",
    providerMode: "hybrid",
    searchMode: "quick"
  }
});
let browser = null;
let memory = null;
async function initializeServices() {
  browser = new PlaywrightBrowser();
  const memoryFolder = store.get("memoryBankFolder");
  memory = new MemoryBank(memoryFolder);
  await memory.initialize();
}
function createWindow() {
  const mainWindow = new BrowserWindow({
    width: 1400,
    height: 900,
    minWidth: 900,
    minHeight: 600,
    webPreferences: {
      preload: path$4.join(__dirname$1, "preload.js"),
      contextIsolation: true,
      nodeIntegration: false,
      sandbox: false
    },
    titleBarStyle: "hiddenInset",
    show: false
  });
  if (process.env.VITE_DEV_SERVER_URL) {
    mainWindow.loadURL(process.env.VITE_DEV_SERVER_URL);
    mainWindow.webContents.openDevTools();
  } else {
    mainWindow.loadFile(path$4.join(__dirname$1, "../dist/index.html"));
  }
  mainWindow.once("ready-to-show", () => {
    mainWindow.show();
  });
  return mainWindow;
}
app$1.whenReady().then(async () => {
  await initializeServices();
  createWindow();
  app$1.on("activate", () => {
    if (BrowserWindow.getAllWindows().length === 0) {
      createWindow();
    }
  });
});
app$1.on("window-all-closed", async () => {
  if (browser) {
    await browser.close();
  }
  if (memory) {
    await memory.close();
  }
  if (process.platform !== "darwin") {
    app$1.quit();
  }
});
ipcMain$1.handle("settings:get", () => {
  return {
    downloadFolder: store.get("downloadFolder"),
    memoryBankFolder: store.get("memoryBankFolder"),
    memoryEnabled: store.get("memoryEnabled"),
    memoryMaxItems: store.get("memoryMaxItems"),
    braveApiKey: store.get("braveApiKey"),
    kimiApiKey: store.get("kimiApiKey"),
    providerMode: store.get("providerMode"),
    searchMode: store.get("searchMode")
  };
});
ipcMain$1.handle("settings:set", (_, key, value) => {
  store.set(key, value);
  return true;
});
ipcMain$1.handle("settings:selectDownloadFolder", async () => {
  const result = await dialog.showOpenDialog({
    properties: ["openDirectory"],
    defaultPath: store.get("downloadFolder")
  });
  if (!result.canceled && result.filePaths.length > 0) {
    const folder = result.filePaths[0];
    store.set("downloadFolder", folder);
    return folder;
  }
  return null;
});
ipcMain$1.handle("settings:selectMemoryBankFolder", async () => {
  const result = await dialog.showOpenDialog({
    properties: ["openDirectory"],
    defaultPath: store.get("memoryBankFolder")
  });
  if (!result.canceled && result.filePaths.length > 0) {
    const folder = result.filePaths[0];
    store.set("memoryBankFolder", folder);
    if (memory) {
      await memory.close();
    }
    memory = new MemoryBank(folder);
    await memory.initialize();
    return folder;
  }
  return null;
});
ipcMain$1.handle("browser:navigate", async (_, url2) => {
  if (!browser) throw new Error("Browser not initialized");
  return await browser.navigate(url2);
});
ipcMain$1.handle("browser:click", async (_, selector) => {
  if (!browser) throw new Error("Browser not initialized");
  return await browser.click(selector);
});
ipcMain$1.handle("browser:type", async (_, selector, text) => {
  if (!browser) throw new Error("Browser not initialized");
  return await browser.type(selector, text);
});
ipcMain$1.handle("browser:getText", async (_, selector) => {
  if (!browser) throw new Error("Browser not initialized");
  return await browser.getText(selector);
});
ipcMain$1.handle("browser:getHtml", async () => {
  if (!browser) throw new Error("Browser not initialized");
  return await browser.getHtml();
});
ipcMain$1.handle("browser:screenshot", async (_, options) => {
  if (!browser) throw new Error("Browser not initialized");
  const downloadFolder = store.get("downloadFolder");
  return await browser.screenshot({
    ...options,
    path: (options == null ? void 0 : options.path) ? path$4.join(downloadFolder, options.path) : void 0
  });
});
ipcMain$1.handle("browser:scroll", async (_, direction) => {
  if (!browser) throw new Error("Browser not initialized");
  return await browser.scroll(direction);
});
ipcMain$1.handle("browser:findElements", async (_, selector) => {
  if (!browser) throw new Error("Browser not initialized");
  return await browser.findElements(selector);
});
ipcMain$1.handle("browser:evaluate", async (_, script) => {
  if (!browser) throw new Error("Browser not initialized");
  return await browser.evaluate(script);
});
ipcMain$1.handle("browser:close", async () => {
  if (browser) {
    await browser.close();
    browser = null;
  }
  return true;
});
ipcMain$1.handle("browser:reopen", async () => {
  if (browser) {
    await browser.close();
  }
  browser = new PlaywrightBrowser();
  return true;
});
ipcMain$1.handle("memory:add", async (_, type2, content2, metadata2) => {
  if (!memory) throw new Error("Memory not initialized");
  if (!store.get("memoryEnabled")) return null;
  return await memory.add(type2, content2, metadata2);
});
ipcMain$1.handle("memory:search", async (_, query, limit2) => {
  if (!memory) throw new Error("Memory not initialized");
  if (!store.get("memoryEnabled")) return [];
  return await memory.search(query, limit2);
});
ipcMain$1.handle("memory:getRecent", async (_, limit2) => {
  if (!memory) throw new Error("Memory not initialized");
  return await memory.getRecent(limit2);
});
ipcMain$1.handle("memory:delete", async (_, id2) => {
  if (!memory) throw new Error("Memory not initialized");
  return await memory.delete(id2);
});
ipcMain$1.handle("memory:clear", async () => {
  if (!memory) throw new Error("Memory not initialized");
  return await memory.clear();
});
ipcMain$1.handle("memory:getStats", async () => {
  if (!memory) throw new Error("Memory not initialized");
  return await memory.getStats();
});
ipcMain$1.handle("shell:openExternal", async (_, url2) => {
  await shell$1.openExternal(url2);
});
ipcMain$1.handle("download:getFolder", () => {
  return store.get("downloadFolder");
});
//# sourceMappingURL=main.js.map
